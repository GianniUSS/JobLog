from __future__ import annotations

import atexit
import base64
import csv
import hashlib
import io
import json
import logging
import os
import random
import secrets
import sqlite3
import time
import re
from decimal import Decimal
from copy import deepcopy
from datetime import date, datetime, timedelta, timezone
from functools import wraps
from pathlib import Path


def format_time_value(value) -> Optional[str]:
    """Formatta un valore tempo (timedelta, datetime.time o stringa) nel formato HH:MM."""
    if value is None:
        return None
    if isinstance(value, timedelta):
        # MySQL TIME restituisce timedelta
        total_seconds = int(value.total_seconds())
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        return f"{hours:02d}:{minutes:02d}"
    if hasattr(value, 'strftime'):
        # datetime.time object
        return value.strftime("%H:%M")
    # Stringa - assicuriamo formato HH:MM
    s = str(value)
    if len(s) >= 5:
        # Potrebbe essere "6:00:00" o "06:00:00" o "06:00"
        parts = s.split(':')
        if len(parts) >= 2:
            return f"{int(parts[0]):02d}:{int(parts[1]):02d}"
    return s[:5] if len(s) >= 5 else s


# Cache per geocoding (evita richieste ripetute a Nominatim)
_geocode_cache: Dict[str, Optional[Tuple[float, float]]] = {}
_geocode_last_request = 0.0  # Timestamp ultima richiesta (rate limiting)


def geocode_address(address: str) -> Optional[Tuple[float, float]]:
    """
    Converte un indirizzo in coordinate GPS usando Nominatim (OpenStreetMap).
    Ritorna (latitude, longitude) o None se non trovato.
    NON fa fallback a indirizzi approssimati per evitare errori di timbratura.
    """
    global _geocode_last_request
    
    if not address or not address.strip():
        return None
    
    # Normalizza l'indirizzo per la cache
    cache_key = address.strip().lower()
    if cache_key in _geocode_cache:
        return _geocode_cache[cache_key]
    
    import time as time_module
    import urllib.request
    import urllib.parse
    import urllib.error
    
    # Rate limiting: aspetta almeno 1 secondo tra le richieste
    elapsed = time_module.time() - _geocode_last_request
    if elapsed < 1.0:
        time_module.sleep(1.0 - elapsed)
    
    try:
        params = urllib.parse.urlencode({
            'q': address,
            'format': 'json',
            'limit': 1,
            'addressdetails': 0,
            'countrycodes': 'it'
        })
        url = f"https://nominatim.openstreetmap.org/search?{params}"
        
        req = urllib.request.Request(url, headers={
            'User-Agent': 'JobLogApp/1.0 (geocoding for work shifts)'
        })
        
        _geocode_last_request = time_module.time()
        
        with urllib.request.urlopen(req, timeout=10) as response:
            data = json.loads(response.read().decode('utf-8'))
            
            if data and len(data) > 0:
                lat = float(data[0]['lat'])
                lon = float(data[0]['lon'])
                result = (lat, lon)
                _geocode_cache[cache_key] = result
                logging.getLogger(__name__).info(f"Geocoding OK: '{address}' -> {result}")
                return result
    except Exception as e:
        logging.getLogger(__name__).warning(f"Geocoding fallito per '{address}': {e}")
    
    _geocode_cache[cache_key] = None
    logging.getLogger(__name__).warning(f"Geocoding: nessun risultato per '{address}'")
    return None


from threading import Event, Thread
from typing import Any, Dict, Iterable, List, Mapping, Optional, Sequence, Set, Tuple, TypeAlias, cast

try:
    import pymysql  # type: ignore[import]
    from pymysql import err as pymysql_err  # type: ignore[import]
    from pymysql.cursors import DictCursor  # type: ignore[import]
except ImportError:  # pragma: no cover - fallback when MySQL client not installed
    pymysql = None
    pymysql_err = None
    DictCursor = None

from flask import Flask, abort, flash, g, jsonify, redirect, render_template, request, send_file, send_from_directory, session, url_for
from flask_session import Session
from flask.typing import ResponseReturnValue
from openpyxl import Workbook
from openpyxl.styles import Alignment, Border, Font, PatternFill, Side
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet
from pywebpush import WebPushException, webpush
import qrcode
from rentman_client import (
    RentmanAPIError,
    RentmanAuthError,
    RentmanClient,
    RentmanError,
    RentmanNotFound,
    MAX_LIMIT,
)


SECRET_FILE = Path(__file__).with_name('.flask_secret')


def _load_or_create_secret_key() -> str:
    override = os.environ.get('FLASK_SECRET_KEY')
    if override:
        return override
    if SECRET_FILE.exists():
        try:
            value = SECRET_FILE.read_text(encoding='utf-8').strip()
            if value:
                return value
        except OSError:
            pass
    generated = secrets.token_hex(32)
    try:
        SECRET_FILE.write_text(generated, encoding='utf-8')
    except OSError:
        logging.getLogger(__name__).warning("Impossibile salvare la chiave segreta su %s", SECRET_FILE)
    return generated


app = Flask(__name__)
app.secret_key = _load_or_create_secret_key()
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(hours=24)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50 MB max upload

PERSISTENT_SESSION_COOKIE_NAME = os.environ.get('JOBLOG_PERSISTENT_COOKIE_NAME', 'joblog_auth')
PERSISTENT_SESSION_MAX_AGE = int(os.environ.get('JOBLOG_PERSISTENT_SESSION_MAX_AGE', str(30 * 86400)))
app.config['PERSISTENT_SESSION_COOKIE_NAME'] = PERSISTENT_SESSION_COOKIE_NAME
app.config['PERSISTENT_SESSION_MAX_AGE'] = PERSISTENT_SESSION_MAX_AGE

SESSION_STORAGE = Path(__file__).with_name('.flask_session')
SESSION_STORAGE.mkdir(parents=True, exist_ok=True)
app.config['SESSION_TYPE'] = 'filesystem'
app.config['SESSION_FILE_DIR'] = str(SESSION_STORAGE)
app.config['SESSION_FILE_THRESHOLD'] = 1024
app.config['SESSION_PERMANENT'] = True
session_manager = Session(app)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
    force=True,
)
app.logger.handlers = logging.getLogger().handlers
app.logger.setLevel(logging.INFO)
app.logger.propagate = True
DATABASE = Path(__file__).with_name("joblog.db")
PROJECTS_FILE = Path(__file__).with_name("projects.json")
CONFIG_FILE = Path(__file__).with_name("config.json")
USERS_FILE = Path(__file__).with_name("users.json")
DEMO_PROJECT_CODE = "1001"

# ═══════════════════════════════════════════════════════════════════
# DATE SIMULATION FOR TESTING
# ═══════════════════════════════════════════════════════════════════
# Per simulare una data diversa, imposta SIMULATED_DATE nel formato "YYYY-MM-DD"
# Es: SIMULATED_DATE = "2026-01-10"
# Per usare la data reale, lascia None
SIMULATED_DATE: Optional[str] = None


def get_simulated_now() -> datetime:
    """
    Ritorna datetime.now() o la data simulata se impostata.
    Usa questa funzione invece di datetime.now() per testare date diverse.
    """
    if SIMULATED_DATE:
        try:
            simulated = datetime.strptime(SIMULATED_DATE, "%Y-%m-%d")
            # Mantieni l'ora corrente ma con la data simulata
            now = datetime.now()
            return simulated.replace(hour=now.hour, minute=now.minute, second=now.second, microsecond=now.microsecond)
        except ValueError:
            app.logger.warning(f"SIMULATED_DATE '{SIMULATED_DATE}' non valida, uso data reale")
    return datetime.now()


def get_simulated_today() -> date:
    """Ritorna la data di oggi o la data simulata se impostata."""
    return get_simulated_now().date()


def static_version(filename: str) -> str:
    """Return cache-busted static URL using file mtime as version."""
    safe_path = filename.lstrip("/")
    static_folder = app.static_folder or os.path.join(app.root_path, "static")
    file_path = os.path.join(static_folder, safe_path)
    try:
        version = int(os.path.getmtime(file_path))
    except (OSError, TypeError):
        version = int(time.time())
    return url_for("static", filename=safe_path, v=version)


app.jinja_env.globals["static_version"] = static_version


@app.context_processor
def inject_company_logo():
    """Inietta il logo aziendale in tutti i template."""
    logo_path = None
    try:
        db = get_db()
        cursor = db.execute("SELECT logo_path FROM company_settings WHERE id = 1")
        row = cursor.fetchone()
        if row:
            if isinstance(row, dict):
                logo_path = row.get('logo_path')
            else:
                logo_path = row[0]
    except Exception:
        pass
    return {'company_logo': logo_path}


MOCK_PROJECTS: Dict[str, Dict[str, Any]] = {
    "1001": {
        "project_code": "1001",
        "project_name": "Allestimento Stand Futuro",
        "activities": [
            {"id": "PREP", "label": "Preparazione materiali"},
            {"id": "MONT", "label": "Montaggio struttura"},
            {"id": "LGT", "label": "Illuminazione e cablaggi"},
            {"id": "FIN", "label": "Finiture e collaudo"},
        ],
        "team": [
            {"key": "anna", "name": "Anna Rossi"},
            {"key": "luca", "name": "Luca Bianchi"},
            {"key": "mario", "name": "Mario Verdi"},
            {"key": "giulia", "name": "Giulia Neri"},
        ],
    },
    "1002": {
        "project_code": "1002",
        "project_name": "Evento Corporate Milano",
        "activities": [
            {"id": "LOAD", "label": "Carico materiali"},
            {"id": "STAGE", "label": "Montaggio palco"},
            {"id": "AUDIO", "label": "Audio & video"},
            {"id": "DECOR", "label": "Decorazioni"},
        ],
        "team": [
            {"key": "federico", "name": "Federico Cattaneo"},
            {"key": "ilaria", "name": "Ilaria Riva"},
            {"key": "paolo", "name": "Paolo Gallo"},
            {"key": "roberta", "name": "Roberta Colombo"},
        ],
    },
}


@app.get("/sw.js")
def service_worker() -> ResponseReturnValue:
    response = app.send_static_file("sw.js")
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
    return response


class RowMapping(dict):
    """Row helper that mimics sqlite3.Row access for dict-based cursors."""

    __slots__ = ("_ordered",)

    def __init__(self, data: Dict[str, Any], columns: Sequence[str]):
        super().__init__(data)
        self._ordered = [data.get(col) for col in columns]

    def __getitem__(self, key: Any) -> Any:  # type: ignore[override]
        if isinstance(key, int):
            return self._ordered[key]
        return super().__getitem__(key)


class CursorWrapper:
    """Minimal cursor wrapper to align PyMySQL cursor behaviour with sqlite3."""

    __slots__ = ("_cursor", "_columns", "_closed")

    def __init__(self, cursor):
        self._cursor = cursor
        self._columns = [col[0] for col in cursor.description] if cursor.description else []
        self._closed = False

    @property
    def description(self):
        return self._cursor.description

    @property
    def lastrowid(self):
        return self._cursor.lastrowid

    def fetchone(self):
        row = self._cursor.fetchone()
        if row is None:
            return None
        if isinstance(row, dict):
            return RowMapping(row, self._columns)
        return row

    def fetchall(self):
        rows = self._cursor.fetchall()
        try:
            if rows and isinstance(rows[0], dict):
                mapped = [RowMapping(row, self._columns) for row in rows]
            else:
                mapped = rows
        finally:
            self.close()
        return mapped

    def __iter__(self):
        for row in self._cursor:
            if isinstance(row, dict):
                yield RowMapping(row, self._columns)
            else:
                yield row
        self.close()

    def close(self):
        if not self._closed:
            try:
                self._cursor.close()
            finally:
                self._closed = True

    def __del__(self):  # pragma: no cover - best effort cleanup
        self.close()


class MySQLConnection:
    """Adapter to expose a sqlite-like interface backed by PyMySQL."""

    def __init__(self, settings: Dict[str, Any]):
        if pymysql is None or DictCursor is None:
              raise RuntimeError("PyMySQL non è installato. Esegui 'pip install PyMySQL' per usare il backend MySQL.")
        self._settings = settings
        self._conn = self._connect_with_autocreate()

    # Internal helpers -------------------------------------------------
    def _base_connect(self, include_db: bool = True):
        kwargs = {
            "host": self._settings["host"],
            "port": int(self._settings.get("port", 3306)),
            "user": self._settings["user"],
            "password": self._settings["password"],
            "charset": "utf8mb4",
            "cursorclass": DictCursor,
            "autocommit": False,
        }
        if include_db:
            kwargs["database"] = self._settings["name"]
        return pymysql.connect(**kwargs)  # type: ignore[union-attr]

    def _connect_with_autocreate(self):
        try:
                return self._base_connect(include_db=True)
        except Exception as exc:  # pragma: no cover - MySQL specific bootstrap
            if pymysql_err is not None and isinstance(exc, pymysql_err.OperationalError):
                err_code = exc.args[0] if exc.args else None
                if err_code == 1049:  # Unknown database
                    bootstrap = self._base_connect(include_db=False)
                    try:
                        with bootstrap.cursor() as cursor:
                            cursor.execute(
                                f"CREATE DATABASE IF NOT EXISTS `{self._settings['name']}` "
                                "DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci"
                            )
                        bootstrap.commit()
                    finally:
                        bootstrap.close()
                    return self._base_connect(include_db=True)
            raise

    @staticmethod
    def _prepare_sql(sql: str) -> str:
        if "%s" in sql or "%(" in sql:
            return sql
        return sql.replace("?", "%s")

    @staticmethod
    def _prepare_params(params: Any) -> tuple:
        if params is None:
            return ()
        if isinstance(params, (list, tuple)):
            return tuple(params)
        return (params,)

    # Public API -------------------------------------------------------
    def execute(self, sql: str, params: Any = None) -> CursorWrapper:
        cursor = self._conn.cursor()
        cursor.execute(self._prepare_sql(sql), self._prepare_params(params))
        return CursorWrapper(cursor)

    def executemany(self, sql: str, seq_of_params: Iterable[Iterable[Any]]) -> CursorWrapper:
        cursor = self._conn.cursor()
        prepared_sql = self._prepare_sql(sql)
        prepared_params = [self._prepare_params(params) for params in seq_of_params]
        if prepared_params:
            cursor.executemany(prepared_sql, prepared_params)
        return CursorWrapper(cursor)

    def executescript(self, script: str) -> None:
        for statement in script.split(";"):
            stmt = statement.strip()
            if stmt:
                self.execute(stmt)

    def commit(self) -> None:
        self._conn.commit()

    def rollback(self) -> None:
        self._conn.rollback()

    def close(self) -> None:
        self._conn.close()


DatabaseLike: TypeAlias = sqlite3.Connection | MySQLConnection

_RENTMAN_CLIENT: Optional[RentmanClient] = None
_RENTMAN_CLIENT_TOKEN: Optional[str] = None
_CONFIG_CACHE: Optional[Dict[str, Any]] = None
_CONFIG_CACHE_MTIME: Optional[float] = None
_WEBPUSH_SETTINGS: Optional[Dict[str, Optional[str]]] = None
_NOTIFICATION_THREAD: Optional[Thread] = None
_NOTIFICATION_STOP: Optional[Event] = None
_CEDOLINO_RETRY_THREAD: Optional[Thread] = None
_CEDOLINO_RETRY_STOP: Optional[Event] = None

NOTIFICATION_INTERVAL_SECONDS = int(os.environ.get("JOBLOG_NOTIFICATION_INTERVAL", "60"))
CEDOLINO_RETRY_INTERVAL_SECONDS = int(os.environ.get("JOBLOG_CEDOLINO_RETRY_INTERVAL", "300"))  # 5 minuti
ACTIVITY_OVERDUE_GRACE_MS = 10 * 60 * 1000  # 10 minuti di ritardo tollerato
PUSH_NOTIFIED_STATE_KEY = "push_notified_activities"
LONG_RUNNING_STATE_KEY = "long_running_member_notifications"
LONG_RUNNING_THRESHOLD_MS = 2 * 60 * 1000  # 2 minuti
OVERDUE_PUSH_TTL_SECONDS = max(300, int(os.environ.get("JOBLOG_OVERDUE_PUSH_TTL", "3600")))

RUN_STATE_PAUSED = 0
RUN_STATE_RUNNING = 1
RUN_STATE_FINISHED = 2
VALID_RUN_STATES = {RUN_STATE_PAUSED, RUN_STATE_RUNNING, RUN_STATE_FINISHED}

ROLE_USER = "user"
ROLE_SUPERVISOR = "supervisor"
ROLE_ADMIN = "admin"
VALID_USER_ROLES = {ROLE_USER, ROLE_SUPERVISOR, ROLE_ADMIN}


# Permission check helpers
def is_admin_or_supervisor() -> bool:
    """Check if current user is admin or supervisor (responsabile squadra)."""
    return bool(session.get("is_admin") or session.get("is_supervisor"))


def is_admin_only() -> bool:
    """Check if current user is admin only."""
    return bool(session.get("is_admin"))


# Authentication helpers
def hash_password(password: str) -> str:
    """Hash a password using SHA-256."""
    return hashlib.sha256(password.encode('utf-8')).hexdigest()


def verify_password(password: str, hashed: str) -> bool:
    """Verify a password against a hash."""
    return hash_password(password) == hashed


def compute_initials(value: str) -> str:
    """Return up to two initials from the provided value."""
    if not value:
        return "?"
    cleaned = value.replace("-", " ")
    tokens = [part for part in cleaned.split() if part]
    if not tokens:
        return value[:2].upper()
    initials = "".join(part[0] for part in tokens[:2]).upper()
    if initials:
        return initials
    return value[:2].upper()


def load_users_file() -> Dict[str, Dict[str, Any]]:
    """Return the legacy users.json payload (if present) for migrations."""
    if not USERS_FILE.exists():
        return {}
    try:
        with open(USERS_FILE, 'r', encoding='utf-8') as f:
            payload = json.load(f)
    except Exception:
        return {}
    return payload if isinstance(payload, dict) else {}


def _normalize_username(value: str) -> str:
    return value.strip().lower()


def _normalize_role(value: Optional[str]) -> str:
    if not value:
        return ROLE_USER
    candidate = value.strip().lower()
    if candidate in VALID_USER_ROLES:
        return candidate
    return ROLE_USER


def _role_from_legacy_entry(entry: Mapping[str, Any]) -> str:
    roles_field = entry.get("roles")
    candidates: List[str] = []
    if isinstance(roles_field, str):
        candidates.append(roles_field)
    elif isinstance(roles_field, Iterable):
        for role in roles_field:
            if isinstance(role, str):
                candidates.append(role)

    for role in candidates:
        normalized = role.strip().lower()
        if normalized == ROLE_ADMIN:
            return ROLE_ADMIN
        if normalized == ROLE_SUPERVISOR:
            return ROLE_SUPERVISOR

    is_admin_flag = entry.get("is_admin")
    if isinstance(is_admin_flag, bool) and is_admin_flag:
        return ROLE_ADMIN
    if isinstance(is_admin_flag, str) and is_admin_flag.strip().lower() in {"1", "true", "yes", "y"}:
        return ROLE_ADMIN
    return ROLE_USER


def fetch_user_record(db: DatabaseLike, username: str) -> Optional[Mapping[str, Any]]:
    if not username:
        return None
    return db.execute(
        """
        SELECT username, password_hash, display_name, full_name, role, is_active,
               current_project_code, current_project_name
        FROM app_users
        WHERE LOWER(username)=LOWER(?)
        """,
        (username,),
    ).fetchone()


def _persistent_cookie_name() -> str:
    return app.config.get('PERSISTENT_SESSION_COOKIE_NAME', PERSISTENT_SESSION_COOKIE_NAME)


def _persistent_session_max_age() -> int:
    value = app.config.get('PERSISTENT_SESSION_MAX_AGE', PERSISTENT_SESSION_MAX_AGE)
    try:
        parsed = int(value)
    except (TypeError, ValueError):
        return PERSISTENT_SESSION_MAX_AGE
    return max(300, parsed)


def _hash_persistent_token(token: str) -> str:
    return hashlib.sha256(token.encode('utf-8')).hexdigest()


def _request_metadata() -> Tuple[Optional[str], Optional[str]]:
    user_agent = request.headers.get('User-Agent', '').strip()
    forwarded_for = request.headers.get('X-Forwarded-For', '').strip()
    if forwarded_for:
        ip_candidate = forwarded_for.split(',')[0].strip()
    else:
        ip_candidate = request.remote_addr or ''
    user_agent = user_agent or None
    ip_candidate = ip_candidate or None
    return user_agent, ip_candidate


def _store_persistent_session(username: str) -> Tuple[str, int]:
    token = secrets.token_urlsafe(48)
    token_hash = _hash_persistent_token(token)
    now = now_ms()
    max_age_ms = _persistent_session_max_age() * 1000
    expires_ts = now + max_age_ms
    user_agent, ip_addr = _request_metadata()
    db = get_db()
    db.execute(
        """
        INSERT INTO persistent_sessions(token_hash, username, user_agent, ip_address, created_ts, last_seen_ts, expires_ts)
        VALUES(?,?,?,?,?,?,?)
        """,
        (token_hash, username, user_agent, ip_addr, now, now, expires_ts),
    )
    try:
        db.commit()
    except Exception:
        pass
    return token, expires_ts


def _delete_persistent_session(token_value: Optional[str]) -> None:
    if not token_value:
        return
    token_hash = _hash_persistent_token(token_value)
    db = get_db()
    db.execute("DELETE FROM persistent_sessions WHERE token_hash=?", (token_hash,))
    try:
        db.commit()
    except Exception:
        pass


def _load_persistent_session(token_value: str) -> Optional[Tuple[str, int]]:
    if not token_value:
        return None
    token_hash = _hash_persistent_token(token_value)
    db = get_db()
    row = db.execute(
        "SELECT username, expires_ts FROM persistent_sessions WHERE token_hash=?",
        (token_hash,),
    ).fetchone()
    if not row:
        return None
    username = row.get('username') if isinstance(row, Mapping) else row[0]
    expires_raw = row.get('expires_ts') if isinstance(row, Mapping) else row[1]
    expires_ts = _coerce_int(expires_raw) or 0
    now = now_ms()
    if expires_ts <= now:
        db.execute("DELETE FROM persistent_sessions WHERE token_hash=?", (token_hash,))
        try:
            db.commit()
        except Exception:
            pass
        return None
    new_expires = now + _persistent_session_max_age() * 1000
    db.execute(
        "UPDATE persistent_sessions SET last_seen_ts=?, expires_ts=? WHERE token_hash=?",
        (now, new_expires, token_hash),
    )
    try:
        db.commit()
    except Exception:
        pass
    return username, new_expires


def _set_persistent_cookie(response, token_value: str, expires_ts: Optional[int] = None) -> None:
    max_age = _persistent_session_max_age()
    expires = expires_ts or (now_ms() + max_age * 1000)
    expires_dt = datetime.fromtimestamp(expires / 1000, tz=timezone.utc)
    response.set_cookie(
        _persistent_cookie_name(),
        token_value,
        max_age=max_age,
        expires=expires_dt,
        httponly=True,
        secure=app.config.get('SESSION_COOKIE_SECURE', False),
        samesite=app.config.get('SESSION_COOKIE_SAMESITE', 'Lax'),
        path='/',
    )


def _apply_user_session(user_row: Mapping[str, Any]) -> None:
    username = user_row.get('username') or ''
    display = user_row.get('display_name') or username
    full_name = user_row.get('full_name') or display
    role = _normalize_role(user_row.get('role'))
    session.permanent = True
    session['user'] = username
    session['user_display'] = display
    session['user_name'] = full_name
    session['user_initials'] = compute_initials(full_name)
    session['user_role'] = role
    session['is_admin'] = role == ROLE_ADMIN
    session['is_supervisor'] = role in {ROLE_SUPERVISOR, ROLE_ADMIN}
    
    # Ripristina il progetto salvato per i supervisor
    if role in {ROLE_SUPERVISOR, ROLE_ADMIN}:
        current_project_code = user_row.get('current_project_code')
        current_project_name = user_row.get('current_project_name')
        app.logger.info("Login %s: recupero progetto salvato = %s", username, current_project_code)
        if current_project_code:
            session['supervisor_project_code'] = current_project_code
            session['supervisor_project_name'] = current_project_name or current_project_code


@app.before_request
def _restore_persistent_session() -> None:
    if 'user' in session:
        return
    token = request.cookies.get(_persistent_cookie_name())
    if not token:
        return
    loaded = _load_persistent_session(token)
    if not loaded:
        return
    username, new_expires = loaded
    db = get_db()
    user_row = fetch_user_record(db, username)
    if not user_row or not user_row.get('is_active'):
        _delete_persistent_session(token)
        return
    _apply_user_session(user_row)
    g.persistent_cookie_refresh = (token, new_expires)


@app.after_request
def _refresh_persistent_cookie(response):
    pending = g.pop('persistent_cookie_refresh', None)
    if pending:
        token_value, expires_ts = pending
        _set_persistent_cookie(response, token_value, expires_ts)
    return response


def migrate_users_file(db: DatabaseLike) -> bool:
    legacy = load_users_file()
    if not legacy:
        return False

    rows: List[tuple] = []
    now = now_ms()
    for raw_username, entry in legacy.items():
        if not isinstance(entry, Mapping):
            continue
        username = _normalize_username(str(raw_username))
        password_hash = entry.get("password") or entry.get("password_hash")
        if not username or not isinstance(password_hash, str) or not password_hash.strip():
            continue
        display = str(entry.get("display") or raw_username).strip() or username
        full_name = str(entry.get("name") or display).strip() or display
        role = _role_from_legacy_entry(entry)
        rows.append((username, password_hash.strip(), display, full_name, role, 1, now, now))

    if not rows:
        return False

    if DB_VENDOR == "mysql":
        insert_sql = (
            "INSERT INTO app_users("
            "username, password_hash, display_name, full_name, role, is_active, created_ts, updated_ts"
            ") VALUES(?,?,?,?,?,?,?,?) "
            "ON DUPLICATE KEY UPDATE username=VALUES(username)"
        )
    else:
        insert_sql = (
            "INSERT INTO app_users("
            "username, password_hash, display_name, full_name, role, is_active, created_ts, updated_ts"
            ") VALUES(?,?,?,?,?,?,?,?) "
            "ON CONFLICT(username) DO NOTHING"
        )

    db.executemany(insert_sql, rows)
    app.logger.info("Importati %s utenti da %s", len(rows), USERS_FILE.name)
    return True


def bootstrap_user_store(db: DatabaseLike) -> None:
    try:
        ensure_app_users_table(db)
    except Exception:
        app.logger.exception("Impossibile preparare la tabella app_users")
        return

    try:
        row = db.execute("SELECT COUNT(*) AS total FROM app_users").fetchone()
        existing = int(row["total"] if row else 0)
    except Exception:
        app.logger.exception("Impossibile verificare il conteggio degli utenti")
        return

    if existing > 0:
        return

    try:
        migrated = migrate_users_file(db)
    except Exception:
        app.logger.exception("Migrazione utenti legacy fallita")
        migrated = False

    if migrated:
        return

    bootstrap_user = os.environ.get("JOBLOG_BOOTSTRAP_ADMIN_USER", "admin")
    bootstrap_password = os.environ.get("JOBLOG_BOOTSTRAP_ADMIN_PASSWORD")
    if not bootstrap_password:
        app.logger.warning(
            "Nessun utente configurato: crea un account con 'python manage_users.py create <utente> --role admin'"
        )
        return

    now = now_ms()
    username = _normalize_username(bootstrap_user)
    db.execute(
        """
        INSERT INTO app_users(username, password_hash, display_name, full_name, role, is_active, created_ts, updated_ts)
        VALUES(?,?,?,?,?,?,?,?)
        """,
        (
            username,
            hash_password(bootstrap_password),
            bootstrap_user,
            bootstrap_user,
            ROLE_ADMIN,
            1,
            now,
            now,
        ),
    )
    app.logger.warning(
        "Creato automaticamente l'utente amministratore '%s' dalle variabili JOBLOG_BOOTSTRAP_ADMIN_*",
        bootstrap_user,
    )


def login_required(f):
    """Decorator to require login for a route."""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user' not in session:
            if request.path.startswith('/api/'):
                return jsonify({'error': 'Authentication required'}), 401
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function


def _is_truthy(value: Any) -> bool:
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        return value.strip().lower() in {"1", "true", "t", "yes", "y", "si"}
    if isinstance(value, (int, float)):
        return value != 0
    return False




def _normalize_datetime(value: Any) -> Optional[str]:
    """Normalizza un valore data/ora in formato ISO 8601 (se possibile)."""

    if value is None:
        return None

    if isinstance(value, (int, float)):
        try:
            return datetime.fromtimestamp(float(value), tz=timezone.utc).isoformat()
        except (ValueError, OSError):
            return None

    if isinstance(value, str):
        slug = value.strip()
        if not slug:
            return None
        normalized = slug.replace("Z", "+00:00")
        try:
            dt = datetime.fromisoformat(normalized)
        except ValueError:
            return slug
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt.isoformat()

    return None


def _normalize_date(value: Any) -> Optional[str]:
    """Normalizza un valore data (YYYY-MM-DD)."""

    if value is None:
        return None

    if isinstance(value, datetime):
        return value.date().isoformat()

    if isinstance(value, (int, float)):
        try:
            return datetime.fromtimestamp(float(value), tz=timezone.utc).date().isoformat()
        except (ValueError, OSError):
            return None

    if isinstance(value, str):
        slug = value.strip()
        if not slug:
            return None
        for candidate in (slug, slug.replace("/", "-")):
            try:
                dt = datetime.fromisoformat(candidate)
            except ValueError:
                try:
                    dt = datetime.strptime(candidate, "%Y-%m-%d")
                except ValueError:
                    continue
            return dt.date().isoformat()
        return None

    return None


def _extract_iso_date(value: Optional[str]) -> Optional[str]:
    if not value:
        return None
    cleaned = value.replace("Z", "+00:00")
    try:
        dt = datetime.fromisoformat(cleaned)
    except ValueError:
        if len(value) >= 10:
            return value[:10]
        return None
    return dt.date().isoformat()


def _parse_date_any(value: Any) -> Optional[date]:
    """Parsa una data da vari formati (ISO, timestamp, dd/mm/yyyy, dd-mm-yyyy)."""

    if value is None:
        return None

    if isinstance(value, date) and not isinstance(value, datetime):
        return value

    if isinstance(value, datetime):
        return value.date()

    if isinstance(value, (int, float)):
        try:
            return datetime.fromtimestamp(float(value), tz=timezone.utc).date()
        except (ValueError, OSError):
            return None

    if isinstance(value, str):
        slug = value.strip()
        if not slug:
            return None
        slug = slug.replace("Z", "+00:00")
        # ISO 8601 (date o datetime)
        try:
            return datetime.fromisoformat(slug).date()
        except ValueError:
            pass
        # Se contiene un datetime ma non ISO perfetto, prova a prendere YYYY-MM-DD
        if len(slug) >= 10:
            head = slug[:10]
            try:
                return datetime.strptime(head, "%Y-%m-%d").date()
            except ValueError:
                pass
        # Formati europei
        for fmt in ("%d/%m/%Y", "%d-%m-%Y", "%d.%m.%Y"):
            try:
                return datetime.strptime(slug[:10], fmt).date()
            except ValueError:
                continue
        return None

    return None


def _coerce_int(value: Any) -> Optional[int]:
    if isinstance(value, bool):
        return int(value)
    if isinstance(value, (int, float, Decimal)):
        return int(value)
    if isinstance(value, str):
        slug = value.strip()
        if not slug:
            return None
        try:
            return int(slug)
        except ValueError:
            return None
    return None


def _normalize_running(value: Any, default: int | None = None) -> int:
    coerced = _coerce_int(value)
    if coerced in VALID_RUN_STATES:
        return int(coerced)
    if default is None:
        return RUN_STATE_PAUSED
    return default


def _slugify(value: str) -> str:
    """Crea uno slug alfanumerico minuscolo."""

    normalized = value.strip().lower()
    if not normalized:
        return ""
    buffer: List[str] = []
    previous_dash = False
    for char in normalized:
        if char.isalnum():
            buffer.append(char)
            previous_dash = False
        elif not previous_dash:
            buffer.append("-")
            previous_dash = True
    slug = "".join(buffer).strip("-")
    return slug


def _normalize_activity_id(value: str) -> str:
    slug = _slugify(value)
    if not slug:
        return ""
    return slug.replace("-", "_").upper()


def _generate_activity_id(db: DatabaseLike, label: str) -> str:
    base = _normalize_activity_id(label) or "ATTIVITA"
    base = base[:24]
    if not base:
        base = "ATTIVITA"
    candidate = base
    suffix = 1
    while True:
        row = db.execute("SELECT 1 FROM activities WHERE activity_id=?", (candidate,)).fetchone()
        if row is None:
            return candidate
        suffix += 1
        padded = f"{suffix:02d}"
        truncated = base[: max(4, 24 - len(padded) - 1)]
        candidate = f"{truncated}_{padded}"


def compute_planned_duration_ms(
    plan_start: Optional[str],
    plan_end: Optional[str],
    planned_members: Optional[int],
) -> Optional[int]:
    start_ms = parse_iso_to_ms(plan_start)
    end_ms = parse_iso_to_ms(plan_end)
    if start_ms is None or end_ms is None:
        return None
    base = max(0, end_ms - start_ms)
    if base == 0:
        return 0
    normalized_members = planned_members if isinstance(planned_members, int) else None
    if normalized_members is None:
        normalized_members = _coerce_int(planned_members)
    if normalized_members is None or normalized_members <= 0:
        normalized_members = 1
    return base * normalized_members


def load_activity_meta(db: DatabaseLike) -> Dict[str, Any]:
    raw = get_app_state(db, "activity_plan_meta")
    if not raw:
        return {}
    try:
        meta = json.loads(raw)
    except json.JSONDecodeError:
        return {}
    if isinstance(meta, dict):
        return meta
    return {}


def save_activity_meta(db: DatabaseLike, meta: Mapping[str, Any]) -> None:
    set_app_state(db, "activity_plan_meta", json.dumps(meta))


def refresh_activity_meta(db: DatabaseLike) -> Dict[str, Any]:
    rows = db.execute(
        "SELECT activity_id, plan_start, plan_end, planned_members, planned_duration_ms FROM activities"
    ).fetchall()
    current = load_activity_meta(db)
    next_meta: Dict[str, Any] = {}
    for row in rows:
        activity_id = row["activity_id"]
        if not activity_id:
            continue
        previous = current.get(activity_id)
        previous_runtime = 0
        if isinstance(previous, Mapping):
            try:
                previous_runtime = int(previous.get("actual_runtime_ms") or 0)
            except (TypeError, ValueError):
                previous_runtime = 0
        next_meta[str(activity_id)] = {
            "plan_start": row["plan_start"],
            "plan_end": row["plan_end"],
            "planned_members": row["planned_members"],
            "planned_duration_ms": row["planned_duration_ms"],
            "actual_runtime_ms": previous_runtime,
        }
    save_activity_meta(db, next_meta)
    return next_meta


def increment_activity_runtime(meta: Dict[str, Any], activity_id: Optional[str], delta_ms: int) -> bool:
    if not activity_id:
        return False
    try:
        contribution = int(delta_ms)
    except (TypeError, ValueError):
        return False
    if contribution <= 0:
        return False

    entry = meta.get(activity_id)
    if not isinstance(entry, dict):
        entry = {}
    current_value = entry.get("actual_runtime_ms")
    try:
        current_int = int(current_value)
    except (TypeError, ValueError):
        current_int = 0
    entry["actual_runtime_ms"] = current_int + contribution
    meta[activity_id] = entry
    return True


def _activity_matches_date(plan_start: Optional[str], plan_end: Optional[str], expected: str) -> bool:
    """Verifica se la data selezionata cade nell'intervallo dell'attività."""
    expected_date = _parse_date_any(expected)
    start = _parse_date_any(plan_start)
    end = _parse_date_any(plan_end)

    if expected_date is None:
        return False

    # Se non abbiamo date valide, escludiamo l'attività
    if start is None and end is None:
        return False

    # Se abbiamo solo una data, verifichiamo l'uguaglianza
    if start is not None and end is None:
        return start == expected_date
    if end is not None and start is None:
        return end == expected_date

    assert start is not None and end is not None
    if end < start:
        start, end = end, start
    return start <= expected_date <= end


def load_external_projects() -> Dict[str, Dict[str, Any]]:
    """Legge un catalogo di progetti personalizzati da projects.json."""

    if not PROJECTS_FILE.exists():
        return {}

    try:
        content = PROJECTS_FILE.read_text(encoding="utf-8")
    except OSError:
        return {}

    try:
        payload = json.loads(content) if content.strip() else {}
    except json.JSONDecodeError:
        return {}

    def normalize(entry: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        code_raw = entry.get("project_code") or entry.get("code")
        code = str(code_raw or "").strip().upper()
        if not code:
            return None

        name_raw = entry.get("project_name") or entry.get("name")
        project_name = str(name_raw or code).strip()

        activities_payload = entry.get("activities") or []
        activities: List[Dict[str, Any]] = []
        for index, item in enumerate(activities_payload, start=1):
            if not isinstance(item, dict):
                continue
            raw_id = item.get("id") or item.get("code")
            activity_id = str(raw_id or "").strip().upper() or f"ACT{index:02}"
            raw_label = item.get("label") or item.get("name")
            label = str(raw_label or activity_id).strip() or activity_id
            activities.append(
                {
                    "id": activity_id,
                    "label": label,
                    "plan_start": _normalize_datetime(item.get("plan_start")),
                    "plan_end": _normalize_datetime(item.get("plan_end")),
                }
            )

        team_payload = entry.get("team") or entry.get("members") or []
        team: List[Dict[str, Any]] = []
        for member in team_payload:
            if not isinstance(member, dict):
                continue
            raw_key = member.get("key") or member.get("id")
            key = str(raw_key or "").strip()
            raw_name = member.get("name") or member.get("full_name")
            name = str(raw_name or key or "Operatore").strip()
            activity_id = member.get("activity_id")
            if isinstance(activity_id, str):
                activity_id = activity_id.strip().upper() or None
            else:
                activity_id = None
            team.append({
                "key": key,
                "name": name,
                "activity_id": activity_id,
            })

        return {
            "project_code": code,
            "project_name": project_name,
            "activities": activities,
            "team": team,
        }

    catalog: Dict[str, Dict[str, Any]] = {}

    if isinstance(payload, dict):
        for key, value in payload.items():
            if not isinstance(value, dict):
                continue
            entry = dict(value)
            entry.setdefault("project_code", key)
            normalized = normalize(entry)
            if normalized:
                catalog[normalized["project_code"]] = normalized
    elif isinstance(payload, list):
        for entry in payload:
            if not isinstance(entry, dict):
                continue
            normalized = normalize(entry)
            if normalized:
                catalog[normalized["project_code"]] = normalized

    return catalog


def load_config() -> Dict[str, Any]:
    """Carica config.json quando disponibile e mantiene una cache in memoria."""

    global _CONFIG_CACHE, _CONFIG_CACHE_MTIME, _DATABASE_SETTINGS, _WEBPUSH_SETTINGS

    if not CONFIG_FILE.exists():
        _CONFIG_CACHE = {}
        _CONFIG_CACHE_MTIME = None
        return {}

    try:
        mtime = CONFIG_FILE.stat().st_mtime
    except OSError:
        return {}

    if _CONFIG_CACHE is not None and _CONFIG_CACHE_MTIME == mtime:
        return _CONFIG_CACHE

    try:
        content = CONFIG_FILE.read_text(encoding="utf-8")
        data = json.loads(content) if content.strip() else {}
        if not isinstance(data, dict):
            raise ValueError("Config root deve essere un oggetto JSON")
    except (OSError, ValueError, json.JSONDecodeError) as exc:
        app.logger.warning("Config: impossibile leggere %s (%s)", CONFIG_FILE.name, exc)
        _CONFIG_CACHE = {}
        _CONFIG_CACHE_MTIME = mtime
        return {}

    _CONFIG_CACHE = data
    _CONFIG_CACHE_MTIME = mtime
    _DATABASE_SETTINGS = None
    _WEBPUSH_SETTINGS = None
    return data


APP_USERS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS app_users (
    username VARCHAR(190) PRIMARY KEY,
    password_hash VARCHAR(255) NOT NULL,
    display_name VARCHAR(255) NOT NULL,
    full_name VARCHAR(255) DEFAULT NULL,
    role VARCHAR(32) NOT NULL DEFAULT 'user',
    is_active TINYINT(1) NOT NULL DEFAULT 1,
    external_id VARCHAR(255) DEFAULT NULL,
    external_group_id VARCHAR(255) DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

APP_USERS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS app_users (
    username TEXT PRIMARY KEY,
    password_hash TEXT NOT NULL,
    display_name TEXT NOT NULL,
    full_name TEXT,
    role TEXT NOT NULL DEFAULT 'user',
    is_active INTEGER NOT NULL DEFAULT 1,
    external_id TEXT DEFAULT NULL,
    external_group_id TEXT DEFAULT NULL,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
)
"""

# ═══════════════════════════════════════════════════════════════════
# TABELLA GRUPPI UTENTI
# ═══════════════════════════════════════════════════════════════════
USER_GROUPS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS user_groups (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT DEFAULT NULL,
    cedolino_group_id VARCHAR(255) DEFAULT NULL,
    gps_location_name VARCHAR(255) DEFAULT NULL COMMENT 'Nome sede GPS associata al gruppo',
    is_active TINYINT(1) NOT NULL DEFAULT 1,
    is_production TINYINT(1) NOT NULL DEFAULT 0 COMMENT 'Flag per gruppi di produzione',
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    UNIQUE KEY uk_group_name (name)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

USER_GROUPS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS user_groups (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    description TEXT DEFAULT NULL,
    cedolino_group_id TEXT DEFAULT NULL,
    gps_location_name TEXT DEFAULT NULL,
    is_active INTEGER NOT NULL DEFAULT 1,
    is_production INTEGER NOT NULL DEFAULT 0,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
)
"""

SESSION_OVERRIDES_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS activity_session_overrides (
    id INT AUTO_INCREMENT PRIMARY KEY,
    member_key VARCHAR(255) NOT NULL,
    member_name VARCHAR(255) NOT NULL,
    activity_id VARCHAR(255) NOT NULL,
    activity_label VARCHAR(255) DEFAULT NULL,
    project_code VARCHAR(64) DEFAULT NULL,
    start_ts BIGINT NOT NULL,
    end_ts BIGINT DEFAULT NULL,
    net_ms BIGINT DEFAULT NULL,
    pause_ms BIGINT DEFAULT NULL,
    pause_count INT NOT NULL DEFAULT 0,
    status VARCHAR(32) NOT NULL DEFAULT 'completed',
    source_member_key VARCHAR(255) DEFAULT NULL,
    source_activity_id VARCHAR(255) DEFAULT NULL,
    source_start_ts BIGINT DEFAULT NULL,
    manual_entry TINYINT(1) NOT NULL DEFAULT 0,
    note TEXT,
    created_by VARCHAR(190) DEFAULT NULL,
    updated_by VARCHAR(190) DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    INDEX idx_session_override_source (source_member_key, source_activity_id, source_start_ts),
    INDEX idx_session_override_member (member_key),
    INDEX idx_session_override_activity (activity_id),
    INDEX idx_session_override_project (project_code)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

SESSION_OVERRIDES_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS activity_session_overrides (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    member_key TEXT NOT NULL,
    member_name TEXT NOT NULL,
    activity_id TEXT NOT NULL,
    activity_label TEXT,
    project_code TEXT,
    start_ts INTEGER NOT NULL,
    end_ts INTEGER,
    net_ms INTEGER,
    pause_ms INTEGER,
    pause_count INTEGER NOT NULL DEFAULT 0,
    status TEXT NOT NULL DEFAULT 'completed',
    source_member_key TEXT,
    source_activity_id TEXT,
    source_start_ts INTEGER,
    manual_entry INTEGER NOT NULL DEFAULT 0,
    note TEXT,
    created_by TEXT,
    updated_by TEXT,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_session_override_source ON activity_session_overrides(source_member_key, source_activity_id, source_start_ts);
CREATE INDEX IF NOT EXISTS idx_session_override_member ON activity_session_overrides(member_key);
CREATE INDEX IF NOT EXISTS idx_session_override_activity ON activity_session_overrides(activity_id);
CREATE INDEX IF NOT EXISTS idx_session_override_project ON activity_session_overrides(project_code);
"""

PERSISTENT_SESSIONS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS persistent_sessions (
    token_hash CHAR(64) PRIMARY KEY,
    username VARCHAR(190) NOT NULL,
    user_agent VARCHAR(255) DEFAULT NULL,
    ip_address VARCHAR(64) DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    last_seen_ts BIGINT NOT NULL,
    expires_ts BIGINT NOT NULL,
    INDEX idx_persistent_sessions_user (username)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

PERSISTENT_SESSIONS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS persistent_sessions (
    token_hash TEXT PRIMARY KEY,
    username TEXT NOT NULL,
    user_agent TEXT,
    ip_address TEXT,
    created_ts INTEGER NOT NULL,
    last_seen_ts INTEGER NOT NULL,
    expires_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_persistent_sessions_user ON persistent_sessions(username);
"""


EQUIPMENT_CHECKS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS equipment_checks (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_code VARCHAR(128) NOT NULL,
    item_key VARCHAR(512) NOT NULL,
    checked_ts BIGINT NOT NULL,
    username VARCHAR(190) DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    UNIQUE KEY uq_equipment_project_item (project_code, item_key),
    INDEX idx_equipment_project (project_code)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""


EQUIPMENT_CHECKS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS equipment_checks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_code TEXT NOT NULL,
    item_key TEXT NOT NULL,
    checked_ts INTEGER NOT NULL,
    username TEXT,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE UNIQUE INDEX IF NOT EXISTS uq_equipment_project_item ON equipment_checks(project_code, item_key);
CREATE INDEX IF NOT EXISTS idx_equipment_project ON equipment_checks(project_code);
"""


LOCAL_EQUIPMENT_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS local_equipment (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_code VARCHAR(128) NOT NULL,
    name VARCHAR(255) NOT NULL,
    quantity INT NOT NULL DEFAULT 1,
    notes TEXT,
    group_name VARCHAR(255) DEFAULT 'Attrezzature extra',
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    INDEX idx_local_equipment_project (project_code)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""


LOCAL_EQUIPMENT_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS local_equipment (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_code TEXT NOT NULL,
    name TEXT NOT NULL,
    quantity INTEGER NOT NULL DEFAULT 1,
    notes TEXT,
    group_name TEXT DEFAULT 'Attrezzature extra',
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_local_equipment_project ON local_equipment(project_code);
"""


PROJECT_PHOTOS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS project_photos (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_code VARCHAR(128) NOT NULL,
    filename VARCHAR(255) NOT NULL,
    original_name VARCHAR(255) NOT NULL,
    mime_type VARCHAR(100) NOT NULL,
    file_size INT NOT NULL,
    caption TEXT,
    created_ts BIGINT NOT NULL,
    INDEX idx_project_photos_project (project_code)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""


PROJECT_PHOTOS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS project_photos (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_code TEXT NOT NULL,
    filename TEXT NOT NULL,
    original_name TEXT NOT NULL,
    mime_type TEXT NOT NULL,
    file_size INTEGER NOT NULL,
    caption TEXT,
    created_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_project_photos_project ON project_photos(project_code);
"""


PROJECT_MATERIALS_CACHE_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS project_materials_cache (
    project_code VARCHAR(128) PRIMARY KEY,
    project_name VARCHAR(255) NOT NULL,
    data_json LONGTEXT NOT NULL,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""


PROJECT_MATERIALS_CACHE_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS project_materials_cache (
    project_code TEXT PRIMARY KEY,
    project_name TEXT NOT NULL,
    data_json TEXT NOT NULL,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
"""


# ═══════════════════════════════════════════════════════════════════════════════
#  CEDOLINO TIMBRATURE - Integrazione CedolinoWeb
# ═══════════════════════════════════════════════════════════════════════════════

CEDOLINO_TIMBRATURE_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS cedolino_timbrature (
    id INT AUTO_INCREMENT PRIMARY KEY,
    member_key VARCHAR(255) DEFAULT NULL,
    member_name VARCHAR(255) NOT NULL,
    username VARCHAR(190) DEFAULT NULL,
    external_id VARCHAR(255) NOT NULL,
    timeframe_id INT NOT NULL COMMENT '1=inizio giornata, 4=inizio pausa, 5=fine pausa, 8=fine giornata',
    timestamp_ms BIGINT NOT NULL,
    data_riferimento DATE NOT NULL,
    ora_originale TIME NOT NULL,
    ora_modificata TIME NOT NULL,
    project_code VARCHAR(128) DEFAULT NULL,
    activity_id VARCHAR(255) DEFAULT NULL,
    synced_ts BIGINT DEFAULT NULL,
    sync_error TEXT DEFAULT NULL,
    sync_attempts INT NOT NULL DEFAULT 0,
    overtime_request_id INT DEFAULT NULL COMMENT 'ID richiesta straordinario collegata (blocca sync fino a revisione)',
    created_ts BIGINT NOT NULL,
    INDEX idx_cedolino_member (member_key),
    INDEX idx_cedolino_username (username),
    INDEX idx_cedolino_external (external_id),
    INDEX idx_cedolino_synced (synced_ts),
    INDEX idx_cedolino_data (data_riferimento),
    INDEX idx_cedolino_overtime (overtime_request_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

CEDOLINO_TIMBRATURE_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS cedolino_timbrature (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    member_key TEXT,
    member_name TEXT NOT NULL,
    username TEXT,
    external_id TEXT NOT NULL,
    timeframe_id INTEGER NOT NULL,
    timestamp_ms INTEGER NOT NULL,
    data_riferimento TEXT NOT NULL,
    ora_originale TEXT NOT NULL,
    ora_modificata TEXT NOT NULL,
    project_code TEXT,
    activity_id TEXT,
    synced_ts INTEGER,
    sync_error TEXT,
    sync_attempts INTEGER NOT NULL DEFAULT 0,
    overtime_request_id INTEGER DEFAULT NULL,
    created_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_cedolino_member ON cedolino_timbrature(member_key);
CREATE INDEX IF NOT EXISTS idx_cedolino_username ON cedolino_timbrature(username);
CREATE INDEX IF NOT EXISTS idx_cedolino_external ON cedolino_timbrature(external_id);
CREATE INDEX IF NOT EXISTS idx_cedolino_synced ON cedolino_timbrature(synced_ts);
CREATE INDEX IF NOT EXISTS idx_cedolino_data ON cedolino_timbrature(data_riferimento);
CREATE INDEX IF NOT EXISTS idx_cedolino_overtime ON cedolino_timbrature(overtime_request_id);
"""

# Costanti timeframe CedolinoWeb
TIMEFRAME_INIZIO_GIORNATA = 1
TIMEFRAME_INIZIO_PAUSA = 4
TIMEFRAME_FINE_PAUSA = 5
TIMEFRAME_FINE_GIORNATA = 8

CEDOLINO_WEB_ENDPOINT = "http://80.211.18.30/WebServices/crea_timbrata_elaborata"
CEDOLINO_CODICE_TERMINALE = "musa_mobile"


# ═══════════════════════════════════════════════════════════════════════════════
#  EMPLOYEE SHIFTS - Turni settimanali per impiegati non-Rentman
# ═══════════════════════════════════════════════════════════════════════════════

EMPLOYEE_SHIFTS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS employee_shifts (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(190) NOT NULL,
    day_of_week TINYINT NOT NULL COMMENT '0=Lunedì, 1=Martedì, ..., 6=Domenica',
    start_time TIME NOT NULL,
    end_time TIME NOT NULL,
    break_start TIME DEFAULT NULL,
    break_end TIME DEFAULT NULL,
    shift_name VARCHAR(100) DEFAULT NULL COMMENT 'Nome identificativo del turno (es. Turno Mattina)',
    location_name VARCHAR(255) DEFAULT NULL COMMENT 'Nome sede GPS associata al turno',
    is_active TINYINT(1) NOT NULL DEFAULT 1,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    UNIQUE KEY uk_user_day (username, day_of_week),
    INDEX idx_shifts_username (username),
    INDEX idx_shifts_active (is_active)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

EMPLOYEE_SHIFTS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS employee_shifts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT NOT NULL,
    day_of_week INTEGER NOT NULL,
    start_time TEXT NOT NULL,
    end_time TEXT NOT NULL,
    break_start TEXT,
    break_end TEXT,
    shift_name TEXT,
    location_name TEXT,
    is_active INTEGER NOT NULL DEFAULT 1,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
    UNIQUE (username, day_of_week)
);
CREATE INDEX IF NOT EXISTS idx_shifts_username ON employee_shifts(username);
CREATE INDEX IF NOT EXISTS idx_shifts_active ON employee_shifts(is_active);
"""


MYSQL_SCHEMA_STATEMENTS: List[str] = [
    """
    CREATE TABLE IF NOT EXISTS activities (
        activity_id VARCHAR(255) NOT NULL,
        project_code VARCHAR(64) NOT NULL DEFAULT '',
        label VARCHAR(255) NOT NULL,
        sort_order INT NOT NULL,
        plan_start TEXT NULL,
        plan_end TEXT NULL,
        planned_members INT NULL,
        planned_duration_ms BIGINT NULL,
        notes TEXT NULL,
        phase_id TEXT NULL,
        phase_label TEXT NULL,
        PRIMARY KEY (activity_id, project_code)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """,
    """
    CREATE TABLE IF NOT EXISTS member_state (
        member_key VARCHAR(255) NOT NULL,
        project_code VARCHAR(64) NOT NULL DEFAULT '',
        member_name VARCHAR(255) NOT NULL,
        activity_id VARCHAR(255),
        running TINYINT(1) NOT NULL DEFAULT 0,
        start_ts BIGINT,
        elapsed_cached BIGINT NOT NULL DEFAULT 0,
        pause_start BIGINT,
        entered_ts BIGINT,
        current_phase VARCHAR(255),
        PRIMARY KEY (member_key, project_code)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """,
    """
    CREATE TABLE IF NOT EXISTS event_log (
        id INT AUTO_INCREMENT PRIMARY KEY,
        project_code VARCHAR(64) NOT NULL DEFAULT '',
        ts BIGINT NOT NULL,
        kind VARCHAR(64) NOT NULL,
        member_key VARCHAR(255),
        details LONGTEXT,
        INDEX idx_event_project (project_code)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """,
    """
    CREATE TABLE IF NOT EXISTS app_state (
        `key` VARCHAR(128) PRIMARY KEY,
        value TEXT NOT NULL
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """,
    """
    CREATE TABLE IF NOT EXISTS push_subscriptions (
        id INT AUTO_INCREMENT PRIMARY KEY,
        username VARCHAR(190) NOT NULL,
        endpoint VARCHAR(500) NOT NULL UNIQUE,
        p256dh VARCHAR(255) NOT NULL,
        auth VARCHAR(128) NOT NULL,
        content_encoding VARCHAR(32) DEFAULT NULL,
        user_agent VARCHAR(255) DEFAULT NULL,
        expiration_time BIGINT DEFAULT NULL,
        created_ts BIGINT NOT NULL,
        updated_ts BIGINT NOT NULL,
        INDEX idx_push_username (username)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """,
    """
    CREATE TABLE IF NOT EXISTS push_notification_log (
        id INT AUTO_INCREMENT PRIMARY KEY,
        kind VARCHAR(32) NOT NULL,
        activity_id VARCHAR(255) DEFAULT NULL,
        username VARCHAR(190) DEFAULT NULL,
        title VARCHAR(255) NOT NULL,
        body TEXT,
        payload LONGTEXT,
        sent_ts BIGINT NOT NULL,
        created_ts BIGINT NOT NULL,
        read_at BIGINT DEFAULT NULL,
        INDEX idx_push_log_user (username),
        INDEX idx_push_log_sent (sent_ts)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """,
    APP_USERS_TABLE_MYSQL,
    SESSION_OVERRIDES_TABLE_MYSQL,
    EQUIPMENT_CHECKS_TABLE_MYSQL,
    PROJECT_MATERIALS_CACHE_TABLE_MYSQL,
    LOCAL_EQUIPMENT_TABLE_MYSQL,
]


_DATABASE_SETTINGS: Optional[Dict[str, Any]] = None


REQUIRED_ACTIVITY_COLUMNS: Dict[str, str] = {
    "plan_start": "TEXT",
    "plan_end": "TEXT",
    "planned_members": "INTEGER",
    "planned_duration_ms": "BIGINT",
    "notes": "TEXT",
    "phase_id": "TEXT",
    "phase_label": "TEXT",
}

_ACTIVITY_SCHEMA_READY = False


def _get_existing_columns(db: DatabaseLike, table: str) -> Set[str]:
    columns: Set[str] = set()
    if DB_VENDOR == "mysql":
        query = (
            "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS "
            "WHERE TABLE_SCHEMA=? AND TABLE_NAME=?"
        )
        rows = db.execute(query, (DATABASE_SETTINGS["name"], table)).fetchall()
        for row in rows:
            if isinstance(row, Mapping):
                columns.add(str(row.get("COLUMN_NAME")))
            elif isinstance(row, Sequence) and row:
                columns.add(str(row[0]))
    else:
        rows = db.execute(f"PRAGMA table_info({table})").fetchall()
        for row in rows:
            if isinstance(row, Mapping):
                columns.add(str(row.get("name")))
            elif isinstance(row, Sequence) and len(row) > 1:
                columns.add(str(row[1]))
    return {str(col).lower() for col in columns if col}


def ensure_activity_schema(db: DatabaseLike) -> None:
    global _ACTIVITY_SCHEMA_READY
    if _ACTIVITY_SCHEMA_READY:
        return
    try:
        existing = _get_existing_columns(db, "activities")
    except Exception:
        return
    alter_template = (
        "ALTER TABLE activities ADD COLUMN {name} {definition}"
        if DB_VENDOR == "mysql"
        else "ALTER TABLE activities ADD COLUMN {name} {definition}"
    )
    for name, definition in REQUIRED_ACTIVITY_COLUMNS.items():
        if name.lower() in existing:
            continue
        db.execute(alter_template.format(name=name, definition=definition))
    _ACTIVITY_SCHEMA_READY = True


_PROJECT_CODE_MIGRATION_DONE = False


def ensure_project_code_columns(db: DatabaseLike) -> None:
    """Migra le tabelle esistenti per aggiungere la colonna project_code."""
    global _PROJECT_CODE_MIGRATION_DONE
    if _PROJECT_CODE_MIGRATION_DONE:
        return
    
    tables_to_migrate = {
        "activities": "VARCHAR(64) NOT NULL DEFAULT ''" if DB_VENDOR == "mysql" else "TEXT NOT NULL DEFAULT ''",
        "member_state": "VARCHAR(64) NOT NULL DEFAULT ''" if DB_VENDOR == "mysql" else "TEXT NOT NULL DEFAULT ''",
        "event_log": "VARCHAR(64) NOT NULL DEFAULT ''" if DB_VENDOR == "mysql" else "TEXT NOT NULL DEFAULT ''",
    }
    
    for table, col_def in tables_to_migrate.items():
        try:
            existing = _get_existing_columns(db, table)
            if "project_code" not in existing:
                db.execute(f"ALTER TABLE {table} ADD COLUMN project_code {col_def}")
                app.logger.info("Aggiunta colonna project_code a tabella %s", table)
        except Exception as e:
            app.logger.warning("Impossibile aggiungere project_code a %s: %s", table, e)
    
    # Aggiungi indice su event_log se non esiste
    try:
        if DB_VENDOR == "mysql":
            # MySQL: verifica se l'indice esiste
            idx_check = db.execute(
                "SELECT COUNT(*) as cnt FROM INFORMATION_SCHEMA.STATISTICS WHERE TABLE_SCHEMA=%s AND TABLE_NAME='event_log' AND INDEX_NAME='idx_event_project'",
                (DATABASE_SETTINGS["name"],)
            ).fetchone()
            cnt = idx_check["cnt"] if isinstance(idx_check, Mapping) else idx_check[0]
            if cnt == 0:
                db.execute("CREATE INDEX idx_event_project ON event_log(project_code)")
        else:
            db.execute("CREATE INDEX IF NOT EXISTS idx_event_project ON event_log(project_code)")
    except Exception as e:
        app.logger.warning("Impossibile creare indice idx_event_project: %s", e)
    
    _PROJECT_CODE_MIGRATION_DONE = True


def get_database_settings(force_refresh: bool = False) -> Dict[str, Any]:
    """Restituisce le impostazioni DB combinando env e config.json."""

    global _DATABASE_SETTINGS
    if _DATABASE_SETTINGS is not None and not force_refresh:
        return _DATABASE_SETTINGS

    config = load_config()
    db_section = config.get("database")
    raw_db: Dict[str, Any] = db_section if isinstance(db_section, dict) else {}

    def read(key: str, env_key: str, default: Any = None) -> Any:
        env_value = os.environ.get(env_key)
        if env_value not in (None, ""):
            return env_value
        if key in raw_db:
            value = raw_db.get(key)
            if value not in (None, ""):
                return value
        return default

    vendor = str(read("vendor", "JOBLOG_DB_VENDOR", "sqlite") or "sqlite").lower()
    port_value = read("port", "JOBLOG_DB_PORT", 3306)
    try:
        port = int(port_value)
    except (TypeError, ValueError):  # pragma: no cover - configurazione invalida
        port = 3306

    settings = {
        "vendor": vendor,
        "host": read("host", "JOBLOG_DB_HOST", "localhost"),
        "port": port,
        "user": read("user", "JOBLOG_DB_USER", "root"),
        "password": read("password", "JOBLOG_DB_PASSWORD", ""),
        "name": read("name", "JOBLOG_DB_NAME", "joblog"),
    }

    _DATABASE_SETTINGS = settings
    return settings


DATABASE_SETTINGS = get_database_settings()
DB_VENDOR = DATABASE_SETTINGS["vendor"]
APP_STATE_KEY_COLUMN = "`key`" if DB_VENDOR == "mysql" else "key"


def get_webpush_settings(force_refresh: bool = False) -> Optional[Dict[str, str]]:
    """Restituisce le impostazioni VAPID per il Web Push, se configurate."""

    global _WEBPUSH_SETTINGS
    if _WEBPUSH_SETTINGS is not None and not force_refresh:
        return cast(Optional[Dict[str, str]], _WEBPUSH_SETTINGS)

    config = load_config()
    section = config.get("webpush")
    raw_section: Dict[str, Any] = section if isinstance(section, dict) else {}

    def read(key: str, env_key: str) -> Optional[str]:
        value = os.environ.get(env_key)
        if value not in (None, ""):
            return value.strip()
        candidate = raw_section.get(key)
        if isinstance(candidate, str) and candidate.strip():
            return candidate.strip()
        return None

    public = read("vapid_public", "WEBPUSH_VAPID_PUBLIC")
    private = read("vapid_private", "WEBPUSH_VAPID_PRIVATE")
    subject = read("subject", "WEBPUSH_VAPID_SUBJECT")

    if not public or not private or not subject:
        _WEBPUSH_SETTINGS = None
        return None

    _WEBPUSH_SETTINGS = {
        "vapid_public": public,
        "vapid_private": private,
        "subject": subject,
    }
    return cast(Dict[str, str], _WEBPUSH_SETTINGS)


def get_rentman_client() -> Optional[RentmanClient]:
    """Istanzia il client Rentman solo quando disponibile un token valido."""

    global _RENTMAN_CLIENT, _RENTMAN_CLIENT_TOKEN

    token = (os.environ.get("RENTMAN_API_TOKEN") or "").strip()
    if not token:
        config = load_config()
        token = str(config.get("rentman_api_token") or "").strip()
        if token:
            app.logger.warning("Rentman: uso token da config.json")

    if not token:
        app.logger.warning("Rentman: token non trovato (env o config)")
        return None

    if _RENTMAN_CLIENT and _RENTMAN_CLIENT_TOKEN == token:
        return _RENTMAN_CLIENT

    try:
        client = RentmanClient(token=token)
    except RentmanAuthError as exc:
        app.logger.warning("Rentman: token non valido (%s)", exc)
        return None

    app.logger.debug("Rentman: client inizializzato con token attivo")

    _RENTMAN_CLIENT = client
    _RENTMAN_CLIENT_TOKEN = token
    return client


def parse_reference(reference: Any) -> Optional[int]:
    """Estrae l'identificativo numerico da un riferimento Rentman."""

    if reference is None:
        return None

    if isinstance(reference, int):
        return reference

    if isinstance(reference, dict):
        candidate = reference.get("id") or reference.get("href") or reference.get("resource")
        if isinstance(candidate, int):
            return candidate
        reference = candidate

    if isinstance(reference, str):
        slug = reference.strip()
        if not slug:
            return None
        slug = slug.strip("/")
        last_segment = slug.split("/")[-1]
        last_segment = last_segment.split("?")[0]
        try:
            return int(last_segment)
        except ValueError:
            return None

    return None


def fetch_rentman_plan(project_code: str, project_date: Optional[str] = None) -> Optional[Dict[str, Any]]:
    """Recupera da Rentman le funzioni equiparate alle attività e il relativo crew."""

    client = get_rentman_client()
    if not client:
        return None

    app.logger.warning("Rentman: ricerca progetto per codice '%s' (data: %s)", project_code, project_date)

    try:
        project = client.find_project(project_code)
        app.logger.info(
            "Rentman: payload progetto=\n%s",
            json.dumps(project, ensure_ascii=False, indent=2) if project else "{}",
        )
    except RentmanNotFound:
        app.logger.warning("Rentman: progetto %s non trovato", project_code)
        return None
    except RentmanAuthError as exc:
        app.logger.error("Rentman: autenticazione fallita (%s)", exc)
        return None
    except RentmanAPIError as exc:
        app.logger.error("Rentman: errore recuperando il progetto %s: %s", project_code, exc)
        return None

    if not project:
        app.logger.warning(
            "Rentman: nessun progetto associato al codice %s (number/reference)",
            project_code,
        )
        return None

    project_id = parse_reference(project.get("id")) or project.get("id")
    if not isinstance(project_id, int):
        app.logger.error("Rentman: progetto %s senza id valido", project_code)
        return None

    try:
        subprojects = client.get_project_subprojects(project_id)
        app.logger.info(
            "Rentman: payload subprojects=\n%s",
            json.dumps(subprojects, ensure_ascii=False, indent=2),
        )
    except RentmanNotFound:
        subprojects = []
    except RentmanAPIError as exc:
        app.logger.error(
            "Rentman: errore leggendo i subprojects del progetto %s: %s",
            project_code,
            exc,
        )
        subprojects = []

    subproject_labels: Dict[int, str] = {}
    for sub in subprojects:
        sub_id = parse_reference(sub.get("id")) or sub.get("id")
        if not isinstance(sub_id, int):
            continue
        label = (
            sub.get("displayname")
            or sub.get("name")
            or sub.get("description")
            or str(sub_id)
        )
        subproject_labels[sub_id] = str(label)

    # ── Funzioni del progetto ──────────────────────────────────────────
    try:
        functions = client.get_project_functions(project_id)
        app.logger.info(
            "Rentman: payload funzioni=\n%s",
            json.dumps(functions, ensure_ascii=False, indent=2),
        )
    except RentmanNotFound:
        functions = []
    except RentmanAPIError as exc:
        app.logger.error(
            "Rentman: errore leggendo le funzioni del progetto %s: %s",
            project_code,
            exc,
        )
        functions = []

    # ── Function Groups (fasi) del progetto ────────────────────────────
    try:
        function_groups = client.get_project_function_groups(project_id)
        app.logger.info(
            "Rentman: payload function groups=\n%s",
            json.dumps(function_groups, ensure_ascii=False, indent=2),
        )
    except (RentmanNotFound, RentmanAPIError) as exc:
        app.logger.warning("Rentman: function groups non disponibili per %s: %s", project_code, exc)
        function_groups = []

    # Mappa group_id → info fase
    group_map: Dict[int, Dict[str, Any]] = {}
    for grp in function_groups:
        grp_id = parse_reference(grp.get("id")) or grp.get("id")
        if isinstance(grp_id, int):
            group_map[grp_id] = {
                "name": grp.get("name") or grp.get("displayname") or f"Fase {grp_id}",
                "planperiod_start": _normalize_datetime(grp.get("planperiod_start")),
                "planperiod_end": _normalize_datetime(grp.get("planperiod_end")),
            }

    # Mappa function_id → entry per lookup rapido
    function_map: Dict[int, Dict[str, Any]] = {}
    for entry in functions:
        func_id = parse_reference(entry.get("id")) or entry.get("id")
        if isinstance(func_id, int) and func_id not in function_map:
            function_map[func_id] = entry

    # ── Crew dalla pianificazione del progetto ─────────────────────────
    # Usiamo /projects/{id}/projectcrew che restituisce TUTTA la crew
    # pianificata con i rispettivi planperiod_start / planperiod_end.
    crew_assignments = client.get_project_crew(project_id)
    app.logger.info(
        "Rentman: crew pianificata totale=%d record",
        len(crew_assignments),
    )

    # Se non ci sono record dalla rotta diretta, fallback per function_ids
    if not crew_assignments and function_map:
        all_function_ids = list(function_map)
        try:
            crew_assignments = client.get_project_crew_by_function_ids(all_function_ids)
            app.logger.info(
                "Rentman: fallback crew by function_ids=%d record",
                len(crew_assignments),
            )
        except (RentmanNotFound, RentmanAPIError) as exc:
            app.logger.warning("Rentman: fallback crew fallito: %s", exc)
            crew_assignments = []

    if crew_assignments:
        app.logger.info(
            "Rentman: payload crew assignments=\n%s",
            json.dumps(crew_assignments, ensure_ascii=False, indent=2),
        )

    # ── Filtra crew per planperiod (data della pianificazione) ─────────
    def _crew_matches_date(assignment: Dict[str, Any], target_date: str) -> bool:
        """Verifica se il planperiod del record crew include la data selezionata."""
        ps = _normalize_datetime(assignment.get("planperiod_start"))
        pe = _normalize_datetime(assignment.get("planperiod_end"))
        return _activity_matches_date(ps, pe, target_date)

    filtered_crew = crew_assignments
    if project_date and crew_assignments:
        date_filtered = [a for a in crew_assignments if _crew_matches_date(a, project_date)]
        if date_filtered:
            app.logger.info(
                "Rentman: crew filtrata per data '%s': %d/%d record",
                project_date,
                len(date_filtered),
                len(crew_assignments),
            )
            filtered_crew = date_filtered
        else:
            app.logger.warning(
                "Rentman: nessuna crew per data '%s', uso tutta la crew (%d record)",
                project_date,
                len(crew_assignments),
            )

    # ── Determina le funzioni usate dalla crew ─────────────────────────
    used_function_ids: Set[int] = set()
    for assignment in filtered_crew:
        func_id = parse_reference(assignment.get("function"))
        if isinstance(func_id, int):
            used_function_ids.add(func_id)

    app.logger.info("Rentman: funzioni usate dalla crew=%s", sorted(used_function_ids))

    # ── Costruisci attività dalle funzioni che hanno crew ──────────────
    activity_lookup: Dict[int, str] = {}
    activities: List[Dict[str, Any]] = []
    for func_id in sorted(used_function_ids):
        entry = function_map.get(func_id)
        if not entry:
            # Funzione non trovata nel payload functions — crea entry minimale
            activity_id = f"rentman-f-{func_id}"
            activities.append({
                "id": activity_id,
                "label": f"Funzione {func_id} [ID {func_id}]",
                "plan_start": None,
                "plan_end": None,
                "phase_id": None,
                "phase_label": None,
            })
            activity_lookup[func_id] = activity_id
            continue

        activity_id = f"rentman-f-{func_id}"
        label = (
            entry.get("name")
            or entry.get("displayname")
            or entry.get("description")
            or f"Funzione {func_id}"
        )
        label = f"{label} [ID {func_id}]"

        plan_start = (
            _normalize_datetime(entry.get("planperiod_start"))
            or _normalize_datetime(entry.get("usageperiod_start"))
        )
        plan_end = (
            _normalize_datetime(entry.get("planperiod_end"))
            or _normalize_datetime(entry.get("usageperiod_end"))
        )

        # Determina la fase (function group) della funzione
        func_group_ref = entry.get("group")
        func_group_id = parse_reference(func_group_ref) if func_group_ref else None
        phase_info = group_map.get(func_group_id) if isinstance(func_group_id, int) else None

        activities.append({
            "id": activity_id,
            "label": str(label),
            "plan_start": plan_start,
            "plan_end": plan_end,
            "phase_id": f"rentman-fg-{func_group_id}" if phase_info else None,
            "phase_label": phase_info["name"] if phase_info else None,
        })
        activity_lookup[func_id] = activity_id

    activities.sort(key=lambda item: (item.get("phase_label") or "", item["label"].lower()))
    app.logger.info(
        "Rentman: funzioni considerate=%s",
        json.dumps(activities, ensure_ascii=False, indent=2),
    )

    valid_function_ids: Set[int] = set(activity_lookup)
    crew_ids: Set[int] = set()
    for assignment in filtered_crew:
        member_id = parse_reference(assignment.get("crewmember"))
        function_id = parse_reference(assignment.get("function"))
        if not isinstance(function_id, int) or function_id not in valid_function_ids:
            continue
        if isinstance(member_id, int):
            crew_ids.add(member_id)

    crew_details: List[Dict[str, Any]] = []
    if crew_ids:
        try:
            crew_details = client.get_crew_members_by_ids(crew_ids)
            app.logger.info(
                "Rentman: payload crew details=\n%s",
                json.dumps(crew_details, ensure_ascii=False, indent=2),
            )
        except RentmanNotFound:
            crew_details = []
        except RentmanAPIError as exc:
            app.logger.error(
                "Rentman: errore leggendo i membri crew del progetto %s: %s",
                project_code,
                exc,
            )
            crew_details = []

    crew_map: Dict[int, Dict[str, Any]] = {}
    for member in crew_details:
        member_id = parse_reference(member.get("id")) or member.get("id")
        if isinstance(member_id, int):
            crew_map[member_id] = member

    team: List[Dict[str, Any]] = []
    seen_members: Set[str] = set()
    for assignment in filtered_crew:
        assignment_id = assignment.get("id")
        member_id = parse_reference(assignment.get("crewmember"))
        function_id = parse_reference(assignment.get("function"))

        if (
            not isinstance(assignment_id, int)
            or member_id is None
            or function_id is None
            or function_id not in valid_function_ids
        ):
            continue

        activity_id = activity_lookup.get(function_id)
        if not activity_id:
            continue

        crew_info = crew_map.get(member_id, {})
        display_name = (
            crew_info.get("displayname")
            or crew_info.get("name")
            or assignment.get("displayname")
            or assignment.get("name")
            or "Operatore"
        )

        member_key = f"rentman-crew-{assignment_id}"
        if member_key in seen_members:
            continue
        seen_members.add(member_key)

        team.append(
            {
                "key": member_key,
                "name": str(display_name),
                "activity_id": activity_id,
            }
        )

    project_name = (
        project.get("name")
        or project.get("displayname")
        or project.get("description")
        or project_code
    )

    plan = {
        "project_code": str(project.get("number") or project_code),
        "project_name": str(project_name),
        "activities": activities,
        "team": team,
    }

    return plan


def _normalize_attachment_name(entry: Mapping[str, Any]) -> str:
    for key in (
        "readable_name",
        "displayname",
        "friendly_name_without_extension",
        "name_without_extension",
    ):
        value = entry.get(key)
        if isinstance(value, str) and value.strip():
            return value.strip()
    identifier = entry.get("id")
    return f"Allegato {identifier}" if identifier is not None else "Allegato"


def _normalize_attachment_extension(value: Any) -> str:
    if not isinstance(value, str):
        return ""
    slug = value.strip().lstrip(".")
    return slug.upper()

ATTACHMENT_IMAGE_EXTENSIONS: Set[str] = {
    "JPG",
    "JPEG",
    "PNG",
    "GIF",
    "WEBP",
    "BMP",
    "TIFF",
    "HEIC",
}


def _attachment_is_image(entry: Mapping[str, Any]) -> bool:
    if _is_truthy(entry.get("image")):
        return True
    extension = _normalize_attachment_extension(entry.get("extension") or entry.get("type"))
    if extension and extension in ATTACHMENT_IMAGE_EXTENSIONS:
        return True
    description = entry.get("description")
    if isinstance(description, str):
        slug = description.lower()
        if any(token in slug for token in ("photo", "immagine", "preview")):
            return True
    return False


def _folder_display_name(entry: Mapping[str, Any]) -> str:
    for key in ("displayname", "name", "readable_name"):
        value = entry.get(key)
        if isinstance(value, str) and value.strip():
            return value.strip()
    identifier = entry.get("id")
    return f"Cartella {identifier}" if identifier is not None else "Cartella"


def _build_folder_path(folder_id: int, lookup: Mapping[int, Mapping[str, Any]], max_depth: int = 20) -> str:
    parts: List[str] = []
    current = folder_id
    visited: Set[int] = set()
    depth = 0
    while isinstance(current, int) and current not in visited and depth < max_depth:
        visited.add(current)
        entry = lookup.get(current)
        if not entry:
            break
        parts.append(_folder_display_name(entry))
        current = parse_reference(entry.get("parent"))
        depth += 1
    if not parts:
        return ""
    return " / ".join(reversed(parts))


def _collect_project_folders(client: RentmanClient, project_id: int) -> List[Dict[str, Any]]:
    try:
        raw_folders = client.get_project_file_folders(project_id)
    except RentmanError as exc:
        app.logger.error("Rentman: errore recuperando le cartelle file del progetto %s: %s", project_id, exc)
        return []

    folder_lookup: Dict[int, Mapping[str, Any]] = {}
    for entry in raw_folders:
        folder_id = parse_reference(entry.get("id")) or entry.get("id")
        if isinstance(folder_id, int):
            folder_lookup[folder_id] = entry

    try:
        raw_files = client.get_project_files(project_id, exhaustive=False)
    except RentmanError as exc:
        app.logger.error("Rentman: errore recuperando i file per il progetto %s: %s", project_id, exc)
        raw_files = []

    folder_files: Dict[int, List[Dict[str, Any]]] = {}
    for entry in raw_files:
        folder_id = parse_reference(entry.get("folder"))
        if not isinstance(folder_id, int):
            continue
        normalized = {
            "id": entry.get("id"),
            "name": _normalize_attachment_name(entry),
            "extension": _normalize_attachment_extension(entry.get("extension") or entry.get("type")),
            "url": entry.get("url"),
            "preview_url": entry.get("proxy_url") or entry.get("url"),
            "image": _attachment_is_image(entry),
        }
        folder_files.setdefault(folder_id, []).append(normalized)

    folders: List[Dict[str, Any]] = []
    for folder_id, entry in folder_lookup.items():
        parent_id = parse_reference(entry.get("parent"))
        path_value = entry.get("path") or _build_folder_path(folder_id, folder_lookup)
        files = folder_files.get(folder_id, [])
        image_file = next((item for item in files if item.get("image")), None)
        if not image_file and files:
            image_file = files[0]
        folders.append(
            {
                "id": folder_id,
                "name": _folder_display_name(entry),
                "parent_id": parent_id,
                "path": path_value or _folder_display_name(entry),
                "file_count": len(files),
                "photo": {
                    "name": image_file.get("name"),
                    "url": image_file.get("url"),
                    "preview_url": image_file.get("preview_url"),
                    "extension": image_file.get("extension"),
                }
                if image_file
                else None,
            }
        )

    folders.sort(key=lambda item: str(item.get("path") or item.get("name") or "").lower())
    return folders


def _equipment_group_display_name(entry: Mapping[str, Any]) -> str:
    for key in ("path", "displayname", "name", "description"):
        value = entry.get(key)
        if isinstance(value, str) and value.strip():
            return value.strip()
    identifier = entry.get("id")
    return f"Gruppo {identifier}" if identifier is not None else "Gruppo"


def _build_equipment_group_path(
    group_id: int,
    lookup: Mapping[int, Mapping[str, Any]],
    *,
    max_depth: int = 20,
) -> str:
    parts: List[str] = []
    current = group_id
    visited: Set[int] = set()
    depth = 0
    while isinstance(current, int) and current not in visited and depth < max_depth:
        visited.add(current)
        entry = lookup.get(current)
        if not entry:
            break
        parts.append(_equipment_group_display_name(entry))
        current = parse_reference(entry.get("parent"))
        depth += 1
    if not parts:
        return ""
    return " / ".join(reversed(parts))


def _collect_material_groups(client: RentmanClient, project_id: int) -> Dict[int, Dict[str, Any]]:
    try:
        raw_groups = client.get_project_equipment_groups(project_id)
    except RentmanError as exc:
        app.logger.error("Rentman: errore recuperando i gruppi materiali del progetto %s: %s", project_id, exc)
        return {}

    group_lookup: Dict[int, Mapping[str, Any]] = {}
    for entry in raw_groups:
        group_id = parse_reference(entry.get("id")) or entry.get("id")
        if isinstance(group_id, int):
            group_lookup[group_id] = entry

    result: Dict[int, Dict[str, Any]] = {}
    for group_id, entry in group_lookup.items():
        parent_id = parse_reference(entry.get("parent"))
        path_value = entry.get("path")
        if not isinstance(path_value, str) or not path_value.strip():
            path_value = _build_equipment_group_path(group_id, group_lookup)
        result[group_id] = {
            "id": group_id,
            "name": _equipment_group_display_name(entry),
            "parent_id": parent_id,
            "path": path_value or _equipment_group_display_name(entry),
        }

    return result


def fetch_project_attachments(project_code: Optional[str], *, exhaustive: bool = False) -> List[Dict[str, Any]]:
    attachments: List[Dict[str, Any]] = []
    code = (project_code or "").strip()
    if not code:
        return attachments

    client = get_rentman_client()
    if not client:
        return attachments

    try:
        project = client.find_project(code)
    except RentmanNotFound:
        app.logger.warning("Rentman: nessun progetto per allegati %s", code)
        return attachments
    except (RentmanAuthError, RentmanAPIError) as exc:
        app.logger.error("Rentman: errore durante la ricerca degli allegati per %s: %s", code, exc)
        return attachments

    if not project:
        app.logger.info("Rentman: progetto %s non trovato, nessun allegato", code)
        return attachments

    project_id = parse_reference(project.get("id")) or project.get("id")
    if not isinstance(project_id, int):
        app.logger.warning("Rentman: allegati non disponibili, id progetto non valido per %s (%s)", code, project.get("id"))
        return attachments

    try:
        app.logger.info(
            "Rentman: recupero allegati progetto %s (id=%s, exhaustive=%s)",
            code,
            project_id,
            exhaustive,
        )
        files = client.get_project_files(project_id, exhaustive=exhaustive)
        app.logger.info(
            "Rentman: payload files raw (primi 3)=\n%s",
            json.dumps(files[:3], ensure_ascii=False, indent=2) if files else "[]",
        )
    except RentmanNotFound:
        app.logger.warning("Rentman: endpoint files non trovato (404) per progetto %s", code)
        files = []
    except RentmanAuthError as exc:
        app.logger.error("Rentman: autenticazione fallita leggendo allegati per %s: %s", code, exc)
        files = []
    except RentmanAPIError as exc:
        app.logger.error(
            "Rentman: errore leggendo gli allegati del progetto %s: %s",
            code,
            exc,
        )
        files = []

    app.logger.info("Rentman: ricevuti %s allegati per progetto %s", len(files), code)

    for entry in files:
        if not isinstance(entry, Mapping):
            continue
        attachments.append(
            {
                "id": entry.get("id"),
                "name": _normalize_attachment_name(entry),
                "created": entry.get("created"),
                "type": _normalize_attachment_extension(entry.get("extension") or entry.get("type")),
                "size": entry.get("size"),
                "url": entry.get("url"),
                "preview_url": entry.get("proxy_url") or entry.get("url"),
            }
        )

    attachments.sort(key=lambda item: str(item.get("name") or "").lower())
    return attachments


def _normalize_material_name(entry: Mapping[str, Any]) -> str:
    for key in ("displayname", "name", "description"):
        value = entry.get(key)
        if isinstance(value, str) and value.strip():
            return value.strip()
    identifier = entry.get("id")
    return f"Materiale {identifier}" if identifier is not None else "Materiale"


def _extract_material_quantity(entry: Mapping[str, Any]) -> Tuple[Optional[float], str]:
    numeric_candidate = entry.get("quantity_total")
    quantity_label = ""
    quantity_value: Optional[float] = None
    if isinstance(numeric_candidate, (int, float)):
        quantity_value = float(numeric_candidate)

    raw_quantity = entry.get("quantity")
    if quantity_value is None:
        if isinstance(raw_quantity, (int, float)):
            quantity_value = float(raw_quantity)
        elif isinstance(raw_quantity, str):
            slug = raw_quantity.strip().replace(",", ".")
            try:
                quantity_value = float(slug)
            except ValueError:
                quantity_value = None

    if quantity_value is not None:
        if quantity_value.is_integer():
            quantity_label = str(int(quantity_value))
        else:
            quantity_label = f"{quantity_value:.2f}".rstrip("0").rstrip(".")

    if not quantity_label and isinstance(raw_quantity, str) and raw_quantity.strip():
        quantity_label = raw_quantity.strip()
    elif not quantity_label and isinstance(numeric_candidate, (int, float)):
        quantity_label = str(numeric_candidate)

    return quantity_value, quantity_label or "0"


def _material_status(entry: Mapping[str, Any]) -> Tuple[str, str]:
    if _is_truthy(entry.get("has_missings")):
        return "missing", "Mancanze"
    if _is_truthy(entry.get("delay_notified")):
        return "delayed", "In ritardo"
    subrent = _coerce_int(entry.get("subrent_reservations")) or 0
    if subrent > 0:
        return "subrent", "Subnoleggio"
    reserved = _coerce_int(entry.get("warehouse_reservations")) or 0
    if reserved > 0:
        return "reserved", "Riservato"
    if _is_truthy(entry.get("is_option")):
        return "option", "Opzione"
    return "planned", "Pianificato"


def _coerce_float(value: Any) -> Optional[float]:
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        slug = value.strip().replace(",", ".")
        if not slug:
            return None
        try:
            return float(slug)
        except ValueError:
            return None
    return None


def _format_dimension_value(value: Optional[float]) -> Optional[str]:
    if value is None:
        return None
    if value.is_integer():
        return str(int(value))
    return f"{value:.2f}".rstrip("0").rstrip(".")


def _format_dimensions_label(length: Optional[float], width: Optional[float], height: Optional[float]) -> str:
    components: List[str] = []
    for component in (length, width, height):
        label = _format_dimension_value(component)
        components.append(label or "0")
    if not any(component for component in components if component != "0"):
        return "---"
    return "x".join(components)


def _format_weight_label(value: Optional[float]) -> str:
    if value is None:
        return "---"
    label = _format_dimension_value(value)
    if not label:
        return "---"
    return f"{label} kg"


def _resolve_equipment_meta(
    equipment_ref: Any,
    client: RentmanClient,
    cache: Dict[int, Optional[Mapping[str, Any]]],
) -> Optional[Mapping[str, Any]]:
    equipment_id = parse_reference(equipment_ref)
    if not isinstance(equipment_id, int):
        return None
    if equipment_id in cache:
        return cache[equipment_id]
    try:
        meta = client.get_equipment(equipment_id)
    except RentmanError as exc:
        app.logger.error("Rentman: errore recuperando equipment %s: %s", equipment_id, exc)
        cache[equipment_id] = None
        return None
    cache[equipment_id] = meta
    return meta


def _resolve_photo_payload(
    reference: Any,
    client: RentmanClient,
    cache: Dict[int, Optional[Mapping[str, Any]]],
) -> Optional[Dict[str, Any]]:
    if not reference:
        return None

    if isinstance(reference, str) and reference.startswith("http"):
        return {"name": "Foto materiale", "url": reference, "preview_url": reference}

    file_id = parse_reference(reference)
    if not isinstance(file_id, int):
        return None

    if file_id in cache:
        file_entry = cache[file_id]
    else:
        try:
            file_entry = client.get_file(file_id)
        except RentmanError as exc:
            app.logger.error("Rentman: errore recuperando file %s: %s", file_id, exc)
            file_entry = None
        cache[file_id] = file_entry

    if not file_entry:
        return None

    url = file_entry.get("url")
    preview = file_entry.get("proxy_url") or url
    if not url and not preview:
        return None

    return {
        "name": _normalize_attachment_name(file_entry),
        "url": url or preview,
        "preview_url": preview or url,
        "extension": _normalize_attachment_extension(file_entry.get("extension") or file_entry.get("type")),
    }


def fetch_project_materials(project_code: Optional[str]) -> Dict[str, List[Dict[str, Any]]]:
    result: Dict[str, List[Dict[str, Any]]] = {"items": [], "folders": []}
    code = (project_code or "").strip()
    if not code:
        return result

    client = get_rentman_client()
    if not client:
        return result

    try:
        project = client.find_project(code)
    except RentmanNotFound:
        app.logger.warning("Rentman: nessun progetto per materiali %s", code)
        return result
    except (RentmanAuthError, RentmanAPIError) as exc:
        app.logger.error("Rentman: errore durante la ricerca dei materiali per %s: %s", code, exc)
        return result

    if not project:
        app.logger.info("Rentman: progetto %s non trovato, nessun materiale", code)
        return result

    project_id = parse_reference(project.get("id")) or project.get("id")
    if not isinstance(project_id, int):
        app.logger.warning("Rentman: materiali non disponibili, id progetto non valido per %s (%s)", code, project.get("id"))
        return result

    try:
        records = client.get_project_planned_equipment(project_id)
        app.logger.info(
            "Rentman: materiali pianificati raw (primi 3)=\n%s",
            json.dumps(records[:3], ensure_ascii=False, indent=2) if records else "[]",
        )
    except RentmanError as exc:
        app.logger.error("Rentman: errore leggendo i materiali del progetto %s: %s", code, exc)
        return result

    equipment_cache: Dict[int, Optional[Mapping[str, Any]]] = {}
    file_cache: Dict[int, Optional[Mapping[str, Any]]] = {}
    group_lookup = _collect_material_groups(client, project_id)
    default_group_label = "Altri materiali"
    materials: List[Dict[str, Any]] = []
    for entry in records:
        if not isinstance(entry, Mapping):
            continue
        quantity_value, quantity_label = _extract_material_quantity(entry)
        status_code, status_label = _material_status(entry)
        equipment_meta = _resolve_equipment_meta(entry.get("equipment"), client, equipment_cache)
        length = _coerce_float(entry.get("length")) or ( _coerce_float(equipment_meta.get("length")) if equipment_meta else None)
        width = _coerce_float(entry.get("width")) or ( _coerce_float(equipment_meta.get("width")) if equipment_meta else None)
        height = _coerce_float(entry.get("height")) or ( _coerce_float(equipment_meta.get("height")) if equipment_meta else None)
        weight_value = _coerce_float(entry.get("weight"))
        if weight_value is None and equipment_meta:
            weight_value = _coerce_float(equipment_meta.get("weight"))
        dimensions_label = _format_dimensions_label(length, width, height)
        weight_label = _format_weight_label(weight_value)
        image_reference = entry.get("image") or (equipment_meta.get("image") if equipment_meta else None)
        photo_payload = _resolve_photo_payload(image_reference, client, file_cache)
        group_id = parse_reference(entry.get("equipment_group"))
        group_entry = group_lookup.get(group_id) if isinstance(group_id, int) else None
        group_name = group_entry.get("name") if group_entry else default_group_label
        group_path = group_entry.get("path") if group_entry else group_name
        notes: List[str] = []
        for key in ("internal_remark", "external_remark"):
            value = entry.get(key)
            if isinstance(value, str):
                stripped = value.strip()
                if stripped:
                    notes.append(stripped)
        note_text = " · ".join(dict.fromkeys(notes)) if notes else ""
        materials.append(
            {
                "id": entry.get("id"),
                "name": _normalize_material_name(entry),
                "quantity": quantity_value,
                "quantity_label": quantity_label,
                "period_start": entry.get("planperiod_start"),
                "period_end": entry.get("planperiod_end"),
                "note": note_text,
                "status": status_label,
                "status_code": status_code,
                "has_missings": bool(_is_truthy(entry.get("has_missings"))),
                "is_option": bool(_is_truthy(entry.get("is_option"))),
                "dimensions_label": dimensions_label,
                "weight_label": weight_label,
                "photo": photo_payload,
                "group_id": group_id,
                "group_name": group_name,
                "group_path": group_path,
            }
        )

    materials.sort(
        key=lambda item: (
            str(item.get("group_path") or item.get("group_name") or "").lower(),
            item.get("status_code"),
            str(item.get("name") or "").lower(),
        )
    )

    folders = _collect_project_folders(client, project_id)
    result["items"] = materials
    result["folders"] = folders
    return result


def now_ms() -> int:
    return int(time.time() * 1000)


def ensure_app_users_table(db: DatabaseLike) -> None:
    statement = APP_USERS_TABLE_MYSQL if DB_VENDOR == "mysql" else APP_USERS_TABLE_SQLITE
    cursor = db.execute(statement)
    try:
        cursor.close()
    except AttributeError:
        pass
    
    # Migrazione: aggiungi colonna full_name se non esiste
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN full_name VARCHAR(255) DEFAULT NULL")
            db.commit()
        except Exception:
            pass  # Colonna già esistente
        # Migrazione: aggiungi colonna rentman_crew_id se non esiste
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN rentman_crew_id INT DEFAULT NULL")
            db.commit()
        except Exception:
            pass  # Colonna già esistente
        # Migrazione: aggiungi colonne per progetto corrente supervisor
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN current_project_code VARCHAR(64) DEFAULT NULL")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN current_project_name VARCHAR(255) DEFAULT NULL")
            db.commit()
        except Exception:
            pass
        # Migrazione: aggiungi colonne external_id e external_group_id per CedolinoWeb
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN external_id VARCHAR(255) DEFAULT NULL")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN external_group_id VARCHAR(255) DEFAULT NULL")
            db.commit()
        except Exception:
            pass
    else:
        # SQLite
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN full_name TEXT")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN rentman_crew_id INTEGER")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN current_project_code TEXT")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN current_project_name TEXT")
            db.commit()
        except Exception:
            pass
        # Migrazione: aggiungi colonne external_id e external_group_id per CedolinoWeb
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN external_id TEXT")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN external_group_id TEXT")
            db.commit()
        except Exception:
            pass
    
    # Migrazione: aggiungi colonna group_id per collegamento a user_groups
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN group_id INT DEFAULT NULL")
            db.commit()
        except Exception:
            pass
    else:
        try:
            db.execute("ALTER TABLE app_users ADD COLUMN group_id INTEGER DEFAULT NULL")
            db.commit()
        except Exception:
            pass


def ensure_user_groups_table(db: DatabaseLike) -> None:
    """Crea la tabella user_groups se non esiste."""
    statement = USER_GROUPS_TABLE_MYSQL if DB_VENDOR == "mysql" else USER_GROUPS_TABLE_SQLITE
    cursor = db.execute(statement)
    try:
        cursor.close()
    except AttributeError:
        pass
    
    # Migrazione: aggiunge colonna gps_location_name se non esiste
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE user_groups ADD COLUMN gps_location_name VARCHAR(255) DEFAULT NULL COMMENT 'Nome sede GPS associata al gruppo'")
        else:
            db.execute("ALTER TABLE user_groups ADD COLUMN gps_location_name TEXT DEFAULT NULL")
        db.commit()
    except Exception:
        pass  # Colonna già esistente
    
    # Migrazione: aggiunge colonna is_production se non esiste
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE user_groups ADD COLUMN is_production TINYINT(1) NOT NULL DEFAULT 0 COMMENT 'Flag per gruppi di produzione'")
        else:
            db.execute("ALTER TABLE user_groups ADD COLUMN is_production INTEGER NOT NULL DEFAULT 0")
        db.commit()
    except Exception:
        pass  # Colonna già esistente


def ensure_session_override_table(db: DatabaseLike) -> None:
    if DB_VENDOR == "mysql":
        cursor = db.execute(SESSION_OVERRIDES_TABLE_MYSQL)
        try:
            cursor.close()
        except AttributeError:
            pass
        # Migrazione: aggiungi colonna project_code se non esiste
        try:
            db.execute("ALTER TABLE activity_session_overrides ADD COLUMN project_code VARCHAR(64) DEFAULT NULL")
            db.commit()
        except Exception:
            pass  # Colonna già esistente
        try:
            db.execute("CREATE INDEX idx_session_override_project ON activity_session_overrides(project_code)")
            db.commit()
        except Exception:
            pass  # Indice già esistente


def ensure_persistent_session_table(db: DatabaseLike) -> None:
    statement = (
        PERSISTENT_SESSIONS_TABLE_MYSQL if DB_VENDOR == "mysql" else PERSISTENT_SESSIONS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_equipment_checks_table(db: DatabaseLike) -> None:
    statement = EQUIPMENT_CHECKS_TABLE_MYSQL if DB_VENDOR == "mysql" else EQUIPMENT_CHECKS_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_project_materials_cache_table(db: DatabaseLike) -> None:
    statement = (
        PROJECT_MATERIALS_CACHE_TABLE_MYSQL if DB_VENDOR == "mysql" else PROJECT_MATERIALS_CACHE_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_push_notification_read_column(db: DatabaseLike) -> None:
    """Assicura che la colonna read_at esista in push_notification_log."""
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE push_notification_log ADD COLUMN read_at BIGINT DEFAULT NULL")
            db.commit()
        except Exception:
            pass  # Colonna già esistente
    else:
        try:
            db.execute("ALTER TABLE push_notification_log ADD COLUMN read_at INTEGER DEFAULT NULL")
            db.commit()
        except Exception:
            pass  # Colonna già esistente


def ensure_local_equipment_table(db: DatabaseLike) -> None:
    statement = LOCAL_EQUIPMENT_TABLE_MYSQL if DB_VENDOR == "mysql" else LOCAL_EQUIPMENT_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_project_photos_table(db: DatabaseLike) -> None:
    statement = PROJECT_PHOTOS_TABLE_MYSQL if DB_VENDOR == "mysql" else PROJECT_PHOTOS_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_employee_shifts_table(db: DatabaseLike) -> None:
    """Assicura l'esistenza della tabella employee_shifts per turni impiegati non-Rentman."""
    statement = EMPLOYEE_SHIFTS_TABLE_MYSQL if DB_VENDOR == "mysql" else EMPLOYEE_SHIFTS_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Migrazione: aggiunge colonna location_name se non esiste
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE employee_shifts ADD COLUMN location_name VARCHAR(255) DEFAULT NULL COMMENT 'Nome sede GPS associata al turno'")
        else:
            db.execute("ALTER TABLE employee_shifts ADD COLUMN location_name TEXT")
        db.commit()
    except Exception:
        pass  # Colonna già esistente
    
    # Migrazione: aggiunge colonna shift_name se non esiste
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE employee_shifts ADD COLUMN shift_name VARCHAR(100) DEFAULT NULL COMMENT 'Nome identificativo del turno' AFTER break_end")
        else:
            db.execute("ALTER TABLE employee_shifts ADD COLUMN shift_name TEXT")
        db.commit()
    except Exception:
        pass  # Colonna già esistente


# Cartella per salvare le foto del progetto
PHOTOS_UPLOAD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), "uploads", "photos")
os.makedirs(PHOTOS_UPLOAD_FOLDER, exist_ok=True)

ALLOWED_PHOTO_EXTENSIONS = {"png", "jpg", "jpeg", "gif", "webp", "heic", "heif"}
MAX_PHOTO_SIZE = 10 * 1024 * 1024  # 10 MB


def allowed_photo_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_PHOTO_EXTENSIONS


def _last_insert_id(db: DatabaseLike) -> Optional[int]:
    query = "SELECT LAST_INSERT_ID() AS lid" if DB_VENDOR == "mysql" else "SELECT last_insert_rowid() AS lid"
    row = db.execute(query).fetchone()
    if not row:
        return None
    value = row.get("lid") if isinstance(row, Mapping) else row[0]
    try:
        return int(value)
    except (TypeError, ValueError):
        return None
        return

    for stmt in SESSION_OVERRIDES_TABLE_SQLITE.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def init_db() -> None:
    if DB_VENDOR == "mysql":
        db = MySQLConnection(DATABASE_SETTINGS)
        try:
            for statement in MYSQL_SCHEMA_STATEMENTS:
                cursor = db.execute(statement)
                cursor.close()
            _ensure_entered_ts_column(db, "BIGINT")
            purge_legacy_seed(db)
            ensure_app_users_table(db)
            ensure_session_override_table(db)
            ensure_persistent_session_table(db)
            ensure_equipment_checks_table(db)
            ensure_project_materials_cache_table(db)
            ensure_employee_shifts_table(db)
            ensure_user_groups_table(db)
            bootstrap_user_store(db)
            db.commit()
        finally:
            db.close()
        return

    db = sqlite3.connect(DATABASE)
    try:
        db.row_factory = sqlite3.Row
        db.executescript(
            """
            CREATE TABLE IF NOT EXISTS activities (
                activity_id TEXT NOT NULL,
                project_code TEXT NOT NULL DEFAULT '',
                label TEXT NOT NULL,
                sort_order INTEGER NOT NULL,
                plan_start TEXT,
                plan_end TEXT,
                planned_members INTEGER,
                planned_duration_ms INTEGER,
                notes TEXT,
                phase_id TEXT,
                phase_label TEXT,
                PRIMARY KEY (activity_id, project_code)
            );

            CREATE TABLE IF NOT EXISTS member_state (
                member_key TEXT NOT NULL,
                project_code TEXT NOT NULL DEFAULT '',
                member_name TEXT NOT NULL,
                activity_id TEXT,
                running INTEGER NOT NULL DEFAULT 0,
                start_ts INTEGER,
                elapsed_cached INTEGER NOT NULL DEFAULT 0,
                pause_start INTEGER,
                entered_ts INTEGER,
                current_phase TEXT,
                PRIMARY KEY (member_key, project_code)
            );

            CREATE TABLE IF NOT EXISTS event_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                project_code TEXT NOT NULL DEFAULT '',
                ts INTEGER NOT NULL,
                kind TEXT NOT NULL,
                member_key TEXT,
                details TEXT
            );

            CREATE INDEX IF NOT EXISTS idx_event_project ON event_log(project_code);

            CREATE TABLE IF NOT EXISTS app_state (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL
            );

            CREATE TABLE IF NOT EXISTS push_subscriptions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT NOT NULL,
                endpoint TEXT NOT NULL UNIQUE,
                p256dh TEXT NOT NULL,
                auth TEXT NOT NULL,
                content_encoding TEXT,
                user_agent TEXT,
                expiration_time INTEGER,
                created_ts INTEGER NOT NULL,
                updated_ts INTEGER NOT NULL
            );

            CREATE INDEX IF NOT EXISTS idx_push_username ON push_subscriptions(username);

            CREATE TABLE IF NOT EXISTS push_notification_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                kind TEXT NOT NULL,
                activity_id TEXT,
                username TEXT,
                title TEXT NOT NULL,
                body TEXT,
                payload TEXT,
                sent_ts INTEGER NOT NULL,
                created_ts INTEGER NOT NULL,
                read_at INTEGER DEFAULT NULL
            );

            CREATE INDEX IF NOT EXISTS idx_push_log_user ON push_notification_log(username);
            CREATE INDEX IF NOT EXISTS idx_push_log_sent ON push_notification_log(sent_ts);

            CREATE TABLE IF NOT EXISTS app_users (
                username TEXT PRIMARY KEY,
                password_hash TEXT NOT NULL,
        ensure_app_users_table(db)
                display_name TEXT NOT NULL,
                full_name TEXT,
                role TEXT NOT NULL DEFAULT 'user',
                is_active INTEGER NOT NULL DEFAULT 1,
                created_ts INTEGER NOT NULL,
                updated_ts INTEGER NOT NULL
            );
            CREATE TABLE IF NOT EXISTS equipment_checks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                project_code TEXT NOT NULL,
                item_key TEXT NOT NULL,
                checked_ts INTEGER NOT NULL,
                username TEXT,
                created_ts INTEGER NOT NULL,
                updated_ts INTEGER NOT NULL
            );
            CREATE UNIQUE INDEX IF NOT EXISTS uq_equipment_project_item ON equipment_checks(project_code, item_key);
            CREATE INDEX IF NOT EXISTS idx_equipment_project ON equipment_checks(project_code);
            CREATE TABLE IF NOT EXISTS project_materials_cache (
                project_code TEXT PRIMARY KEY,
                project_name TEXT NOT NULL,
                data_json TEXT NOT NULL,
                created_ts INTEGER NOT NULL,
                updated_ts INTEGER NOT NULL
            );
            """
        )
        _ensure_entered_ts_column(db, "INTEGER")
        purge_legacy_seed(db)
        ensure_persistent_session_table(db)
        ensure_equipment_checks_table(db)
        ensure_project_materials_cache_table(db)
        ensure_employee_shifts_table(db)
        ensure_user_groups_table(db)
        bootstrap_user_store(db)
        db.commit()
    finally:
        db.close()


def _ensure_entered_ts_column(db: DatabaseLike, column_type: str) -> None:
    try:
        db.execute(f"ALTER TABLE member_state ADD COLUMN entered_ts {column_type}")
    except Exception:
        return


def _ensure_member_state_current_phase(db: DatabaseLike) -> None:
    """Add current_phase column to member_state if it doesn't exist."""
    try:
        col_type = "VARCHAR(255)" if DB_VENDOR == "mysql" else "TEXT"
        db.execute(f"ALTER TABLE member_state ADD COLUMN current_phase {col_type}")
    except Exception:
        return


def purge_legacy_seed(db: DatabaseLike) -> None:
    try:
        project_code = get_app_state(db, "project_code")
    except Exception:  # pragma: no cover - ignora errori iniziali
        return

    if project_code != DEMO_PROJECT_CODE:
        return

    db.execute("DELETE FROM activities")
    db.execute("DELETE FROM member_state")
    db.execute("DELETE FROM event_log")
    db.execute(
        f"DELETE FROM app_state WHERE {APP_STATE_KEY_COLUMN} IN ('project_code','project_name','activity_plan_meta','push_notified_activities','long_running_member_notifications')"
    )


def mock_fetch_project(project_code: str, project_date: Optional[str] = None) -> Optional[Dict[str, Any]]:
    code = (project_code or "").strip().upper()
    if not code:
        return None
    plan = fetch_rentman_plan(code, project_date)
    if plan:
        app.logger.warning("Rentman: piano caricato da API per %s (data: %s)", code, project_date)
        return plan
    external = load_external_projects().get(code)
    plan = external or MOCK_PROJECTS.get(code)
    if plan is None:
        app.logger.warning("Rentman: nessun piano disponibile per %s", code)
        return None
    app.logger.warning("Rentman: uso piano locale per %s", code)
    result = deepcopy(plan)
    result["project_code"] = code
    return result


def set_app_state(db: DatabaseLike, key: str, value: str) -> None:
    if DB_VENDOR == "mysql":
        db.execute(
            """
            INSERT INTO app_state(`key`, value) VALUES(?, ?)
            ON DUPLICATE KEY UPDATE value=VALUES(value)
            """,
            (key, value),
        )
        return

    db.execute(
        """
        INSERT INTO app_state(key, value) VALUES(?, ?)
        ON CONFLICT(key) DO UPDATE SET value=excluded.value
        """,
        (key, value),
    )


def get_app_state(db: DatabaseLike, key: str) -> Optional[str]:
    try:
        query = f"SELECT value FROM app_state WHERE {APP_STATE_KEY_COLUMN}=?"
        row = db.execute(query, (key,)).fetchone()
    except sqlite3.OperationalError:
        return None
    except Exception as exc:  # pragma: no cover - gestione MySQL
        if pymysql_err is not None and isinstance(exc, pymysql_err.ProgrammingError):
            return None
        raise
    return row["value"] if row else None


def get_push_notified_map(db: DatabaseLike) -> Dict[str, Any]:
    raw = get_app_state(db, PUSH_NOTIFIED_STATE_KEY)
    if not raw:
        return {}
    try:
        data = json.loads(raw)
    except json.JSONDecodeError:
        return {}
    if isinstance(data, dict):
        return data
    return {}


def save_push_notified_map(db: DatabaseLike, payload: Mapping[str, Any]) -> None:
    set_app_state(db, PUSH_NOTIFIED_STATE_KEY, json.dumps(payload))


def get_long_running_notified_map(db: DatabaseLike) -> Dict[str, Any]:
    raw = get_app_state(db, LONG_RUNNING_STATE_KEY)
    if not raw:
        return {}
    try:
        data = json.loads(raw)
    except json.JSONDecodeError:
        return {}
    if isinstance(data, dict):
        return data
    return {}


def save_long_running_notified_map(db: DatabaseLike, payload: Mapping[str, Any]) -> None:
    set_app_state(db, LONG_RUNNING_STATE_KEY, json.dumps(payload))


def parse_iso_to_ms(value: Optional[str]) -> Optional[int]:
    if not value:
        return None
    slug = value.replace("Z", "+00:00")
    try:
        dt = datetime.fromisoformat(slug)
    except ValueError:
        return None
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return int(dt.timestamp() * 1000)


def clear_project_state(db: DatabaseLike, project_code: Optional[str] = None) -> None:
    """Rimuove il progetto e i relativi dati dal database."""
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    if project_code:
        # Cancella solo i dati del progetto specifico
        db.execute(f"DELETE FROM activities WHERE project_code = {placeholder}", (project_code,))
        db.execute(f"DELETE FROM member_state WHERE project_code = {placeholder}", (project_code,))
        db.execute(f"DELETE FROM event_log WHERE project_code = {placeholder}", (project_code,))
        delete_project_materials_cache(db, project_code)
    else:
        # Fallback: cancella tutto (per retrocompatibilità)
        db.execute("DELETE FROM activities")
        db.execute("DELETE FROM member_state")
        db.execute("DELETE FROM event_log")
        db.execute(
            f"DELETE FROM app_state WHERE {APP_STATE_KEY_COLUMN} IN ('project_code','project_name','activity_plan_meta','push_notified_activities','long_running_member_notifications')"
        )


def has_active_member_sessions(db: DatabaseLike) -> bool:
    """Restituisce True se esistono timer in corso o posti in pausa."""
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    row = db.execute(
        f"""
        SELECT 1 FROM member_state
        WHERE running={placeholder} OR pause_start IS NOT NULL OR COALESCE(elapsed_cached, 0) > 0
        LIMIT 1
        """,
        (RUN_STATE_RUNNING,),
    ).fetchone()
    return row is not None


def apply_project_plan(db: DatabaseLike, plan: Dict[str, Any]) -> None:
    activities = list(plan.get("activities") or [])
    team = list(plan.get("team") or [])
    project_code = str(plan.get("project_code") or "UNKNOWN")
    project_name = str(plan.get("project_name") or project_code)
    
    # Cancella solo i dati del progetto specifico (non tocca altri progetti)
    clear_project_state(db, project_code)

    planned_counts: Dict[str, int] = {}
    for member in team:
        activity_id = (member.get("activity_id") or "").strip()
        if activity_id:
            planned_counts[activity_id] = planned_counts.get(activity_id, 0) + 1

    activity_rows: List[tuple] = []
    for index, activity in enumerate(activities, start=1):
        activity_id = activity.get("id")
        activity_key = (str(activity_id).strip() if activity_id is not None else "")
        plan_start = activity.get("plan_start")
        plan_end = activity.get("plan_end")
        planned_members = planned_counts.get(activity_key, 0)
        planned_duration_ms = compute_planned_duration_ms(
            plan_start,
            plan_end,
            planned_members,
        )
        activity_rows.append(
            (
                activity_id,
                project_code,
                activity.get("label"),
                index,
                plan_start,
                plan_end,
                planned_members,
                planned_duration_ms,
                activity.get("notes"),
                activity.get("phase_id"),
                activity.get("phase_label"),
            )
        )

    db.executemany(
        """
        INSERT INTO activities(
            activity_id, project_code, label, sort_order, plan_start, plan_end,
            planned_members, planned_duration_ms, notes, phase_id, phase_label
        ) VALUES(?,?,?,?,?,?,?,?,?,?,?)
        """,
        activity_rows,
    )

    now = now_ms()
    member_rows: List[tuple] = []
    seen_keys = set()
    for member in team:
        raw_key = (member.get("key") or "").strip()
        name = (member.get("name") or raw_key or "Operatore").strip()
        key = raw_key or name.lower().replace(" ", "-")
        while key in seen_keys:
            key = f"{key}-dup"
        seen_keys.add(key)
        activity_id = (member.get("activity_id") or "").strip() or None
        # Non avviare automaticamente il timer, il capo squadra lo avvierà manualmente
        running = RUN_STATE_PAUSED
        start_ts = None
        member_rows.append(
            (key, project_code, name, activity_id, running, start_ts, 0, None, None)
        )

    if member_rows:
        db.executemany(
            """
            INSERT INTO member_state(
                member_key, project_code, member_name, activity_id, running, start_ts, elapsed_cached, pause_start, entered_ts
            ) VALUES(?,?,?,?,?,?,?,?,?)
            """,
            member_rows,
        )

    activity_meta = {}
    for activity in activities:
        activity_id = activity.get("id")
        if not activity_id:
            continue
        key = str(activity_id).strip()
        if not key:
            continue
        plan_start = activity.get("plan_start")
        plan_end = activity.get("plan_end")
        planned_members = planned_counts.get(key, 0)
        activity_meta[key] = {
            "plan_start": plan_start,
            "plan_end": plan_end,
            "planned_members": planned_members,
            "planned_duration_ms": compute_planned_duration_ms(
                plan_start,
                plan_end,
                planned_members,
            ),
            "actual_runtime_ms": 0,
        }

    set_app_state(db, "project_code", project_code)
    set_app_state(db, "project_name", project_name)
    set_app_state(db, "activity_plan_meta", json.dumps(activity_meta))
    set_app_state(db, PUSH_NOTIFIED_STATE_KEY, json.dumps({}))
    set_app_state(db, LONG_RUNNING_STATE_KEY, json.dumps({}))

    db.execute(
        "INSERT INTO event_log(ts, kind, details) VALUES(?,?,?)",
        (
            now,
            "project_load",
            json.dumps({"project_code": project_code, "project_name": project_name}),
        ),
    )


def seed_demo_data(db: DatabaseLike) -> None:
    plan = mock_fetch_project(DEMO_PROJECT_CODE, None)
    if plan is None:
        raise RuntimeError("Demo project configuration missing")
    apply_project_plan(db, plan)


def get_db() -> DatabaseLike:
    if "db" not in g:
        if DB_VENDOR == "mysql":
            g.db = MySQLConnection(DATABASE_SETTINGS)
        else:
            conn = sqlite3.connect(DATABASE)
            conn.row_factory = sqlite3.Row
            g.db = conn
        try:
            ensure_activity_schema(g.db)
            ensure_project_code_columns(g.db)
            ensure_app_users_table(g.db)
            ensure_session_override_table(g.db)
            ensure_persistent_session_table(g.db)
            ensure_equipment_checks_table(g.db)
            ensure_project_materials_cache_table(g.db)
        except Exception:
            app.logger.exception("Impossibile aggiornare lo schema attività")
    return g.db


@app.teardown_appcontext
def close_db(_: BaseException | None) -> None:
    db = g.pop("db", None)
    if db is not None:
        db.close()


def compute_elapsed(row: Mapping[str, Any], reference: int) -> int:
    elapsed = row["elapsed_cached"] or 0
    if row["running"] == RUN_STATE_RUNNING:
        start_ts = row["start_ts"] or reference
        elapsed += max(0, reference - start_ts)
    return elapsed


def row_value(row: Mapping[str, Any], key: str) -> Optional[Any]:
    if hasattr(row, "get"):
        try:
            return row.get(key)  # type: ignore[call-arg]
        except Exception:
            pass
    try:
        return row[key]
    except Exception:
        return None


def fetch_equipment_checks(db: DatabaseLike, project_code: Optional[str]) -> Dict[str, int]:
    if not project_code:
        return {}
    rows = db.execute(
        "SELECT item_key, checked_ts FROM equipment_checks WHERE project_code=?",
        (project_code,),
    ).fetchall()
    result: Dict[str, int] = {}
    for row in rows:
        item_key = row_value(row, "item_key")
        if not item_key:
            continue
        timestamp_raw = row_value(row, "checked_ts")
        try:
            timestamp_int = int(timestamp_raw)
        except (TypeError, ValueError):
            continue
        result[str(item_key)] = timestamp_int
    return result


def persist_equipment_check(
    db: DatabaseLike,
    *,
    project_code: str,
    item_key: str,
    checked: bool,
    username: Optional[str] = None,
) -> Optional[int]:
    normalized_project = (project_code or "").strip()
    normalized_item = (item_key or "").strip()
    if not normalized_project or not normalized_item:
        return None
    if checked:
        now = now_ms()
        if DB_VENDOR == "mysql":
            db.execute(
                """
                INSERT INTO equipment_checks(project_code, item_key, checked_ts, username, created_ts, updated_ts)
                VALUES(?,?,?,?,?,?)
                ON DUPLICATE KEY UPDATE checked_ts=VALUES(checked_ts), username=VALUES(username), updated_ts=VALUES(updated_ts)
                """,
                (normalized_project, normalized_item, now, username, now, now),
            )
        else:
            db.execute(
                """
                INSERT INTO equipment_checks(project_code, item_key, checked_ts, username, created_ts, updated_ts)
                VALUES(?,?,?,?,?,?)
                ON CONFLICT(project_code, item_key) DO UPDATE SET
                    checked_ts=excluded.checked_ts,
                    username=excluded.username,
                    updated_ts=excluded.updated_ts
                """,
                (normalized_project, normalized_item, now, username, now, now),
            )
        return now

    db.execute(
        "DELETE FROM equipment_checks WHERE project_code=? AND item_key=?",
        (normalized_project, normalized_item),
    )
    return None


def load_project_materials_cache(db: DatabaseLike, project_code: Optional[str]) -> Optional[Dict[str, Any]]:
    if not project_code:
        return None
    row = db.execute(
        "SELECT project_name, data_json, updated_ts FROM project_materials_cache WHERE project_code=?",
        (project_code,),
    ).fetchone()
    if not row:
        return None
    raw_payload = row_value(row, "data_json")
    try:
        payload = json.loads(raw_payload) if raw_payload else {}
    except json.JSONDecodeError:
        payload = {}
    items = payload.get("items")
    if not isinstance(items, list):
        items = []
    folders = payload.get("folders")
    if not isinstance(folders, list):
        folders = []
    return {
        "project": {
            "code": project_code,
            "name": row_value(row, "project_name") or project_code,
        },
        "items": items,
        "folders": folders,
        "updated_ts": row_value(row, "updated_ts"),
    }


def save_project_materials_cache(
    db: DatabaseLike,
    project_code: Optional[str],
    project_name: Optional[str],
    *,
    items: Sequence[Mapping[str, Any]] | Sequence[Any],
    folders: Sequence[Mapping[str, Any]] | Sequence[Any],
) -> int:
    if not project_code:
        return 0
    normalized_name = project_name or project_code
    sanitized_items = list(items or [])
    sanitized_folders = list(folders or [])
    payload = json.dumps({"items": sanitized_items, "folders": sanitized_folders}, ensure_ascii=False)
    now = now_ms()
    if DB_VENDOR == "mysql":
        db.execute(
            """
            INSERT INTO project_materials_cache(project_code, project_name, data_json, created_ts, updated_ts)
            VALUES(?,?,?,?,?)
            ON DUPLICATE KEY UPDATE project_name=VALUES(project_name), data_json=VALUES(data_json), updated_ts=VALUES(updated_ts)
            """,
            (project_code, normalized_name, payload, now, now),
        )
    else:
        db.execute(
            """
            INSERT INTO project_materials_cache(project_code, project_name, data_json, created_ts, updated_ts)
            VALUES(?,?,?,?,?)
            ON CONFLICT(project_code) DO UPDATE SET
                project_name=excluded.project_name,
                data_json=excluded.data_json,
                updated_ts=excluded.updated_ts
            """,
            (project_code, normalized_name, payload, now, now),
        )
    return now


def delete_project_materials_cache(db: DatabaseLike, project_code: Optional[str]) -> None:
    if not project_code:
        return
    db.execute("DELETE FROM project_materials_cache WHERE project_code=?", (project_code,))


def find_last_move_ts(db: DatabaseLike, member_key: str, activity_id: str) -> Optional[int]:
    if not member_key or not activity_id:
        return None
    rows = db.execute(
        "SELECT ts, details FROM event_log WHERE member_key=? AND kind='move' ORDER BY ts DESC LIMIT 200",
        (member_key,),
    ).fetchall()
    for row in rows:
        try:
            details = json.loads(row["details"] or "{}")
        except Exception:
            continue
        if str(details.get("to")) == activity_id:
            return row["ts"]
    return None


def fetch_member(db: DatabaseLike, member_key: str, project_code: Optional[str] = None) -> Optional[Mapping[str, Any]]:
    if not member_key:
        return None
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    if project_code is not None:
        return db.execute(
            f"SELECT * FROM member_state WHERE member_key={placeholder} AND project_code={placeholder}",
            (member_key, project_code),
        ).fetchone()
    return db.execute(
        f"SELECT * FROM member_state WHERE member_key={placeholder}",
        (member_key,),
    ).fetchone()


def fetch_push_subscriptions(db: DatabaseLike) -> List[Mapping[str, Any]]:
    rows = db.execute(
        "SELECT username, endpoint, p256dh, auth, content_encoding, user_agent FROM push_subscriptions"
    ).fetchall()
    return [dict(row) for row in rows]  # type: ignore[list-item]


def remove_push_subscription(db: DatabaseLike, endpoint: str) -> None:
    if not endpoint:
        return
    db.execute("DELETE FROM push_subscriptions WHERE endpoint=?", (endpoint,))


def record_push_notification(
    db: DatabaseLike,
    *,
    kind: str,
    title: str,
    body: Optional[str],
    payload: Mapping[str, Any],
    activity_id: Optional[str] = None,
    username: Optional[str] = None,
) -> None:
    sent_ts = now_ms()
    try:
        serialized = json.dumps(payload, ensure_ascii=False)
    except TypeError:
        serialized = json.dumps({"payload_repr": repr(payload)}, ensure_ascii=False)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    db.execute(
        f"""
        INSERT INTO push_notification_log(
            kind, activity_id, username, title, body, payload, sent_ts, created_ts
        ) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder})
        """,
        (
            kind,
            activity_id,
            username,
            title,
            body,
            serialized,
            sent_ts,
            sent_ts,
        ),
    )
    db.commit()


def fetch_recent_push_notifications(
    db: DatabaseLike,
    *,
    username: str,
    limit: Optional[int] = None,
) -> List[Dict[str, Any]]:
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    sql = f"""
        SELECT id, kind, activity_id, username, title, body, payload, sent_ts, created_ts, read_at
        FROM push_notification_log
        WHERE username = {placeholder}
        ORDER BY sent_ts DESC, id DESC
    """
    params: List[Any] = [username]
    if limit is not None and limit > 0:
        safe_limit = max(1, min(limit, 1000))
        sql += f" LIMIT {placeholder}"
        params.append(safe_limit)
    rows = db.execute(sql, tuple(params)).fetchall()

    items: List[Dict[str, Any]] = []
    for row in rows:
        raw_payload = row["payload"]
        try:
            payload = json.loads(raw_payload) if raw_payload else None
        except json.JSONDecodeError:
            payload = None
        items.append(
            {
                "id": row["id"],
                "kind": row["kind"],
                "activity_id": row["activity_id"],
                "username": row["username"],
                "title": row["title"],
                "body": row["body"],
                "payload": payload,
                "sent_ts": row["sent_ts"],
                "created_ts": row["created_ts"],
                "read_at": row["read_at"],
                "read": row["read_at"] is not None,
            }
        )
    return items


def format_duration_ms(ms: Any) -> Optional[str]:
    if not isinstance(ms, (int, float)):
        return None
    total_seconds = max(0, int(ms // 1000))
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    if hours:
        return f"{hours:02}:{minutes:02}:{seconds:02}"
    return f"{minutes:02}:{seconds:02}"


def parse_iso_date(value: Optional[str]) -> Optional[date]:
    if not value:
        return None
    candidate = value.strip()
    if not candidate:
        return None
    try:
        return date.fromisoformat(candidate)
    except ValueError:
        return None


def _normalize_epoch_ms(value: Any) -> Optional[int]:
    ms = _coerce_int(value)
    if ms is None:
        return None
    return max(0, ms)


def _fetch_session_override_rows(
    db: DatabaseLike,
    *,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    member_filter: Optional[str] = None,
    activity_filter: Optional[str] = None,
) -> List[Dict[str, Any]]:
    clauses: List[str] = []
    params: List[Any] = []

    if member_filter:
        clauses.append("LOWER(member_key)=LOWER(?)")
        params.append(member_filter.strip())
    if activity_filter:
        clauses.append("activity_id=?")
        params.append(activity_filter.strip())

    query = "SELECT * FROM activity_session_overrides"
    if clauses:
        query += " WHERE " + " AND ".join(clauses)
    query += " ORDER BY start_ts DESC"

    rows = db.execute(query, tuple(params) if params else None).fetchall()
    results: List[Dict[str, Any]] = []
    for row in rows:
        record = dict(row)
        start_dt = datetime.fromtimestamp(record["start_ts"] / 1000, tz=timezone.utc).date()
        if start_date and start_dt < start_date:
            continue
        if end_date and start_dt > end_date:
            continue
        results.append(record)
    return results


def _override_row_to_session(row: Mapping[str, Any]) -> Dict[str, Any]:
    start_ts = int(row.get("start_ts") or 0)
    end_ts_value = row.get("end_ts")
    end_ts = int(end_ts_value) if end_ts_value is not None else start_ts
    net_ms = max(0, int(row.get("net_ms") or 0))
    pause_ms = max(0, int(row.get("pause_ms") or 0))
    pause_count = max(0, int(row.get("pause_count") or 0))
    manual_entry = bool(row.get("manual_entry"))
    note = row.get("note") or ""
    status = row.get("status") or "completed"

    payload = {
        "member_key": row.get("member_key"),
        "member_name": row.get("member_name"),
        "activity_id": row.get("activity_id"),
        "activity_label": row.get("activity_label") or row.get("activity_id"),
        "project_code": row.get("project_code") or "",
        "start_ts": start_ts,
        "end_ts": end_ts,
        "status": status if status in {"completed", "running"} else "completed",
        "net_ms": net_ms,
        "pause_ms": pause_ms,
        "pause_count": pause_count,
        "auto_closed": False,
        "override_id": row.get("id"),
        "manual_entry": manual_entry,
        "note": note,
        "source_member_key": row.get("source_member_key"),
        "source_activity_id": row.get("source_activity_id"),
        "source_start_ts": row.get("source_start_ts"),
    }
    return payload


def build_session_rows(
    db: DatabaseLike,
    *,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    member_filter: Optional[str] = None,
    activity_filter: Optional[str] = None,
    project_filter: Optional[str] = None,
) -> List[Dict[str, Any]]:
    activity_rows = db.execute(
        "SELECT activity_id, project_code, label, planned_duration_ms, notes FROM activities ORDER BY sort_order, label"
    ).fetchall()
    # Mappa con chiave (activity_id, project_code) per supportare attività multi-progetto
    activity_map = {(row["activity_id"], row["project_code"]): row["label"] for row in activity_rows}
    activity_planned_map = {(row["activity_id"], row["project_code"]): row["planned_duration_ms"] for row in activity_rows}
    activity_notes_map = {(row["activity_id"], row["project_code"]): row["notes"] or "" for row in activity_rows}
    # Fallback senza project_code per retrocompatibilità
    for row in activity_rows:
        if row["activity_id"] not in activity_map:
            activity_map[row["activity_id"]] = row["label"]
            activity_planned_map[row["activity_id"]] = row["planned_duration_ms"]
            activity_notes_map[row["activity_id"]] = row["notes"] or ""

    query = (
        "SELECT el.ts, el.kind, el.member_key, el.details, ms.member_name "
        "FROM event_log el "
        "LEFT JOIN member_state ms ON el.member_key = ms.member_key "
        "WHERE el.kind IN ('project_load', 'move', 'finish_activity', 'pause_member', 'resume_member') "
        "ORDER BY el.ts ASC"
    )
    event_rows = db.execute(query).fetchall()

    member_filter_norm = member_filter.strip().lower() if member_filter else None
    activity_filter_norm = activity_filter.strip() if activity_filter else None
    project_filter_norm = project_filter.strip() if project_filter else None

    sessions: Dict[Tuple[str, str], Dict[str, Any]] = {}
    last_project_code: Optional[str] = None

    for row in event_rows:
        try:
            details = json.loads(row["details"]) if row["details"] else {}
        except json.JSONDecodeError:
            details = {}

        if row["kind"] == "project_load":
            candidate = details.get("project_code")
            if candidate:
                last_project_code = str(candidate).strip() or last_project_code
            continue

        if last_project_code and not details.get("project_code"):
            details["project_code"] = last_project_code

        # Applica filtro progetto
        event_project = details.get("project_code") or ""
        if project_filter_norm and str(event_project) != project_filter_norm:
            continue

        member_key = row["member_key"]
        if not member_key:
            continue

        if member_filter_norm and member_key.lower() != member_filter_norm:
            continue

        if row["kind"] == "move":
            activity_id = details.get("to")
        else:
            activity_id = details.get("activity_id")

        if not activity_id:
            continue

        if activity_filter_norm and str(activity_id) != activity_filter_norm:
            continue

        ts = row["ts"]
        if ts is None:
            continue
        dt = datetime.fromtimestamp(ts / 1000, tz=timezone.utc)
        event_date = dt.date()
        if start_date and event_date < start_date:
            continue
        if end_date and event_date > end_date:
            continue

        member_name = row["member_name"] or details.get("member_name") or "Operatore"
        session_key = (member_key, str(activity_id))
        if session_key not in sessions:
            sessions[session_key] = {
                "member_key": member_key,
                "member_name": member_name,
                "activity_id": str(activity_id),
                "events": [],
            }

        sessions[session_key]["events"].append(
            {
                "ts": ts,
                "dt": dt,
                "kind": row["kind"],
                "details": details,
            }
        )

    if not sessions:
        return []

    # Ottieni lo stato corrente degli operatori per determinare quali sessioni sono ancora in corso
    current_state_query = "SELECT member_key, activity_id FROM member_state WHERE activity_id IS NOT NULL"
    current_state_rows = db.execute(current_state_query).fetchall()
    currently_active = {(row["member_key"], str(row["activity_id"])) for row in current_state_rows}

    now_utc = datetime.now(tz=timezone.utc)
    results: List[Dict[str, Any]] = []

    for session_key, session in sessions.items():
        events = sorted(session["events"], key=lambda e: e["ts"])
        if not events:
            continue

        member_key, activity_id = session_key
        member_name = session["member_name"]
        activity_label = activity_map.get(activity_id, activity_id)

        start_event = None
        end_event = None
        pause_events: List[Dict[str, Any]] = []
        project_code = None

        for event in events:
            if event["kind"] == "move" and str(event["details"].get("to") or "") == activity_id:
                if not start_event:
                    start_event = event
                project_code = project_code or event["details"].get("project_code")
            elif event["kind"] == "pause_member":
                pause_events.append(event)
            elif event["kind"] == "finish_activity":
                end_event = event
                project_code = project_code or event["details"].get("project_code")

        if not start_event:
            start_event = events[0]
        if not start_event:
            continue

        start_dt = start_event["dt"]
        end_dt = end_event["dt"] if end_event else now_utc
        total_duration_ms = max(0, int((end_dt - start_dt).total_seconds() * 1000))

        net_duration_ms = total_duration_ms
        pause_duration_ms = 0
        if end_event:
            net_duration_ms = int(end_event["details"].get("duration_ms", total_duration_ms))
            pause_duration_ms = int(end_event["details"].get("pause_ms", max(0, total_duration_ms - net_duration_ms)))
            # Se la durata reale (duration_ms) è molto maggiore del tempo trascorso
            # tra il primo move event e il finish, il vero inizio era precedente
            # (tipico quando il move iniziale non viene loggato, es. caricamento da Rentman)
            real_total = net_duration_ms + pause_duration_ms
            if real_total > total_duration_ms + 5000:  # tolleranza 5s
                computed_start_ms = int(end_dt.timestamp() * 1000) - real_total
                start_dt = datetime.fromtimestamp(computed_start_ms / 1000, tz=timezone.utc)
                total_duration_ms = real_total
        else:
            pause_duration_ms = max(0, total_duration_ms - net_duration_ms)

        pause_count = len(pause_events)
        
        # Una sessione è "running" se l'operatore è attualmente su questa attività
        # altrimenti è "completed" (anche se non c'è un finish_activity esplicito)
        is_currently_active = session_key in currently_active
        status = "running" if is_currently_active else "completed"

        end_ts_value = int(end_dt.timestamp() * 1000)
        
        # Ore preventivate per questa attività (usa chiave composita o fallback)
        activity_key = (activity_id, project_code) if project_code else activity_id
        planned_ms = activity_planned_map.get(activity_key) or activity_planned_map.get(activity_id) or 0
        activity_note = activity_notes_map.get(activity_key) or activity_notes_map.get(activity_id) or ""

        results.append(
            {
                "member_key": member_key,
                "member_name": member_name,
                "activity_id": activity_id,
                "activity_label": activity_label,
                "start_ts": int(start_dt.timestamp() * 1000),
                "end_ts": end_ts_value,
                "status": status,
                "net_ms": max(0, net_duration_ms),
                "pause_ms": max(0, pause_duration_ms),
                "pause_count": pause_count,
                "auto_closed": bool(end_event and end_event["details"].get("auto_close")),
                "project_code": project_code,
                "planned_ms": planned_ms,
                "override_id": None,
                "manual_entry": False,
                "note": activity_note,
                "source_member_key": member_key,
                "source_activity_id": activity_id,
                "source_start_ts": int(start_dt.timestamp() * 1000),
            }
        )

    session_map: Dict[Tuple[str, str, int], Dict[str, Any]] = {
        (item["member_key"], item["activity_id"], item["start_ts"]): item
        for item in results
    }

    overrides = _fetch_session_override_rows(
        db,
        start_date=start_date,
        end_date=end_date,
        member_filter=member_filter,
        activity_filter=activity_filter,
    )

    merged: List[Dict[str, Any]] = []
    replaced_keys: Set[Tuple[str, str, int]] = set()

    for override_row in overrides:
        payload = _override_row_to_session(override_row)
        key = None
        if (
            payload.get("source_member_key")
            and payload.get("source_activity_id")
            and payload.get("source_start_ts")
        ):
            key = (
                str(payload["source_member_key"]),
                str(payload["source_activity_id"]),
                int(payload["source_start_ts"]),
            )
        if key and key in session_map:
            replaced_keys.add(key)
            session_map.pop(key, None)
        merged.append(payload)

    for key, item in session_map.items():
        if key in replaced_keys:
            continue
        merged.append(item)

    merged.sort(key=lambda item: item["start_ts"], reverse=True)
    return merged


def evaluate_overdue_activities(db: DatabaseLike) -> List[Dict[str, Any]]:
    meta = load_activity_meta(db)
    if not meta:
        return []

    now = now_ms()
    activity_labels = {
        row["activity_id"]: row["label"]
        for row in db.execute("SELECT activity_id, label FROM activities")
    }

    notified = get_push_notified_map(db)
    overdue: List[Dict[str, Any]] = []

    for activity_id, entry in meta.items():
        if not isinstance(entry, Mapping):
            app.logger.info(
                "Push worker: meta inatteso per attività %s (%s)", activity_id, type(entry)
            )
            continue

        member_rows = db.execute(
            "SELECT running, start_ts, elapsed_cached, pause_start FROM member_state WHERE activity_id=?",
            (activity_id,),
        ).fetchall()

        assigned_count = len(member_rows)
        running_rows = [row for row in member_rows if row["running"] == RUN_STATE_RUNNING]
        paused_count = sum(1 for row in member_rows if row["pause_start"] is not None)
        running_count = len(running_rows)

        if assigned_count == 0:
            continue

        plan_start_ms = parse_iso_to_ms(cast(Optional[str], entry.get("plan_start")))
        plan_end_ms = parse_iso_to_ms(cast(Optional[str], entry.get("plan_end")))
        planned_members = _coerce_int(entry.get("planned_members"))
        planned_duration_ms = _coerce_int(entry.get("planned_duration_ms"))

        if planned_duration_ms is None:
            if plan_start_ms is None or plan_end_ms is None:
                app.logger.info(
                    "Push worker: pianificazione assente/illeggibile per attività %s",
                    activity_id,
                )
                continue
            base_duration_ms = max(0, plan_end_ms - plan_start_ms)
            if base_duration_ms == 0:
                continue
            normalized_members = planned_members if planned_members and planned_members > 0 else assigned_count
            if normalized_members <= 0:
                normalized_members = 1
            planned_duration_ms = base_duration_ms * normalized_members

        if planned_duration_ms <= 0:
            continue

        running_total_ms = 0
        for row in running_rows:
            elapsed = int(row["elapsed_cached"] or 0)
            start_ts = row["start_ts"]
            start_value: Optional[int]
            try:
                start_value = int(start_ts) if start_ts is not None else None
            except (TypeError, ValueError):
                start_value = None
            if start_value is not None:
                elapsed += max(0, now - start_value)
            running_total_ms += elapsed

        threshold_ms = planned_duration_ms + ACTIVITY_OVERDUE_GRACE_MS
        if running_total_ms <= threshold_ms:
            app.logger.info(
                "Push worker: attività %s ancora entro il margine (tempo %sms, soglia %sms)",
                activity_id,
                running_total_ms,
                threshold_ms,
            )
            continue

        previous = notified.get(activity_id)
        if isinstance(previous, Mapping):
            previous_signature = previous.get("planned_duration_ms")
            if previous_signature is None:
                previous_signature = previous.get("plan_end_ms")
            try:
                previous_signature_int = (
                    int(previous_signature) if previous_signature is not None else None
                )
            except (TypeError, ValueError):
                previous_signature_int = None
            if previous_signature_int == planned_duration_ms:
                app.logger.info(
                    "Push worker: attività %s già notificata per questa durata prevista",
                    activity_id,
                )
                continue

        overdue_minutes = max(1, int((running_total_ms - planned_duration_ms) // 60000))
        app.logger.info(
            "Push worker: attività %s supera la durata prevista di %s minuti",
            activity_id,
            overdue_minutes,
        )
        overdue.append(
            {
                "activity_id": activity_id,
                "activity_label": activity_labels.get(activity_id, activity_id),
                "planned_duration_ms": planned_duration_ms,
                "overdue_minutes": overdue_minutes,
                "assigned_members": assigned_count,
                "active_members": running_count,
                "paused_members": paused_count,
                "actual_running_ms": running_total_ms,
            }
        )

    return overdue


def deliver_overdue_notifications(
    db: DatabaseLike,
    overdue_items: Sequence[Mapping[str, Any]],
    settings: Mapping[str, str],
) -> Set[str]:
    if not overdue_items:
        return set()

    subscriptions = fetch_push_subscriptions(db)
    if not subscriptions:
        app.logger.info(
            "Push worker: nessuna subscription attiva, skip notifica %s",
            [item.get("activity_id") for item in overdue_items],
        )
        return set()

    invalid_endpoints: Set[str] = set()
    delivered: Set[str] = set()

    for item in overdue_items:
        activity_id = cast(str, item.get("activity_id"))
        label = cast(str, item.get("activity_label", activity_id))
        overdue_minutes = cast(int, item.get("overdue_minutes", 0))
        planned_duration_ms = int(cast(Optional[int], item.get("planned_duration_ms")) or 0)
        actual_running_ms = int(cast(Optional[int], item.get("actual_running_ms")) or 0)
        planned_label = format_duration_ms(planned_duration_ms) or "Durata prevista"
        actual_label = format_duration_ms(actual_running_ms) or "Tempo in corso"
        assigned_members = int(cast(Optional[int], item.get("assigned_members")) or 0)
        active_members = int(cast(Optional[int], item.get("active_members")) or 0)
        paused_members = int(cast(Optional[int], item.get("paused_members")) or 0)

        if active_members:
            status_suffix = f" · {active_members} operatori ancora attivi"
        elif paused_members:
            status_suffix = f" · {paused_members} operatori in pausa"
        else:
            status_suffix = " · Nessun timer attivo"

        payload = {
            "title": "Attività oltre il termine",
            "body": (
                f"{label}: il tempo in corso ({actual_label}) supera la durata prevista ({planned_label})"
                f" di {overdue_minutes} minuti{status_suffix}"
            ),
            "data": {
                "activity_id": activity_id,
                "notification_type": "overdue_activity",
                "overdue_minutes": overdue_minutes,
                "planned_duration_ms": planned_duration_ms,
                "actual_running_ms": actual_running_ms,
                "assigned_members": assigned_members,
                "active_members": active_members,
                "paused_members": paused_members,
            },
        }

        delivered_this_round = False

        for sub in subscriptions:
            endpoint = sub.get("endpoint")
            if not endpoint or endpoint in invalid_endpoints:
                continue
            key_p256dh = sub.get("p256dh")
            key_auth = sub.get("auth")
            if not key_p256dh or not key_auth:
                invalid_endpoints.add(str(endpoint))
                continue
            subscription_info = {
                "endpoint": endpoint,
                "keys": {
                    "p256dh": key_p256dh,
                    "auth": key_auth,
                },
            }
            encoding = sub.get("content_encoding") or "aes128gcm"
            try:
                webpush(
                    subscription_info=subscription_info,
                    data=json.dumps(payload),
                    vapid_private_key=settings["vapid_private"],
                    vapid_claims={"sub": settings["subject"]},
                    ttl=OVERDUE_PUSH_TTL_SECONDS,
                    content_encoding=encoding,
                )
                delivered_this_round = True
                record_push_notification(
                    db,
                    kind="overdue_activity",
                    title=payload.get("title", "Notifica"),
                    body=payload.get("body"),
                    payload=payload,
                    activity_id=activity_id,
                    username=sub.get("username"),
                )
            except WebPushException as exc:
                status = getattr(exc.response, "status_code", None)
                app.logger.warning("WebPush fallita (%s): %s", status, exc)
                if status in (404, 410):
                    invalid_endpoints.add(endpoint)
            except Exception as exc:  # pragma: no cover - logging best effort
                app.logger.exception("Errore imprevisto nell'invio push", exc_info=exc)

        if delivered_this_round:
            delivered.add(activity_id)

    if invalid_endpoints:
        for endpoint in invalid_endpoints:
            remove_push_subscription(db, endpoint)
        db.commit()
        app.logger.info(
            "Push worker: rimossa %s subscription invalida", len(invalid_endpoints)
        )

    return delivered


def evaluate_long_running_members(db: DatabaseLike) -> List[Dict[str, Any]]:
    rows = db.execute(
        """
        SELECT
            ms.member_key,
            ms.member_name,
            ms.activity_id,
            ms.start_ts,
            a.label AS activity_label
        FROM member_state ms
        LEFT JOIN activities a ON a.activity_id = ms.activity_id
        WHERE ms.running=? AND ms.start_ts IS NOT NULL
        """,
        (RUN_STATE_RUNNING,),
    ).fetchall()

    now = now_ms()
    notified = get_long_running_notified_map(db)
    active_starts = {
        row["member_key"]: int(row["start_ts"])
        for row in rows
        if row["start_ts"] is not None
    }

    # Pulisce lo stato dei long running non più validi
    cleaned_state: Dict[str, Any] = {}
    changed = False
    for key, value in notified.items():
        if not isinstance(value, Mapping):
            changed = True
            continue
        try:
            recorded_start = int(value.get("start_ts"))
        except (TypeError, ValueError):
            changed = True
            continue
        if active_starts.get(key) == recorded_start:
            cleaned_state[key] = value
        else:
            changed = True

    if changed:
        save_long_running_notified_map(db, cleaned_state)
        notified = cleaned_state

    long_running: List[Dict[str, Any]] = []

    for row in rows:
        member_key = row["member_key"]
        start_ts = row["start_ts"]
        if start_ts is None:
            continue
        duration = max(0, now - int(start_ts))
        if duration < LONG_RUNNING_THRESHOLD_MS:
            continue
        previous = notified.get(member_key)
        previous_start = None
        if isinstance(previous, Mapping):
            try:
                previous_start = int(previous.get("start_ts"))
            except (TypeError, ValueError):
                previous_start = None
        if previous_start == int(start_ts):
            continue
        long_running.append(
            {
                "member_key": member_key,
                "member_name": row["member_name"],
                "activity_id": row["activity_id"],
                "activity_label": row["activity_label"] or row["activity_id"],
                "start_ts": int(start_ts),
                "duration_ms": duration,
            }
        )

    return long_running


def deliver_long_running_notifications(
    db: DatabaseLike,
    items: Sequence[Mapping[str, Any]],
    settings: Mapping[str, str],
) -> Set[str]:
    if not items:
        return set()

    subscriptions = fetch_push_subscriptions(db)
    if not subscriptions:
        app.logger.info(
            "Push worker: nessuna subscription attiva, skip avvisi operatori oltre soglia"
        )
        return set()

    invalid_endpoints: Set[str] = set()
    delivered_members: Set[str] = set()

    for item in items:
        member_key = cast(str, item.get("member_key"))
        member_name = cast(str, item.get("member_name", member_key))
        activity_label = cast(str, item.get("activity_label"))
        duration_ms = cast(int, item.get("duration_ms", 0))
        duration_label = format_duration_ms(duration_ms) or "02:00"

        payload = {
            "title": "Operatore in attività",
            "body": f"{member_name} è su {activity_label} da {duration_label}",
            "data": {
                "notification_type": "long_running_member",
                "member_key": member_key,
                "member_name": member_name,
                "activity_id": item.get("activity_id"),
                "activity_label": activity_label,
                "start_ts": item.get("start_ts"),
                "duration_ms": duration_ms,
            },
        }

        delivered_this_round = False

        for sub in subscriptions:
            endpoint = sub.get("endpoint")
            if not endpoint or endpoint in invalid_endpoints:
                continue
            key_p256dh = sub.get("p256dh")
            key_auth = sub.get("auth")
            if not key_p256dh or not key_auth:
                invalid_endpoints.add(str(endpoint))
                continue
            subscription_info = {
                "endpoint": endpoint,
                "keys": {
                    "p256dh": key_p256dh,
                    "auth": key_auth,
                },
            }
            encoding = sub.get("content_encoding") or "aes128gcm"
            try:
                webpush(
                    subscription_info=subscription_info,
                    data=json.dumps(payload),
                    vapid_private_key=settings["vapid_private"],
                    vapid_claims={"sub": settings["subject"]},
                    ttl=120,
                    content_encoding=encoding,
                )
                delivered_this_round = True
                record_push_notification(
                    db,
                    kind="long_running_member",
                    title=payload.get("title", "Notifica"),
                    body=payload.get("body"),
                    payload=payload,
                    activity_id=cast(Optional[str], item.get("activity_id")),
                    username=sub.get("username"),
                )
            except WebPushException as exc:
                status = getattr(exc.response, "status_code", None)
                app.logger.warning("WebPush fallita (%s): %s", status, exc)
                if status in (404, 410):
                    invalid_endpoints.add(endpoint)
            except Exception as exc:  # pragma: no cover - logging best effort
                app.logger.exception("Errore imprevisto nell'invio push", exc_info=exc)

        if delivered_this_round:
            delivered_members.add(member_key)

    if invalid_endpoints:
        for endpoint in invalid_endpoints:
            remove_push_subscription(db, endpoint)
        db.commit()
        app.logger.info(
            "Push worker: rimossa %s subscription invalida (avvisi long running)",
            len(invalid_endpoints),
        )

    return delivered_members


def _notification_worker() -> None:
    stop_event = _NOTIFICATION_STOP
    if stop_event is None:
        return

    app.logger.info(
        "Push worker: avviato (intervallo %ss)", NOTIFICATION_INTERVAL_SECONDS
    )

    while not stop_event.is_set():
        try:
            with app.app_context():
                settings = get_webpush_settings()
                if not settings:
                    app.logger.info("Push worker: impostazioni VAPID mancanti")
                    continue
                db = get_db()
                overdue_items = evaluate_overdue_activities(db)
                if overdue_items:
                    overdue_ids = [str(item.get("activity_id")) for item in overdue_items]
                    app.logger.info(
                        "Push worker: trovate %s attività in ritardo %s",
                        len(overdue_items),
                        overdue_ids,
                    )
                    delivered = deliver_overdue_notifications(db, overdue_items, settings)
                    if delivered:
                        app.logger.info(
                            "Push worker: notifiche inviate a %s",
                            sorted(delivered),
                        )
                        state = get_push_notified_map(db)
                        now_sent = now_ms()
                        for item in overdue_items:
                            activity_id = item.get("activity_id")
                            if activity_id in delivered:
                                state[str(activity_id)] = {
                                    "planned_duration_ms": item.get("planned_duration_ms"),
                                    "sent_ts": now_sent,
                                }
                        save_push_notified_map(db, state)
                        db.commit()
                    else:
                        app.logger.info(
                            "Push worker: nessuna notifica consegnata per %s",
                            overdue_ids,
                        )
                else:
                    app.logger.info("Push worker: nessuna attività oltre il termine")

                # Notifiche "operatore long running" disattivate su richiesta
        except Exception as exc:  # pragma: no cover - worker should never crash
            app.logger.exception("Worker notifiche push in errore", exc_info=exc)
        finally:
            stop_event.wait(NOTIFICATION_INTERVAL_SECONDS)


def start_notification_worker() -> None:
    global _NOTIFICATION_THREAD, _NOTIFICATION_STOP

    if _NOTIFICATION_THREAD and _NOTIFICATION_THREAD.is_alive():
        return

    _NOTIFICATION_STOP = Event()
    _NOTIFICATION_THREAD = Thread(target=_notification_worker, name="joblog-push-worker", daemon=True)
    _NOTIFICATION_THREAD.start()
    app.logger.info("Push worker: thread avviato")


def stop_notification_worker() -> None:
    global _NOTIFICATION_THREAD, _NOTIFICATION_STOP

    stop_event = _NOTIFICATION_STOP
    thread = _NOTIFICATION_THREAD

    if stop_event is not None:
        stop_event.set()

    if thread and thread.is_alive():
        thread.join(timeout=5)

    _NOTIFICATION_THREAD = None
    _NOTIFICATION_STOP = None


def describe_event(kind: str, details: Dict[str, Any], activity_labels: Dict[str, str]) -> str:
    def label_for(activity_id: Optional[str]) -> str:
        if not activity_id:
            return "Disponibili"
        return activity_labels.get(activity_id, activity_id)

    if kind == "move":
        member_name = details.get("member_name") or "Operatore"
        origin = label_for(details.get("from"))
        destination = label_for(details.get("to"))
        summary = f"{member_name}: {origin} → {destination}"
        duration = format_duration_ms(details.get("duration_ms"))
        if duration:
            summary += f" · {duration}"
        return summary

    if kind == "project_load":
        code = details.get("project_code") or "--"
        name = details.get("project_name") or ""
        if name:
            return f"Progetto {code} · {name}"
        return f"Progetto {code} attivato"

    if kind == "create_activity":
        label = details.get("label") or label_for(details.get("activity_id"))
        return f"Nuova attività: {label or 'Attività'}"

    if kind == "pause_all":
        affected = details.get("affected") or 0
        return f"Pausa collettiva ({affected} operatori)"

    if kind == "resume_all":
        affected = details.get("affected") or 0
        return f"Ripresa collettiva ({affected} operatori)"

    if kind == "pause_member":
        member_name = details.get("member_name") or "Operatore"
        activity_label = label_for(details.get("activity_id"))
        duration = format_duration_ms(details.get("duration_ms"))
        summary = f"{member_name}: Pausa {activity_label}"
        if duration:
            summary += f" · {duration}"
        return summary

    if kind == "resume_member":
        member_name = details.get("member_name") or "Operatore"
        activity_label = label_for(details.get("activity_id"))
        return f"{member_name}: Ripresa {activity_label}"

    if kind == "finish_activity":
        member_name = details.get("member_name") or "Operatore"
        activity_label = label_for(details.get("activity_id"))
        summary = f"{member_name}: Fine {activity_label}"
        duration = format_duration_ms(details.get("duration_ms"))
        if duration:
            summary += f" · {duration}"
        return summary

    if kind == "finish_all":
        affected = details.get("affected") or 0
        return f"Fine attività collettiva ({affected} operatori)"

    return kind.replace("_", " ").title()


# Authentication routes
@app.route("/login")
def login():
    """Render login page. Redirect to home if already logged in."""
    if 'user' in session:
        return redirect(url_for('home'))
    phone_code = request.args.get('phone', '').strip()
    return render_template("login.html", phone_code=phone_code)


@app.get("/api/ping")
def api_ping():
    """Simple endpoint to check server connectivity."""
    return jsonify({"status": "ok", "timestamp": int(datetime.now().timestamp() * 1000)})


@app.post("/api/login")
def api_login():
    """Handle login POST request."""
    data = request.get_json()
    if not data:
        return jsonify({'success': False, 'error': 'Dati non validi'}), 400
    
    username_input = data.get('username', '').strip()
    password = data.get('password', '')
    
    if not username_input or not password:
        return jsonify({'success': False, 'error': 'Username e password richiesti'}), 400
    
    db = get_db()
    user_row = fetch_user_record(db, username_input)
    if not user_row:
        return jsonify({'success': False, 'error': 'Credenziali non valide'}), 401

    if not user_row.get('is_active'):
        return jsonify({'success': False, 'error': 'Account disabilitato'}), 403

    password_hash = user_row.get('password_hash') or ''
    if not verify_password(password, password_hash):
        return jsonify({'success': False, 'error': 'Credenziali non valide'}), 401

    username = user_row.get('username') or _normalize_username(username_input)
    _apply_user_session({**dict(user_row), 'username': username})

    # Gestione telefono aziendale: salva phone_code in sessione
    phone_code = (data.get('phone_code') or '').strip()
    if phone_code:
        # Cerca un'assegnazione attiva per questo telefono
        phone_allowed = False
        try:
            db2 = get_db()
            ensure_phone_assignments_table(db2)
            ph = "%s" if DB_VENDOR == "mysql" else "?"
            assign = db2.execute(
                f"""SELECT project_code, activity_id, assigned_to, assigned_username FROM phone_assignments
                    WHERE phone_code = {ph} AND released_at IS NULL
                    ORDER BY assigned_at DESC LIMIT 1""",
                (phone_code,)
            ).fetchone()
            if assign:
                assigned_username = (assign['assigned_username'] if isinstance(assign, dict) else assign[3]) or ''
                assigned_to_name = (assign['assigned_to'] if isinstance(assign, dict) else assign[2]) or ''
                proj_code = assign['project_code'] if isinstance(assign, dict) else assign[0]
                # Verifica che l'utente corrisponda
                if assigned_username and assigned_username.lower() == username.lower():
                    phone_allowed = True
                elif not assigned_username:
                    # Fallback: match per nome se assigned_username non ancora popolato
                    resolved = _resolve_crew_username(db2, assigned_to_name)
                    if resolved and resolved.lower() == username.lower():
                        phone_allowed = True
                        # Aggiorna assigned_username per futuri login
                        try:
                            assign_id = assign['id'] if isinstance(assign, dict) else None
                            if assign_id:
                                db2.execute(f"UPDATE phone_assignments SET assigned_username = {ph} WHERE id = {ph}", (resolved, assign_id))
                                db2.commit()
                        except Exception:
                            pass
                if phone_allowed:
                    session['phone_code'] = phone_code
                    session['is_supervisor'] = True
                    session['user_role'] = ROLE_SUPERVISOR
                    session['supervisor_project_code'] = proj_code
                    # ── Salva activity_id per filtrare la funzione dell'operatore ──
                    phone_act_id = (assign['activity_id'] if isinstance(assign, dict) else assign[1]) or None
                    if phone_act_id:
                        session['supervisor_activity_id'] = phone_act_id
                        app.logger.info("[PHONE] Activity scope: %s", phone_act_id)
                    else:
                        session.pop('supervisor_activity_id', None)
                    app.logger.info("[PHONE] Login telefono %s per %s -> supervisor, progetto %s, activity=%s", phone_code, username, proj_code, phone_act_id)
                else:
                    app.logger.warning("[PHONE] Utente %s tentato login su telefono %s assegnato a %s (%s) -> RIFIUTATO",
                                       username, phone_code, assigned_to_name, assigned_username)
            else:
                app.logger.warning("[PHONE] Telefono %s non ha assegnazioni attive, login normale per %s", phone_code, username)
        except Exception as e:
            app.logger.error("[PHONE] Errore verifica telefono: %s", e)

    response = jsonify({'success': True, 'phone_mode': phone_allowed if phone_code else False})
    try:
        token_value, expires_ts = _store_persistent_session(username)
    except Exception:
        app.logger.exception("Impossibile creare una sessione persistente per %s", username)
    else:
        _set_persistent_cookie(response, token_value, expires_ts)
    return response


@app.route("/logout")
def logout():
    """Clear session and redirect to login."""
    token = request.cookies.get(_persistent_cookie_name())
    if token:
        _delete_persistent_session(token)
    session.clear()
    response = redirect(url_for('login'))
    response.delete_cookie(_persistent_cookie_name(), path='/')
    return response


@app.route("/")
def home() -> ResponseReturnValue:
    if 'user' not in session:
        return redirect(url_for('login'))
    if session.get('is_admin'):
        return redirect(url_for('admin_dashboard_page'))

    # Utenti "user" senza ruolo specifico - mostrano pagina minima con solo logout
    # Ma se is_supervisor è True (es. login da telefono aziendale), mostra dashboard supervisor
    if session.get('user_role') == ROLE_USER and not session.get('is_supervisor'):
        db = get_db()
        display_name = session.get('user_display') or session.get('user_name') or session.get('user')
        primary_name = session.get('user_name') or display_name or session.get('user')
        initials = session.get('user_initials') or compute_initials(primary_name or "")
        user_role = session.get('user_role', 'user')
        username = session.get('user')
        # Verifica se il modulo produzione è abilitato
        return render_template(
            "user_home.html",
            user_name=primary_name,
            user_display=display_name,
            user_initials=initials,
            user_role=user_role,
            username=username,
        )
    # Supervisor e altri ruoli - mostrano dashboard operativa completa
    db = get_db()
    display_name = session.get('user_display') or session.get('user_name') or session.get('user')
    primary_name = session.get('user_name') or display_name or session.get('user')
    initials = session.get('user_initials') or compute_initials(primary_name or "")
    is_admin = bool(session.get('is_admin'))
    project_code = get_app_state(db, "project_code")
    project_name = get_app_state(db, "project_name")
    initial_attachments: Dict[str, Any] = {"project": None, "items": []}
    initial_materials: Dict[str, Any] = {
        "project": None,
        "items": [],
        "folders": [],
        "equipment_checks": {},
        "updated_ts": None,
        "from_cache": False,
    }
    initial_project = None
    if project_code:
        initial_project = {
            "code": project_code,
            "name": project_name or project_code,
        }
        initial_attachments["project"] = initial_project
        initial_materials["project"] = initial_project
        initial_materials["equipment_checks"] = fetch_equipment_checks(db, project_code)
        cached_materials = load_project_materials_cache(db, project_code)
        if cached_materials:
            initial_materials["items"] = cached_materials.get("items", [])
            initial_materials["folders"] = cached_materials.get("folders", [])
            cached_project = cached_materials.get("project")
            if cached_project:
                initial_materials["project"] = cached_project
            initial_materials["updated_ts"] = cached_materials.get("updated_ts")
            initial_materials["from_cache"] = True
    header_clock = datetime.now().strftime("%d/%m/%Y | %H:%M")

    # Progetto salvato del supervisor (per auto-load se necessario)
    saved_supervisor_project = None
    supervisor_project_code = session.get('supervisor_project_code')
    if supervisor_project_code:
        saved_supervisor_project = {
            "code": supervisor_project_code,
            "name": session.get('supervisor_project_name') or supervisor_project_code,
        }

    phone_mode = bool(session.get('phone_code'))

    return render_template(
        "index.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=is_admin,
        user_role=session.get('user_role', 'user'),
        initial_attachments=initial_attachments,
        initial_materials=initial_materials,
        initial_project=initial_project,
        saved_supervisor_project=saved_supervisor_project,
        header_clock=header_clock,
        phone_mode=phone_mode,
    )


# ============================================================
# API TIMBRATURA
# ============================================================

@app.get("/api/timbratura/oggi")
@login_required
def api_timbratura_oggi():
    """Restituisce le timbrature dell'utente per oggi."""
    username = session.get('user')
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    ensure_timbrature_table(db)
    ensure_cedolino_timbrature_table(db)
    
    # Recupera le regole dell'utente per sapere se usa rounding daily
    user_rules = get_user_timbratura_rules(db, username)
    rounding_mode = user_rules.get('rounding_mode', 'single')
    
    today = datetime.now().strftime("%Y-%m-%d")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Prima recupera le timbrature di oggi
    rows = db.execute(
        f"""
        SELECT id, tipo, ora, ora_mod, method, gps_lat, gps_lon, location_name, created_ts, created_by
        FROM timbrature
        WHERE username = {placeholder} AND data = {placeholder}
        ORDER BY created_ts ASC
        """,
        (username, today)
    ).fetchall()
    
    timbrature = []
    for row in rows:
        timbratura_id = row['id'] if isinstance(row, dict) else row[0]
        tipo = row['tipo'] if isinstance(row, dict) else row[1]
        ora_val = row['ora'] if isinstance(row, dict) else row[2]
        ora_mod_val = row['ora_mod'] if isinstance(row, dict) else row[3]
        method = row['method'] if isinstance(row, dict) else row[4]
        gps_lat = row['gps_lat'] if isinstance(row, dict) else row[5]
        gps_lon = row['gps_lon'] if isinstance(row, dict) else row[6]
        location_name = row['location_name'] if isinstance(row, dict) else row[7]
        created_ts = row['created_ts'] if isinstance(row, dict) else row[8]
        created_by = row['created_by'] if isinstance(row, dict) else row[9]
        
        # Mappa tipo timbratura -> timeframe_id
        timeframe_map = {
            'inizio_giornata': 1,
            'inizio_pausa': 4,
            'fine_pausa': 5,
            'fine_giornata': 8
        }
        timeframe_id = timeframe_map.get(tipo, 0)
        
        # Cerca il cedolino corrispondente più recente (basato su created_ts vicino a quello della timbratura)
        cedolino_row = db.execute(
            f"""
            SELECT synced_ts, sync_error, overtime_request_id
            FROM cedolino_timbrature
            WHERE username = {placeholder} 
              AND data_riferimento = {placeholder}
              AND timeframe_id = {placeholder}
              AND ABS(created_ts - {placeholder}) < 60000
            ORDER BY ABS(created_ts - {placeholder}) ASC
            LIMIT 1
            """,
            (username, today, timeframe_id, created_ts, created_ts)
        ).fetchone()
        
        synced_ts = None
        sync_error = None
        overtime_request_id = None
        if cedolino_row:
            synced_ts = cedolino_row['synced_ts'] if isinstance(cedolino_row, dict) else cedolino_row[0]
            sync_error = cedolino_row['sync_error'] if isinstance(cedolino_row, dict) else cedolino_row[1]
            overtime_request_id = cedolino_row['overtime_request_id'] if isinstance(cedolino_row, dict) else cedolino_row[2]
        
        # Gestisce sia TIME che stringa
        if hasattr(ora_val, 'strftime'):
            ora_str = ora_val.strftime("%H:%M")
        else:
            ora_str = str(ora_val)[:5] if ora_val else ""
        
        # Formatta ora_mod
        ora_mod_str = None
        if ora_mod_val:
            if hasattr(ora_mod_val, 'strftime'):
                ora_mod_str = ora_mod_val.strftime("%H:%M")
            else:
                ora_mod_str = str(ora_mod_val)[:5]
        
        # Converti Decimal a float per JSON
        if gps_lat is not None:
            gps_lat = float(gps_lat)
        if gps_lon is not None:
            gps_lon = float(gps_lon)
        
        # Determina se è in attesa di conferma Extra Turno
        pending_extra_turno = False
        if overtime_request_id and synced_ts is None:
            pending_extra_turno = True
        
        # Determina se c'è una richiesta Giustificazione Ritardo per questa timbratura
        late_arrival_request = None
        flex_request = None
        if tipo == 'inizio_giornata':
            # Cerca richiesta di ritardo per oggi
            late_req = db.execute(f"""
                SELECT r.id, r.status, rt.name
                FROM user_requests r
                JOIN request_types rt ON r.request_type_id = rt.id
                WHERE r.username = {placeholder} 
                  AND r.date_from = {placeholder}
                  AND rt.name = 'Giustificazione Ritardo'
                ORDER BY r.created_ts DESC
                LIMIT 1
            """, (username, today)).fetchone()
            
            if late_req:
                req_id = late_req['id'] if isinstance(late_req, dict) else late_req[0]
                req_status = late_req['status'] if isinstance(late_req, dict) else late_req[1]
                late_arrival_request = {
                    "id": req_id,
                    "status": req_status
                }

                        # Cerca richiesta Anticipo Ingresso per oggi (compatibile con nome legacy)
            flex_req = db.execute(f"""
                SELECT r.id, r.status, r.notes, r.review_notes
                FROM user_requests r
                LEFT JOIN request_types rt ON r.request_type_id = rt.id
                WHERE r.username = {placeholder}
                  AND r.date_from = {placeholder}
                                    AND (
                                                rt.name = 'Fuori Flessibilità'
                                                OR rt.name = 'Richiesta anticipo ingresso'
                                            )
                ORDER BY r.created_ts DESC
                LIMIT 1
            """, (username, today)).fetchone()

            if flex_req:
                flex_req_id = flex_req['id'] if isinstance(flex_req, dict) else flex_req[0]
                flex_req_status = flex_req['status'] if isinstance(flex_req, dict) else flex_req[1]
                flex_req_notes = flex_req['notes'] if isinstance(flex_req, dict) else flex_req[2]
                flex_req_review_notes = flex_req['review_notes'] if isinstance(flex_req, dict) else flex_req[3]
                flex_request = {
                    "id": flex_req_id,
                    "status": flex_req_status,
                    "notes": flex_req_notes,
                    "review_notes": flex_req_review_notes,
                }
        
        # Cerca richiesta Deroga Pausa Ridotta per fine_pausa
        break_reduction_request = None
        if tipo == 'fine_pausa':
            br_req = db.execute(f"""
                SELECT r.id, r.status, r.notes, r.extra_data
                FROM user_requests r
                JOIN request_types rt ON r.request_type_id = rt.id
                WHERE r.username = {placeholder}
                  AND r.date_from = {placeholder}
                  AND rt.name = 'Deroga Pausa Ridotta'
                ORDER BY r.created_ts DESC
                LIMIT 1
            """, (username, today)).fetchone()
            
            if br_req:
                br_id = br_req['id'] if isinstance(br_req, dict) else br_req[0]
                br_status = br_req['status'] if isinstance(br_req, dict) else br_req[1]
                br_notes = br_req['notes'] if isinstance(br_req, dict) else br_req[2]
                br_extra = br_req['extra_data'] if isinstance(br_req, dict) else br_req[3]
                br_extra_data = {}
                if br_extra:
                    try:
                        br_extra_data = json.loads(br_extra) if isinstance(br_extra, str) else br_extra
                    except Exception:
                        pass
                break_reduction_request = {
                    "id": br_id,
                    "status": br_status,
                    "notes": br_notes,
                    "planned_break_minutes": br_extra_data.get('planned_break_minutes'),
                    "effective_break_minutes": br_extra_data.get('effective_break_minutes'),
                    "rounded_break_minutes": br_extra_data.get('rounded_break_minutes'),
                    "break_reduction_minutes": br_extra_data.get('break_reduction_minutes'),
                }
        
        # Cerca richiesta Mancata Timbratura pendente per timbrature pre-inserite (produzione)
        mancata_timbratura_request = None
        if method == 'manual_request' and location_name == 'Mancata Timbratura':
            tipo_to_timb = {
                'inizio_giornata': 'ingresso',
                'fine_giornata': 'uscita',
                'inizio_pausa': 'pausa_in',
                'fine_pausa': 'pausa_out'
            }
            tipo_timb = tipo_to_timb.get(tipo, '')
            mt_req = db.execute(f"""
                SELECT r.id, r.status
                FROM user_requests r
                JOIN request_types rt ON r.request_type_id = rt.id
                WHERE r.username = {placeholder}
                  AND r.date_from = {placeholder}
                  AND rt.name = 'Mancata Timbratura'
                  AND r.extra_data LIKE {placeholder}
                ORDER BY r.created_ts DESC
                LIMIT 1
            """, (username, today, f'%"tipo_timbratura":%"{tipo_timb}"%')).fetchone()
            
            if mt_req:
                mt_id = mt_req['id'] if isinstance(mt_req, dict) else mt_req[0]
                mt_status = mt_req['status'] if isinstance(mt_req, dict) else mt_req[1]
                mancata_timbratura_request = {
                    "id": mt_id,
                    "status": mt_status
                }
        
        timbrature.append({
            "id": timbratura_id,
            "tipo": row['tipo'] if isinstance(row, dict) else row[1],
            "ora": ora_str,
            "ora_mod": ora_mod_str,
            "rounding_mode": rounding_mode,  # 'single' o 'daily'
            "method": method,
            "created_by": created_by,
            "gps_lat": gps_lat,
            "gps_lon": gps_lon,
            "location_name": location_name,
            "pending_extra_turno": pending_extra_turno,
            "sync_error": sync_error if pending_extra_turno else None,
            "late_arrival_request": late_arrival_request,
            "flex_request": flex_request,
            "break_reduction_request": break_reduction_request,
            "mancata_timbratura_request": mancata_timbratura_request
        })
    
    # Verifica se c'è uno straordinario (qualsiasi stato) per oggi
    pending_overtime = None
    overtime_type_id = get_overtime_request_type_id(db)
    ot_row = db.execute(f"""
        SELECT id, value_amount, extra_data, status FROM user_requests
        WHERE username = {placeholder} AND request_type_id = {placeholder}
          AND date_from = {placeholder}
        ORDER BY created_ts DESC
        LIMIT 1
    """, (username, overtime_type_id, today)).fetchone()
    if ot_row:
        ot_id = ot_row['id'] if isinstance(ot_row, dict) else ot_row[0]
        minutes = int(ot_row['value_amount'] if isinstance(ot_row, dict) else ot_row[1]) if ot_row else 0
        ot_status = ot_row['status'] if isinstance(ot_row, dict) else ot_row[3]
        ot_extra_data = ot_row['extra_data'] if isinstance(ot_row, dict) else ot_row[2]
        ot_ora_mod = None
        if ot_extra_data:
            try:
                import json as _json
                ed = _json.loads(ot_extra_data) if isinstance(ot_extra_data, str) else ot_extra_data
                ot_ora_mod = ed.get('ora_mod')
            except Exception:
                pass
        pending_overtime = {
            "id": ot_id,
            "minutes": minutes,
            "status": ot_status,
            "ora_mod": ot_ora_mod
        }
    
    return jsonify({"timbrature": timbrature, "pending_overtime": pending_overtime})


@app.post("/api/timbratura")
@login_required
def api_timbratura_registra():
    """Registra una nuova timbratura."""
    username = session.get('user')
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    tipo = data.get('tipo')
    if tipo not in ('inizio_giornata', 'fine_giornata', 'inizio_pausa', 'fine_pausa'):
        return jsonify({"error": "Tipo timbratura non valido"}), 400
    
    # Verifica bypass QR (solo per sviluppo)
    bypass_qr = data.get('bypass_qr', False)
    
    # Gestione dati offline (GPS o QR salvati quando offline)
    offline_timestamp = data.get('offline_timestamp')  # ISO timestamp da quando era offline
    offline_gps = data.get('offline_gps')  # {latitude, longitude, accuracy}
    offline_qr = data.get('offline_qr')  # QR code scansionato offline
    break_info = data.get('break_info')  # Info pausa: {break_confirmed, break_skipped, break_skip_reason}
    if tipo == 'fine_giornata':
        app.logger.info(f"BREAK_INFO DEBUG: username={username}, break_info={break_info}, raw_data_keys={list(data.keys())}")

    db = get_db()
    ensure_timbrature_table(db)
    
    # Recupera configurazione timbratura GLOBALE (non per utente)
    global_timb_config = get_timbratura_config()
    gps_enabled_globally = global_timb_config.get("gps_enabled", False)
    qr_enabled_globally = global_timb_config.get("qr_enabled", True)
    
    # Se GPS è abilitato globalmente e c'è un tentativo di bypass senza coordinate GPS,
    # BLOCCA la timbratura - richiede validazione GPS
    if gps_enabled_globally and bypass_qr and not offline_gps:
        # Verifica se ha un token GPS valido dalla sessione
        timbratura_method = session.get("timbratura_method")
        token = data.get('token')
        session_token = session.get('timbratura_token')
        token_expires = session.get('timbratura_token_expires', 0)
        
        # Se non ha un token GPS valido, blocca
        if timbratura_method != "gps" or not token or token != session_token or now_ms() > token_expires:
            app.logger.warning(f"Tentativo timbratura bypass senza GPS valido per {username} - GPS richiesto")
            return jsonify({
                "error": "Timbratura GPS richiesta. Usa la funzione GPS per timbrare.",
                "need_gps": True
            }), 403
    
    # Se presente offline_gps, valida SEMPRE le coordinate (anche con bypass_qr)
    if offline_gps:
        try:
            latitude = offline_gps.get('latitude')
            longitude = offline_gps.get('longitude')
            accuracy = offline_gps.get('accuracy', 9999)
            
            # Recupera configurazione GPS
            settings = get_company_settings(db)
            custom = settings.get('custom_settings', {})
            timbratura_config = custom.get('timbratura', {})
            gps_enabled = timbratura_config.get('gps_enabled', False)
            gps_locations = timbratura_config.get('gps_locations', [])
            gps_max_accuracy = timbratura_config.get('gps_max_accuracy_meters', 50)
            
            # NUOVA LOGICA: Verifica se l'utente ha un turno Rentman per oggi con GPS configurato
            rentman_gps_location = None
            try:
                ensure_rentman_plannings_table(db)
                today = datetime.now().date().isoformat()
                placeholder = "%s" if DB_VENDOR == "mysql" else "?"
                
                # Trova il rentman_crew_id dell'utente
                user_row = db.execute(
                    f"SELECT rentman_crew_id, group_id FROM app_users WHERE username = {placeholder}",
                    (username,)
                ).fetchone()
                
                if user_row:
                    crew_id = user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]
                    user_group_id = user_row['group_id'] if isinstance(user_row, dict) else user_row[1]
                    
                    if crew_id:
                        # Cerca turno Rentman di oggi per l'utente (solo se inviato)
                        rentman_row = db.execute(f"""
                            SELECT location_name, location_id,
                                   timbratura_gps_mode, gps_timbratura_location, custom_location_ids
                            FROM rentman_plannings
                            WHERE crew_id = {placeholder}
                              AND planning_date = {placeholder}
                              AND sent_to_webservice = 1
                            ORDER BY plan_start ASC LIMIT 1
                        """, (crew_id, today)).fetchone()

                        if rentman_row:
                            if isinstance(rentman_row, dict):
                                loc_name = rentman_row.get('location_name')
                                loc_id = rentman_row.get('location_id')
                                gps_mode = rentman_row.get('timbratura_gps_mode') or 'group'
                                group_gps_name = rentman_row.get('gps_timbratura_location')
                            else:
                                loc_name = rentman_row[0]
                                loc_id = rentman_row[1]
                                gps_mode = rentman_row[2] or 'group'
                                group_gps_name = rentman_row[3]
                            
                            # Cerca coordinate nella cache
                            loc_lat, loc_lon, loc_radius = None, None, 300
                            ensure_location_cache_table(db)
                            cached_coords = get_location_cache(db, loc_name, loc_id)
                            if cached_coords:
                                loc_lat, loc_lon, loc_radius = cached_coords

                            # Carica eventuali location custom assegnate al planning (custom_location_ids)
                            custom_locs = []
                            try:
                                raw_custom = rentman_row.get('custom_location_ids') if isinstance(rentman_row, dict) else rentman_row[4]
                                if raw_custom:
                                    import json as _json
                                    parsed = None
                                    if isinstance(raw_custom, str):
                                        try:
                                            parsed = _json.loads(raw_custom)
                                        except Exception:
                                            # potrebbe essere già un list-like string, ignora
                                            parsed = None
                                    elif isinstance(raw_custom, (list, tuple)):
                                        parsed = list(raw_custom)

                                    if parsed:
                                        # recupera righe da location_cache
                                        placeholder_ids = ",".join(["%s"] * len(parsed)) if DB_VENDOR == "mysql" else ",".join(["?"] * len(parsed))
                                        rows = db.execute(f"SELECT id, location_name, latitude, longitude, radius_meters, address FROM location_cache WHERE id IN ({placeholder_ids})", tuple(parsed) if isinstance(parsed, (list, tuple)) else (parsed,)).fetchall()
                                        for r in rows:
                                            rid = r['id'] if isinstance(r, dict) else r[0]
                                            name = r['location_name'] if isinstance(r, dict) else r[1]
                                            lat = float(r['latitude'] if isinstance(r, dict) else r[2])
                                            lon = float(r['longitude'] if isinstance(r, dict) else r[3])
                                            rad = int(r['radius_meters'] if isinstance(r, dict) else r[4]) if (r['radius_meters'] if isinstance(r, dict) else r[4]) else 300
                                            addr = (r['address'] if isinstance(r, dict) else r[5]) or ''
                                            custom_locs.append({
                                                'id': rid,
                                                'name': name,
                                                'latitude': lat,
                                                'longitude': lon,
                                                'radius_meters': rad,
                                                'address': addr
                                            })
                            except Exception as _e:
                                app.logger.warning(f"Errore caricamento custom_location_ids per rentman_row: {_e}")
                            
                            app.logger.info(f"Timbratura GPS: mode={gps_mode}, loc_name={loc_name}, loc_lat={loc_lat}, loc_lon={loc_lon}, loc_radius={loc_radius}, group_gps_name={group_gps_name}")
                            app.logger.info(f"GPS locations configurate: {[l.get('name') for l in gps_locations]}")
                            
                            # Decidi quale location usare in base al mode
                            if gps_mode == 'location' and loc_lat and loc_lon and (float(loc_lat) != 0 or float(loc_lon) != 0):
                                # Usa le coordinate della location del progetto
                                rentman_gps_location = {
                                    'name': loc_name or 'Location Progetto',
                                    'latitude': float(loc_lat),
                                    'longitude': float(loc_lon),
                                    'radius_meters': loc_radius  # Raggio dalla cache
                                }
                                app.logger.info(f"Timbratura GPS Rentman: usando location progetto '{loc_name}' per {username} (raggio: {loc_radius}m)")
                            elif gps_mode == 'group' and group_gps_name:
                                # Usa la sede GPS del gruppo - cerca nelle locations configurate
                                group_location = None
                                for loc in gps_locations:
                                    if loc.get('name') == group_gps_name:
                                        group_location = loc
                                        break
                                
                                if group_location:
                                    rentman_gps_location = group_location
                                    app.logger.info(f"Timbratura GPS Rentman: usando sede gruppo '{group_gps_name}' per {username}")
                                else:
                                    # Se non trova la sede nelle locations, cerca nelle coordinate del gruppo
                                    if user_group_id:
                                        group_row = db.execute(f"""
                                            SELECT gps_location_name, gps_location_lat, gps_location_lon, gps_location_radius
                                            FROM user_groups WHERE id = {placeholder}
                                        """, (user_group_id,)).fetchone()
                                        if group_row:
                                            g_lat = group_row['gps_location_lat'] if isinstance(group_row, dict) else group_row[1]
                                            g_lon = group_row['gps_location_lon'] if isinstance(group_row, dict) else group_row[2]
                                            g_radius = group_row['gps_location_radius'] if isinstance(group_row, dict) else group_row[3]
                                            if g_lat and g_lon:
                                                rentman_gps_location = {
                                                    'name': group_gps_name,
                                                    'latitude': float(g_lat),
                                                    'longitude': float(g_lon),
                                                    'radius_meters': g_radius or 300
                                                }
                                                app.logger.info(f"Timbratura GPS Rentman: usando coordinate gruppo '{group_gps_name}' per {username}")
                                # se abbiamo location custom per il planning, aggiungile
                                if custom_locs:
                                    try:
                                        # aggiungi in coda le custom locations così vengono considerate nella validazione
                                        for cl in custom_locs:
                                            gps_locations.append({
                                                'name': cl.get('name'),
                                                'latitude': cl.get('latitude'),
                                                'longitude': cl.get('longitude'),
                                                'radius_meters': cl.get('radius_meters', 300)
                                            })
                                        app.logger.info(f"Validazione GPS: aggiunte {len(custom_locs)} location custom al set di validazione per {username}")
                                    except Exception:
                                        pass
            except Exception as e:
                app.logger.warning(f"Errore lettura turno Rentman per GPS: {e}")
            
            # Se abbiamo una location Rentman specifica, usala come unica location valida
            if rentman_gps_location:
                gps_locations = [rentman_gps_location]
                app.logger.info(f"Validazione GPS: override con location Rentman per {username}")
            
            # Verifica se il turno dell'utente ha una sede specifica (fallback employee_shifts)
            shift_location_name = data.get('shift_location_name')  # Sede specifica del turno
            if not shift_location_name and not rentman_gps_location:
                # Prova a recuperare dal turno odierno
                ensure_employee_shifts_table(db)
                day_of_week = datetime.now().weekday()
                placeholder = "%s" if DB_VENDOR == "mysql" else "?"
                shift_row = db.execute(f"""
                    SELECT location_name FROM employee_shifts
                    WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                """, (username, day_of_week)).fetchone()
                if shift_row:
                    shift_location_name = shift_row['location_name'] if isinstance(shift_row, dict) else shift_row[0]
            
            # Se il turno ha una sede specifica, filtra le locations per usare solo quella
            if shift_location_name and gps_locations:
                filtered_locations = [loc for loc in gps_locations if loc.get('name') == shift_location_name]
                if filtered_locations:
                    gps_locations = filtered_locations
                    app.logger.info(f"Validazione GPS: usando sede specifica del turno '{shift_location_name}' per {username}")
            
            if gps_enabled and gps_locations:
                from math import radians, sin, cos, sqrt, atan2
                
                # Verifica prima l'accuratezza del GPS
                if accuracy > gps_max_accuracy:
                    app.logger.warning(f"Timbratura offline GPS rifiutata: {username} - precisione insufficiente {accuracy:.0f}m > {gps_max_accuracy}m")
                    return jsonify({"error": f"Precisione GPS insufficiente ({int(accuracy)}m). Richiesta: max {gps_max_accuracy}m"}), 400
                
                # Verifica se la posizione è entro il raggio di una delle sedi
                R = 6371000  # Raggio Terra in metri
                matched_location = None
                min_distance = float('inf')
                
                for loc in gps_locations:
                    loc_lat = loc.get('latitude')
                    loc_lon = loc.get('longitude')
                    loc_radius = loc.get('radius_meters', 300)
                    
                    if loc_lat is None or loc_lon is None:
                        continue
                    
                    lat1, lon1 = radians(float(loc_lat)), radians(float(loc_lon))
                    lat2, lon2 = radians(float(latitude)), radians(float(longitude))
                    dlat = lat2 - lat1
                    dlon = lon2 - lon1
                    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
                    c = 2 * atan2(sqrt(a), sqrt(1-a))
                    distance = R * c
                    
                    if distance < min_distance:
                        min_distance = distance
                    
                    # Considera l'accuratezza GPS: la distanza effettiva minima
                    effective_distance = max(0, distance - accuracy)
                    
                    if effective_distance <= loc_radius:
                        matched_location = loc
                        break
                
                if not matched_location:
                    app.logger.warning(f"Timbratura offline GPS rifiutata: {username} - distanza minima {min_distance:.0f}m da sedi configurate")
                    return jsonify({"error": f"Posizione GPS non valida. Distanza dalla sede più vicina: {int(min_distance)}m"}), 400
                
                app.logger.info(f"Timbratura offline GPS validata: {username} - {matched_location.get('name', 'Sede')} (distanza {min_distance:.0f}m)")
                bypass_qr = True  # GPS valido, bypassa verifica QR
        except Exception as e:
            app.logger.error(f"Errore validazione GPS offline: {e}")
    
    # Se presente offline_qr, valida il QR code
    if offline_qr and not bypass_qr:
        try:
            settings = get_company_settings(db)
            custom = settings.get('custom_settings', {})
            timbratura_config = custom.get('timbratura', {})
            qr_code = timbratura_config.get('qr_code', '')
            if qr_code and offline_qr == qr_code:
                app.logger.info(f"Timbratura offline QR validata: {username}")
                bypass_qr = True  # QR valido
            else:
                app.logger.warning(f"Timbratura offline QR rifiutata: {username} - QR non corrispondente")
                return jsonify({"error": "QR Code non valido"}), 400
        except Exception as e:
            app.logger.error(f"Errore validazione QR offline: {e}")
    
    if not bypass_qr:
        # Verifica token di validazione QR
        token = data.get('token')
        session_token = session.get('timbratura_token')
        token_expires = session.get('timbratura_token_expires', 0)
        
        if not token or token != session_token:
            return jsonify({"error": "Devi prima scansionare il QR code", "need_qr": True}), 403
        
        if now_ms() > token_expires:
            # Pulisce token scaduto
            session.pop('timbratura_token', None)
            session.pop('timbratura_token_expires', None)
            return jsonify({"error": "Token scaduto, scansiona nuovamente il QR", "need_qr": True}), 403
    
    # Usa timestamp offline se presente, altrimenti ora attuale
    if offline_timestamp:
        try:
            # Parse ISO timestamp
            from dateutil import parser as dateparser
            offline_dt = dateparser.parse(offline_timestamp)
            now = offline_dt
            app.logger.info(f"Usando timestamp offline: {offline_timestamp}")
        except Exception as e:
            app.logger.warning(f"Errore parsing offline_timestamp: {e}, uso ora attuale")
            now = datetime.now()
    else:
        now = datetime.now()
    
    today = now.strftime("%Y-%m-%d")
    ora = now.strftime("%H:%M:%S")
    created_ts = now_ms()
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica regole business
    existing = db.execute(
        f"SELECT tipo FROM timbrature WHERE username = {placeholder} AND data = {placeholder} ORDER BY created_ts ASC",
        (username, today)
    ).fetchall()
    existing_types = [r['tipo'] if isinstance(r, dict) else r[0] for r in existing]
    
    if tipo == 'inizio_giornata' and 'inizio_giornata' in existing_types:
        return jsonify({"error": "Hai già registrato l'inizio giornata oggi"}), 400
    
    if tipo == 'fine_giornata':
        if 'inizio_giornata' not in existing_types:
            return jsonify({"error": "Devi prima registrare l'inizio giornata"}), 400
        if 'fine_giornata' in existing_types:
            return jsonify({"error": "Hai già registrato la fine giornata oggi"}), 400
    
    if tipo == 'inizio_pausa':
        if 'inizio_giornata' not in existing_types:
            return jsonify({"error": "Devi prima registrare l'inizio giornata"}), 400
        if 'fine_giornata' in existing_types:
            return jsonify({"error": "Non puoi iniziare una pausa dopo la fine giornata"}), 400
        # Controlla se c'è già una pausa aperta
        pause_count = existing_types.count('inizio_pausa') - existing_types.count('fine_pausa')
        if pause_count > 0:
            return jsonify({"error": "Hai già una pausa in corso"}), 400
    
    if tipo == 'fine_pausa':
        pause_count = existing_types.count('inizio_pausa') - existing_types.count('fine_pausa')
        if pause_count <= 0:
            return jsonify({"error": "Non hai nessuna pausa in corso"}), 400
    
    # Calcola ora_mod in base alle regole (usa regole specifiche per gruppo se esistono)
    ora_mod = None
    turno_start = None
    turno_end = None
    day_of_week = datetime.now().weekday()
    rounding_mode = 'single'
    flex_warning = None  # DEPRECATO - mantenuto per compatibilità
    flex_request_id = None  # DEPRECATO - mantenuto per compatibilità
    try:
        # Usa le regole specifiche dell'utente (gruppo o globali)
        rules = get_user_timbratura_rules(db, username)
        rounding_mode = rules.get('rounding_mode', 'single')
        
        app.logger.info(f"Timbratura {username}: usando regole {rules.get('source')} (mode={rounding_mode})")
        
        # Ottieni turno per normalizzazione e rilevamento Extra Turno
        # Recupera sia inizio che fine turno
        day_of_week = datetime.now().weekday()
        
        if tipo in ('inizio_giornata', 'fine_giornata'):
            # Prima cerca nei turni configurati manualmente (employee_shifts)
            try:
                ensure_employee_shifts_table(db)
                shift_row = db.execute(
                    f"""SELECT start_time, end_time FROM employee_shifts 
                       WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                       ORDER BY start_time ASC LIMIT 1""",
                    (username, day_of_week)
                ).fetchone()
                if shift_row:
                    start_time = shift_row['start_time'] if isinstance(shift_row, dict) else shift_row[0]
                    end_time = shift_row['end_time'] if isinstance(shift_row, dict) else shift_row[1]
                    if start_time:
                        if hasattr(start_time, 'strftime'):
                            turno_start = start_time.strftime("%H:%M")
                        elif hasattr(start_time, 'total_seconds'):
                            # È un timedelta (MySQL TIME restituisce timedelta)
                            total_sec = int(start_time.total_seconds())
                            turno_start = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
                        else:
                            turno_start = str(start_time)[:5]
                    if end_time:
                        if hasattr(end_time, 'strftime'):
                            turno_end = end_time.strftime("%H:%M")
                        elif hasattr(end_time, 'total_seconds'):
                            # È un timedelta (MySQL TIME restituisce timedelta)
                            total_sec = int(end_time.total_seconds())
                            turno_end = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
                        else:
                            turno_end = str(end_time)[:5]
                    if turno_start or turno_end:
                        app.logger.info(f"Turno trovato in employee_shifts per {username}: {turno_start} - {turno_end}")
            except Exception as e:
                app.logger.warning(f"Errore lettura employee_shifts: {e}")
            
            # Se non trovato, cerca in rentman_plannings (turni da Rentman)
            if not turno_start or not turno_end:
                # Trova il rentman_crew_id dell'utente
                user_row = db.execute(
                    f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
                    (username,)
                ).fetchone()
                
                if user_row:
                    crew_id = user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]
                    if crew_id:
                        # Cerca turno di oggi per l'utente dalla tabella rentman_plannings
                        # Recupera PRIMO inizio (plan_start ASC) e ULTIMO fine (plan_end DESC)
                        turno_row = db.execute(
                            f"""SELECT 
                                   (SELECT plan_start FROM rentman_plannings 
                                    WHERE crew_id = {placeholder} AND planning_date = {placeholder} 
                                    ORDER BY plan_start ASC LIMIT 1) as first_start,
                                   (SELECT plan_end FROM rentman_plannings 
                                    WHERE crew_id = {placeholder} AND planning_date = {placeholder} 
                                    ORDER BY plan_end DESC LIMIT 1) as last_end
                            """, (crew_id, today, crew_id, today)
                        ).fetchone()
                        if turno_row:
                            plan_start = turno_row['first_start'] if isinstance(turno_row, dict) else turno_row[0]
                            plan_end = turno_row['last_end'] if isinstance(turno_row, dict) else turno_row[1]
                            if plan_start and not turno_start:
                                if hasattr(plan_start, 'strftime'):
                                    turno_start = plan_start.strftime("%H:%M")
                                else:
                                    plan_str = str(plan_start)
                                    if len(plan_str) > 11:
                                        turno_start = plan_str[11:16]
                                    else:
                                        turno_start = plan_str[:5]
                            if plan_end and not turno_end:
                                if hasattr(plan_end, 'strftime'):
                                    turno_end = plan_end.strftime("%H:%M")
                                else:
                                    plan_str = str(plan_end)
                                    if len(plan_str) > 11:
                                        turno_end = plan_str[11:16]
                                    else:
                                        turno_end = plan_str[:5]
                            if turno_start or turno_end:
                                app.logger.info(f"Turno trovato in rentman_plannings per {username}: {turno_start} - {turno_end}")
        
        # Per fine_pausa, applica le regole sulla durata della pausa
        _br_fine_pausa_rounded_min = None  # Minuti pausa arrotondati (per richiesta admin)
        if tipo == 'fine_pausa':
            # Se c'è una motivazione per pausa ridotta, NON arrotondare ora_mod.
            # Lascia ora_mod = ora (tempo reale) in attesa dell'approvazione admin.
            # L'admin deciderà se autorizzare la pausa ridotta (keep reale) o rifiutarla (applica pianificata).
            has_break_reduction_reason = bool(((break_info or {}).get('break_reduction_reason') or '').strip())
            
            if has_break_reduction_reason:
                # Arrotonda la pausa reale ai 15 minuti più vicini (per eccesso)
                # Recupera inizio_pausa per calcolare la durata arrotondata
                ip_rows_br = db.execute(
                    f"""SELECT ora, ora_mod FROM timbrature 
                       WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'inizio_pausa'
                       ORDER BY created_ts DESC LIMIT 1""",
                    (username, today)
                ).fetchone()
                if ip_rows_br:
                    ip_ora_br = ip_rows_br['ora_mod'] if isinstance(ip_rows_br, dict) else ip_rows_br[1]
                    if not ip_ora_br:
                        ip_ora_br = ip_rows_br['ora'] if isinstance(ip_rows_br, dict) else ip_rows_br[0]
                    if hasattr(ip_ora_br, 'strftime'):
                        ip_str_br = ip_ora_br.strftime("%H:%M")
                    else:
                        ip_str_br = str(ip_ora_br)[:5]
                    ip_min_br = int(ip_str_br.split(':')[0]) * 60 + int(ip_str_br.split(':')[1])
                    fp_min_br = int(ora[:2]) * 60 + int(ora[3:5])
                    durata_reale = fp_min_br - ip_min_br
                    # Arrotonda ai 15 minuti più vicini
                    # TODO FUTURO: rendere configurabile l'intervallo di arrotondamento
                    arrotondamento = 15
                    durata_arrotondata = ((durata_reale + arrotondamento // 2) // arrotondamento) * arrotondamento
                    new_fp_min = ip_min_br + durata_arrotondata
                    _br_fine_pausa_rounded_min = durata_arrotondata  # Salva per la richiesta admin
                    ora_mod = f"{new_fp_min // 60:02d}:{new_fp_min % 60:02d}:00"
                    app.logger.info(f"Pausa ridotta con motivazione: durata reale={durata_reale}m, arrotondata={durata_arrotondata}m, ora_mod={ora_mod} (in attesa approvazione admin)")
                else:
                    ora_mod = ora  # Fallback: nessun inizio pausa trovato
                    app.logger.info(f"Pausa ridotta: inizio_pausa non trovato, ora_mod = ora reale ({ora})")
            else:
                # Arrotondamento normale della pausa
                # Recupera l'ora di inizio pausa (l'ultima non chiusa)
                inizio_pausa_rows = db.execute(
                    f"""SELECT ora, ora_mod FROM timbrature 
                       WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'inizio_pausa'
                       ORDER BY created_ts DESC LIMIT 1""",
                    (username, today)
                ).fetchone()
                
                if inizio_pausa_rows:
                    inizio_ora_mod = inizio_pausa_rows['ora_mod'] if isinstance(inizio_pausa_rows, dict) else inizio_pausa_rows[1]
                    if not inizio_ora_mod:
                        inizio_ora_mod = inizio_pausa_rows['ora'] if isinstance(inizio_pausa_rows, dict) else inizio_pausa_rows[0]
                    
                    # Formatta l'ora di inizio pausa
                    if hasattr(inizio_ora_mod, 'strftime'):
                        inizio_str = inizio_ora_mod.strftime("%H:%M")
                    else:
                        inizio_str = str(inizio_ora_mod)[:5]
                    
                    # Calcola durata modificata usando le regole pause
                    durata_mod = calcola_pausa_mod(inizio_str, ora[:5], rules)
                    
                    # Calcola ora_mod di fine_pausa = inizio_pausa_mod + durata_mod
                    inizio_parts = inizio_str.split(':')
                    inizio_min = int(inizio_parts[0]) * 60 + int(inizio_parts[1])
                    fine_mod_min = inizio_min + durata_mod
                    
                    h = fine_mod_min // 60
                    m = fine_mod_min % 60
                    ora_mod = f"{h:02d}:{m:02d}:00"
                    
                    app.logger.info(f"Pausa: {inizio_str} -> {ora[:5]} (durata effettiva {int(ora[:2])*60+int(ora[3:5]) - inizio_min} min, durata mod {durata_mod} min, fine mod {ora_mod})")
                else:
                    ora_mod = calcola_ora_mod(ora, tipo, turno_start, rules)
        elif rounding_mode == 'daily' and tipo == 'fine_giornata':
            # Per daily mode: calcola l'ora di uscita che porta esattamente alle ore del turno
            ora_mod = _calcola_ora_fine_daily(db, username, today, ora, turno_start, turno_end, rules, placeholder, break_info=break_info)
        else:
            ora_mod = calcola_ora_mod(ora, tipo, turno_start, rules)
        
        # Verifica anticipo eccessivo in ingresso (richiesta motivazione)
        # Se l'utente timbra prima di (turno_start - anticipo_max_minuti),
        # crea automaticamente una richiesta "Fuori Flessibilità".
        if tipo == 'inizio_giornata' and turno_start:
            try:
                ora_parts = ora[:5].split(':')
                turno_parts = turno_start.split(':')
                ora_min = int(ora_parts[0]) * 60 + int(ora_parts[1])
                turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
                diff_minutes = ora_min - turno_min  # negativo = anticipo

                anticipo_max = int(rules.get('anticipo_max_minuti', 30) or 30)
                flessibilita_ingresso = int(rules.get('flessibilita_ingresso_minuti', anticipo_max) or anticipo_max)

                # Gruppi di produzione NON hanno flessibilità → skip
                _is_prod_flex_ing = False
                try:
                    _upfi = db.execute(
                        f"SELECT g.is_production FROM app_users u JOIN user_groups g ON u.group_id = g.id WHERE u.username = {placeholder}",
                        (username,)
                    ).fetchone()
                    _is_prod_flex_ing = bool((_upfi['is_production'] if isinstance(_upfi, dict) else _upfi[0]) if _upfi else False)
                except Exception:
                    pass

                anticipo_assoluto = abs(diff_minutes)
                # Trigger su uscita dalla flessibilità ingresso (richiesta motivazione)
                if diff_minutes < 0 and anticipo_assoluto >= flessibilita_ingresso and not _is_prod_flex_ing:
                    message = (
                        f"Timbrata in anticipo di {anticipo_assoluto} minuti "
                        f"(turno {turno_start}, flessibilità ingresso {flessibilita_ingresso} min)"
                    )

                    arrotondamento_minuti = int(
                        rules.get('arrotondamento_giornaliero_minuti', 30) or 30
                    )

                    flex_request_id = _create_flex_request(
                        db=db,
                        username=username,
                        date_str=today,
                        tipo=tipo,
                        ora_timbrata=ora,
                        ora_mod=ora_mod,
                        diff_minutes=diff_minutes,
                        message=message,
                        placeholder=placeholder,
                        turno_start=turno_start,
                        turno_end=turno_end,
                        arrotondamento_minuti=arrotondamento_minuti,
                    )

                    if flex_request_id:
                        flex_warning = {
                            "detected": True,
                            "tipo": tipo,
                            "message": message,
                            "diff_minutes": diff_minutes,
                            "request_id": flex_request_id,
                        }
                        app.logger.info(
                            "Ingresso anticipato oltre limite: creata richiesta Fuori Flessibilità id=%s per %s",
                            flex_request_id,
                            username,
                        )
            except Exception as flex_e:
                app.logger.warning(f"Errore verifica anticipo ingresso/flex request: {flex_e}")

        # Verifica uscita oltre flessibilità (messaggio + richiesta)
        # NOTA: i gruppi di produzione NON hanno flessibilità → skip
        flex_exit_debug = {}
        _is_production_flex = False
        try:
            _upfx = db.execute(
                f"SELECT g.is_production FROM app_users u JOIN user_groups g ON u.group_id = g.id WHERE u.username = {placeholder}",
                (username,)
            ).fetchone()
            _is_production_flex = bool((_upfx['is_production'] if isinstance(_upfx, dict) else _upfx[0]) if _upfx else False)
        except Exception:
            pass
        
        if tipo == 'fine_giornata':
            flex_exit_debug['turno_end'] = turno_end
            flex_exit_debug['ora'] = ora[:5]
            flex_exit_debug['has_turno_end'] = turno_end is not None
            flex_exit_debug['is_production'] = _is_production_flex
        
        if tipo == 'fine_giornata' and turno_end and not _is_production_flex:
            try:
                ora_parts = ora[:5].split(':')
                turno_parts = turno_end.split(':')
                ora_min = int(ora_parts[0]) * 60 + int(ora_parts[1])
                turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
                diff_minutes = ora_min - turno_min  # positivo = uscita dopo

                flessibilita_uscita = int(rules.get('flessibilita_uscita_minuti', 30) or 30)
                
                flex_exit_debug['ora_min'] = ora_min
                flex_exit_debug['turno_min'] = turno_min
                flex_exit_debug['diff_minutes'] = diff_minutes
                flex_exit_debug['flessibilita_uscita'] = flessibilita_uscita
                flex_exit_debug['should_trigger'] = diff_minutes > flessibilita_uscita

                if diff_minutes > flessibilita_uscita:
                    oltre_min = diff_minutes - flessibilita_uscita
                    message = (
                        f"Uscita oltre di {oltre_min} minuti "
                        f"(turno {turno_end}, flessibilità uscita {flessibilita_uscita} min)"
                    )

                    arrotondamento_minuti = int(
                        rules.get('arrotondamento_giornaliero_minuti', 30) or 30
                    )

                    flex_request_id = _create_flex_request(
                        db=db,
                        username=username,
                        date_str=today,
                        tipo=tipo,
                        ora_timbrata=ora,
                        ora_mod=ora_mod,
                        diff_minutes=diff_minutes,
                        message=message,
                        placeholder=placeholder,
                        turno_start=turno_start,
                        turno_end=turno_end,
                        arrotondamento_minuti=arrotondamento_minuti,
                    )
                    
                    flex_exit_debug['flex_request_id'] = flex_request_id

                    if flex_request_id:
                        flex_warning = {
                            "detected": True,
                            "tipo": tipo,
                            "message": message,
                            "diff_minutes": diff_minutes,
                            "request_id": flex_request_id,
                        }
                        app.logger.info(
                            "Uscita oltre flessibilità: creata richiesta id=%s per %s",
                            flex_request_id,
                            username,
                        )
                    else:
                        flex_exit_debug['flex_request_failed'] = True
            except Exception as flex_e:
                flex_exit_debug['error'] = str(flex_e)
                app.logger.warning(f"Errore verifica uscita oltre flessibilità/flex request: {flex_e}")
        
        app.logger.info(f"FLEX_EXIT_DEBUG {username}: {json.dumps(flex_exit_debug)}")
        
        app.logger.info(f"Ora mod calcolata: {ora} -> {ora_mod} (turno: {turno_start} - {turno_end}, tipo: {tipo}, mode: {rounding_mode})")
    except Exception as e:
        app.logger.error(f"Errore calcolo ora_mod: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        ora_mod = ora  # Fallback: usa ora originale

    # ═══════════════════════════════════════════════════════════════════════════
    # REGOLA PAUSA RIDOTTA: se pausa timbrata è inferiore di >=30 min
    # rispetto alla pianificata, richiede motivazione utente + approvazione admin.
    # Il check avviene al momento del fine_pausa.
    # ═══════════════════════════════════════════════════════════════════════════
    break_reduction_data = None
    break_reduction_request_id = None
    if tipo == 'fine_pausa':
        try:
            planned_break_data = _get_planned_break_minutes_for_day(
                db=db,
                username=username,
                date_str=today,
                day_of_week=day_of_week,
                placeholder=placeholder,
            )
            planned_break_minutes = int(planned_break_data.get('minutes', 0) or 0)
            
            # Al momento del fine_pausa, il record fine_pausa NON è ancora nel DB.
            # Cerco l'ultimo inizio_pausa e uso 'ora' corrente come fine pausa.
            inizio_pausa_row = db.execute(
                f"""SELECT ora FROM timbrature
                   WHERE username = {placeholder} AND data = {placeholder}
                     AND tipo = 'inizio_pausa'
                   ORDER BY created_ts DESC LIMIT 1""",
                (username, today)
            ).fetchone()
            
            effective_break_minutes = 0
            if inizio_pausa_row:
                ip_ora = inizio_pausa_row['ora'] if isinstance(inizio_pausa_row, dict) else inizio_pausa_row[0]
                ip_min = _safe_time_to_minutes(ip_ora)
                fp_min = _safe_time_to_minutes(ora)  # 'ora' è l'orario del fine_pausa corrente
                if ip_min is not None and fp_min is not None and fp_min >= ip_min:
                    effective_break_minutes = fp_min - ip_min
            
            app.logger.info(
                "Break reduction check: user=%s planned=%s effective=%s (inizio_pausa→%s, fine_pausa→%s)",
                username, planned_break_minutes, effective_break_minutes,
                inizio_pausa_row['ora'] if inizio_pausa_row and isinstance(inizio_pausa_row, dict) else (inizio_pausa_row[0] if inizio_pausa_row else 'N/A'),
                ora
            )
            
            break_reduction_minutes = planned_break_minutes - effective_break_minutes

            if planned_break_minutes > 0 and effective_break_minutes > 0 and break_reduction_minutes >= 30:
                reason = ((break_info or {}).get('break_reduction_reason') or '').strip()
                if not reason:
                    return jsonify({
                        "error": (
                            "Pausa ridotta rilevata: la pausa effettuata è inferiore di "
                            f"{break_reduction_minutes} minuti rispetto al pianificato. "
                            "Inserisci una motivazione per proseguire."
                        ),
                        "need_break_reduction_reason": True,
                        "break_reduction": {
                            "planned_break_minutes": planned_break_minutes,
                            "effective_break_minutes": effective_break_minutes,
                            "break_reduction_minutes": break_reduction_minutes,
                        }
                    }), 400

                break_reduction_data = {
                    "planned_break_minutes": planned_break_minutes,
                    "effective_break_minutes": effective_break_minutes,
                    "break_reduction_minutes": break_reduction_minutes,
                    "rounded_break_minutes": _br_fine_pausa_rounded_min,
                    "break_source": planned_break_data.get('source'),
                    "break_start": planned_break_data.get('break_start'),
                    "break_end": planned_break_data.get('break_end'),
                    "reason": reason,
                    "turno_start": turno_start,
                    "turno_end": turno_end,
                    "ora_timbrata": ora,
                    "ora_mod": ora_mod,
                }
                app.logger.info(
                    "Break reduction detected: user=%s date=%s planned=%s effective=%s reduction=%s",
                    username,
                    today,
                    planned_break_minutes,
                    effective_break_minutes,
                    break_reduction_minutes,
                )
        except Exception as br_e:
            app.logger.warning(f"Errore verifica pausa ridotta: {br_e}")

    # ═══════════════════════════════════════════════════════════════════════════
    # REGOLA PAUSA ASSENTE: se a fine_giornata non è stata timbrata nessuna pausa
    # ma ne era pianificata una, richiede motivazione (stessa logica Deroga Pausa Ridotta)
    # ═══════════════════════════════════════════════════════════════════════════
    if tipo == 'fine_giornata' and break_reduction_data is None:
        try:
            planned_break_data_fg = _get_planned_break_minutes_for_day(
                db=db,
                username=username,
                date_str=today,
                day_of_week=day_of_week,
                placeholder=placeholder,
            )
            planned_break_minutes_fg = int(planned_break_data_fg.get('minutes', 0) or 0)

            if planned_break_minutes_fg > 0:
                # Verifica se è stata registrata almeno una pausa oggi
                pausa_row = db.execute(
                    f"""SELECT COUNT(*) as cnt FROM timbrature
                       WHERE username = {placeholder} AND data = {placeholder}
                         AND tipo IN ('inizio_pausa', 'fine_pausa')""",
                    (username, today)
                ).fetchone()
                n_pause = (pausa_row['cnt'] if isinstance(pausa_row, dict) else pausa_row[0]) if pausa_row else 0

                if n_pause == 0:
                    # Nessuna pausa timbrata: riduzione totale = tutta la pausa pianificata
                    reason = ((break_info or {}).get('break_reduction_reason') or '').strip()
                    if not reason:
                        return jsonify({
                            "error": (
                                f"Pausa non timbrata: era prevista una pausa di {planned_break_minutes_fg} minuti "
                                "che non risulta effettuata. Inserisci una motivazione per proseguire."
                            ),
                            "need_break_reduction_reason": True,
                            "break_reduction": {
                                "planned_break_minutes": planned_break_minutes_fg,
                                "effective_break_minutes": 0,
                                "break_reduction_minutes": planned_break_minutes_fg,
                            }
                        }), 400

                    break_reduction_data = {
                        "planned_break_minutes": planned_break_minutes_fg,
                        "effective_break_minutes": 0,
                        "break_reduction_minutes": planned_break_minutes_fg,
                        "rounded_break_minutes": None,
                        "break_source": planned_break_data_fg.get('source'),
                        "break_start": planned_break_data_fg.get('break_start'),
                        "break_end": planned_break_data_fg.get('break_end'),
                        "reason": reason,
                        "turno_start": turno_start,
                        "turno_end": turno_end,
                        "ora_timbrata": ora,
                        "ora_mod": ora_mod,
                    }
                    app.logger.info(
                        "Break assente a fine_giornata: user=%s date=%s planned=%s effective=0",
                        username, today, planned_break_minutes_fg,
                    )
        except Exception as br_fg_e:
            app.logger.warning(f"Errore verifica pausa assente a fine_giornata: {br_fg_e}")

    # ═══════════════════════════════════════════════════════════════════════════
    # RILEVAMENTO EXTRA TURNO
    # ═══════════════════════════════════════════════════════════════════════════
    extra_turno_request_id = None
    extra_turno_data = None
    extra_turno_skip_motivation = False
    extra_turno_anticipo_notes = None
    
    # Verifica se il modulo straordinari è attivo prima di rilevare Extra Turno
    # Extra Turno scatta SOLO a fine_giornata quando le ore lavorate superano le ore pianificate
    if is_module_enabled(db, "straordinari") and tipo == 'fine_giornata':
        try:
            rules_for_extra = get_user_timbratura_rules(db, username)
            
            # Calcola ore pianificate totali del giorno (somma di tutti i turni)
            planned_minutes = 0
            user_row_et = db.execute(
                f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
                (username,)
            ).fetchone()
            crew_id_et = None
            if user_row_et:
                crew_id_et = user_row_et['rentman_crew_id'] if isinstance(user_row_et, dict) else user_row_et[0]
            
            if crew_id_et:
                # Somma tutti i turni Rentman del giorno per l'utente
                turni_rows = db.execute(
                    f"""SELECT plan_start, plan_end FROM rentman_plannings 
                       WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                       AND (is_obsolete IS NULL OR is_obsolete = 0)""",
                    (crew_id_et, today)
                ).fetchall()
                for tr in turni_rows:
                    ps = tr['plan_start'] if isinstance(tr, dict) else tr[0]
                    pe = tr['plan_end'] if isinstance(tr, dict) else tr[1]
                    if ps and pe:
                        # Converti plan_start e plan_end in minuti
                        if hasattr(ps, 'hour'):
                            ps_min = ps.hour * 60 + ps.minute
                        else:
                            ps_str = str(ps)
                            ps_time = ps_str[11:16] if len(ps_str) > 11 else ps_str[:5]
                            ps_parts = ps_time.split(':')
                            ps_min = int(ps_parts[0]) * 60 + int(ps_parts[1])
                        if hasattr(pe, 'hour'):
                            pe_min = pe.hour * 60 + pe.minute
                        else:
                            pe_str = str(pe)
                            pe_time = pe_str[11:16] if len(pe_str) > 11 else pe_str[:5]
                            pe_parts = pe_time.split(':')
                            pe_min = int(pe_parts[0]) * 60 + int(pe_parts[1])
                        planned_minutes += max(0, pe_min - ps_min)
            
            if planned_minutes == 0:
                # Se non ci sono turni Rentman, usa employee_shifts
                try:
                    ensure_employee_shifts_table(db)
                    shift_rows = db.execute(
                        f"""SELECT start_time, end_time FROM employee_shifts 
                           WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1""",
                        (username, day_of_week)
                    ).fetchall()
                    for sr in shift_rows:
                        st = sr['start_time'] if isinstance(sr, dict) else sr[0]
                        et = sr['end_time'] if isinstance(sr, dict) else sr[1]
                        if st and et:
                            if hasattr(st, 'total_seconds'):
                                st_min = int(st.total_seconds()) // 60
                            elif hasattr(st, 'hour'):
                                st_min = st.hour * 60 + st.minute
                            else:
                                st_parts = str(st)[:5].split(':')
                                st_min = int(st_parts[0]) * 60 + int(st_parts[1])
                            if hasattr(et, 'total_seconds'):
                                et_min = int(et.total_seconds()) // 60
                            elif hasattr(et, 'hour'):
                                et_min = et.hour * 60 + et.minute
                            else:
                                et_parts = str(et)[:5].split(':')
                                et_min = int(et_parts[0]) * 60 + int(et_parts[1])
                            planned_minutes += max(0, et_min - st_min)
                except Exception:
                    pass
            
            if planned_minutes > 0:
                # Sottrai la pausa pianificata per ottenere le ore nette pianificate
                # (worked_minutes sottrae solo le pause effettivamente timbraste)
                planned_break = 0  # Inizializza a 0, verrà valorizzata se trovata
                try:
                    ensure_employee_shifts_table(db)
                    break_row = db.execute(
                        f"""SELECT break_start, break_end FROM employee_shifts 
                           WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1""",
                        (username, day_of_week)
                    ).fetchone()
                    if break_row:
                        _bs = break_row['break_start'] if isinstance(break_row, dict) else break_row[0]
                        _be = break_row['break_end'] if isinstance(break_row, dict) else break_row[1]
                        if _bs and _be:
                            if hasattr(_bs, 'total_seconds'):
                                _bs_min = int(_bs.total_seconds()) // 60
                            elif hasattr(_bs, 'hour'):
                                _bs_min = _bs.hour * 60 + _bs.minute
                            else:
                                _bs_parts = str(_bs)[:5].split(':')
                                _bs_min = int(_bs_parts[0]) * 60 + int(_bs_parts[1])
                            if hasattr(_be, 'total_seconds'):
                                _be_min = int(_be.total_seconds()) // 60
                            elif hasattr(_be, 'hour'):
                                _be_min = _be.hour * 60 + _be.minute
                            else:
                                _be_parts = str(_be)[:5].split(':')
                                _be_min = int(_be_parts[0]) * 60 + int(_be_parts[1])
                            planned_break = _be_min - _bs_min
                            if planned_break > 0:
                                planned_minutes -= planned_break
                                app.logger.info(
                                    "Extra Turno: planned_minutes ridotto da %s a %s (pausa pianificata %s min)",
                                    planned_minutes + planned_break, planned_minutes, planned_break
                                )
                except Exception:
                    pass
                
                # Calcola ore effettivamente lavorate dal giorno
                # Recupera tutte le timbrature del giorno (inclusa l'attuale fine_giornata)
                timbrature_giorno = db.execute(
                    f"""SELECT tipo, ora_mod FROM timbrature 
                       WHERE username = {placeholder} AND data = {placeholder}
                       ORDER BY ora_mod ASC""",
                    (username, today)
                ).fetchall()
                
                # Aggiungi la timbratura corrente (fine_giornata) che non è ancora salvata
                all_timbrature = []
                for t in timbrature_giorno:
                    t_tipo = t['tipo'] if isinstance(t, dict) else t[0]
                    t_ora = t['ora_mod'] if isinstance(t, dict) else t[1]
                    if t_ora:
                        if hasattr(t_ora, 'strftime'):
                            t_ora_str = t_ora.strftime("%H:%M")
                        elif hasattr(t_ora, 'total_seconds'):
                            total_sec = int(t_ora.total_seconds())
                            t_ora_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
                        else:
                            t_ora_str = str(t_ora)[:5]
                        all_timbrature.append((t_tipo, t_ora_str))
                
                # Aggiungi fine_giornata corrente
                all_timbrature.append(('fine_giornata', ora_mod[:5] if ora_mod else ora[:5]))
                
                # Calcola ore lavorate: somma dei periodi inizio_giornata→fine_giornata meno pause
                worked_minutes = 0
                inizio = None
                first_inizio_min = None
                last_fine_min = None
                
                for t_tipo, t_ora_str in all_timbrature:
                    t_parts = t_ora_str.split(':')
                    t_min = int(t_parts[0]) * 60 + int(t_parts[1])
                    
                    if t_tipo == 'inizio_giornata':
                        if first_inizio_min is None:
                            first_inizio_min = t_min
                        inizio = t_min
                    elif t_tipo == 'fine_giornata' and inizio is not None:
                        last_fine_min = t_min
                        worked_minutes += (t_min - inizio)
                        inizio = None
                
                # Per coerenza con _calcola_ora_fine_daily, usa SEMPRE la pausa pianificata
                # (tranne quando l'utente ha dichiarato di non averla fatta)
                total_pausa_effettiva = planned_break if planned_break else 0
                
                if break_info and break_info.get('break_skipped'):
                    # L'utente ha saltato la pausa: nessuna sottrazione
                    total_pausa_effettiva = 0
                    reason = break_info.get('break_skip_reason', 'Nessuna motivazione')
                    app.logger.info(
                        "Extra Turno: pausa saltata dall'utente, motivo: %s - pausa=0",
                        reason
                    )
                else:
                    # Pausa pianificata (sia timbrata che confermata o default)
                    worked_minutes -= total_pausa_effettiva
                    app.logger.info(
                        "Extra Turno: uso pausa pianificata = %s min (worked_net=%s)",
                        total_pausa_effettiva, worked_minutes
                    )
                
                extra_minutes = worked_minutes - planned_minutes
                
                app.logger.info(
                    "Extra Turno check: user=%s, worked=%s min, planned=%s min, extra=%s min, "
                    "pausa_eff=%s, planned_break=%s, break_info=%s",
                    username, worked_minutes, planned_minutes, extra_minutes,
                    total_pausa_effettiva, planned_break, break_info
                )
                
                if extra_minutes > 0:
                    # Calcola l'ora di uscita per il caso RIFIUTO:
                    # inizio + ore_pianificate_nette + pausa_effettiva → dà esattamente le ore del turno
                    rejection_end_time = turno_end or ""
                    if first_inizio_min is not None:
                        rej_end_min = first_inizio_min + planned_minutes + total_pausa_effettiva
                        rej_h = rej_end_min // 60
                        rej_m = rej_end_min % 60
                        rejection_end_time = f"{rej_h:02d}:{rej_m:02d}"
                        app.logger.info(
                            "Extra Turno rejection_end: inizio=%s + planned=%s + pausa_eff=%s = %s",
                            first_inizio_min, planned_minutes, total_pausa_effettiva, rejection_end_time
                        )
                    
                    # Blocco straordinario dalle regole del gruppo
                    blocco_str = rules_for_extra.get('arrotondamento_giornaliero_minuti', 30)
                    tipo_arrot = rules_for_extra.get('arrotondamento_giornaliero_tipo', 'floor')
                    # Calcola straordinario lordo (prima dell'arrotondamento a blocchi)
                    extra_minutes_lordo = worked_minutes - planned_minutes
                    
                    extra_turno_data = {
                        "extra_type": "daily_overtime",
                        "extra_minutes": extra_minutes,
                        "extra_minutes_lordo": extra_minutes_lordo,
                        "worked_minutes": worked_minutes,
                        "planned_minutes": planned_minutes,
                        "pausa_effettiva_minuti": total_pausa_effettiva,
                        "pausa_pianificata_minuti": planned_break,
                        "blocco_straordinario_minuti": blocco_str,
                        "tipo_arrotondamento": tipo_arrot,
                        "differenza_minuti": extra_minutes_lordo - extra_minutes,
                        "break_confirmed": break_info.get('break_confirmed', False) if break_info else False,
                        "break_skipped": break_info.get('break_skipped', False) if break_info else False,
                        "break_skip_reason": break_info.get('break_skip_reason', '') if break_info else '',
                        "rejection_end_time": rejection_end_time,
                        "turno_time": turno_end or "",
                        "ora_timbrata": ora,
                        "ora_mod": ora_mod,
                        "planned_start": turno_start,
                        "planned_end": turno_end,
                    }
                    
                    app.logger.info(
                        "Extra Turno rilevato per %s: worked=%s min, planned=%s min, extra=%s min",
                        username, worked_minutes, planned_minutes, extra_minutes
                    )
                    
                    # ── Verifica anticipo == extra turno PRIMA di creare la richiesta ──
                    # Se esiste un'autorizzazione Fuori Flessibilità (tipo 17) per oggi
                    # con lo stesso numero di minuti dell'extra turno, l'anticipo copre
                    # già il tempo extra → NON creare la richiesta ET, skip popup
                    try:
                        flex_row_pre = db.execute(
                            f"""SELECT id, value_amount, notes FROM user_requests
                               WHERE username = {placeholder}
                                 AND request_type_id = (SELECT id FROM request_types WHERE name = 'Fuori Flessibilità' LIMIT 1)
                                 AND date_from = {placeholder}
                                 AND status != 'rejected'
                               ORDER BY created_ts DESC LIMIT 1""",
                            (username, today)
                        ).fetchone()
                        if flex_row_pre:
                            flex_val_pre = float(flex_row_pre['value_amount'] if isinstance(flex_row_pre, dict) else flex_row_pre[1]) if (flex_row_pre['value_amount'] if isinstance(flex_row_pre, dict) else flex_row_pre[1]) else 0
                            flex_notes_pre = (flex_row_pre['notes'] if isinstance(flex_row_pre, dict) else flex_row_pre[2]) or ''
                            if abs(flex_val_pre - extra_minutes) < 1:
                                # Anticipo autorizzato == Extra Turno → nessuna richiesta ET
                                extra_turno_skip_motivation = True
                                extra_turno_anticipo_notes = flex_notes_pre
                                app.logger.info(
                                    "Extra Turno SKIP: anticipo autorizzato=%.0f min == extra=%.0f min → nessuna richiesta ET creata",
                                    flex_val_pre, extra_minutes
                                )
                    except Exception as skip_pre_e:
                        app.logger.warning(f"Errore verifica anticipo pre-ET: {skip_pre_e}")
                    
                    # Crea la richiesta ET solo se NON è già coperta dall'anticipo
                    if not extra_turno_skip_motivation:
                        extra_turno_request_id = _create_auto_extra_turno_request(
                            db=db,
                            username=username,
                            date_str=today,
                            extra_data=extra_turno_data,
                            notes=f"Extra Turno rilevato automaticamente - {extra_minutes} min oltre le {planned_minutes // 60}h{planned_minutes % 60:02d} pianificate"
                        )
                else:
                    app.logger.info(
                        "Extra Turno NON rilevato per %s: worked=%s min <= planned=%s min",
                        username, worked_minutes, planned_minutes
                    )
            else:
                app.logger.info("Extra Turno SKIP per %s: nessun turno pianificato trovato", username)
                
        except Exception as e:
            app.logger.error(f"Errore rilevamento Extra Turno: {e}")
            import traceback
            app.logger.error(f"Traceback: {traceback.format_exc()}")
    
    # ═══════════════════════════════════════════════════════════════════════════
    # RILEVAMENTO RITARDO (Late Arrival)
    # ═══════════════════════════════════════════════════════════════════════════
    late_arrival_request_id = None
    late_arrival_data = None
    _is_production_late = False
    
    # Rileva ritardi SOLO per inizio_giornata (per tutti i gruppi)
    if tipo == 'inizio_giornata':
        try:
            # Usa le regole specifiche dell'utente (gruppo o globali)
            rules_for_late = get_user_timbratura_rules(db, username)
            
            # Determina se il gruppo è di produzione
            _is_production_late = False
            try:
                _user_grp = db.execute(
                    f"SELECT g.is_production FROM app_users u JOIN user_groups g ON u.group_id = g.id WHERE u.username = {placeholder}",
                    (username,)
                ).fetchone()
                _is_production_late = bool(
                    (_user_grp['is_production'] if isinstance(_user_grp, dict) else _user_grp[0]) if _user_grp else False
                )
            except Exception:
                pass
            
            app.logger.info(
                "Checking Late Arrival: user=%s, ora=%s, ora_mod=%s, turno_start=%s, threshold=%s, is_production=%s, flex=%s",
                username, ora, ora_mod, turno_start, rules_for_late.get('late_threshold_minutes', 15),
                _is_production_late, rules_for_late.get('flessibilita_ingresso_minuti', 0)
            )
            
            late_arrival_data = _detect_late_arrival(
                ora_timbrata=ora,
                ora_mod=ora_mod,
                turno_start=turno_start,
                rules=rules_for_late,
                is_production=_is_production_late
            )
            
            if late_arrival_data:
                late_arrival_data['is_production'] = _is_production_late
                
                app.logger.info(
                    "Late Arrival rilevato per %s: late_minutes=%s, threshold_effettivo=%s, is_production=%s",
                    username, late_arrival_data.get("late_minutes"), 
                    late_arrival_data.get("threshold"),
                    _is_production_late
                )
                
                # Crea automaticamente la richiesta di Giustificazione Ritardo
                late_arrival_request_id = _create_late_arrival_request(
                    db=db,
                    username=username,
                    date_str=today,
                    late_data=late_arrival_data,
                    placeholder=placeholder
                )
            else:
                app.logger.info(
                    "Late Arrival NON rilevato per %s: ora=%s, turno_start=%s",
                    username, ora, turno_start
                )
        except Exception as e:
            app.logger.error(f"Errore rilevamento Late Arrival: {e}")
            import traceback
            app.logger.error(f"Traceback: {traceback.format_exc()}")
    
    # Recupera dati GPS dalla sessione o da offline_gps
    method = session.get("timbratura_method", "manual")
    gps_lat = session.get("timbratura_gps_lat")
    gps_lon = session.get("timbratura_gps_lon")
    location_name = session.get("timbratura_location")
    
    # Se è una timbratura offline GPS, usa quei dati
    if offline_gps and bypass_qr:
        method = "gps_offline"
        gps_lat = offline_gps.get('latitude')
        gps_lon = offline_gps.get('longitude')
        # Cerca location name dalle coordinate
        settings = get_company_settings(db)
        custom = settings.get('custom_settings', {})
        timbratura_config = custom.get('timbratura', {})
        locations = timbratura_config.get('gps_locations', [])
        for loc in locations:
            loc_lat = loc.get("latitude")
            loc_lon = loc.get("longitude")
            loc_radius = loc.get("radius_meters", 300)
            if loc_lat and loc_lon:
                from math import radians, sin, cos, sqrt, atan2
                R = 6371000
                lat1, lon1 = radians(float(loc_lat)), radians(float(loc_lon))
                lat2, lon2 = radians(float(gps_lat)), radians(float(gps_lon))
                dlat = lat2 - lat1
                dlon = lon2 - lon1
                a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
                c = 2 * atan2(sqrt(a), sqrt(1-a))
                distance = R * c
                if distance <= loc_radius:
                    location_name = loc.get("name", "Sede")
                    break
    elif offline_qr and bypass_qr:
        method = "qr_offline"
    
    # Inserisce la timbratura con dati GPS
    cursor = db.execute(
        f"""
        INSERT INTO timbrature (username, tipo, data, ora, ora_mod, created_ts, method, gps_lat, gps_lon, location_name)
        VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
        """,
        (username, tipo, today, ora, ora_mod, created_ts, method, gps_lat, gps_lon, location_name)
    )
    new_timbratura_id = cursor.lastrowid
    
    # Se fine_giornata, verifica che ora_mod non sia prima di fine_pausa.ora_mod
    # (la giornata non può finire prima che finisca la pausa normalizzata)
    if tipo == 'fine_giornata':
        fine_pausa_row = db.execute(
            f"""
            SELECT ora_mod FROM timbrature 
            WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'fine_pausa'
            ORDER BY ora DESC LIMIT 1
            """,
            (username, today)
        ).fetchone()
        
        if fine_pausa_row:
            fp_ora_mod = fine_pausa_row['ora_mod'] if isinstance(fine_pausa_row, dict) else fine_pausa_row[0]
            
            if fp_ora_mod and ora_mod:
                # Converti in minuti per confronto
                fp_mod_parts = str(fp_ora_mod).split(':')
                fg_parts = str(ora_mod).split(':')
                fp_mod_min = int(fp_mod_parts[0]) * 60 + int(fp_mod_parts[1])
                fg_min = int(fg_parts[0]) * 60 + int(fg_parts[1])
                
                if fp_mod_min > fg_min:
                    # fine_giornata.ora_mod deve essere almeno = fine_pausa.ora_mod
                    app.logger.info(f"Aggiusto fine_giornata: ora_mod {ora_mod} < fine_pausa.ora_mod {fp_ora_mod}, aggiorno a {fp_ora_mod}")
                    db.execute(
                        f"UPDATE timbrature SET ora_mod = {placeholder} WHERE id = {placeholder}",
                        (fp_ora_mod, new_timbratura_id)
                    )
                    ora_mod = fp_ora_mod  # Aggiorna per CedolinoWeb
    
    # ═══════════════════════════════════════════════════════════════════════════
    # PAUSA CONFERMATA: se l'utente ha confermato la pausa (non timbrata),
    # crea le timbrature inizio_pausa e fine_pausa con gli orari pianificati
    # e invia a CedolinoWeb
    # ═══════════════════════════════════════════════════════════════════════════
    created_break_records = []
    break_debug = {}  # Debug info per risposta API
    
    if tipo == 'fine_giornata':
        break_debug['break_info_received'] = break_info is not None
        break_debug['break_info_value'] = str(break_info) if break_info else None
        break_debug['condition_confirmed'] = bool(break_info and break_info.get('break_confirmed'))
        break_debug['condition_not_stamped'] = bool(break_info and not break_info.get('break_stamped'))
    
    if tipo == 'fine_giornata' and break_info and break_info.get('break_confirmed') and not break_info.get('break_stamped'):
        break_debug['entered_creation_block'] = True
        try:
            # Verifica che non ci siano già pause timbraste oggi
            existing_pausa = db.execute(
                f"""SELECT COUNT(*) as cnt FROM timbrature 
                   WHERE username = {placeholder} AND data = {placeholder} 
                   AND tipo IN ('inizio_pausa', 'fine_pausa')""",
                (username, today)
            ).fetchone()
            existing_count = existing_pausa['cnt'] if isinstance(existing_pausa, dict) else existing_pausa[0]
            break_debug['existing_pausa_count'] = existing_count
            
            if existing_count == 0:
                # Recupera break_start e break_end dalla configurazione turno
                break_start_str = None
                break_end_str = None
                break_minutes_info = None
                break_source = None  # Traccia da dove arrivano i dati

                # ── Priorità 1: dati passati dal frontend nel break_info ──
                if break_info:
                    bi_start = break_info.get('break_start')
                    bi_end = break_info.get('break_end')
                    bi_minutes = break_info.get('break_minutes')
                    break_debug['p1_bi_start'] = str(bi_start)
                    break_debug['p1_bi_end'] = str(bi_end)
                    break_debug['p1_bi_minutes'] = str(bi_minutes)

                    if bi_start and bi_end:
                        break_start_str = f"{str(bi_start)[:5]}:00"
                        break_end_str = f"{str(bi_end)[:5]}:00"
                        break_source = "frontend_break_info"
                    try:
                        if bi_minutes is not None:
                            break_minutes_info = int(float(bi_minutes))
                    except Exception:
                        break_minutes_info = None

                # ── Priorità 2: employee_shifts (SOLO se P1 non ha trovato orari) ──
                if not break_start_str or not break_end_str:
                    try:
                        ensure_employee_shifts_table(db)
                        brow = db.execute(
                            f"""SELECT break_start, break_end FROM employee_shifts 
                               WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1""",
                            (username, day_of_week)
                        ).fetchone()
                        break_debug['p2_employee_shifts_found'] = brow is not None
                        if brow:
                            _bs = brow['break_start'] if isinstance(brow, dict) else brow[0]
                            _be = brow['break_end'] if isinstance(brow, dict) else brow[1]
                            break_debug['p2_bs'] = str(_bs)
                            break_debug['p2_be'] = str(_be)
                            if _bs and _be:
                                if hasattr(_bs, 'total_seconds'):
                                    total_sec = int(_bs.total_seconds())
                                    break_start_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}:00"
                                elif hasattr(_bs, 'strftime'):
                                    break_start_str = _bs.strftime("%H:%M:%S")
                                else:
                                    bs_s = str(_bs)[:5]
                                    break_start_str = f"{bs_s}:00"
                                if hasattr(_be, 'total_seconds'):
                                    total_sec = int(_be.total_seconds())
                                    break_end_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}:00"
                                elif hasattr(_be, 'strftime'):
                                    break_end_str = _be.strftime("%H:%M:%S")
                                else:
                                    be_s = str(_be)[:5]
                                    break_end_str = f"{be_s}:00"
                                break_source = "employee_shifts"
                    except Exception as e:
                        break_debug['p2_error'] = str(e)
                        app.logger.warning(f"Errore lettura break da employee_shifts per pausa confermata: {e}")

                # ── Priorità 3: Rentman plannings (SOLO se P1 e P2 non hanno trovato) ──
                if not break_start_str or not break_end_str:
                    try:
                        user_row_break = db.execute(
                            f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
                            (username,)
                        ).fetchone()
                        crew_id_break = None
                        if user_row_break:
                            crew_id_break = user_row_break['rentman_crew_id'] if isinstance(user_row_break, dict) else user_row_break[0]
                        break_debug['p3_crew_id'] = str(crew_id_break)

                        if crew_id_break:
                            # Cerca pausa in TUTTI i turni, non solo il primo
                            rentman_break_rows = db.execute(
                                f"""SELECT break_start, break_end, break_minutes, plan_start, plan_end FROM rentman_plannings
                                   WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                                     AND (is_obsolete IS NULL OR is_obsolete = 0)
                                   ORDER BY plan_start ASC""",
                                (crew_id_break, today)
                            ).fetchall()
                            break_debug['p3_rentman_rows_count'] = len(rentman_break_rows) if rentman_break_rows else 0

                            for idx_rb, rentman_break_row in enumerate(rentman_break_rows or []):
                                _rbs = rentman_break_row['break_start'] if isinstance(rentman_break_row, dict) else rentman_break_row[0]
                                _rbe = rentman_break_row['break_end'] if isinstance(rentman_break_row, dict) else rentman_break_row[1]
                                _rbm = rentman_break_row['break_minutes'] if isinstance(rentman_break_row, dict) else rentman_break_row[2]
                                _rps = rentman_break_row['plan_start'] if isinstance(rentman_break_row, dict) else rentman_break_row[3]
                                _rpe = rentman_break_row['plan_end'] if isinstance(rentman_break_row, dict) else rentman_break_row[4]
                                break_debug[f'p3_row{idx_rb}'] = f"bs={_rbs}, be={_rbe}, bm={_rbm}, ps={_rps}, pe={_rpe}"

                                # 3a: usa break_start/break_end direttamente
                                if _rbs and _rbe and not break_start_str:
                                    if hasattr(_rbs, 'strftime'):
                                        break_start_str = _rbs.strftime("%H:%M:%S")
                                    else:
                                        rbs_s = str(_rbs)[:5]
                                        break_start_str = f"{rbs_s}:00"

                                    if hasattr(_rbe, 'strftime'):
                                        break_end_str = _rbe.strftime("%H:%M:%S")
                                    else:
                                        rbe_s = str(_rbe)[:5]
                                        break_end_str = f"{rbe_s}:00"
                                    break_source = f"rentman_break_times_row{idx_rb}"
                                    break

                                # 3b: solo break_minutes → calcola intervallo centrato
                                if (not break_start_str or not break_end_str) and _rbm:
                                    try:
                                        break_minutes_val = int(float(_rbm))
                                    except Exception:
                                        break_minutes_val = 0

                                    if break_minutes_val > 0:
                                        ps_str = None
                                        pe_str = None

                                        if _rps:
                                            ps_str = _rps.strftime("%H:%M") if hasattr(_rps, 'strftime') else str(_rps)[11:16] if len(str(_rps)) > 11 else str(_rps)[:5]
                                        if _rpe:
                                            pe_str = _rpe.strftime("%H:%M") if hasattr(_rpe, 'strftime') else str(_rpe)[11:16] if len(str(_rpe)) > 11 else str(_rpe)[:5]

                                        if not ps_str:
                                            ps_str = turno_start
                                        if not pe_str:
                                            pe_str = turno_end

                                        break_debug[f'p3_row{idx_rb}_compute'] = f"bm={break_minutes_val}, ps={ps_str}, pe={pe_str}"

                                        if ps_str and pe_str:
                                            try:
                                                ps_min = int(ps_str[:2]) * 60 + int(ps_str[3:5])
                                                pe_min = int(pe_str[:2]) * 60 + int(pe_str[3:5])
                                                if pe_min > ps_min and break_minutes_val < (pe_min - ps_min):
                                                    break_start_min = ps_min + ((pe_min - ps_min - break_minutes_val) // 2)
                                                    break_end_min = break_start_min + break_minutes_val
                                                    break_start_str = f"{break_start_min // 60:02d}:{break_start_min % 60:02d}:00"
                                                    break_end_str = f"{break_end_min // 60:02d}:{break_end_min % 60:02d}:00"
                                                    break_source = f"rentman_break_minutes_computed_row{idx_rb}"
                                                    break
                                            except Exception as comp_e:
                                                break_debug[f'p3_row{idx_rb}_compute_error'] = str(comp_e)
                    except Exception as e:
                        break_debug['p3_error'] = str(e)
                        app.logger.warning(f"Errore fallback break da rentman_plannings per pausa confermata: {e}")

                # ── Priorità 4: Fallback finale con break_minutes_info + turno_start/turno_end ──
                if (not break_start_str or not break_end_str) and break_minutes_info and turno_start and turno_end:
                    break_debug['p4_fallback'] = f"bm={break_minutes_info}, ts={turno_start}, te={turno_end}"
                    try:
                        ts_min = int(turno_start[:2]) * 60 + int(turno_start[3:5])
                        te_min = int(turno_end[:2]) * 60 + int(turno_end[3:5])
                        if te_min > ts_min and break_minutes_info < (te_min - ts_min):
                            bs_min = ts_min + ((te_min - ts_min - break_minutes_info) // 2)
                            be_min = bs_min + break_minutes_info
                            break_start_str = f"{bs_min // 60:02d}:{bs_min % 60:02d}:00"
                            break_end_str = f"{be_min // 60:02d}:{be_min % 60:02d}:00"
                            break_source = "final_fallback_turno"
                    except Exception as ff_e:
                        break_debug['p4_error'] = str(ff_e)
                
                break_debug['final_break_start'] = break_start_str
                break_debug['final_break_end'] = break_end_str
                break_debug['break_source'] = break_source
                
                if break_start_str and break_end_str:
                    now_ts = now_ms()
                    # Crea inizio_pausa
                    db.execute(
                        f"""INSERT INTO timbrature (username, tipo, data, ora, ora_mod, created_ts, method)
                           VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})""",
                        (username, 'inizio_pausa', today, break_start_str, break_start_str, now_ts, 'confirmed_by_user')
                    )
                    # Crea fine_pausa
                    db.execute(
                        f"""INSERT INTO timbrature (username, tipo, data, ora, ora_mod, created_ts, method)
                           VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})""",
                        (username, 'fine_pausa', today, break_end_str, break_end_str, now_ts, 'confirmed_by_user')
                    )
                    created_break_records = [
                        {'tipo': 'inizio_pausa', 'ora': break_start_str, 'timeframe': TIMEFRAME_INIZIO_PAUSA},
                        {'tipo': 'fine_pausa', 'ora': break_end_str, 'timeframe': TIMEFRAME_FINE_PAUSA},
                    ]
                    break_debug['records_created'] = True
                    app.logger.info(
                        "Pausa confermata per %s: create timbrature inizio_pausa %s e fine_pausa %s (method=confirmed_by_user, source=%s)",
                        username, break_start_str, break_end_str, break_source
                    )
                else:
                    break_debug['records_created'] = False
                    break_debug['failure_reason'] = 'break_start or break_end non trovati in nessuna sorgente'
                    app.logger.warning(
                        "Pausa confermata per %s MA orari pausa non trovati! Debug: %s",
                        username, json.dumps(break_debug)
                    )
            else:
                break_debug['skipped_reason'] = f'existing_pausa_count={existing_count}'
        except Exception as e:
            break_debug['exception'] = str(e)
            import traceback
            break_debug['traceback'] = traceback.format_exc()
            app.logger.error(f"Errore creazione timbrature pausa confermata: {e}\n{traceback.format_exc()}")
    elif tipo == 'fine_giornata':
        if not break_info:
            break_debug['skipped_reason'] = 'break_info is None/empty'
        elif not break_info.get('break_confirmed'):
            break_debug['skipped_reason'] = 'break_confirmed is False'
        elif break_info.get('break_stamped'):
            break_debug['skipped_reason'] = 'break already stamped'
    
    app.logger.info(f"BREAK_DEBUG {username}: {json.dumps(break_debug)}")
    
    # Pulisce dati timbratura dalla sessione
    session.pop("timbratura_method", None)
    session.pop("timbratura_gps_lat", None)
    session.pop("timbratura_gps_lon", None)
    session.pop("timbratura_location", None)
    
    # CedolinoWeb: invia timbrata con ora originale e modificata
    # Mappa tipo timbratura -> timeframe CedolinoWeb
    TIPO_TO_TIMEFRAME = {
        'inizio_giornata': TIMEFRAME_INIZIO_GIORNATA,  # 1
        'inizio_pausa': TIMEFRAME_INIZIO_PAUSA,        # 4
        'fine_pausa': TIMEFRAME_FINE_PAUSA,            # 5
        'fine_giornata': TIMEFRAME_FINE_GIORNATA,      # 8
    }
    
    timeframe_id = TIPO_TO_TIMEFRAME.get(tipo)
    cedolino_url = None
    
    if timeframe_id:
        # Recupera il nome dell'utente per il log
        user_row = db.execute(
            f"SELECT display_name FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        display_name = username
        if user_row:
            display_name = (user_row['display_name'] if isinstance(user_row, dict) else user_row[0]) or username
        
        # Genera sempre l'URL di debug (anche se CedolinoWeb è disabilitato)
        from urllib.parse import urlencode
        external_id_debug = get_external_id_for_username(db, username) or "N/A"
        external_group_id_debug = get_external_group_id_for_username(db, username) or "NULL"
        debug_params = {
            "data_riferimento": today,
            "data_originale": f"{today} {ora}",
            "data_modificata": f"{today} {ora_mod or ora}",
            "codice_utente": external_id_debug,
            "codice_terminale": CEDOLINO_CODICE_TERMINALE,
            "timeframe_id": str(timeframe_id),
            "assunzione_id": external_id_debug,
            "terminale_id": "NULL",
            "gruppo_id": external_group_id_debug,
            "turno_id": "NULL",
            "note": "",
            "validata": "true",
        }
        cedolino_url = f"{CEDOLINO_WEB_ENDPOINT}?{urlencode(debug_params)}"
        
        # Determina se bloccare la sync per Extra Turno:
        # 1. Se abbiamo appena creato una richiesta Extra Turno automatica, usa quell'ID
        # 2. Altrimenti verifica se c'è una richiesta Extra Turno pending esistente
        overtime_request_id = extra_turno_request_id  # Usa l'ID Extra Turno appena creato se presente
        
        if not overtime_request_id:
            # Cerca richieste Extra Turno pending esistenti per oggi
            overtime_request_id = _get_pending_overtime_request_id(db, username, today)
        
        if overtime_request_id:
            app.logger.info(
                "Timbratura %s per %s bloccata in attesa revisione Extra Turno (request_id=%s)",
                tipo, username, overtime_request_id
            )
        
        ora_da_salvare = ora_mod or ora
        
        timbrata_ok, external_id, timbrata_error, _ = send_timbrata_utente(
            db,
            username=username,
            member_name=display_name,
            timeframe_id=timeframe_id,
            data_riferimento=today,
            ora_originale=ora,
            ora_modificata=ora_da_salvare,
            overtime_request_id=overtime_request_id,
        )
        
        if not timbrata_ok and external_id is None:
            # Utente senza ID esterno - blocca l'operazione (rollback implicito)
            return jsonify({
                "error": timbrata_error or "Utente senza ID esterno CedolinoWeb. Contattare l'amministratore.",
                "missing_external_id": True,
                "cedolino_url": cedolino_url  # Mostra comunque l'URL per debug
            }), 400
    
    # Invia a CedolinoWeb le timbrature pausa confermate (inizio_pausa + fine_pausa)
    if created_break_records:
        try:
            # Recupera display_name se non già disponibile
            _dn_row = db.execute(
                f"SELECT display_name FROM app_users WHERE username = {placeholder}",
                (username,)
            ).fetchone()
            _disp_name = username
            if _dn_row:
                _disp_name = (_dn_row['display_name'] if isinstance(_dn_row, dict) else _dn_row[0]) or username
            
            # Usa lo stesso overtime_request_id se definito
            _ot_req_id = extra_turno_request_id or _get_pending_overtime_request_id(db, username, today)
            
            for brec in created_break_records:
                try:
                    brk_ok, brk_ext_id, brk_err, _ = send_timbrata_utente(
                        db,
                        username=username,
                        member_name=_disp_name,
                        timeframe_id=brec['timeframe'],
                        data_riferimento=today,
                        ora_originale=brec['ora'],
                        ora_modificata=brec['ora'],
                        overtime_request_id=_ot_req_id,
                    )
                    if brk_ok:
                        app.logger.info(
                            "CedolinoWeb: inviata pausa confermata %s alle %s per %s",
                            brec['tipo'], brec['ora'], username
                        )
                    else:
                        app.logger.warning(
                            "CedolinoWeb: errore invio pausa confermata %s per %s: %s",
                            brec['tipo'], username, brk_err
                        )
                except Exception as e:
                    app.logger.error(f"Errore invio pausa confermata a CedolinoWeb: {e}")
        except Exception as e:
            app.logger.error(f"Errore preparazione invio pause confermate: {e}")

    # Se rilevata pausa ridotta significativa, crea richiesta admin
    if break_reduction_data:
        break_reduction_request_id = _create_break_reduction_request(
            db=db,
            username=username,
            date_str=today,
            break_data=break_reduction_data,
            reason=break_reduction_data.get('reason', ''),
            placeholder=placeholder,
        )
    
    db.commit()
    
    # Invalida il token dopo l'uso (ogni timbratura richiede nuova scansione)
    session.pop('timbratura_token', None)
    session.pop('timbratura_token_expires', None)
    
    app.logger.info(f"Timbratura registrata: {username} - {tipo} alle {ora}")
    
    # Restituisci anche l'URL CedolinoWeb per debug
    response_data = {"success": True, "tipo": tipo, "ora": ora[:5]}
    if cedolino_url:
        response_data["cedolino_url"] = cedolino_url
    
    # Se c'è un Extra Turno rilevato, informa il frontend
    if extra_turno_data:
        response_data["extra_turno"] = {
            "detected": True,
            "type": extra_turno_data.get("extra_type"),
            "minutes": extra_turno_data.get("extra_minutes"),
            "worked_minutes": extra_turno_data.get("worked_minutes"),
            "planned_minutes": extra_turno_data.get("planned_minutes"),
            "request_id": extra_turno_request_id,
            "skip_motivation": extra_turno_skip_motivation,
            "anticipo_notes": extra_turno_anticipo_notes,
        }
    
    # Se c'è un Late Arrival rilevato, informa il frontend
    if late_arrival_data and late_arrival_request_id:
        response_data["late_arrival"] = {
            "detected": True,
            "late_minutes": late_arrival_data.get("late_minutes"),
            "threshold": late_arrival_data.get("threshold"),
            "late_threshold_minutes": late_arrival_data.get("late_threshold_minutes", 15),
            "turno_start": late_arrival_data.get("turno_start"),
            "request_id": late_arrival_request_id,
            "flessibilita_ingresso_minuti": late_arrival_data.get("flessibilita_ingresso_minuti", 0),
            "is_production": _is_production_late
        }

    # Se c'è un Fuori Flessibilità rilevato, informa il frontend
    if flex_warning and flex_request_id:
        response_data["flex_warning"] = flex_warning

    if break_reduction_data and break_reduction_request_id:
        response_data["break_reduction_request"] = {
            "detected": True,
            "request_id": break_reduction_request_id,
            "planned_break_minutes": break_reduction_data.get("planned_break_minutes"),
            "effective_break_minutes": break_reduction_data.get("effective_break_minutes"),
            "break_reduction_minutes": break_reduction_data.get("break_reduction_minutes"),
        }
    
    # Debug info per diagnostica pausa confermata e flessibilità uscita
    if tipo == 'fine_giornata':
        response_data["_break_debug"] = break_debug
        try:
            response_data["_flex_exit_debug"] = flex_exit_debug
        except NameError:
            response_data["_flex_exit_debug"] = {"error": "flex_exit_debug not in scope (ora_mod exception?)"}
    
    # ═══════════════════════════════════════════════════════════════════
    # GRUPPI DI PRODUZIONE - Gestione automatica attività
    # ═══════════════════════════════════════════════════════════════════
    # Per utenti in gruppi di produzione (is_production=1) che timbrano:
    # - inizio_giornata: chiedi se avviare l'attività prevista dal turno
    # - inizio_pausa: metti in pausa l'attività
    # - fine_pausa: riprendi l'attività
    # - fine_giornata: termina l'attività
    try:
        app.logger.info(f"[PRODUZIONE] Verifica attività per {username}, tipo={tipo}")
        
        # Recupera info utente: group_id e rentman_crew_id
        user_info_row = db.execute(
            f"SELECT group_id, rentman_crew_id FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        
        app.logger.info(f"[PRODUZIONE] user_info_row={user_info_row}")
        
        if user_info_row:
            user_group_id = user_info_row['group_id'] if isinstance(user_info_row, dict) else user_info_row[0]
            user_crew_id = user_info_row['rentman_crew_id'] if isinstance(user_info_row, dict) else user_info_row[1]
            
            # Verifica se il gruppo è di produzione
            is_production_group = False
            if user_group_id:
                group_row = db.execute(
                    f"SELECT is_production FROM user_groups WHERE id = {placeholder}",
                    (user_group_id,)
                ).fetchone()
                if group_row:
                    is_production_group = bool(group_row['is_production'] if isinstance(group_row, dict) else group_row[0])
            
            if is_production_group and user_crew_id:
                app.logger.info(f"Utente {username} appartiene a gruppo produzione (group_id={user_group_id})")
                
                # Cerca TUTTI i turni odierni dell'utente da rentman_plannings
                turni_oggi = db.execute(
                    f"""SELECT project_code, project_name, function_name, is_leader, plan_start, plan_end, gestione_squadra
                        FROM rentman_plannings
                        WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                          AND sent_to_webservice = 1 AND (is_obsolete = 0 OR is_obsolete IS NULL)
                        ORDER BY plan_start ASC""",
                    (user_crew_id, today)
                ).fetchall()
                
                # Usa il primo turno per pausa/resume/stop
                turno_info = turni_oggi[0] if turni_oggi else None
                
                # Cerca il primo turno SENZA gestione squadra per proporre il popup attività
                turno_per_popup = None
                for t in turni_oggi:
                    t_proj = t['project_code'] if isinstance(t, dict) else t[0]
                    t_is_leader = bool(t['is_leader'] if isinstance(t, dict) else t[3])
                    t_gestione_squadra = bool(t['gestione_squadra'] if isinstance(t, dict) else t[6])
                    
                    if t_is_leader:
                        # L'utente è leader in questo turno, il leader non ha bisogno del popup
                        continue
                    
                    if t_gestione_squadra:
                        # Gestione squadra attiva → il leader gestisce le attività, skip
                        app.logger.info(f"Turno {t_proj}: gestione_squadra attiva, skip popup")
                        continue
                    
                    # Gestione squadra NON attiva → popup attività individuale
                    turno_per_popup = t
                    break

                # Verifica se TUTTI i turni sono gestione_squadra (per l'utente non-leader)
                all_gestione_squadra = turni_oggi and len(turni_oggi) > 0 and all(
                    (bool(t['gestione_squadra'] if isinstance(t, dict) else (t[6] if len(t) > 6 else False))
                     and not bool(t['is_leader'] if isinstance(t, dict) else (t[3] if len(t) > 3 else False)))
                    for t in turni_oggi
                )

                # Inizio giornata: proponi popup attività
                # - con dati pianificati se disponibili
                # - in modalità manuale (progetto + attività) se non c'è turno/mansione
                # - MA NON se tutti i turni sono gestione_squadra (attività gestite dal caposquadra)
                if tipo == 'inizio_giornata':
                    if turno_per_popup:
                        popup_proj = turno_per_popup['project_code'] if isinstance(turno_per_popup, dict) else turno_per_popup[0]
                        popup_name = turno_per_popup['project_name'] if isinstance(turno_per_popup, dict) else turno_per_popup[1]
                        popup_func = turno_per_popup['function_name'] if isinstance(turno_per_popup, dict) else turno_per_popup[2]
                        if popup_func:
                            response_data["production_activity"] = {
                                "detected": True,
                                "project_code": popup_proj,
                                "project_name": popup_name,
                                "activity_label": popup_func,
                                "action": "start",
                                "timbratura_ts": created_ts
                            }
                            app.logger.info(f"Proposta avvio attività produzione: {popup_func} per {username} (progetto senza gestione squadra)")
                        else:
                            response_data["production_activity"] = {
                                "detected": True,
                                "project_code": "",
                                "project_name": "",
                                "activity_label": "",
                                "action": "start",
                                "manual_selection": True,
                                "requires_project_selection": True,
                                "requires_activity_selection": True,
                                "timbratura_ts": created_ts
                            }
                            app.logger.info(f"Popup attività produzione manuale: nessuna mansione pianificata per {username}")
                    elif all_gestione_squadra:
                        # Tutti i turni sono gestione_squadra → nessun popup, solo timbratura
                        app.logger.info(f"Skip popup attività per {username}: tutti i turni sono gestione_squadra")
                    else:
                        response_data["production_activity"] = {
                            "detected": True,
                            "project_code": "",
                            "project_name": "",
                            "activity_label": "",
                            "action": "start",
                            "manual_selection": True,
                            "requires_project_selection": True,
                            "requires_activity_selection": True,
                            "timbratura_ts": created_ts
                        }
                        app.logger.info(f"Popup attività produzione manuale: nessun turno pianificato per {username}")
                
                if turno_info:
                    if isinstance(turno_info, dict):
                        proj_code = turno_info['project_code']
                        proj_name = turno_info['project_name']
                        func_name = turno_info['function_name']
                        user_is_leader = bool(turno_info['is_leader'])
                    else:
                        proj_code = turno_info[0]
                        proj_name = turno_info[1]
                        func_name = turno_info[2]
                        user_is_leader = bool(turno_info[3])
                    
                    app.logger.info(f"Turno produzione: project={proj_code}, funzione={func_name}, is_leader={user_is_leader}")
                    
                    # Gestisci pausa/resume/stop SEMPRE se c'è un timer attivo (indipendentemente dal leader)
                    if tipo == 'inizio_pausa':
                        # Inizio pausa: metti in pausa l'attività se attiva
                        if _pause_production_timer(db, username, proj_code):
                            response_data["production_activity"] = {
                                "detected": True,
                                "action": "paused"
                            }
                    
                    elif tipo == 'fine_pausa':
                        # Fine pausa: riprendi l'attività se era in pausa
                        if _resume_production_timer(db, username, proj_code):
                            response_data["production_activity"] = {
                                "detected": True,
                                "action": "resumed"
                            }
                    
                    elif tipo == 'fine_giornata':
                        # Fine giornata: termina l'attività
                        if _stop_production_timer(db, username, proj_code):
                            response_data["production_activity"] = {
                                "detected": True,
                                "action": "stopped"
                            }
                else:
                    # Nessun turno oggi, ma potrebbe esserci un timer attivo avviato manualmente
                    # Gestisci comunque pausa/resume/stop
                    if tipo == 'inizio_pausa':
                        if _pause_production_timer(db, username, None):
                            response_data["production_activity"] = {"detected": True, "action": "paused"}
                    elif tipo == 'fine_pausa':
                        if _resume_production_timer(db, username, None):
                            response_data["production_activity"] = {"detected": True, "action": "resumed"}
                    elif tipo == 'fine_giornata':
                        if _stop_production_timer(db, username, None):
                            response_data["production_activity"] = {"detected": True, "action": "stopped"}
    except Exception as e:
        app.logger.warning(f"Errore gestione attività produzione: {e}")
    
    app.logger.info(f"Risposta timbratura per {username}: extra_turno_data={extra_turno_data}, flex_warning={flex_warning}, late_arrival_data={late_arrival_data}, response_data={response_data}")
    
    return jsonify(response_data)


@app.get("/api/check_break_needed")
@login_required
def api_check_break_needed():
    """Verifica se oggi è prevista una pausa (da employee_shifts o Rentman) e se è già stata timbrata."""
    username = session.get('user_id')
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    today = datetime.now().strftime('%Y-%m-%d')
    day_of_week = datetime.now().weekday()  # 0=lunedì … 6=domenica

    planned_minutes = 0
    try:
        planned_break_data = _get_planned_break_minutes_for_day(
            db=db,
            username=username,
            date_str=today,
            day_of_week=day_of_week,
            placeholder=placeholder,
        )
        planned_minutes = int(planned_break_data.get('minutes', 0) or 0)
    except Exception as e:
        app.logger.warning(f"api_check_break_needed: errore _get_planned: {e}")

    has_pausa = False
    try:
        pausa_row = db.execute(
            f"""SELECT COUNT(*) as cnt FROM timbrature
               WHERE username = {placeholder} AND data = {placeholder}
                 AND tipo IN ('inizio_pausa', 'fine_pausa')""",
            (username, today)
        ).fetchone()
        n_pause = (pausa_row['cnt'] if isinstance(pausa_row, dict) else pausa_row[0]) if pausa_row else 0
        has_pausa = n_pause > 0
    except Exception as e:
        app.logger.warning(f"api_check_break_needed: errore query timbrature: {e}")

    return jsonify({
        "planned_break_minutes": planned_minutes,
        "has_pausa_timbrata": has_pausa,
    })


@app.post("/api/user/change-password")
@login_required
def api_user_change_password():
    """Permette all'utente di cambiare la propria password."""
    username = session.get('user')
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    current_password = data.get('current_password', '')
    new_password = data.get('new_password', '')
    
    if not current_password or not new_password:
        return jsonify({"error": "Password attuale e nuova password richieste"}), 400
    
    if len(new_password) < 4:
        return jsonify({"error": "La nuova password deve essere di almeno 4 caratteri"}), 400
    
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica password attuale
    user = db.execute(
        f"SELECT password_hash FROM app_users WHERE username = {placeholder}",
        (username,)
    ).fetchone()
    
    if not user:
        return jsonify({"error": "Utente non trovato"}), 404
    
    stored_hash = user['password_hash'] if isinstance(user, dict) else user[0]
    
    # Verifica la password attuale
    if not check_password_hash(stored_hash, current_password):
        return jsonify({"error": "Password attuale non corretta"}), 400
    
    # Genera hash per la nuova password
    new_hash = generate_password_hash(new_password)
    
    # Aggiorna nel database
    db.execute(
        f"UPDATE app_users SET password_hash = {placeholder}, updated_ts = {placeholder} WHERE username = {placeholder}",
        (new_hash, now_ms(), username)
    )
    db.commit()
    
    app.logger.info(f"Utente {username} ha cambiato la propria password")
    
    return jsonify({"success": True, "message": "Password aggiornata con successo"})


def _build_valid_locations(group_default_loc, timbratura_location, timbratura_lat, timbratura_lon, timbratura_radius, location_name, location_lat, location_lon, location_radius, gps_mode, custom_locations=None):
    """Costruisce la lista delle locations valide per la timbratura GPS.
    Include sempre la sede default del gruppo + la location del turno (Rentman) se presente e diversa
    + eventuali custom locations assegnate al planning."""
    valid = []
    seen_names = set()

    app.logger.info(f"_build_valid_locations CALLED: group_default={group_default_loc}, timbratura_location={timbratura_location}, "
                    f"timbratura_lat={timbratura_lat}, timbratura_lon={timbratura_lon}, "
                    f"location_name={location_name}, location_lat={location_lat}, location_lon={location_lon}, location_radius={location_radius}, gps_mode={gps_mode}, custom_locations={custom_locations}")

    # 1. Sede default del gruppo (sempre valida)
    if group_default_loc and group_default_loc.get('latitude') and group_default_loc.get('longitude'):
        valid.append(group_default_loc)
        seen_names.add(group_default_loc['name'])
        app.logger.info(f"_build_valid_locations: +sede gruppo '{group_default_loc['name']}'")
    else:
        app.logger.warning(f"_build_valid_locations: sede gruppo MANCANTE o senza coordinate: {group_default_loc}")

    # 2. Location del turno Rentman (se ha coordinate e non è già presente)
    #    Sempre inclusa indipendentemente dal gps_mode
    if location_name and location_lat and location_lon and location_name not in seen_names:
        valid.append({
            "name": location_name,
            "latitude": float(location_lat),
            "longitude": float(location_lon),
            "radius_meters": location_radius or 300
        })
        seen_names.add(location_name)
        app.logger.info(f"_build_valid_locations: +location Rentman '{location_name}'")
    else:
        app.logger.info(f"_build_valid_locations: location Rentman NON aggiunta: name={location_name}, lat={location_lat}, lon={location_lon}, already_seen={location_name in seen_names if location_name else 'N/A'}")

    # 3. GPS timbratura location (se diversa da sede gruppo e da location Rentman)
    if timbratura_location and timbratura_lat and timbratura_lon and timbratura_location not in seen_names:
        valid.append({
            "name": timbratura_location,
            "latitude": float(timbratura_lat),
            "longitude": float(timbratura_lon),
            "radius_meters": timbratura_radius or 300
        })
        seen_names.add(timbratura_location)
        app.logger.info(f"_build_valid_locations: +timbratura location '{timbratura_location}'")

    # 4. Custom locations assegnate al planning (da custom_location_ids)
    if custom_locations:
        for cl in custom_locations:
            cl_name = cl.get('name', '')
            if cl_name and cl_name not in seen_names and cl.get('latitude') and cl.get('longitude'):
                valid.append({
                    "name": cl_name,
                    "latitude": float(cl['latitude']),
                    "longitude": float(cl['longitude']),
                    "radius_meters": cl.get('radius_meters', 300)
                })
                seen_names.add(cl_name)
                app.logger.info(f"_build_valid_locations: +custom location '{cl_name}'")

    app.logger.info(f"_build_valid_locations RESULT: {len(valid)} locations: {[v.get('name') for v in valid]}")
    return valid


@app.get("/api/user/turno-oggi")
@login_required
def api_user_turno_oggi():
    """Restituisce il turno dell'utente per oggi (da Rentman o da employee_shifts)."""
    try:
        username = session.get('user')
        if not username:
            return jsonify({"error": "Non autenticato"}), 401
        
        db = get_db()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        # Trova il rentman_crew_id dell'utente
        user_row = db.execute(
            f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        
        if not user_row:
            return jsonify({"turno": None, "turni": [], "message": "Utente non trovato"})
        
        crew_id = user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]
        
        # Se non ha crew_id Rentman, cerca nella tabella employee_shifts
        if not crew_id:
            ensure_employee_shifts_table(db)
            
            # Carica le gps_locations dalla configurazione per associare coordinate ai turni
            settings = get_company_settings(db)
            custom = settings.get('custom_settings', {})
            timbratura_config = custom.get('timbratura', {})
            gps_locations = timbratura_config.get('gps_locations', [])
            
            # Trova il giorno della settimana (0=Lunedì, 6=Domenica)
            today = get_simulated_now()
            day_of_week = today.weekday()
            
            shift_row = db.execute(f"""
                SELECT start_time, end_time, break_start, break_end, location_name
                FROM employee_shifts
                WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
            """, (username, day_of_week)).fetchone()
            
            if shift_row:
                if isinstance(shift_row, dict):
                    start_time = str(shift_row['start_time'])[:5] if shift_row['start_time'] else None
                    end_time = str(shift_row['end_time'])[:5] if shift_row['end_time'] else None
                    break_start = str(shift_row['break_start'])[:5] if shift_row['break_start'] else None
                    break_end = str(shift_row['break_end'])[:5] if shift_row['break_end'] else None
                    location_name = shift_row.get('location_name')
                else:
                    start_time = str(shift_row[0])[:5] if shift_row[0] else None
                    end_time = str(shift_row[1])[:5] if shift_row[1] else None
                    break_start = str(shift_row[2])[:5] if shift_row[2] else None
                    break_end = str(shift_row[3])[:5] if shift_row[3] else None
                    location_name = shift_row[4] if len(shift_row) > 4 else None
                
                # Cerca coordinate della location nelle gps_locations configurate
                timbratura_lat = None
                timbratura_lon = None
                timbratura_radius = 300
                if location_name:
                    for loc in gps_locations:
                        if loc.get('name') == location_name:
                            timbratura_lat = loc.get('latitude')
                            timbratura_lon = loc.get('longitude')
                            timbratura_radius = loc.get('radius_meters', 300)
                            app.logger.info(f"✅ employee_shifts: Location '{location_name}' trovata con coordinate: {timbratura_lat}, {timbratura_lon}, raggio={timbratura_radius}")
                            break
                    if not timbratura_lat:
                        app.logger.warning(f"⚠️ employee_shifts: Location '{location_name}' NON trovata nelle gps_locations: {[l.get('name') for l in gps_locations]}")
                
                # Recupera sede default del gruppo per employee_shifts
                es_group_default = None
                try:
                    es_group_row = db.execute(
                        f"""SELECT ug.gps_location_name
                            FROM app_users au JOIN user_groups ug ON au.group_id = ug.id
                            WHERE au.username = {placeholder}""",
                        (username,)
                    ).fetchone()
                    if es_group_row:
                        es_gps_name = es_group_row['gps_location_name'] if isinstance(es_group_row, dict) else es_group_row[0]
                        if es_gps_name:
                            for loc in gps_locations:
                                if loc.get('name') == es_gps_name:
                                    es_group_default = {"name": es_gps_name, "latitude": loc.get('latitude'), "longitude": loc.get('longitude'), "radius_meters": loc.get('radius_meters', 300)}
                                    break
                except Exception:
                    pass

                turno = {
                    "project_code": "UFFICIO",
                    "project_name": "Lavoro in ufficio",
                    "function": "Impiegato",
                    "start": start_time,
                    "end": end_time,
                    "break_start": break_start,
                    "break_end": break_end,
                    "hours": None,
                    "note": None,
                    "is_leader": False,
                    "transport": None,
                    "source": "employee_shifts",
                    "location_name": location_name,
                    "timbratura_location": location_name,
                    "timbratura_lat": timbratura_lat,
                    "timbratura_lon": timbratura_lon,
                    "timbratura_radius": timbratura_radius,
                    "gps_mode": "group",
                    "valid_locations": _build_valid_locations(es_group_default, location_name, timbratura_lat, timbratura_lon, timbratura_radius, location_name, None, None, None, "group"),
                }
                return jsonify({"turno": turno, "turni": [turno]})
            
            return jsonify({"turno": None, "turni": [], "message": "Nessun turno configurato"})
        
        # Se ha crew_id, cerca in rentman_plannings
        today = get_simulated_now().strftime("%Y-%m-%d")
        ensure_rentman_plannings_table(db)
        
        # DEBUG: Mostra cosa c'è nel database per questo utente oggi
        debug_rows = db.execute(
            f"""SELECT crew_id, planning_date, project_name, location_name, 
                      timbratura_gps_mode, gps_timbratura_location, location_id
               FROM rentman_plannings WHERE crew_id = {placeholder} AND planning_date = {placeholder}
               AND (is_obsolete = 0 OR is_obsolete IS NULL)""",
            (crew_id, today)
        ).fetchall()
        
        if debug_rows:
            for debug_row in debug_rows:
                if isinstance(debug_row, dict):
                    app.logger.info(f"DEBUG DB: project={debug_row.get('project_name')}, "
                                  f"location_name={debug_row.get('location_name')}, "
                                  f"gps_mode={debug_row.get('timbratura_gps_mode')}, "
                                  f"gps_timbratura_location={debug_row.get('gps_timbratura_location')}, "
                                  f"location_id={debug_row.get('location_id')}")
                else:
                    app.logger.info(f"DEBUG DB (tuple): {debug_row}")
        else:
            app.logger.warning(f"DEBUG: Nessun turno trovato per crew_id={crew_id}, date={today}")
        
        planning = db.execute(
            f"""
            SELECT project_code, project_name, function_name, plan_start, plan_end,
                   hours_planned, remark, is_leader, transport, break_start, break_end, break_minutes,
                   location_name, timbratura_gps_mode, gps_timbratura_location, location_id, remark_planner,
                   custom_location_ids, gestione_squadra
            FROM rentman_plannings
            WHERE crew_id = {placeholder} AND planning_date = {placeholder} AND sent_to_webservice = 1
              AND (is_obsolete = 0 OR is_obsolete IS NULL)
            ORDER BY plan_start ASC
            """,
            (crew_id, today)
        ).fetchall()
        
        if not planning:
            return jsonify({"turno": None, "turni": [], "message": "Nessun turno per oggi"})
        
        # Recupera la sede default del gruppo dell'utente
        group_default_location = None  # {name, latitude, longitude, radius_meters}
        try:
            group_row = db.execute(
                f"""SELECT ug.gps_location_name
                    FROM app_users au
                    JOIN user_groups ug ON au.group_id = ug.id
                    WHERE au.username = {placeholder}""",
                (username,)
            ).fetchone()
            if group_row:
                gps_loc_name = group_row['gps_location_name'] if isinstance(group_row, dict) else group_row[0]
                if gps_loc_name:
                    # Cerca le coordinate nelle gps_locations della config aziendale
                    settings = get_company_settings(db)
                    custom = settings.get('custom_settings', {})
                    timbratura_cfg = custom.get('timbratura', {})
                    cfg_locations = timbratura_cfg.get('gps_locations', [])
                    for loc in cfg_locations:
                        if loc.get('name') == gps_loc_name:
                            group_default_location = {
                                "name": gps_loc_name,
                                "latitude": loc.get('latitude'),
                                "longitude": loc.get('longitude'),
                                "radius_meters": loc.get('radius_meters', 300)
                            }
                            app.logger.info(f"✅ Sede default gruppo per {username}: '{gps_loc_name}' ({group_default_location['latitude']}, {group_default_location['longitude']})")
                            break
                    if not group_default_location:
                        app.logger.warning(f"⚠️ Sede default gruppo '{gps_loc_name}' non trovata in gps_locations config")
        except Exception as e:
            app.logger.warning(f"Errore recupero sede default gruppo: {e}")
        
        turni = []
        for row in planning:
            if isinstance(row, dict):
                plan_start = row['plan_start']
                plan_end = row['plan_end']
            else:
                plan_start = row[3]
                plan_end = row[4]
            
            start_str = ""
            end_str = ""
            if plan_start:
                if hasattr(plan_start, 'strftime'):
                    start_str = plan_start.strftime("%H:%M")
                else:
                    start_str = str(plan_start)[11:16] if len(str(plan_start)) > 11 else str(plan_start)[:5]
            if plan_end:
                if hasattr(plan_end, 'strftime'):
                    end_str = plan_end.strftime("%H:%M")
                else:
                    end_str = str(plan_end)[11:16] if len(str(plan_end)) > 11 else str(plan_end)[:5]
            
            if isinstance(row, dict):
                break_start = format_time_value(row.get('break_start'))
                break_end = format_time_value(row.get('break_end'))
                break_minutes = row.get('break_minutes')
                location_name = row.get('location_name')
                gps_mode = row.get('timbratura_gps_mode') or 'group'
                gps_timbratura_location = row.get('gps_timbratura_location')
                location_id = row.get('location_id')
                remark_planner = row.get('remark_planner')
                raw_custom_loc_ids = row.get('custom_location_ids')
                row_gestione_squadra = bool(row.get('gestione_squadra'))
            else:
                break_start = format_time_value(row[9] if len(row) > 9 else None)
                break_end = format_time_value(row[10] if len(row) > 10 else None)
                break_minutes = row[11] if len(row) > 11 else None
                location_name = row[12] if len(row) > 12 else None
                gps_mode = (row[13] if len(row) > 13 else None) or 'group'
                gps_timbratura_location = row[14] if len(row) > 14 else None
                location_id = row[15] if len(row) > 15 else None
                remark_planner = row[16] if len(row) > 16 else None
                raw_custom_loc_ids = row[17] if len(row) > 17 else None
                row_gestione_squadra = bool(row[18]) if len(row) > 18 else False
            
            # Coordinate dalla cache globale
            location_lat, location_lon, location_radius = None, None, 300
            if location_name:
                ensure_location_cache_table(db)
                cached_coords = get_location_cache(db, location_name, location_id)
                if cached_coords:
                    location_lat, location_lon, location_radius = cached_coords
                    app.logger.info(f"✅ Location '{location_name}' (id={location_id}): usando coordinate dalla cache globale (turno-oggi): {location_lat}, {location_lon}, raggio={location_radius}m")
                else:
                    app.logger.info(f"⚠️ Location '{location_name}' (id={location_id}): nessuna cache (turno-oggi)")
            
            # Determina dove timbrare e le coordinate GPS
            timbratura_location = None
            timbratura_lat = None
            timbratura_lon = None
            timbratura_radius = 300
            
            # DEBUG
            app.logger.info(f"DEBUG TURNO OGGI: gps_mode={gps_mode}, location_name={location_name}, location_lat={location_lat}, location_lon={location_lon}, gps_timbratura_location={gps_timbratura_location}")
            
            # LOGICA TIMBRATURA:
            # - timbratura_location: dove registrare la timbratura (il nome della sede)
            # - timbratura_lat/lon: le coordinate di quella sede
            
            if gps_mode == 'location':
                # Modalità LOCATION: timbrare presso la location del progetto (da Rentman)
                timbratura_location = location_name
                if location_lat and location_lon:
                    timbratura_lat = location_lat
                    timbratura_lon = location_lon
                    timbratura_radius = location_radius  # Usa il raggio dalla cache
                    app.logger.info(f"DEBUG: Modo LOCATION - Timbratura presso '{timbratura_location}' con coordinate da Rentman: {timbratura_lat}, {timbratura_lon}, raggio={timbratura_radius}m")
                else:
                    app.logger.warning(f"DEBUG: Modo LOCATION - Location '{location_name}' senza coordinate in Rentman")
            
            elif gps_mode == 'group':
                # Modalità GROUP: timbrare presso la sede del gruppo (da config aziendale)
                # timbratura_location è il nome della sede dove timbrare (gps_timbratura_location)
                timbratura_location = gps_timbratura_location or location_name
                
                app.logger.info(f"DEBUG: Modo GROUP - timbratura_location='{timbratura_location}' (gps_timbratura_location='{gps_timbratura_location}'), location_name='{location_name}'")
                
                if gps_timbratura_location:
                    # Usa la sede configurata per il gruppo
                    try:
                        settings = get_company_settings(db)
                        app.logger.info(f"DEBUG: Company settings retrieved: {type(settings)}")
                        
                        custom = settings.get('custom_settings', {})
                        app.logger.info(f"DEBUG: custom_settings keys: {custom.keys() if custom else 'empty'}")
                        
                        timbratura_config = custom.get('timbratura', {})
                        app.logger.info(f"DEBUG: timbratura_config keys: {timbratura_config.keys() if timbratura_config else 'empty'}")
                        
                        gps_locations = timbratura_config.get('gps_locations', [])
                        app.logger.info(f"DEBUG: gps_locations count: {len(gps_locations)}, names: {[l.get('name') for l in gps_locations]}")
                        
                        for loc in gps_locations:
                            loc_name = loc.get('name')
                            app.logger.info(f"DEBUG: Comparing '{gps_timbratura_location}' == '{loc_name}' ? {gps_timbratura_location == loc_name}")
                            if loc_name == gps_timbratura_location:
                                timbratura_lat = loc.get('latitude')
                                timbratura_lon = loc.get('longitude')
                                timbratura_radius = loc.get('radius_meters', 300)
                                app.logger.info(f"DEBUG: ✓ Modo GROUP - TROVATO! Timbratura presso '{gps_timbratura_location}' con coordinate: {timbratura_lat}, {timbratura_lon}, raggio={timbratura_radius}m")
                                break
                        if not timbratura_lat or not timbratura_lon:
                            app.logger.warning(f"DEBUG: ✗ Modo GROUP - Sede gruppo '{gps_timbratura_location}' NON TROVATA in config. Sedi disponibili: {[l.get('name') for l in gps_locations]}")
                    except Exception as e:
                        app.logger.error(f"DEBUG: Errore lettura config aziendale (gps_mode=group): {e}", exc_info=True)
                else:
                    app.logger.warning(f"DEBUG: Modo GROUP - gps_timbratura_location È VUOTO! Non posso cercare le coordinate.")
            
            else:
                app.logger.warning(f"DEBUG: gps_mode sconosciuto: '{gps_mode}'")
            
            # 4. Carica eventuali custom locations dal campo custom_location_ids del planning
            planning_custom_locs = []
            try:
                if raw_custom_loc_ids:
                    import json as _json
                    parsed_ids = None
                    if isinstance(raw_custom_loc_ids, str):
                        try:
                            parsed_ids = _json.loads(raw_custom_loc_ids)
                        except Exception:
                            parsed_ids = None
                    elif isinstance(raw_custom_loc_ids, (list, tuple)):
                        parsed_ids = list(raw_custom_loc_ids)

                    if parsed_ids:
                        ensure_location_cache_table(db)
                        ph = ",".join(["%s"] * len(parsed_ids)) if DB_VENDOR == "mysql" else ",".join(["?"] * len(parsed_ids))
                        cl_rows = db.execute(
                            f"SELECT id, location_name, latitude, longitude, radius_meters, address FROM location_cache WHERE id IN ({ph})",
                            tuple(parsed_ids)
                        ).fetchall()
                        for cr in cl_rows:
                            c_name = cr['location_name'] if isinstance(cr, dict) else cr[1]
                            c_lat = cr['latitude'] if isinstance(cr, dict) else cr[2]
                            c_lon = cr['longitude'] if isinstance(cr, dict) else cr[3]
                            c_rad = cr['radius_meters'] if isinstance(cr, dict) else cr[4]
                            planning_custom_locs.append({
                                'name': c_name,
                                'latitude': float(c_lat) if c_lat else None,
                                'longitude': float(c_lon) if c_lon else None,
                                'radius_meters': int(c_rad) if c_rad else 300
                            })
                        app.logger.info(f"DEBUG: Loaded {len(planning_custom_locs)} custom locations for planning: {[cl['name'] for cl in planning_custom_locs]}")
            except Exception as cl_err:
                app.logger.warning(f"Errore caricamento custom_location_ids per turno-oggi: {cl_err}")

            turni.append({
                "project_code": row['project_code'] if isinstance(row, dict) else row[0],
                "project_name": row['project_name'] if isinstance(row, dict) else row[1],
                "function": row['function_name'] if isinstance(row, dict) else row[2],
                "planning_date": today,
                "start": start_str,
                "end": end_str,
                "hours": float(row['hours_planned'] if isinstance(row, dict) else row[5] or 0),
                "note": row['remark'] if isinstance(row, dict) else row[6],
                "note_planner": remark_planner,
                "is_leader": bool(row['is_leader'] if isinstance(row, dict) else row[7]),
                "transport": row['transport'] if isinstance(row, dict) else row[8],
                "break_start": break_start,
                "break_end": break_end,
                "break_minutes": break_minutes,
                "location_name": location_name,
                "gps_mode": gps_mode,
                "gps_timbratura_location": gps_timbratura_location,
                "timbratura_location": timbratura_location,
                "timbratura_lat": timbratura_lat,
                "timbratura_lon": timbratura_lon,
                "timbratura_radius": timbratura_radius,
                "gestione_squadra": row_gestione_squadra,
                "valid_locations": _build_valid_locations(group_default_location, timbratura_location, timbratura_lat, timbratura_lon, timbratura_radius, location_name, location_lat, location_lon, location_radius, gps_mode, custom_locations=planning_custom_locs),
            })
        
        return jsonify({"turno": turni[0] if turni else None, "turni": turni})
    
    except Exception as e:
        app.logger.exception(f"Errore in api_user_turno_oggi: {str(e)}")
        return jsonify({"error": f"Errore: {str(e)}", "turno": None, "turni": []}), 500


@app.get("/api/user/turno-crew-info")
@login_required
def api_user_turno_crew_info():
    """Restituisce i colleghi in turno sullo stesso progetto e i mezzi assegnati con autisti."""
    try:
        username = session.get('user')
        if not username:
            return jsonify({"error": "Non autenticato"}), 401

        project_code = request.args.get('project_code')
        if not project_code:
            return jsonify({"error": "project_code richiesto"}), 400

        db = get_db()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        today = get_simulated_now().strftime("%Y-%m-%d")

        # Trova il crew_id dell'utente corrente
        user_row = db.execute(
            f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        my_crew_id = (user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]) if user_row else None

        # Trova tutti i colleghi sullo stesso progetto per oggi
        colleagues = db.execute(
            f"""SELECT crew_id, crew_name, function_name, plan_start, plan_end, is_leader,
                       location_name, vehicle_data, project_id
                FROM rentman_plannings
                WHERE project_code = {placeholder} AND planning_date = {placeholder}
                  AND sent_to_webservice = 1
                  AND (is_obsolete = 0 OR is_obsolete IS NULL)
                ORDER BY is_leader DESC, crew_name ASC""",
            (project_code, today)
        ).fetchall()

        crew_list = []
        project_id = None
        for c in colleagues:
            if isinstance(c, dict):
                cid = c['crew_id']
                cname = c['crew_name']
                func = c['function_name']
                ps = c['plan_start']
                pe = c['plan_end']
                leader = c['is_leader']
                loc = c['location_name']
                vd = c.get('vehicle_data')
                pid = c.get('project_id')
            else:
                cid, cname, func, ps, pe, leader, loc, vd, pid = c[0], c[1], c[2], c[3], c[4], c[5], c[6], c[7], c[8]

            if pid:
                project_id = pid

            start_str = ""
            end_str = ""
            if ps:
                if hasattr(ps, 'strftime'):
                    start_str = ps.strftime("%H:%M")
                else:
                    start_str = str(ps)[11:16] if len(str(ps)) > 11 else str(ps)[:5]
            if pe:
                if hasattr(pe, 'strftime'):
                    end_str = pe.strftime("%H:%M")
                else:
                    end_str = str(pe)[11:16] if len(str(pe)) > 11 else str(pe)[:5]

            crew_list.append({
                "crew_id": cid,
                "crew_name": cname or "N/D",
                "function": func or "",
                "start": start_str,
                "end": end_str,
                "is_leader": bool(leader),
                "is_me": (cid == my_crew_id) if my_crew_id else False,
                "location": loc or "",
            })

        # Trova i veicoli assegnati al progetto con autisti
        vehicles = []
        if project_id:
            ensure_vehicle_drivers_table(db)
            vd_rows = db.execute(
                f"""SELECT vehicle_id, vehicle_name, driver_crew_id, driver_name
                    FROM vehicle_driver_assignments
                    WHERE project_id = {placeholder} AND planning_date = {placeholder}""",
                (project_id, today)
            ).fetchall()

            for vr in vd_rows:
                if isinstance(vr, dict):
                    vehicles.append({
                        "vehicle_id": vr['vehicle_id'],
                        "vehicle_name": vr['vehicle_name'] or "Mezzo N/D",
                        "driver_name": vr['driver_name'] or None,
                        "driver_crew_id": vr['driver_crew_id'],
                    })
                else:
                    vehicles.append({
                        "vehicle_id": vr[0],
                        "vehicle_name": vr[1] or "Mezzo N/D",
                        "driver_name": vr[3] or None,
                        "driver_crew_id": vr[2],
                    })

        # Se non ci sono assegnazioni autista ma ci sono vehicle_data nelle pianificazioni, mostra i veicoli senza autista
        if not vehicles and colleagues:
            seen_vehicles = set()
            for c in colleagues:
                vd_str = c.get('vehicle_data') if isinstance(c, dict) else (c[7] if len(c) > 7 else None)
                if vd_str:
                    try:
                        vd_list = json.loads(vd_str) if isinstance(vd_str, str) else vd_str
                        for v in vd_list:
                            vid = v.get('id')
                            if vid and vid not in seen_vehicles:
                                seen_vehicles.add(vid)
                                vname = v.get('name', '')
                                vplate = v.get('plate', '')
                                label = f"{vname} ({vplate})" if vname and vplate else (vname or vplate or "Mezzo N/D")
                                vehicles.append({
                                    "vehicle_id": vid,
                                    "vehicle_name": label,
                                    "driver_name": None,
                                    "driver_crew_id": None,
                                })
                    except (json.JSONDecodeError, TypeError):
                        pass

        return jsonify({
            "crew": crew_list,
            "vehicles": vehicles,
            "project_code": project_code,
            "date": today,
            "total_crew": len(crew_list),
            "total_vehicles": len(vehicles),
        })

    except Exception as e:
        app.logger.exception(f"Errore in api_user_turno_crew_info: {str(e)}")
        return jsonify({"error": f"Errore: {str(e)}"}), 500


@app.get("/api/user/turni")
@login_required
def api_user_turni():
    """Restituisce tutti i turni dell'utente (7 giorni indietro + 60 giorni avanti da Rentman o employee_shifts)."""
    try:
        username = session.get('user')
        if not username:
            return jsonify({"error": "Non autenticato", "turni": []}), 401
        
        db = get_db()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        # Trova il rentman_crew_id dell'utente
        user_row = db.execute(
            f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        
        if not user_row:
            return jsonify({"turni": [], "message": "Utente non trovato"})
        
        crew_id = user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]
        
        # Se non ha crew_id Rentman, usa employee_shifts ricorrenti
        if not crew_id:
            ensure_employee_shifts_table(db)
            
            # Carica le gps_locations dalla configurazione per associare coordinate ai turni
            settings = get_company_settings(db)
            custom = settings.get('custom_settings', {})
            timbratura_config = custom.get('timbratura', {})
            gps_locations = timbratura_config.get('gps_locations', [])
            
            turni = []
            # Genera turni per i 7 giorni precedenti + 60 giorni successivi basandosi su employee_shifts
            today = get_simulated_now()
            for days_offset in range(-7, 60):  # 7 giorni indietro + 60 giorni avanti
                check_date = today + timedelta(days=days_offset)
                day_of_week = check_date.weekday()
                
                shift_row = db.execute(f"""
                    SELECT start_time, end_time, break_start, break_end, location_name
                    FROM employee_shifts
                    WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                """, (username, day_of_week)).fetchone()
                
                if shift_row:
                    if isinstance(shift_row, dict):
                        start_time = str(shift_row['start_time'])[:5] if shift_row['start_time'] else None
                        end_time = str(shift_row['end_time'])[:5] if shift_row['end_time'] else None
                        break_start = str(shift_row['break_start'])[:5] if shift_row['break_start'] else None
                        break_end = str(shift_row['break_end'])[:5] if shift_row['break_end'] else None
                        location_name = shift_row.get('location_name')
                    else:
                        start_time = str(shift_row[0])[:5] if shift_row[0] else None
                        end_time = str(shift_row[1])[:5] if shift_row[1] else None
                        break_start = str(shift_row[2])[:5] if shift_row[2] else None
                        break_end = str(shift_row[3])[:5] if shift_row[3] else None
                        location_name = shift_row[4] if len(shift_row) > 4 else None
                    
                    # Cerca coordinate della location nelle gps_locations configurate
                    timbratura_lat = None
                    timbratura_lon = None
                    timbratura_radius = 300
                    if location_name:
                        for loc in gps_locations:
                            if loc.get('name') == location_name:
                                timbratura_lat = loc.get('latitude')
                                timbratura_lon = loc.get('longitude')
                                timbratura_radius = loc.get('radius_meters', 300)
                                break
                    
                    # Calcola ore e minuti pausa
                    hours_val = None
                    break_minutes_val = 0
                    
                    if start_time and end_time:
                        try:
                            start_parts = start_time.split(':')
                            end_parts = end_time.split(':')
                            start_mins = int(start_parts[0]) * 60 + int(start_parts[1])
                            end_mins = int(end_parts[0]) * 60 + int(end_parts[1])
                            total_mins = end_mins - start_mins
                            if total_mins > 0:
                                hours_val = total_mins / 60.0
                        except:
                            pass
                    
                    if break_start and break_end:
                        try:
                            bs_parts = break_start.split(':')
                            be_parts = break_end.split(':')
                            bs_mins = int(bs_parts[0]) * 60 + int(bs_parts[1])
                            be_mins = int(be_parts[0]) * 60 + int(be_parts[1])
                            break_minutes_val = be_mins - bs_mins
                            if break_minutes_val < 0:
                                break_minutes_val = 0
                        except:
                            pass
                    
                    turni.append({
                        "date": check_date.strftime("%Y-%m-%d"),
                        "project_code": "UFFICIO",
                        "project_name": "Lavoro in ufficio",
                        "function": "Impiegato",
                        "start": start_time,
                        "end": end_time,
                        "break_start": break_start,
                        "break_end": break_end,
                        "hours": hours_val,
                        "break_minutes": break_minutes_val,
                        "note": None,
                        "is_leader": False,
                        "transport": None,
                        "source": "employee_shifts",
                        "location_name": location_name,
                        "timbratura_location": location_name,
                        "timbratura_lat": timbratura_lat,
                        "timbratura_lon": timbratura_lon,
                        "timbratura_radius": timbratura_radius,
                    })
            
            return jsonify({"turni": turni})
        
        # Se ha crew_id, cerca in rentman_plannings (ultimi 30 giorni + prossimi 60 giorni)
        ensure_rentman_plannings_table(db)
        today = get_simulated_now()
        sixty_days_future = (today + timedelta(days=60)).strftime("%Y-%m-%d")
        thirty_days_past = (today - timedelta(days=30)).strftime("%Y-%m-%d")
        
        # Carica le gps_locations dalla configurazione per associare coordinate ai turni
        settings = get_company_settings(db)
        custom = settings.get('custom_settings', {})
        timbratura_config = custom.get('timbratura', {})
        gps_locations = timbratura_config.get('gps_locations', [])
        
        planning = db.execute(
            f"""
            SELECT planning_date, project_code, project_name, function_name, plan_start, plan_end,
                   hours_planned, remark, is_leader, transport, break_start, break_end, break_minutes,
                   location_name, timbratura_gps_mode, gps_timbratura_location
            FROM rentman_plannings
            WHERE crew_id = {placeholder} AND planning_date >= {placeholder} AND planning_date <= {placeholder}
              AND sent_to_webservice = 1
              AND (is_obsolete = 0 OR is_obsolete IS NULL)
            ORDER BY planning_date ASC, plan_start ASC
            """,
            (crew_id, thirty_days_past, sixty_days_future)
        ).fetchall()
        
        turni = []
        for row in planning:
            if isinstance(row, dict):
                planning_date = row['planning_date']
                plan_start = row['plan_start']
                plan_end = row['plan_end']
            else:
                planning_date = row[0]
                plan_start = row[4]
                plan_end = row[5]
            
            # Normalizza la data
            if hasattr(planning_date, 'isoformat'):
                date_str = planning_date.isoformat()
            else:
                date_str = str(planning_date)[:10]
            
            # Formatta orari
            start_str = ""
            end_str = ""
            if plan_start:
                if hasattr(plan_start, 'strftime'):
                    start_str = plan_start.strftime("%H:%M")
                else:
                    start_str = str(plan_start)[11:16] if len(str(plan_start)) > 11 else str(plan_start)[:5]
            if plan_end:
                if hasattr(plan_end, 'strftime'):
                    end_str = plan_end.strftime("%H:%M")
                else:
                    end_str = str(plan_end)[11:16] if len(str(plan_end)) > 11 else str(plan_end)[:5]
            
            # Estrai info break
            if isinstance(row, dict):
                break_start = format_time_value(row.get('break_start'))
                break_end = format_time_value(row.get('break_end'))
                break_minutes = row.get('break_minutes')
                location_name = row.get('location_name')
                gps_mode = row.get('timbratura_gps_mode') or 'group'
                gps_timbratura_location = row.get('gps_timbratura_location')
            else:
                break_start = format_time_value(row[10] if len(row) > 10 else None)
                break_end = format_time_value(row[11] if len(row) > 11 else None)
                break_minutes = row[12] if len(row) > 12 else None
                location_name = row[13] if len(row) > 13 else None
                gps_mode = row[14] if len(row) > 14 else 'group'
                gps_timbratura_location = row[15] if len(row) > 15 else None
            
            # Determina dove timbrare
            timbratura_location = None
            timbratura_lat = None
            timbratura_lon = None
            timbratura_radius = 300
            
            if gps_mode == 'location' and location_name:
                timbratura_location = location_name
                # Cerca coordinate nella cache location di Rentman
                try:
                    ensure_location_cache_table(db)
                    loc_id = row.get('location_id') if isinstance(row, dict) else None
                    cached = get_location_cache(db, location_name, loc_id)
                    if cached:
                        timbratura_lat, timbratura_lon, timbratura_radius = cached
                except:
                    pass
            elif gps_timbratura_location:
                timbratura_location = gps_timbratura_location
                # Cerca coordinate nelle gps_locations configurate
                for loc in gps_locations:
                    if loc.get('name') == gps_timbratura_location:
                        timbratura_lat = loc.get('latitude')
                        timbratura_lon = loc.get('longitude')
                        timbratura_radius = loc.get('radius_meters', 300)
                        break
            
            turni.append({
                "date": date_str,
                "project_code": row['project_code'] if isinstance(row, dict) else row[1],
                "project_name": row['project_name'] if isinstance(row, dict) else row[2],
                "function": row['function_name'] if isinstance(row, dict) else row[3],
                "start": start_str,
                "end": end_str,
                "hours": float(row['hours_planned'] if isinstance(row, dict) else row[6] or 0),
                "note": row['remark'] if isinstance(row, dict) else row[7],
                "is_leader": bool(row['is_leader'] if isinstance(row, dict) else row[8]),
                "transport": row['transport'] if isinstance(row, dict) else row[9],
                "break_start": break_start,
                "break_end": break_end,
                "break_minutes": break_minutes,
                "location_name": location_name,
                "timbratura_location": timbratura_location,
                "timbratura_lat": timbratura_lat,
                "timbratura_lon": timbratura_lon,
                "timbratura_radius": timbratura_radius,
                "gps_mode": gps_mode,
                "gps_timbratura_location": gps_timbratura_location,
            })
        
        return jsonify({"turni": turni})
    
    except Exception as e:
        app.logger.exception(f"Errore in api_user_turni: {str(e)}")
        return jsonify({"error": f"Errore: {str(e)}", "turni": []}), 500


# ============================================================
# TABELLE TELEFONI AZIENDALI
# ============================================================

COMPANY_PHONES_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS company_phones (
    phone_code VARCHAR(3) PRIMARY KEY,
    label VARCHAR(50) NOT NULL,
    active TINYINT DEFAULT 1,
    created_ts BIGINT NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

COMPANY_PHONES_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS company_phones (
    phone_code TEXT PRIMARY KEY,
    label TEXT NOT NULL,
    active INTEGER DEFAULT 1,
    created_ts INTEGER NOT NULL
)
"""

PHONE_ASSIGNMENTS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS phone_assignments (
    id INT AUTO_INCREMENT PRIMARY KEY,
    phone_code VARCHAR(3) NOT NULL,
    project_code VARCHAR(128) NOT NULL,
    activity_id VARCHAR(64) DEFAULT NULL,
    assigned_to VARCHAR(190) NOT NULL,
    assigned_username VARCHAR(190) DEFAULT NULL,
    assigned_at BIGINT NOT NULL,
    released_at BIGINT DEFAULT NULL,
    INDEX idx_phone_assign_code (phone_code),
    INDEX idx_phone_assign_user (assigned_to),
    INDEX idx_phone_assign_project (project_code)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

PHONE_ASSIGNMENTS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS phone_assignments (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    phone_code TEXT NOT NULL,
    project_code TEXT NOT NULL,
    activity_id TEXT DEFAULT NULL,
    assigned_to TEXT NOT NULL,
    assigned_username TEXT DEFAULT NULL,
    assigned_at INTEGER NOT NULL,
    released_at INTEGER DEFAULT NULL
);
CREATE INDEX IF NOT EXISTS idx_phone_assign_code ON phone_assignments(phone_code);
CREATE INDEX IF NOT EXISTS idx_phone_assign_user ON phone_assignments(assigned_to);
CREATE INDEX IF NOT EXISTS idx_phone_assign_project ON phone_assignments(project_code);
"""


def ensure_company_phones_table(db: DatabaseLike) -> None:
    statement = COMPANY_PHONES_TABLE_MYSQL if DB_VENDOR == "mysql" else COMPANY_PHONES_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_phone_assignments_table(db: DatabaseLike) -> None:
    statement = PHONE_ASSIGNMENTS_TABLE_MYSQL if DB_VENDOR == "mysql" else PHONE_ASSIGNMENTS_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    # Migrazione: aggiungi colonna assigned_username se mancante
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE phone_assignments ADD COLUMN assigned_username VARCHAR(190) DEFAULT NULL")
        else:
            db.execute("ALTER TABLE phone_assignments ADD COLUMN assigned_username TEXT DEFAULT NULL")
        db.commit()
    except Exception:
        pass  # colonna già presente


def _resolve_crew_username(db: DatabaseLike, crew_name: str) -> Optional[str]:
    """Cerca di associare un nome crew (Rentman) a un username in app_users.

    Strategia (in ordine di priorità):
    1. full_name esatto (case-insensitive)
    2. display_name esatto (case-insensitive)
    3. Il primo nome del crew (prima parola) corrisponde al username
    """
    if not crew_name:
        return None
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    crew_lower = crew_name.strip().lower()
    rows = db.execute(
        "SELECT username, display_name, full_name FROM app_users WHERE is_active = 1"
    ).fetchall()
    # 1. full_name esatto
    for r in rows:
        fn = (r['full_name'] if isinstance(r, dict) else r[2]) or ''
        if fn.strip().lower() == crew_lower:
            return r['username'] if isinstance(r, dict) else r[0]
    # 2. display_name esatto
    for r in rows:
        dn = (r['display_name'] if isinstance(r, dict) else r[1]) or ''
        if dn.strip().lower() == crew_lower:
            return r['username'] if isinstance(r, dict) else r[0]
    # 3. match primo nome ↔ username
    first_name = crew_lower.split()[0] if crew_lower else ''
    if first_name:
        for r in rows:
            uname = (r['username'] if isinstance(r, dict) else r[0]) or ''
            if uname.lower() == first_name:
                return uname
    return None


def seed_default_phones(db: DatabaseLike) -> None:
    """Inserisce i telefoni predefiniti 001-007 se la tabella è vuota."""
    ensure_company_phones_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    row = db.execute("SELECT COUNT(*) AS cnt FROM company_phones").fetchone()
    cnt = row['cnt'] if isinstance(row, dict) else row[0]
    if cnt == 0:
        now_ts = int(time.time() * 1000)
        for i in range(1, 8):
            code = f"{i:03d}"
            label = f"Telefono Squadra {i}"
            db.execute(
                f"INSERT INTO company_phones (phone_code, label, active, created_ts) VALUES ({placeholder}, {placeholder}, 1, {placeholder})",
                (code, label, now_ts)
            )
        db.commit()
        app.logger.info("Inseriti 7 telefoni aziendali predefiniti (001-007)")


# ═══════════════════════════════════════════════════════════════════
# API TELEFONI AZIENDALI
# ═══════════════════════════════════════════════════════════════════

@app.get("/api/phones")
@login_required
def api_get_phones() -> ResponseReturnValue:
    """Lista tutti i telefoni aziendali con stato assegnazione corrente."""
    db = get_db()
    ensure_company_phones_table(db)
    ensure_phone_assignments_table(db)
    seed_default_phones(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # ── Auto-rilascio assegnazioni vecchie (giorni passati) ──
    # Le assegnazioni che appartengono a turni di giorni precedenti vengono chiuse automaticamente
    today_str = datetime.now().strftime("%Y-%m-%d")
    today_start_ts = int(datetime.strptime(today_str, "%Y-%m-%d").timestamp() * 1000)
    stale = db.execute(
        f"""SELECT pa.id, pa.phone_code, pa.project_code FROM phone_assignments pa
            WHERE pa.released_at IS NULL AND pa.assigned_at < {placeholder}""",
        (today_start_ts,)
    ).fetchall()
    if stale:
        now_ts = int(time.time() * 1000)
        for s_row in stale:
            s_id = s_row['id'] if isinstance(s_row, dict) else s_row[0]
            db.execute(
                f"UPDATE phone_assignments SET released_at = {placeholder} WHERE id = {placeholder}",
                (now_ts, s_id)
            )
        db.commit()
        app.logger.info("[PHONE] Auto-rilasciate %d assegnazioni di giorni precedenti", len(stale))
    
    phones = []
    rows = db.execute("SELECT phone_code, label, active FROM company_phones ORDER BY phone_code").fetchall()
    for r in rows:
        code = r['phone_code'] if isinstance(r, dict) else r[0]
        label = r['label'] if isinstance(r, dict) else r[1]
        active = r['active'] if isinstance(r, dict) else r[2]
        
        # Trova TUTTE le assegnazioni attive (released_at IS NULL)
        assigns = db.execute(
            f"""SELECT assigned_to, project_code, activity_id, assigned_at 
                FROM phone_assignments 
                WHERE phone_code = {placeholder} AND released_at IS NULL 
                ORDER BY assigned_at DESC""",
            (code,)
        ).fetchall()
        
        # Campo "assignment" per compatibilità (primo = più recente)
        assignment = None
        assignments_list = []
        for assign in assigns:
            a = {
                "assigned_to": assign['assigned_to'] if isinstance(assign, dict) else assign[0],
                "project_code": assign['project_code'] if isinstance(assign, dict) else assign[1],
                "activity_id": assign['activity_id'] if isinstance(assign, dict) else assign[2],
                "assigned_at": assign['assigned_at'] if isinstance(assign, dict) else assign[3],
            }
            assignments_list.append(a)
        if assignments_list:
            assignment = assignments_list[0]
        
        phones.append({
            "phone_code": code,
            "label": label,
            "active": bool(active),
            "assignment": assignment,
            "assignments": assignments_list,
        })
    
    return jsonify({"ok": True, "phones": phones})


@app.post("/api/phones/assign")
@login_required
def api_assign_phone() -> ResponseReturnValue:
    """Assegna un telefono a un caposquadra per un progetto/attività.
    
    Body JSON: { phone_code, project_code, activity_id (opzionale), assigned_to }
    """
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400

    phone_code = str(data.get("phone_code") or "").strip()
    project_code = str(data.get("project_code") or "").strip()
    assigned_to = str(data.get("assigned_to") or "").strip()
    activity_id = str(data.get("activity_id") or "").strip() or None
    function_name = str(data.get("function_name") or "").strip() or None

    if not phone_code or not project_code or not assigned_to:
        return jsonify({"error": "phone_code, project_code e assigned_to obbligatori"}), 400

    db = get_db()
    ensure_company_phones_table(db)
    ensure_phone_assignments_table(db)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now_ts = int(time.time() * 1000)

    # Verifica che il telefono esista e sia attivo
    phone = db.execute(
        f"SELECT phone_code FROM company_phones WHERE phone_code = {placeholder} AND active = 1",
        (phone_code,)
    ).fetchone()
    if not phone:
        return jsonify({"error": f"Telefono {phone_code} non trovato o disattivato"}), 404

    # ── Validazione sovrapposizione turni ──
    today_str = datetime.now().strftime("%Y-%m-%d")

    # Recupera l'orario del turno corrente (progetto che si sta assegnando)
    current_plan = db.execute(
        f"""SELECT plan_start, plan_end FROM rentman_plannings
            WHERE project_code = {placeholder} AND planning_date = {placeholder}
            AND is_obsolete = 0 LIMIT 1""",
        (project_code, today_str)
    ).fetchone()
    cur_start = None
    cur_end = None
    if current_plan:
        raw_start = current_plan['plan_start'] if isinstance(current_plan, dict) else current_plan[0]
        raw_end = current_plan['plan_end'] if isinstance(current_plan, dict) else current_plan[1]
        try:
            cur_start = datetime.fromisoformat(str(raw_start).replace("Z", "+00:00")) if raw_start else None
            cur_end = datetime.fromisoformat(str(raw_end).replace("Z", "+00:00")) if raw_end else None
        except Exception:
            pass

    def _shifts_overlap(s1, e1, s2, e2):
        """Ritorna True se i due intervalli si sovrappongono."""
        if not s1 or not e1 or not s2 or not e2:
            return False
        return s1 < e2 and s2 < e1

    # 1) Verifica: lo stesso telefono non può essere assegnato a turni sovrapposti
    existing_phone_assigns = db.execute(
        f"""SELECT project_code, assigned_to FROM phone_assignments
            WHERE phone_code = {placeholder} AND released_at IS NULL AND project_code != {placeholder}""",
        (phone_code, project_code)
    ).fetchall()

    for epa in existing_phone_assigns:
        other_proj = epa['project_code'] if isinstance(epa, dict) else epa[0]
        other_person = epa['assigned_to'] if isinstance(epa, dict) else epa[1]
        other_plan = db.execute(
            f"""SELECT plan_start, plan_end FROM rentman_plannings
                WHERE project_code = {placeholder} AND planning_date = {placeholder}
                AND is_obsolete = 0 LIMIT 1""",
            (other_proj, today_str)
        ).fetchone()
        if other_plan:
            o_raw_start = other_plan['plan_start'] if isinstance(other_plan, dict) else other_plan[0]
            o_raw_end = other_plan['plan_end'] if isinstance(other_plan, dict) else other_plan[1]
            try:
                o_start = datetime.fromisoformat(str(o_raw_start).replace("Z", "+00:00")) if o_raw_start else None
                o_end = datetime.fromisoformat(str(o_raw_end).replace("Z", "+00:00")) if o_raw_end else None
            except Exception:
                o_start = o_end = None
            if _shifts_overlap(cur_start, cur_end, o_start, o_end):
                app.logger.warning("[PHONE] Telefono %s già assegnato a %s nel progetto %s con turno sovrapposto", phone_code, other_person, other_proj)
                return jsonify({"error": f"Il telefono {phone_code} è già assegnato a {other_person} in un turno sovrapposto ({other_proj})"}), 409

    # 2) Verifica: la stessa persona non può avere 2+ telefoni in turni sovrapposti
    existing_person_assigns = db.execute(
        f"""SELECT phone_code, project_code FROM phone_assignments
            WHERE assigned_to = {placeholder} AND released_at IS NULL AND project_code != {placeholder}""",
        (assigned_to, project_code)
    ).fetchall()

    for epa2 in existing_person_assigns:
        other_phone = epa2['phone_code'] if isinstance(epa2, dict) else epa2[0]
        other_proj2 = epa2['project_code'] if isinstance(epa2, dict) else epa2[1]
        other_plan2 = db.execute(
            f"""SELECT plan_start, plan_end FROM rentman_plannings
                WHERE project_code = {placeholder} AND planning_date = {placeholder}
                AND is_obsolete = 0 LIMIT 1""",
            (other_proj2, today_str)
        ).fetchone()
        if other_plan2:
            o2_raw_start = other_plan2['plan_start'] if isinstance(other_plan2, dict) else other_plan2[0]
            o2_raw_end = other_plan2['plan_end'] if isinstance(other_plan2, dict) else other_plan2[1]
            try:
                o2_start = datetime.fromisoformat(str(o2_raw_start).replace("Z", "+00:00")) if o2_raw_start else None
                o2_end = datetime.fromisoformat(str(o2_raw_end).replace("Z", "+00:00")) if o2_raw_end else None
            except Exception:
                o2_start = o2_end = None
            if _shifts_overlap(cur_start, cur_end, o2_start, o2_end):
                app.logger.warning("[PHONE] Persona %s ha già telefono %s nel progetto %s con turno sovrapposto", assigned_to, other_phone, other_proj2)
                return jsonify({"error": f"{assigned_to} ha già il telefono {other_phone} assegnato in un turno sovrapposto ({other_proj2})"}), 409

    # Anche se stesso progetto: controlla che la persona non abbia già un altro telefono sullo stesso progetto
    existing_same_proj = db.execute(
        f"""SELECT phone_code FROM phone_assignments
            WHERE assigned_to = {placeholder} AND project_code = {placeholder} AND phone_code != {placeholder} AND released_at IS NULL""",
        (assigned_to, project_code, phone_code)
    ).fetchone()
    if existing_same_proj:
        other_ph_same = existing_same_proj['phone_code'] if isinstance(existing_same_proj, dict) else existing_same_proj[0]
        app.logger.warning("[PHONE] Persona %s ha già telefono %s sullo stesso progetto %s", assigned_to, other_ph_same, project_code)
        return jsonify({"error": f"{assigned_to} ha già il telefono {other_ph_same} assegnato sullo stesso progetto"}), 409

    # ── Risolvi activity_id dalla funzione dell'operatore ──
    # Se il frontend ha inviato function_name, cerchiamo l'activity corrispondente
    if not activity_id and function_name:
        act_row = db.execute(
            f"SELECT activity_id FROM activities WHERE project_code = {placeholder} AND label LIKE {placeholder} LIMIT 1",
            (project_code, f"{function_name}%")
        ).fetchone()
        if act_row:
            activity_id = act_row["activity_id"] if isinstance(act_row, dict) else act_row[0]
            app.logger.info("[PHONE] Risolto activity_id=%s da function_name=%s", activity_id, function_name)
    # Fallback: se ancora nessun activity_id, cerca dalla pianificazione dell'operatore
    if not activity_id:
        today_str = datetime.now().strftime("%Y-%m-%d")
        plan_row = db.execute(
            f"""SELECT function_name FROM rentman_plannings
                WHERE crew_name = {placeholder} AND project_code = {placeholder}
                AND planning_date = {placeholder} LIMIT 1""",
            (assigned_to, project_code, today_str)
        ).fetchone()
        if plan_row:
            fn = (plan_row["function_name"] if isinstance(plan_row, dict) else plan_row[0] or "").strip()
            if fn:
                act_row2 = db.execute(
                    f"SELECT activity_id FROM activities WHERE project_code = {placeholder} AND label LIKE {placeholder} LIMIT 1",
                    (project_code, f"{fn}%")
                ).fetchone()
                if act_row2:
                    activity_id = act_row2["activity_id"] if isinstance(act_row2, dict) else act_row2[0]
                    app.logger.info("[PHONE] Risolto activity_id=%s da planning function=%s", activity_id, fn)

    # Rilascia solo l'assegnazione precedente dello stesso telefono PER LO STESSO PROGETTO
    # (permette allo stesso telefono di essere assegnato a più turni/progetti diversi)
    db.execute(
        f"UPDATE phone_assignments SET released_at = {placeholder} WHERE phone_code = {placeholder} AND project_code = {placeholder} AND released_at IS NULL",
        (now_ts, phone_code, project_code)
    )

    # Risolvi il crew_name → username in app_users (match fuzzy: primo nome)
    assigned_username = _resolve_crew_username(db, assigned_to)

    # Crea nuova assegnazione
    db.execute(
        f"""INSERT INTO phone_assignments (phone_code, project_code, activity_id, assigned_to, assigned_username, assigned_at)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})""",
        (phone_code, project_code, activity_id, assigned_to, assigned_username, now_ts)
    )
    db.commit()

    app.logger.info(f"[PHONE] Telefono {phone_code} assegnato a {assigned_to} (username={assigned_username}) per progetto {project_code}, activity_id={activity_id}")
    return jsonify({"ok": True, "phone_code": phone_code, "assigned_to": assigned_to, "assigned_username": assigned_username, "activity_id": activity_id})


@app.post("/api/phones/release")
@login_required
def api_release_phone() -> ResponseReturnValue:
    """Rilascia un telefono (termina assegnazione corrente).
    
    Body JSON: { phone_code }
    """
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    data = request.get_json()
    phone_code = (data.get("phone_code") or "").strip() if data else ""
    if not phone_code:
        return jsonify({"error": "phone_code obbligatorio"}), 400
    project_code = (data.get("project_code") or "").strip() if data else ""

    db = get_db()
    ensure_phone_assignments_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now_ts = int(time.time() * 1000)

    if project_code:
        # Rilascia solo l'assegnazione per questo specifico progetto
        db.execute(
            f"UPDATE phone_assignments SET released_at = {placeholder} WHERE phone_code = {placeholder} AND project_code = {placeholder} AND released_at IS NULL",
            (now_ts, phone_code, project_code)
        )
        app.logger.info(f"[PHONE] Telefono {phone_code} rilasciato dal progetto {project_code}")
    else:
        # Rilascia tutte le assegnazioni del telefono
        db.execute(
            f"UPDATE phone_assignments SET released_at = {placeholder} WHERE phone_code = {placeholder} AND released_at IS NULL",
            (now_ts, phone_code)
        )
        app.logger.info(f"[PHONE] Telefono {phone_code} rilasciato (tutte le assegnazioni)")
    db.commit()

    return jsonify({"ok": True})


@app.get("/api/phones/my-assignment")
@login_required
def api_phone_my_assignment() -> ResponseReturnValue:
    """Restituisce l'assegnazione corrente del telefono per l'utente loggato (se presente via phone param)."""
    phone_code = session.get("phone_code")
    if not phone_code:
        return jsonify({"ok": True, "assignment": None})

    db = get_db()
    ensure_phone_assignments_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    username = session.get("user")
    assign = db.execute(
        f"""SELECT phone_code, project_code, activity_id, assigned_to, assigned_at
            FROM phone_assignments 
            WHERE phone_code = {placeholder} AND assigned_to = {placeholder} AND released_at IS NULL
            ORDER BY assigned_at DESC LIMIT 1""",
        (phone_code, username)
    ).fetchone()

    if not assign:
        return jsonify({"ok": True, "assignment": None})

    return jsonify({
        "ok": True,
        "assignment": {
            "phone_code": assign['phone_code'] if isinstance(assign, dict) else assign[0],
            "project_code": assign['project_code'] if isinstance(assign, dict) else assign[1],
            "activity_id": assign['activity_id'] if isinstance(assign, dict) else assign[2],
            "assigned_to": assign['assigned_to'] if isinstance(assign, dict) else assign[3],
            "assigned_at": assign['assigned_at'] if isinstance(assign, dict) else assign[4],
        }
    })


# Tabella per tracciare i timer magazzino attivi lato server
WAREHOUSE_ACTIVE_TIMERS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS warehouse_active_timers (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(190) NOT NULL UNIQUE,
    project_code VARCHAR(128) NOT NULL,
    project_name VARCHAR(500),
    activity_label VARCHAR(255) NOT NULL,
    notes TEXT,
    running TINYINT DEFAULT 1,
    paused TINYINT DEFAULT 0,
    start_ts BIGINT NOT NULL,
    elapsed_ms BIGINT DEFAULT 0,
    pause_start_ts BIGINT DEFAULT NULL,
    updated_ts BIGINT NOT NULL,
    INDEX idx_wh_timer_user (username)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

WAREHOUSE_ACTIVE_TIMERS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS warehouse_active_timers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT NOT NULL UNIQUE,
    project_code TEXT NOT NULL,
    project_name TEXT,
    activity_label TEXT NOT NULL,
    notes TEXT,
    running INTEGER DEFAULT 1,
    paused INTEGER DEFAULT 0,
    start_ts INTEGER NOT NULL,
    elapsed_ms INTEGER DEFAULT 0,
    pause_start_ts INTEGER DEFAULT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_wh_timer_user ON warehouse_active_timers(username);
"""


WAREHOUSE_ACTIVITIES_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS warehouse_activities (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_code VARCHAR(128) NOT NULL,
    activity_label VARCHAR(255) NOT NULL,
    note TEXT,
    username VARCHAR(190) DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    INDEX idx_warehouse_project (project_code),
    INDEX idx_warehouse_created (created_ts)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""


WAREHOUSE_ACTIVITIES_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS warehouse_activities (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_code TEXT NOT NULL,
    activity_label TEXT NOT NULL,
    note TEXT,
    username TEXT,
    created_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_warehouse_project ON warehouse_activities(project_code);
CREATE INDEX IF NOT EXISTS idx_warehouse_created ON warehouse_activities(created_ts);
"""


# Tabella per sessioni di lavoro magazzino (con timer)
WAREHOUSE_SESSIONS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS warehouse_sessions (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_code VARCHAR(128) NOT NULL,
    activity_label VARCHAR(255) NOT NULL,
    elapsed_ms BIGINT NOT NULL DEFAULT 0,
    start_ts BIGINT DEFAULT NULL,
    end_ts BIGINT DEFAULT NULL,
    note TEXT,
    username VARCHAR(190) DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    INDEX idx_wh_sessions_project (project_code),
    INDEX idx_wh_sessions_created (created_ts),
    INDEX idx_wh_sessions_user (username)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""


WAREHOUSE_SESSIONS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS warehouse_sessions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_code TEXT NOT NULL,
    activity_label TEXT NOT NULL,
    elapsed_ms INTEGER NOT NULL DEFAULT 0,
    start_ts INTEGER DEFAULT NULL,
    end_ts INTEGER DEFAULT NULL,
    note TEXT,
    username TEXT,
    created_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_wh_sessions_project ON warehouse_sessions(project_code);
CREATE INDEX IF NOT EXISTS idx_wh_sessions_created ON warehouse_sessions(created_ts);
CREATE INDEX IF NOT EXISTS idx_wh_sessions_user ON warehouse_sessions(username);
"""


# ============================================================
# TABELLE TIMBRATURA
# ============================================================

TIMBRATURE_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS timbrature (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(190) NOT NULL,
    tipo VARCHAR(50) NOT NULL,
    data DATE NOT NULL,
    ora TIME NOT NULL,
    created_ts BIGINT NOT NULL,
    method VARCHAR(20) DEFAULT NULL,
    gps_lat DECIMAL(10,8) DEFAULT NULL,
    gps_lon DECIMAL(11,8) DEFAULT NULL,
    location_name VARCHAR(255) DEFAULT NULL,
    INDEX idx_timbrature_user_date (username, data),
    INDEX idx_timbrature_date (data)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

TIMBRATURE_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS timbrature (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT NOT NULL,
    tipo TEXT NOT NULL,
    data TEXT NOT NULL,
    ora TEXT NOT NULL,
    created_ts INTEGER NOT NULL,
    method TEXT DEFAULT NULL,
    gps_lat REAL DEFAULT NULL,
    gps_lon REAL DEFAULT NULL,
    location_name TEXT DEFAULT NULL
);
CREATE INDEX IF NOT EXISTS idx_timbrature_user_date ON timbrature(username, data);
CREATE INDEX IF NOT EXISTS idx_timbrature_date ON timbrature(data);
"""


def ensure_timbrature_table(db: DatabaseLike) -> None:
    statement = TIMBRATURE_TABLE_MYSQL if DB_VENDOR == "mysql" else TIMBRATURE_TABLE_SQLITE
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Migrazione: aggiungi colonna ora_mod se non esiste
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE timbrature ADD COLUMN ora_mod TIME DEFAULT NULL")
            db.commit()
        except Exception:
            pass  # Colonna già esistente
    else:
        try:
            db.execute("ALTER TABLE timbrature ADD COLUMN ora_mod TEXT")
            db.commit()
        except Exception:
            pass
    
    # Migrazione: aggiungi colonne GPS se non esistono
    new_columns = [
        ("method", "VARCHAR(20) DEFAULT NULL" if DB_VENDOR == "mysql" else "TEXT DEFAULT NULL"),
        ("gps_lat", "DECIMAL(10,8) DEFAULT NULL" if DB_VENDOR == "mysql" else "REAL DEFAULT NULL"),
        ("gps_lon", "DECIMAL(11,8) DEFAULT NULL" if DB_VENDOR == "mysql" else "REAL DEFAULT NULL"),
        ("location_name", "VARCHAR(255) DEFAULT NULL" if DB_VENDOR == "mysql" else "TEXT DEFAULT NULL"),
    ]
    for col_name, col_type in new_columns:
        try:
            db.execute(f"ALTER TABLE timbrature ADD COLUMN {col_name} {col_type}")
            db.commit()
        except Exception:
            pass  # Colonna già esistente
    
    # Migrazione: aggiungi colonna created_by se non esiste
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE timbrature ADD COLUMN created_by VARCHAR(100) DEFAULT NULL")
        else:
            db.execute("ALTER TABLE timbrature ADD COLUMN created_by TEXT DEFAULT NULL")
        db.commit()
    except Exception:
        pass  # Colonna già esistente


def ensure_warehouse_activities_table(db: DatabaseLike) -> None:
    statement = (
        WAREHOUSE_ACTIVITIES_TABLE_MYSQL if DB_VENDOR == "mysql" else WAREHOUSE_ACTIVITIES_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_warehouse_sessions_table(db: DatabaseLike) -> None:
    statement = (
        WAREHOUSE_SESSIONS_TABLE_MYSQL if DB_VENDOR == "mysql" else WAREHOUSE_SESSIONS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Migrazione: aggiungi colonne start_ts e end_ts se non esistono
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE warehouse_sessions ADD COLUMN start_ts BIGINT DEFAULT NULL")
            db.commit()
    except Exception:
        pass
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE warehouse_sessions ADD COLUMN end_ts BIGINT DEFAULT NULL")
            db.commit()
    except Exception:
        pass
    
    # SQLite: verifica se le colonne esistono
    if DB_VENDOR != "mysql":
        try:
            cursor = db.execute("PRAGMA table_info(warehouse_sessions)")
            columns = {row[1] for row in cursor.fetchall()}
            if "start_ts" not in columns:
                db.execute("ALTER TABLE warehouse_sessions ADD COLUMN start_ts INTEGER DEFAULT NULL")
            if "end_ts" not in columns:
                db.execute("ALTER TABLE warehouse_sessions ADD COLUMN end_ts INTEGER DEFAULT NULL")
            if "intervals" not in columns:
                db.execute("ALTER TABLE warehouse_sessions ADD COLUMN intervals TEXT DEFAULT NULL")
            db.commit()
        except Exception:
            pass
    else:
        # MySQL: aggiungi colonna intervals se non esiste
        try:
            db.execute("ALTER TABLE warehouse_sessions ADD COLUMN intervals TEXT DEFAULT NULL")
            db.commit()
        except Exception:
            pass


def ensure_warehouse_active_timers_table(db: DatabaseLike) -> None:
    """Crea tabella per tracciare i timer magazzino attivi."""
    statement = (
        WAREHOUSE_ACTIVE_TIMERS_TABLE_MYSQL
        if DB_VENDOR == "mysql"
        else WAREHOUSE_ACTIVE_TIMERS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


# ═══════════════════════════════════════════════════════════════════
# FUNZIONI HELPER PER TIMER PRODUZIONE
# ═══════════════════════════════════════════════════════════════════

def _start_production_timer(db: DatabaseLike, username: str, project_code: str, project_name: str, activity_label: str, start_ts: int | None = None, notes: str | None = None) -> bool:
    """Avvia un timer di produzione per l'utente."""
    try:
        ensure_warehouse_active_timers_table(db)
        # Usa il timestamp fornito (ora timbratura) o now_ms() come fallback
        now = start_ts if start_ts else now_ms()
        timer_notes = notes if notes else None
        app.logger.info(f"[TIMER] Avvio timer: username={username}, start_ts_param={start_ts}, now={now}, notes={timer_notes}")
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        if DB_VENDOR == "mysql":
            db.execute(
                f"""
                INSERT INTO warehouse_active_timers 
                (username, project_code, project_name, activity_label, notes, running, paused, start_ts, elapsed_ms, pause_start_ts, updated_ts)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, 0, {placeholder}, 0, NULL, {placeholder})
                ON DUPLICATE KEY UPDATE
                    project_code = VALUES(project_code),
                    project_name = VALUES(project_name),
                    activity_label = VALUES(activity_label),
                    notes = VALUES(notes),
                    running = 1,
                    paused = 0,
                    start_ts = VALUES(start_ts),
                    elapsed_ms = 0,
                    pause_start_ts = NULL,
                    updated_ts = VALUES(updated_ts)
                """,
                (username, project_code, project_name, activity_label, timer_notes, now, now)
            )
        else:
            db.execute(
                f"""
                INSERT OR REPLACE INTO warehouse_active_timers 
                (username, project_code, project_name, activity_label, notes, running, paused, start_ts, elapsed_ms, pause_start_ts, updated_ts)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, 0, {placeholder}, 0, NULL, {placeholder})
                """,
                (username, project_code, project_name, activity_label, timer_notes, now, now)
            )
        db.commit()
        app.logger.info(f"Timer produzione avviato: {username} - {project_code} / {activity_label}")
        return True
    except Exception as e:
        app.logger.error(f"Errore avvio timer produzione: {e}")
        return False


def _pause_production_timer(db: DatabaseLike, username: str, project_code: str | None = None) -> bool:
    """Mette in pausa il timer di produzione dell'utente."""
    try:
        ensure_warehouse_active_timers_table(db)
        now = now_ms()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        # Verifica se esiste un timer attivo (running=1, paused=0)
        timer = db.execute(
            f"SELECT id, start_ts, elapsed_ms FROM warehouse_active_timers WHERE username = {placeholder} AND running = 1 AND paused = 0",
            (username,)
        ).fetchone()
        
        if timer:
            timer_id = timer['id'] if isinstance(timer, dict) else timer[0]
            start_ts = timer['start_ts'] if isinstance(timer, dict) else timer[1]
            elapsed_ms = timer['elapsed_ms'] if isinstance(timer, dict) else timer[2]
            
            # Calcola elapsed aggiuntivo
            additional_elapsed = now - start_ts if start_ts else 0
            new_elapsed = (elapsed_ms or 0) + additional_elapsed
            
            db.execute(
                f"UPDATE warehouse_active_timers SET paused = 1, elapsed_ms = {placeholder}, pause_start_ts = {placeholder}, updated_ts = {placeholder} WHERE id = {placeholder}",
                (new_elapsed, now, now, timer_id)
            )
            db.commit()
            app.logger.info(f"Timer produzione in pausa: {username}")
            return True
        return False
    except Exception as e:
        app.logger.error(f"Errore pausa timer produzione: {e}")
        return False


def _resume_production_timer(db: DatabaseLike, username: str, project_code: str | None = None) -> bool:
    """Riprende il timer di produzione dell'utente dalla pausa."""
    try:
        ensure_warehouse_active_timers_table(db)
        now = now_ms()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        # Verifica se esiste un timer in pausa (running=1, paused=1)
        timer = db.execute(
            f"SELECT id FROM warehouse_active_timers WHERE username = {placeholder} AND running = 1 AND paused = 1",
            (username,)
        ).fetchone()
        
        if timer:
            timer_id = timer['id'] if isinstance(timer, dict) else timer[0]
            db.execute(
                f"UPDATE warehouse_active_timers SET paused = 0, start_ts = {placeholder}, pause_start_ts = NULL, updated_ts = {placeholder} WHERE id = {placeholder}",
                (now, now, timer_id)
            )
            db.commit()
            app.logger.info(f"Timer produzione ripreso: {username}")
            return True
        return False
    except Exception as e:
        app.logger.error(f"Errore ripresa timer produzione: {e}")
        return False


def _stop_production_timer(db: DatabaseLike, username: str, project_code: str | None = None) -> bool:
    """Ferma e salva il timer di produzione dell'utente."""
    try:
        ensure_warehouse_active_timers_table(db)
        ensure_warehouse_sessions_table(db)
        now = now_ms()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        # Recupera timer attivo
        timer = db.execute(
            f"""SELECT id, project_code, project_name, activity_label, notes, start_ts, elapsed_ms, paused, pause_start_ts
                FROM warehouse_active_timers WHERE username = {placeholder} AND running = 1""",
            (username,)
        ).fetchone()
        
        if timer:
            if isinstance(timer, dict):
                timer_id = timer['id']
                proj_code = timer['project_code']
                activity = timer['activity_label']
                notes = timer['notes']
                start_ts = timer['start_ts']
                elapsed_ms = timer['elapsed_ms'] or 0
                was_paused = timer['paused']
            else:
                timer_id = timer[0]
                proj_code = timer[1]
                activity = timer[3]
                notes = timer[4]
                start_ts = timer[5]
                elapsed_ms = timer[6] or 0
                was_paused = timer[7]
            
            # Se non era in pausa, aggiungi tempo trascorso
            if not was_paused and start_ts:
                elapsed_ms += now - start_ts
            
            # Salva in warehouse_sessions
            db.execute(
                f"""INSERT INTO warehouse_sessions (project_code, activity_label, elapsed_ms, start_ts, end_ts, note, username, created_ts)
                    VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})""",
                (proj_code, activity, elapsed_ms, start_ts, now, notes, username, now)
            )
            
            # Rimuovi timer attivo
            db.execute(f"DELETE FROM warehouse_active_timers WHERE id = {placeholder}", (timer_id,))
            db.commit()
            app.logger.info(f"Timer produzione fermato e salvato: {username} - {elapsed_ms}ms")
            
            # ── Auto-completamento fase attiva ──
            # Se l'activity_label corrisponde a una fase configurata, marcala come completata
            try:
                _auto_complete_phase_on_stop(db, username, proj_code, activity)
            except Exception as phase_err:
                app.logger.warning(f"Errore auto-completamento fase: {phase_err}")
            
            return True
        return False
    except Exception as e:
        app.logger.error(f"Errore stop timer produzione: {e}")
        return False


def _auto_complete_phase_on_stop(db: DatabaseLike, username: str, project_code: str, activity_label: str) -> None:
    """Marca automaticamente come completata la fase attiva quando il timer viene fermato (fine giornata/cambio attività).
    
    Cerca nelle fasi configurate se l'activity_label corrisponde a un nome fase,
    e se trovata la marca come completata in project_phase_progress.
    """
    if not activity_label or not project_code:
        return
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    today = get_simulated_today().strftime('%Y-%m-%d')
    
    # Cerca in tutte le funzioni configurate se activity_label è una fase
    fn_phases_cfg = get_function_phases_config(db)
    al_lower = activity_label.lower().strip()
    
    matched_function_key = None
    matched_phase = None
    
    for func_key, tmpl in fn_phases_cfg.items():
        for ph in tmpl.get('phases', []):
            if (ph.get('name') or '').lower().strip() == al_lower:
                matched_function_key = func_key
                matched_phase = ph
                break
        if matched_function_key:
            break
    
    if not matched_function_key or not matched_phase:
        app.logger.debug(f"[AUTO-PHASE] Nessuna fase trovata per activity_label='{activity_label}'")
        return
    
    phase_name = matched_phase.get('name', '')
    phase_order = matched_phase.get('order', 0)
    now_ts = int(time.time() * 1000)
    
    # Verifica se già completata
    ensure_project_phase_progress_table(db)
    existing = db.execute(
        f"""SELECT completed FROM project_phase_progress
            WHERE project_date = {placeholder} AND project_key = {placeholder}
              AND function_key = {placeholder} AND phase_name = {placeholder}""",
        (today, project_code, matched_function_key, phase_name)
    ).fetchone()
    
    if existing:
        is_completed = existing['completed'] if isinstance(existing, dict) else existing[0]
        if is_completed:
            app.logger.debug(f"[AUTO-PHASE] Fase '{phase_name}' già completata per {project_code}")
            return
    
    # UPSERT: marca come completata
    if DB_VENDOR == "mysql":
        db.execute(f"""
            INSERT INTO project_phase_progress 
                (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            ON DUPLICATE KEY UPDATE
                completed = 1,
                completed_at = VALUES(completed_at),
                completed_by = VALUES(completed_by),
                updated_ts = VALUES(updated_ts)
        """, (today, project_code, matched_function_key, phase_name, phase_order,
              now_ts, username, now_ts, now_ts))
    else:
        db.execute(f"""
            INSERT INTO project_phase_progress 
                (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            ON CONFLICT(project_date, project_key, function_key, phase_name) DO UPDATE SET
                completed = 1,
                completed_at = excluded.completed_at,
                completed_by = excluded.completed_by,
                updated_ts = excluded.updated_ts
        """, (today, project_code, matched_function_key, phase_name, phase_order,
              now_ts, username, now_ts, now_ts))
    
    db.commit()
    app.logger.info(f"[AUTO-PHASE] Fase '{phase_name}' completata automaticamente per {username} (progetto {project_code}, funzione {matched_function_key})")


# ═══════════════════════════════════════════════════════════════════
# API TIMER PRODUZIONE - Per gruppi di produzione senza leader
# ═══════════════════════════════════════════════════════════════════

@app.get("/api/production/active-timers")
@login_required
def api_production_active_timers() -> ResponseReturnValue:
    """Restituisce tutti i timer attivi raggruppati per project_code e activity_label.
    
    Include sia i timer individuali (warehouse_active_timers) sia gli operatori
    gestiti dal supervisore (member_state) mappati alla fase corrente.
    """
    db = get_db()
    ensure_warehouse_active_timers_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    rows = db.execute(
        "SELECT username, project_code, activity_label FROM warehouse_active_timers WHERE running = 1"
    ).fetchall()
    
    result = {}  # { project_code: { activity_label: [username/member_name, ...] } }
    for row in rows:
        if isinstance(row, dict):
            pc = row['project_code'] or ''
            al = row['activity_label'] or ''
            un = row['username'] or ''
        else:
            pc = row[1] or ''
            al = row[2] or ''
            un = row[0] or ''
        if pc not in result:
            result[pc] = {}
        if al not in result[pc]:
            result[pc][al] = []
        result[pc][al].append(un)
    
    # ── Aggiungi chiavi composte func::phase per timer individuali ──
    # I timer individuali salvano solo activity_label (nome fase), senza la funzione.
    # Per il matching nella pagina planning (che usa func::phase), generiamo le chiavi composte
    # confrontando activity_label con la config function_phases.
    try:
        fn_phases_cfg = get_function_phases_config(db)
        for pc, labels in list(result.items()):
            for al, usernames in list(labels.items()):
                # Cerca se al è un nome di fase in qualche funzione
                if '::' in al:
                    continue  # già compound
                al_lower = al.lower().strip()
                for func_key, tmpl in fn_phases_cfg.items():
                    phases = tmpl.get('phases', [])
                    for ph in phases:
                        if (ph.get('name') or '').lower().strip() == al_lower:
                            compound_key = f"{func_key}::{al}"
                            if compound_key not in result[pc]:
                                result[pc][compound_key] = []
                            for u in usernames:
                                if u not in result[pc][compound_key]:
                                    result[pc][compound_key].append(u)
                            break
    except Exception as e:
        app.logger.warning(f"[active-timers] Errore generazione chiavi composte: {e}")
    
    # ── Includi anche operatori dal flusso supervisore (member_state) ──
    # Quando gestione_squadra è attiva, il supervisore gestisce gli operatori
    # tramite member_state/activities, non warehouse_active_timers.
    try:
        _ensure_member_state_current_phase(db)
        ms_rows = db.execute(
            """SELECT ms.member_name, ms.project_code, ms.activity_id,
                      a.label AS activity_label, ms.current_phase
               FROM member_state ms
               LEFT JOIN activities a ON ms.activity_id = a.activity_id
               WHERE ms.running = 1 AND ms.activity_id IS NOT NULL"""
        ).fetchall()
        
        if ms_rows:
            for ms_row in ms_rows:
                if isinstance(ms_row, dict):
                    m_name = ms_row.get('member_name') or ''
                    m_pc = ms_row.get('project_code') or ''
                    m_label = ms_row.get('activity_label') or ''
                    m_phase = ms_row.get('current_phase') or ''
                else:
                    m_name = ms_row[0] or ''
                    m_pc = ms_row[1] or ''
                    m_label = ms_row[3] or ''
                    m_phase = ms_row[4] or ''
                
                if not m_pc or not m_label:
                    continue
                
                # Usa la fase individuale dal DB; se non disponibile, mostra il nome funzione
                import re as _re_at
                func_name = _re_at.sub(r'\s*\[ID\s+\d+\]$', '', m_label, flags=_re_at.IGNORECASE).strip()
                phase_label = m_phase if m_phase else func_name
                
                if not phase_label:
                    continue
                
                if m_pc not in result:
                    result[m_pc] = {}
                
                # Chiave semplice (retrocompatibile)
                if phase_label not in result[m_pc]:
                    result[m_pc][phase_label] = []
                if m_name not in result[m_pc][phase_label]:
                    result[m_pc][phase_label].append(m_name)
                
                # Chiave composta func::phase per disambiguare fasi con stesso nome in funzioni diverse
                if func_name and m_phase:
                    compound_key = f"{func_name}::{m_phase}"
                    if compound_key not in result[m_pc]:
                        result[m_pc][compound_key] = []
                    if m_name not in result[m_pc][compound_key]:
                        result[m_pc][compound_key].append(m_name)
    except Exception as e:
        app.logger.warning(f"[active-timers] Errore lettura member_state: {e}")
    
    return jsonify({"ok": True, "active_timers": result})


@app.post("/api/production/timer/start")
@login_required
def api_production_timer_start() -> ResponseReturnValue:
    """Avvia il timer di produzione per l'utente (chiamato dopo conferma su timbratura)."""
    username = session.get("user")
    if not username:
        return jsonify({"ok": False, "error": "not_authenticated"}), 401
    
    data = request.get_json(silent=True) or {}
    project_code = (data.get("project_code") or "").strip().upper()
    project_name = (data.get("project_name") or "").strip()
    activity_label = (data.get("activity_label") or "").strip()
    start_ts = data.get("start_ts")  # Timestamp della timbratura (opzionale)
    notes = (data.get("notes") or "").strip() or None
    
    app.logger.info(f"[API] /api/production/timer/start - data={data}, start_ts={start_ts}, type={type(start_ts)}")
    
    if not project_code or not activity_label:
        return jsonify({"ok": False, "error": "missing_required_fields"}), 400
    
    # Note obbligatorie per attività "Altro"
    if activity_label.lower() == "altro" and not notes:
        return jsonify({"ok": False, "error": "Note obbligatorie per attività 'Altro'"}), 400
    
    db = get_db()
    ok = _start_production_timer(db, username, project_code, project_name, activity_label, start_ts, notes)
    
    if ok:
        return jsonify({"ok": True, "message": f"Timer avviato per {activity_label}"})
    else:
        return jsonify({"ok": False, "error": "failed_to_start_timer"}), 500


@app.get("/api/production/project-lookup")
@login_required
def api_production_project_lookup() -> ResponseReturnValue:
    """Cerca un progetto Rentman per numero/codice. Usato dal cambio progetto nel modal attività."""
    code = (request.args.get("code") or "").strip()
    if not code:
        return jsonify({"ok": False, "error": "Inserisci un numero progetto"}), 400

    try:
        from rentman_client import RentmanClient
        cfg = load_config()
        token = cfg.get("rentman_api_token", "")
        if not token:
            return jsonify({"ok": False, "error": "Token Rentman non configurato"}), 500

        client = RentmanClient(token)
        project = client.find_project(code)

        if not project:
            return jsonify({"ok": False, "error": f"Progetto '{code}' non trovato su Rentman"}), 404

        # Estrai i campi utili
        proj_data = project.get("data") if "data" in project else project
        if not proj_data:
            proj_data = project
        project_number = str(proj_data.get("number") or proj_data.get("project_number") or code)
        project_name = proj_data.get("name") or proj_data.get("displayname") or f"Progetto {code}"

        return jsonify({
            "ok": True,
            "project_code": project_number,
            "project_name": project_name
        })

    except Exception as e:
        app.logger.error(f"Errore lookup progetto Rentman: {e}")
        return jsonify({"ok": False, "error": "Errore nella ricerca del progetto"}), 500


@app.post("/api/production/timer/switch")
@login_required
def api_production_timer_switch() -> ResponseReturnValue:
    """Ferma l'attività corrente e avvia una nuova attività di produzione."""
    username = session.get("user")
    if not username:
        return jsonify({"ok": False, "error": "not_authenticated"}), 401

    data = request.get_json(silent=True) or {}
    project_code = (data.get("project_code") or "").strip().upper()
    project_name = (data.get("project_name") or "").strip()
    activity_label = (data.get("activity_label") or "").strip()
    notes = (data.get("notes") or "").strip() or None

    if not project_code or not activity_label:
        return jsonify({"ok": False, "error": "missing_required_fields"}), 400

    # Note obbligatorie per attività "Altro"
    if activity_label.lower() == "altro" and not notes:
        return jsonify({"ok": False, "error": "Note obbligatorie per attività 'Altro'"}), 400

    db = get_db()
    now = now_ms()

    # 1. Ferma il timer corrente (se attivo)
    _stop_production_timer(db, username, None)

    # 2. Avvia il nuovo timer
    ok = _start_production_timer(db, username, project_code, project_name, activity_label, now, notes)

    if ok:
        return jsonify({"ok": True, "message": f"Attività cambiata: {activity_label}"})
    else:
        return jsonify({"ok": False, "error": "failed_to_switch_activity"}), 500


@app.get("/api/production/timer")
@login_required
def api_production_timer_get() -> ResponseReturnValue:
    """Restituisce lo stato del timer di produzione attivo per l'utente."""
    username = session.get("user")
    if not username:
        return jsonify({"ok": False, "error": "not_authenticated"}), 401
    
    db = get_db()
    ensure_warehouse_active_timers_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    timer = db.execute(
        f"""SELECT project_code, project_name, activity_label, notes, running, paused, start_ts, elapsed_ms, pause_start_ts, updated_ts
            FROM warehouse_active_timers WHERE username = {placeholder}""",
        (username,)
    ).fetchone()
    
    if timer:
        if isinstance(timer, dict):
            return jsonify({
                "ok": True,
                "active": True,
                "timer": {
                    "project_code": timer['project_code'],
                    "project_name": timer['project_name'],
                    "activity_label": timer['activity_label'],
                    "notes": timer['notes'],
                    "running": bool(timer['running']),
                    "paused": bool(timer['paused']),
                    "start_ts": timer['start_ts'],
                    "elapsed_ms": timer['elapsed_ms'],
                    "pause_start_ts": timer['pause_start_ts'],
                    "updated_ts": timer['updated_ts']
                }
            })
        else:
            return jsonify({
                "ok": True,
                "active": True,
                "timer": {
                    "project_code": timer[0],
                    "project_name": timer[1],
                    "activity_label": timer[2],
                    "notes": timer[3],
                    "running": bool(timer[4]),
                    "paused": bool(timer[5]),
                    "start_ts": timer[6],
                    "elapsed_ms": timer[7],
                    "pause_start_ts": timer[8],
                    "updated_ts": timer[9]
                }
            })
    
    return jsonify({"ok": True, "active": False, "timer": None})


@app.route("/api/activities", methods=["GET", "POST"])
@login_required
def api_activities():
    if request.method == "GET":
        db = get_db()
        rows = db.execute(
            "SELECT activity_id, label FROM activities ORDER BY sort_order, label"
        ).fetchall()
        return jsonify({"activities": [dict(row) for row in rows]})

    # POST - create new activity
    data = request.get_json(silent=True) or {}
    label = str(data.get("label") or "").strip()
    if not label:
        return jsonify({"ok": False, "error": "missing_label"}), 400

    raw_id = data.get("activity_id")
    requested_id = ""
    if isinstance(raw_id, str) and raw_id.strip():
        requested_id = _normalize_activity_id(raw_id)
        if not requested_id:
            return jsonify({"ok": False, "error": "invalid_activity_id"}), 400

    db = get_db()
    project_code = session.get('supervisor_project_code', '')
    if not project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 409
    project_name = session.get('supervisor_project_name') or project_code
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    if requested_id:
        existing = db.execute(
            f"SELECT 1 FROM activities WHERE activity_id={placeholder} AND project_code={placeholder}",
            (requested_id, project_code),
        ).fetchone()
        if existing is not None:
            return jsonify({"ok": False, "error": "activity_id_in_use"}), 409
        activity_id = requested_id
    else:
        activity_id = _generate_activity_id(db, label)

    order_row = db.execute(f"SELECT COALESCE(MAX(sort_order), 0) AS max_order FROM activities WHERE project_code={placeholder}", (project_code,)).fetchone()
    max_order = 0
    if order_row is not None:
        value = row_value(order_row, "max_order")
        if value is None:
            value = row_value(order_row, 0)
        if isinstance(value, (int, float)):
            max_order = int(value)
    sort_order = max_order + 1

    plan_start = _normalize_datetime(data.get("plan_start"))
    plan_end = _normalize_datetime(data.get("plan_end"))
    planned_members = _coerce_int(data.get("planned_members"))
    if planned_members is None or planned_members < 0:
        planned_members = 0
    notes_raw = data.get("notes")
    notes = str(notes_raw).strip() if isinstance(notes_raw, str) and notes_raw.strip() else None
    planned_duration_ms = compute_planned_duration_ms(plan_start, plan_end, planned_members)

    db.execute(
        f"""
        INSERT INTO activities(
            activity_id, project_code, label, sort_order, plan_start, plan_end,
            planned_members, planned_duration_ms, notes
        ) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder})
        """,
        (
            activity_id,
            project_code,
            label,
            sort_order,
            plan_start,
            plan_end,
            planned_members,
            planned_duration_ms,
            notes,
        ),
    )

    meta = load_activity_meta(db)
    meta[str(activity_id)] = {
        "plan_start": plan_start,
        "plan_end": plan_end,
        "planned_members": planned_members,
        "planned_duration_ms": planned_duration_ms,
        "actual_runtime_ms": 0,
    }
    save_activity_meta(db, meta)

    now = now_ms()
    db.execute(
        f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
        (
            now,
            "create_activity",
            json.dumps({"activity_id": activity_id, "label": label}),
            project_code,
        ),
    )

    db.commit()

    payload = {
        "activity_id": activity_id,
        "label": label,
        "plan_start": plan_start,
        "plan_end": plan_end,
        "planned_members": planned_members,
        "planned_duration_ms": planned_duration_ms,
        "notes": notes,
        "sort_order": sort_order,
    }

    return (
        jsonify(
            {
                "ok": True,
                "activity": payload,
                "project": {"code": project_code, "name": project_name},
            }
        ),
        201,
    )


@app.get("/api/push/status")
@login_required
def api_push_status():
    settings = get_webpush_settings()
    if not settings:
        return jsonify({"enabled": False})

    db = get_db()
    username = session.get("user")
    subscribed = False
    if username:
        row = db.execute(
            "SELECT 1 FROM push_subscriptions WHERE username=? LIMIT 1",
            (username,),
        ).fetchone()
        subscribed = row is not None

    return jsonify(
        {
            "enabled": True,
            "publicKey": settings["vapid_public"],
            "subscribed": subscribed,
        }
    )


@app.post("/api/push/subscribe")
@login_required
def api_push_subscribe():
    settings = get_webpush_settings()
    if not settings:
        return jsonify({"ok": False, "error": "push_not_configured"}), 400

    data = request.get_json(silent=True) or {}
    endpoint_raw = data.get("endpoint")
    if not isinstance(endpoint_raw, str):
        return jsonify({"ok": False, "error": "invalid_subscription"}), 400
    endpoint = endpoint_raw.strip()

    keys = data.get("keys") or {}
    p256dh_raw = keys.get("p256dh")
    auth_raw = keys.get("auth")
    if not isinstance(p256dh_raw, str) or not isinstance(auth_raw, str):
        return jsonify({"ok": False, "error": "invalid_subscription"}), 400
    p256dh = p256dh_raw.strip()
    auth_key = auth_raw.strip()

    if not endpoint or not p256dh or not auth_key:
        return jsonify({"ok": False, "error": "invalid_subscription"}), 400

    encoding_raw = data.get("contentEncoding") or data.get("content_encoding")
    encoding = (
        encoding_raw.strip()
        if isinstance(encoding_raw, str) and encoding_raw.strip()
        else "aes128gcm"
    )

    expiration_raw = data.get("expirationTime")
    expiration_time: Optional[int]
    if isinstance(expiration_raw, (int, float)):
        expiration_time = int(expiration_raw)
    elif isinstance(expiration_raw, str) and expiration_raw.isdigit():
        expiration_time = int(expiration_raw)
    else:
        expiration_time = None

    user_agent = data.get("userAgent")
    if not isinstance(user_agent, str) or not user_agent.strip():
        user_agent = request.headers.get("User-Agent")
    if isinstance(user_agent, str):
        user_agent = user_agent[:255]

    username = session.get("user") or "anonymous"
    now = now_ms()

    db = get_db()
    params = (
        username,
        endpoint,
        p256dh,
        auth_key,
        encoding,
        user_agent,
        expiration_time,
        now,
        now,
    )

    if DB_VENDOR == "mysql":
        db.execute(
            """
            INSERT INTO push_subscriptions(
                username, endpoint, p256dh, auth, content_encoding, user_agent, expiration_time, created_ts, updated_ts
            ) VALUES(?,?,?,?,?,?,?,?,?)
            ON DUPLICATE KEY UPDATE
                username=VALUES(username),
                p256dh=VALUES(p256dh),
                auth=VALUES(auth),
                content_encoding=VALUES(content_encoding),
                user_agent=VALUES(user_agent),
                expiration_time=VALUES(expiration_time),
                updated_ts=VALUES(updated_ts)
            """,
            params,
        )
    else:
        db.execute(
            """
            INSERT INTO push_subscriptions(
                username, endpoint, p256dh, auth, content_encoding, user_agent, expiration_time, created_ts, updated_ts
            ) VALUES(?,?,?,?,?,?,?,?,?)
            ON CONFLICT(endpoint) DO UPDATE SET
                username=excluded.username,
                p256dh=excluded.p256dh,
                auth=excluded.auth,
                content_encoding=excluded.content_encoding,
                user_agent=excluded.user_agent,
                expiration_time=excluded.expiration_time,
                updated_ts=excluded.updated_ts
            """,
            params,
        )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/push/test")
@login_required
def api_push_test():
    settings = get_webpush_settings()
    if not settings:
        return jsonify({"ok": False, "error": "push_not_configured"}), 400

    db = get_db()
    username = session.get("user")
    if not username:
        return jsonify({"ok": False, "error": "missing_user"}), 400

    rows = db.execute(
        "SELECT endpoint, p256dh, auth, content_encoding FROM push_subscriptions WHERE username=?",
        (username,),
    ).fetchall()

    if not rows:
        return jsonify({"ok": False, "error": "no_subscription"}), 404

    subscriptions = [dict(row) for row in rows]
    invalid_endpoints = set()
    delivered = 0

    payload = {
        "title": "JobLog",
        "body": "Notifica di prova inviata con successo",
        "data": {
            "notification_type": "test_message",
            "issued_at": datetime.now(timezone.utc).isoformat(),
        },
    }

    for sub in subscriptions:
        endpoint = sub.get("endpoint") or ""
        if not endpoint or endpoint in invalid_endpoints:
            continue
        key_p256dh = sub.get("p256dh")
        key_auth = sub.get("auth")
        if not key_p256dh or not key_auth:
            invalid_endpoints.add(endpoint)
            continue

        subscription_info = {
            "endpoint": endpoint,
            "keys": {
                "p256dh": key_p256dh,
                "auth": key_auth,
            },
        }
        encoding = sub.get("content_encoding") or "aes128gcm"

        try:
            webpush(
                subscription_info=subscription_info,
                data=json.dumps(payload),
                vapid_private_key=settings["vapid_private"],
                vapid_claims={"sub": settings["subject"]},
                ttl=60,
                content_encoding=encoding,
            )
            delivered += 1
            record_push_notification(
                db,
                kind="test_message",
                title=payload.get("title", "JobLog"),
                body=payload.get("body"),
                payload=payload,
                activity_id=None,
                username=username,
            )
        except WebPushException as exc:
            status = getattr(exc.response, "status_code", None)
            app.logger.warning("WebPush test fallita (%s): %s", status, exc)
            if status in (404, 410):
                invalid_endpoints.add(endpoint)
        except Exception as exc:  # pragma: no cover - logging best effort
            app.logger.exception("Errore generico nell'invio della notifica di prova", exc_info=exc)

    if invalid_endpoints:
        for endpoint in invalid_endpoints:
            remove_push_subscription(db, endpoint)

    db.commit()
    return jsonify({"ok": True, "delivered": delivered, "invalid": list(invalid_endpoints)})


@app.post("/api/push/unsubscribe")
@login_required
def api_push_unsubscribe():
    data = request.get_json(silent=True) or {}
    endpoint = str(data.get("endpoint") or "").strip()
    if not endpoint:
        return jsonify({"ok": False, "error": "invalid_endpoint"}), 400

    db = get_db()
    username = session.get("user")
    if username:
        db.execute(
            "DELETE FROM push_subscriptions WHERE endpoint=? AND username=?",
            (endpoint, username),
        )
    else:
        db.execute("DELETE FROM push_subscriptions WHERE endpoint=?", (endpoint,))

    db.commit()
    return jsonify({"ok": True})


@app.get("/api/push/notifications")
@login_required
def api_push_notifications():
    username = session.get("user")
    if not username:
        return jsonify({"items": []})

    limit_arg = request.args.get("limit", default="20")
    parsed_limit: Optional[int]
    if isinstance(limit_arg, str) and limit_arg.strip().lower() in {"all", "tutti"}:
        parsed_limit = None
    else:
        try:
            parsed_limit = int(limit_arg)
        except (TypeError, ValueError):
            parsed_limit = 20
        else:
            if parsed_limit <= 0:
                parsed_limit = None

    db = get_db()
    ensure_push_notification_read_column(db)
    items = fetch_recent_push_notifications(db, username=username, limit=parsed_limit)
    return jsonify({"items": items})


@app.post("/api/push/notifications/<int:notification_id>/read")
@login_required
def api_push_notification_mark_read(notification_id: int) -> ResponseReturnValue:
    """Marca una notifica come letta."""
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica che la notifica appartenga all'utente
    row = db.execute(
        f"SELECT id FROM push_notification_log WHERE id = {placeholder} AND username = {placeholder}",
        (notification_id, username)
    ).fetchone()
    
    if not row:
        return jsonify({"error": "Notifica non trovata"}), 404
    
    # Marca come letta
    db.execute(
        f"UPDATE push_notification_log SET read_at = {placeholder} WHERE id = {placeholder}",
        (now_ms(), notification_id)
    )
    db.commit()
    
    return jsonify({"ok": True, "read_at": now_ms()})


@app.post("/api/push/notifications/read-all")
@login_required
def api_push_notifications_mark_all_read() -> ResponseReturnValue:
    """Marca tutte le notifiche dell'utente come lette."""
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Marca tutte come lette
    db.execute(
        f"UPDATE push_notification_log SET read_at = {placeholder} WHERE username = {placeholder} AND read_at IS NULL",
        (now_ms(), username)
    )
    db.commit()
    
    return jsonify({"ok": True})


@app.get("/api/state")
@login_required
def api_state():
    db = get_db()
    now = now_ms()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Ogni supervisor vede il proprio progetto (dalla sessione)
    project_code = session.get('supervisor_project_code')
    project_name = session.get('supervisor_project_name') or project_code

    if not project_code:
        return jsonify(
            {
                "team": [],
                "activities": [],
                "allPaused": True,
                "timestamp": now,
                "project": None,
            }
        )

    # ── Se il supervisor è loggato tramite telefono con una funzione specifica,
    #    filtra le attività e i membri per quella funzione. ──
    supervisor_activity_id = session.get('supervisor_activity_id')

    if supervisor_activity_id:
        activity_rows = db.execute(
            f"""SELECT activity_id, label, phase_id, phase_label FROM activities
                WHERE project_code = {placeholder} AND activity_id = {placeholder}
                ORDER BY sort_order, label""",
            (project_code, supervisor_activity_id)
        ).fetchall()
    else:
        activity_rows = db.execute(
            f"SELECT activity_id, label, phase_id, phase_label FROM activities WHERE project_code = {placeholder} ORDER BY sort_order, label",
            (project_code,)
        ).fetchall()

    activity_meta = load_activity_meta(db)

    activity_map: Dict[str, Dict[str, Any]] = {}
    for row in activity_rows:
        activity_id = row["activity_id"]
        activity_key = str(activity_id)
        meta_entry = activity_meta.get(activity_key)
        if not isinstance(meta_entry, dict):
            meta_entry = {}
            activity_meta[activity_key] = meta_entry

        activity_map[activity_id] = {
            "activity_id": activity_id,
            "label": row["label"],
            "members": [],
            "plan_start": meta_entry.get("plan_start"),
            "plan_end": meta_entry.get("plan_end"),
            "planned_members": meta_entry.get("planned_members"),
            "planned_duration_ms": meta_entry.get("planned_duration_ms"),
            "actual_runtime_ms": meta_entry.get("actual_runtime_ms", 0),
            "phase_id": row["phase_id"],
            "phase_label": row["phase_label"],
        }

    if supervisor_activity_id:
        members = db.execute(
            f"SELECT * FROM member_state WHERE project_code = {placeholder} AND activity_id = {placeholder} ORDER BY member_name",
            (project_code, supervisor_activity_id)
        ).fetchall()
    else:
        members = db.execute(
            f"SELECT * FROM member_state WHERE project_code = {placeholder} ORDER BY member_name",
            (project_code,)
        ).fetchall()

    team: List[Dict[str, Any]] = []
    active_members: List[Dict[str, Any]] = []
    paused_keys = {
        row["member_key"]
        for row in db.execute(
            f"SELECT member_key FROM member_state WHERE project_code = {placeholder} AND running={placeholder} AND pause_start IS NOT NULL",
            (project_code, RUN_STATE_PAUSED,)
        ).fetchall()
    }
    for row in members:
        running_state = int(row["running"])
        last_start_ts = row["entered_ts"] or row["start_ts"]
        # current_phase column may not exist yet
        current_phase = None
        try:
            current_phase = row["current_phase"]
        except (KeyError, IndexError):
            pass
        member = {
            "member_key": row["member_key"],
            "member_name": row["member_name"],
            "activity_id": row["activity_id"],
            "running": running_state == RUN_STATE_RUNNING,
            "running_state": running_state,
            "elapsed": compute_elapsed(row, now),
            "paused": row["member_key"] in paused_keys,
            "last_start_ts": last_start_ts,
            "current_phase": current_phase,
        }
        if row["activity_id"] and row["activity_id"] in activity_map:
            activity_map[row["activity_id"]]["members"].append(member)
            active_members.append(member)
        else:
            team.append(member)

    meta_dirty = False
    for activity_id, activity in activity_map.items():
        activity_key = str(activity_id)
        activity["members"].sort(key=lambda m: m["member_name"])
        meta_entry = activity_meta.get(activity_key)
        if not isinstance(meta_entry, dict):
            meta_entry = {}
            activity_meta[activity_key] = meta_entry
        stored_value = _coerce_int(meta_entry.get("planned_members"))
        activity["planned_members"] = stored_value

        plan_start_meta = meta_entry.get("plan_start")
        plan_end_meta = meta_entry.get("plan_end")
        planned_duration_ms = _coerce_int(meta_entry.get("planned_duration_ms"))
        if planned_duration_ms is None:
            computed_duration = compute_planned_duration_ms(
                plan_start_meta,
                plan_end_meta,
                stored_value,
            )
            if computed_duration is not None:
                planned_duration_ms = computed_duration
                meta_entry["planned_duration_ms"] = computed_duration
                meta_dirty = True
        activity["planned_duration_ms"] = planned_duration_ms

    if meta_dirty:
        save_activity_meta(db, activity_meta)

    all_paused = not any(m["running"] for m in team + active_members)
    
    # Verifica se il progetto del supervisor è sincronizzato con quello globale
    project_info = {
        "code": project_code,
        "name": project_name or project_code,
    }

    # ── Fasi operative: config + progresso ──────────────────────────
    function_phases_config = get_function_phases_config(db)
    phase_progress_list: List[Dict[str, Any]] = []
    if function_phases_config:
        today_str = datetime.now().strftime("%Y-%m-%d")
        ensure_project_phase_progress_table(db)
        pp_rows = db.execute(
            f"""SELECT * FROM project_phase_progress
                WHERE project_date = {placeholder} AND project_key = {placeholder}
                ORDER BY function_key, phase_order""",
            (today_str, project_code)
        ).fetchall()
        for r in pp_rows:
            phase_progress_list.append(dict(r) if not isinstance(r, dict) else r)

    return jsonify(
        {
            "team": team,
            "activities": list(activity_map.values()),
            "allPaused": all_paused,
            "timestamp": now,
            "project": project_info,
            "function_phases_config": function_phases_config,
            "phase_progress": phase_progress_list,
        }
    )


@app.get("/api/events")
@login_required
def api_events():
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    project_code = session.get('supervisor_project_code')
    if not project_code:
        return jsonify({"events": []})

    activity_labels = {
        row["activity_id"]: row["label"]
        for row in db.execute(
            f"SELECT activity_id, label FROM activities WHERE project_code = {placeholder}",
            (project_code,)
        )
    }

    rows = db.execute(
        f"SELECT id, ts, kind, member_key, details FROM event_log WHERE project_code = {placeholder} ORDER BY ts DESC LIMIT 25",
        (project_code,)
    ).fetchall()

    events: List[Dict[str, Any]] = []
    for row in rows:
        details_raw = row["details"]
        details: Dict[str, Any]
        if details_raw:
            try:
                details = json.loads(details_raw)
            except json.JSONDecodeError:
                details = {}
        else:
            details = {}

        summary = describe_event(row["kind"], details, activity_labels)
        events.append(
            {
                "id": row["id"],
                "timestamp": row["ts"],
                "kind": row["kind"],
                "summary": summary,
            }
        )

    return jsonify({"events": events})


@app.get("/api/project/attachments")
@login_required
def api_project_attachments():
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"project": None, "attachments": []})

    project_name = get_app_state(db, "project_name") or project_code
    exhaustive = request.args.get("mode") == "deep"
    attachments = fetch_project_attachments(project_code, exhaustive=exhaustive)
    return jsonify({"project": {"code": project_code, "name": project_name}, "attachments": attachments})


@app.get("/api/project/materials")
@login_required
def api_project_materials():
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"project": None, "materials": [], "folders": [], "equipment_checks": {}, "from_cache": False})

    project_name = get_app_state(db, "project_name") or project_code
    mode = (request.args.get("mode") or "").strip().lower()
    refresh_requested = mode == "refresh"

    cached_payload: Optional[Dict[str, Any]] = None
    if not refresh_requested:
        cached_payload = load_project_materials_cache(db, project_code)

    if cached_payload:
        equipment_checks = fetch_equipment_checks(db, project_code)
        return jsonify(
            {
                "project": {"code": project_code, "name": project_name},
                "materials": cached_payload.get("items", []),
                "folders": cached_payload.get("folders", []),
                "equipment_checks": equipment_checks,
                "from_cache": True,
                "updated_ts": cached_payload.get("updated_ts"),
            }
        )

    materials_payload = fetch_project_materials(project_code)
    items = materials_payload.get("items", [])
    folders = materials_payload.get("folders", [])
    saved_ts = save_project_materials_cache(
        db,
        project_code,
        project_name,
        items=items,
        folders=folders,
    )
    try:
        db.commit()
    except Exception:
        app.logger.exception("Impossibile salvare la cache materiali per il progetto %s", project_code)
    equipment_checks = fetch_equipment_checks(db, project_code)
    return jsonify(
        {
            "project": {"code": project_code, "name": project_name},
            "materials": items,
            "folders": folders,
            "equipment_checks": equipment_checks,
            "from_cache": False,
            "updated_ts": saved_ts,
        }
    )


@app.get("/api/project/equipment/checks")
@login_required
def api_project_equipment_checks():
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"project": None, "checks": {}})

    project_name = get_app_state(db, "project_name") or project_code
    checks = fetch_equipment_checks(db, project_code)
    return jsonify({"project": {"code": project_code, "name": project_name}, "checks": checks})


@app.post("/api/project/equipment/checks")
@login_required
def api_update_equipment_check():
    data = request.get_json(silent=True) or {}
    item_key = (data.get("item_key") or "").strip()
    if not item_key:
        return jsonify({"ok": False, "error": "missing_item_key"}), 400
    if "checked" not in data:
        return jsonify({"ok": False, "error": "missing_checked_flag"}), 400

    checked = bool(data.get("checked"))

    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 400

    username = session.get("user")
    timestamp = persist_equipment_check(
        db,
        project_code=project_code,
        item_key=item_key,
        checked=checked,
        username=username,
    )
    db.commit()

    return jsonify({"ok": True, "checked": checked, "timestamp": timestamp})


@app.route("/api/project/local-equipment", methods=["GET", "POST"])
@login_required
def api_local_equipment():
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 400

    ensure_local_equipment_table(db)

    if request.method == "GET":
        rows = db.execute(
            "SELECT id, name, quantity, notes, group_name, created_ts, updated_ts "
            "FROM local_equipment WHERE project_code = ? ORDER BY created_ts DESC",
            (project_code,),
        ).fetchall()
        items = []
        for row in rows:
            if isinstance(row, Mapping):
                items.append(dict(row))
            elif isinstance(row, Sequence):
                items.append({
                    "id": row[0],
                    "name": row[1],
                    "quantity": row[2],
                    "notes": row[3],
                    "group_name": row[4],
                    "created_ts": row[5],
                    "updated_ts": row[6],
                })
        return jsonify({"ok": True, "items": items})

    data = request.get_json(silent=True) or {}
    name = (data.get("name") or "").strip()
    if not name:
        return jsonify({"ok": False, "error": "missing_name"}), 400

    quantity = int(data.get("quantity", 1))
    notes = (data.get("notes") or "").strip() or None
    group_name = (data.get("group_name") or "").strip() or "Attrezzature extra"
    now = int(time.time() * 1000)

    db.execute(
        "INSERT INTO local_equipment (project_code, name, quantity, notes, group_name, created_ts, updated_ts) "
        "VALUES (?, ?, ?, ?, ?, ?, ?)",
        (project_code, name, quantity, notes, group_name, now, now),
    )
    new_id = _last_insert_id(db)
    db.commit()

    return jsonify({
        "ok": True,
        "item": {
            "id": new_id,
            "name": name,
            "quantity": quantity,
            "notes": notes,
            "group_name": group_name,
            "created_ts": now,
            "updated_ts": now,
        },
    })


@app.delete("/api/project/local-equipment/<int:item_id>")
@login_required
def api_delete_local_equipment(item_id: int):
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 400

    ensure_local_equipment_table(db)
    db.execute(
        "DELETE FROM local_equipment WHERE id = ? AND project_code = ?",
        (item_id, project_code),
    )
    db.commit()
    return jsonify({"ok": True})


# ──────────────────────────────────────────────────────────────────────────────
# Foto progetto
# ──────────────────────────────────────────────────────────────────────────────

@app.route("/api/project/photos", methods=["GET", "POST"])
@login_required
def api_project_photos():
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 400

    ensure_project_photos_table(db)

    if request.method == "GET":
        rows = db.execute(
            "SELECT id, filename, original_name, mime_type, file_size, caption, created_ts "
            "FROM project_photos WHERE project_code = ? ORDER BY created_ts DESC",
            (project_code,),
        ).fetchall()
        items = []
        for row in rows:
            if isinstance(row, Mapping):
                items.append(dict(row))
            elif isinstance(row, Sequence):
                items.append({
                    "id": row[0],
                    "filename": row[1],
                    "original_name": row[2],
                    "mime_type": row[3],
                    "file_size": row[4],
                    "caption": row[5],
                    "created_ts": row[6],
                })
        return jsonify({"ok": True, "items": items, "project_code": project_code})

    # POST - Upload nuova foto
    if "photo" not in request.files:
        return jsonify({"ok": False, "error": "no_file"}), 400

    file = request.files["photo"]
    if file.filename == "":
        return jsonify({"ok": False, "error": "no_filename"}), 400

    if not allowed_photo_file(file.filename):
        return jsonify({"ok": False, "error": "invalid_file_type"}), 400

    # Leggi il file in memoria per verificare la dimensione
    file_data = file.read()
    if len(file_data) > MAX_PHOTO_SIZE:
        return jsonify({"ok": False, "error": "file_too_large"}), 400

    # Genera nome file univoco
    original_name = file.filename
    ext = original_name.rsplit(".", 1)[1].lower() if "." in original_name else "jpg"
    unique_filename = f"{project_code}_{int(time.time() * 1000)}_{os.urandom(4).hex()}.{ext}"

    # Salva il file
    file_path = os.path.join(PHOTOS_UPLOAD_FOLDER, unique_filename)
    with open(file_path, "wb") as f:
        f.write(file_data)

    # Salva nel database
    caption = request.form.get("caption", "").strip() or None
    mime_type = file.content_type or f"image/{ext}"
    now = int(time.time() * 1000)

    db.execute(
        "INSERT INTO project_photos (project_code, filename, original_name, mime_type, file_size, caption, created_ts) "
        "VALUES (?, ?, ?, ?, ?, ?, ?)",
        (project_code, unique_filename, original_name, mime_type, len(file_data), caption, now),
    )
    new_id = _last_insert_id(db)
    db.commit()

    return jsonify({
        "ok": True,
        "item": {
            "id": new_id,
            "filename": unique_filename,
            "original_name": original_name,
            "mime_type": mime_type,
            "file_size": len(file_data),
            "caption": caption,
            "created_ts": now,
        },
    })


@app.get("/api/project/photos/<filename>")
@login_required
def api_get_photo(filename: str):
    """Serve una foto dal filesystem"""
    file_path = os.path.join(PHOTOS_UPLOAD_FOLDER, filename)
    if not os.path.exists(file_path):
        return jsonify({"ok": False, "error": "not_found"}), 404

    # Sicurezza: verifica che il file appartenga al progetto attivo
    db = get_db()
    project_code = get_app_state(db, "project_code")
    ensure_project_photos_table(db)

    row = db.execute(
        "SELECT id FROM project_photos WHERE filename = ? AND project_code = ?",
        (filename, project_code),
    ).fetchone()

    if not row:
        return jsonify({"ok": False, "error": "not_authorized"}), 403

    return send_from_directory(PHOTOS_UPLOAD_FOLDER, filename)


@app.delete("/api/project/photos/<int:photo_id>")
@login_required
def api_delete_photo(photo_id: int):
    db = get_db()
    project_code = get_app_state(db, "project_code")
    if not project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 400

    ensure_project_photos_table(db)

    # Recupera il filename per eliminare il file
    row = db.execute(
        "SELECT filename FROM project_photos WHERE id = ? AND project_code = ?",
        (photo_id, project_code),
    ).fetchone()

    if not row:
        return jsonify({"ok": False, "error": "not_found"}), 404

    filename = row["filename"] if isinstance(row, Mapping) else row[0]
    file_path = os.path.join(PHOTOS_UPLOAD_FOLDER, filename)

    # Elimina dal database
    db.execute(
        "DELETE FROM project_photos WHERE id = ? AND project_code = ?",
        (photo_id, project_code),
    )
    db.commit()

    # Elimina il file dal filesystem
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
    except OSError as e:
        app.logger.warning("Impossibile eliminare file foto %s: %s", file_path, e)

    return jsonify({"ok": True})


@app.post("/api/load_project")
@login_required
def api_load_project():
    data = request.get_json(silent=True) or {}
    project_code = (data.get("project_code") or "").strip().upper()
    project_date = (data.get("project_date") or "").strip()
    if not project_code:
        return jsonify({"ok": False, "error": "missing_project_code"}), 400
    if not project_date:
        return jsonify({"ok": False, "error": "missing_project_date"}), 400

    db = get_db()
    if has_active_member_sessions(db):
        return (
            jsonify(
                {
                    "ok": False,
                    "error": "active_sessions_present",
                    "message": "Sono presenti operatori con attività in corso o in pausa. Termina le sessioni prima di ricaricare il progetto.",
                }
            ),
            409,
        )

    plan = mock_fetch_project(project_code, project_date)
    if plan is None:
        clear_project_state(db)
        db.commit()
        # Pulisce anche la sessione del supervisor
        session.pop('supervisor_project_code', None)
        session.pop('supervisor_project_name', None)
        return jsonify({"ok": False, "error": "project_not_found"}), 404

    apply_project_plan(db, plan)
    db.commit()
    
    # Salva il progetto nella sessione del supervisor (individuale)
    session['supervisor_project_code'] = plan["project_code"]
    session['supervisor_project_name'] = plan.get("project_name")
    
    # Salva anche nel database per persistenza dopo logout/login
    username = session.get('user')
    if username:
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        try:
            db.execute(
                f"UPDATE app_users SET current_project_code={placeholder}, current_project_name={placeholder} WHERE username={placeholder}",
                (plan["project_code"], plan.get("project_name"), username)
            )
            db.commit()
            app.logger.info("Progetto %s salvato per utente %s", plan["project_code"], username)
        except Exception as e:
            app.logger.warning("Impossibile salvare progetto corrente per %s: %s", username, e)

    return jsonify(
        {
            "ok": True,
            "project": {
                "code": plan["project_code"],
                "name": plan.get("project_name"),
            },
        }
    )


def _mark_phase_completed_on_move(
    db: DatabaseLike,
    project_code: str,
    activity_id: str,
    phase_name: str,
    completed_by: str,
) -> None:
    """Marca una fase come completata in project_phase_progress quando il supervisor cambia fase."""
    import re as _re_mp
    ensure_project_phase_progress_table(db)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    today_str = datetime.now().strftime("%Y-%m-%d")

    # Recupera il function_key dall'activity_id (es. "rentman-f-18393" → label "Allestimento")
    act_row = db.execute(
        f"SELECT label FROM activities WHERE activity_id={placeholder} AND project_code={placeholder}",
        (activity_id, project_code),
    ).fetchone()
    if not act_row:
        return
    raw_label = act_row["label"] or ""
    function_name = _re_mp.sub(r'\s*\[ID\s+\d+\]$', '', raw_label, flags=_re_mp.IGNORECASE).strip()
    if not function_name:
        return

    # Trova il function_key corrispondente nella config fasi
    fn_config = get_function_phases_config(db)
    matched_key = None
    fn_lower = function_name.lower()
    for key in fn_config:
        if key.lower().strip() == fn_lower:
            matched_key = key
            break
    if not matched_key:
        return

    # Trova l'ordine della fase
    phase_order = 0
    for ph in fn_config[matched_key].get("phases", []):
        if ph.get("name", "").strip().lower() == phase_name.strip().lower():
            phase_order = ph.get("order", 0)
            break

    now_ts = int(time.time() * 1000)
    username = completed_by or "supervisor"

    if DB_VENDOR == "mysql":
        db.execute(f"""
            INSERT INTO project_phase_progress
                (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            ON DUPLICATE KEY UPDATE
                completed = 1,
                completed_at = VALUES(completed_at),
                completed_by = VALUES(completed_by),
                updated_ts = VALUES(updated_ts)
        """, (today_str, project_code, matched_key, phase_name, phase_order, now_ts, username, now_ts, now_ts))
    else:
        db.execute(f"""
            INSERT INTO project_phase_progress
                (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            ON CONFLICT(project_date, project_key, function_key, phase_name) DO UPDATE SET
                completed = 1,
                completed_at = excluded.completed_at,
                completed_by = excluded.completed_by,
                updated_ts = excluded.updated_ts
        """, (today_str, project_code, matched_key, phase_name, phase_order, now_ts, username, now_ts, now_ts))


def _mark_all_phases_completed_for_activity(
    db: DatabaseLike,
    project_code: str,
    activity_id: str,
    completed_by: str,
) -> None:
    """Marca TUTTE le fasi di una funzione come completate quando l'attività viene terminata."""
    import re as _re_ap
    ensure_project_phase_progress_table(db)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    today_str = datetime.now().strftime("%Y-%m-%d")

    # Recupera il function_key dall'activity_id
    act_row = db.execute(
        f"SELECT label FROM activities WHERE activity_id={placeholder} AND project_code={placeholder}",
        (activity_id, project_code),
    ).fetchone()
    if not act_row:
        return
    raw_label = act_row["label"] or ""
    function_name = _re_ap.sub(r'\s*\[ID\s+\d+\]$', '', raw_label, flags=_re_ap.IGNORECASE).strip()
    if not function_name:
        return

    # Trova il function_key nella config fasi
    fn_config = get_function_phases_config(db)
    matched_key = None
    fn_lower = function_name.lower()
    for key in fn_config:
        if key.lower().strip() == fn_lower:
            matched_key = key
            break
    if not matched_key:
        return

    phases = fn_config[matched_key].get("phases", [])
    if not phases:
        return

    now_ts = int(time.time() * 1000)
    username = completed_by or "supervisor"

    for ph in phases:
        ph_name = ph.get("name", "").strip()
        ph_order = ph.get("order", 0)
        if not ph_name:
            continue
        if DB_VENDOR == "mysql":
            db.execute(f"""
                INSERT INTO project_phase_progress
                    (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, {placeholder}, {placeholder}, {placeholder}, {placeholder})
                ON DUPLICATE KEY UPDATE
                    completed = CASE WHEN completed = 0 THEN 1 ELSE completed END,
                    completed_at = CASE WHEN completed = 0 THEN VALUES(completed_at) ELSE completed_at END,
                    completed_by = CASE WHEN completed = 0 THEN VALUES(completed_by) ELSE completed_by END,
                    updated_ts = VALUES(updated_ts)
            """, (today_str, project_code, matched_key, ph_name, ph_order, now_ts, username, now_ts, now_ts))
        else:
            db.execute(f"""
                INSERT INTO project_phase_progress
                    (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 1, {placeholder}, {placeholder}, {placeholder}, {placeholder})
                ON CONFLICT(project_date, project_key, function_key, phase_name) DO UPDATE SET
                    completed = CASE WHEN project_phase_progress.completed = 0 THEN 1 ELSE project_phase_progress.completed END,
                    completed_at = CASE WHEN project_phase_progress.completed = 0 THEN excluded.completed_at ELSE project_phase_progress.completed_at END,
                    completed_by = CASE WHEN project_phase_progress.completed = 0 THEN excluded.completed_by ELSE project_phase_progress.completed_by END,
                    updated_ts = excluded.updated_ts
            """, (today_str, project_code, matched_key, ph_name, ph_order, now_ts, username, now_ts, now_ts))

    app.logger.info("Tutte le fasi di %s marcate come completate per progetto %s da %s",
                     matched_key, project_code, username)


@app.post("/api/move")
@login_required
def api_move():
    data = request.get_json(silent=True) or {}
    member_key = (data.get("member_key") or "").strip()
    member_name = (data.get("member_name") or "").strip()
    activity_id = data.get("activity_id")
    phase_name = (data.get("phase_name") or "").strip() or None

    if isinstance(activity_id, str):
        activity_id = activity_id.strip()
    if activity_id == "":
        activity_id = None

    if not member_key or not member_name:
        return jsonify({"ok": False, "error": "invalid_payload"}), 400

    project_code = session.get('supervisor_project_code')
    if not project_code:
        return jsonify({"ok": False, "error": "no_project_selected"}), 400

    db = get_db()
    now = now_ms()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    if activity_id:
        exists = db.execute(
            f"SELECT 1 FROM activities WHERE activity_id={placeholder} AND project_code={placeholder}",
            (activity_id, project_code),
        ).fetchone()
        if exists is None:
            return jsonify({"ok": False, "error": "unknown_activity"}), 400

    existing = db.execute(
        f"SELECT * FROM member_state WHERE member_key={placeholder} AND project_code={placeholder}",
        (member_key, project_code),
    ).fetchone()

    if existing is None:
        db.execute(
            f"""
            INSERT INTO member_state(
                member_key, project_code, member_name, activity_id, running, start_ts, elapsed_cached, pause_start, entered_ts
            ) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder},{placeholder})
            """,
            (member_key, project_code, member_name, None, 0, None, 0, None, None),
        )
        existing = db.execute(
            f"SELECT * FROM member_state WHERE member_key={placeholder} AND project_code={placeholder}",
            (member_key, project_code),
        ).fetchone()
    else:
        db.execute(
            f"UPDATE member_state SET member_name={placeholder} WHERE member_key={placeholder} AND project_code={placeholder}",
            (member_name, member_key, project_code),
        )

    if existing is None:
        app.logger.error("Member state insert fallita per %s", member_key)
        return jsonify({"ok": False, "error": "member_state_error"}), 500

    previous_activity = existing["activity_id"]
    previous_entered_ts = row_value(existing, "entered_ts")
    prev_elapsed = compute_elapsed(existing, now)
    normalized_previous = str(previous_activity) if previous_activity else None
    normalized_target = str(activity_id) if activity_id else None
    same_activity = normalized_previous is not None and normalized_previous == normalized_target

    # Rileva cambio fase nella stessa attività
    previous_phase = row_value(existing, "current_phase") or None
    phase_changed = same_activity and phase_name is not None and phase_name != previous_phase

    running = RUN_STATE_RUNNING if activity_id else RUN_STATE_PAUSED
    start_ts = now if running else None
    reset_elapsed = (bool(activity_id) and not same_activity) or phase_changed
    elapsed_cached = 0 if reset_elapsed else prev_elapsed
    next_entered_ts = previous_entered_ts
    if activity_id and not same_activity:
        next_entered_ts = now
    if phase_changed:
        next_entered_ts = now  # Nuovo ingresso per la nuova fase
    if not activity_id:
        next_entered_ts = None

    activity_meta = load_activity_meta(db)
    meta_changed = False
    auto_closed_previous = False
    if normalized_previous and normalized_previous != normalized_target:
        if prev_elapsed > 0:
            meta_changed = increment_activity_runtime(activity_meta, normalized_previous, prev_elapsed)
        auto_closed_previous = True

    # ── Cambio fase nella stessa attività: chiudi la fase precedente ──
    phase_finish_logged = False
    if phase_changed and prev_elapsed > 0 and previous_phase:
        activity_start_ts = find_last_move_ts(db, member_key, normalized_previous)
        if activity_start_ts is None:
            activity_start_ts = previous_entered_ts or existing["start_ts"]
        total_ms = max(0, now - activity_start_ts) if activity_start_ts else prev_elapsed
        pause_ms = max(0, total_ms - prev_elapsed)

        finish_payload = {
            "member_name": existing["member_name"],
            "activity_id": normalized_previous,
            "duration_ms": prev_elapsed,
            "total_ms": total_ms,
            "pause_ms": pause_ms,
            "auto_close": True,
            "project_code": project_code,
            "phase_name": previous_phase,
            "phase_change": True,
        }
        db.execute(
            f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
            (now, "finish_activity", member_key, json.dumps(finish_payload), project_code),
        )
        phase_finish_logged = True

        # Marca la fase precedente come completata in project_phase_progress
        try:
            _mark_phase_completed_on_move(db, project_code, normalized_previous, previous_phase, member_name)
        except Exception as e:
            app.logger.warning("Errore marcatura fase completata per %s: %s", member_key, e)

    # Ensure current_phase column exists
    _ensure_member_state_current_phase(db)

    db.execute(
        f"""
        UPDATE member_state
        SET activity_id={placeholder}, running={placeholder}, start_ts={placeholder}, elapsed_cached={placeholder}, pause_start=NULL, entered_ts={placeholder}, current_phase={placeholder}
        WHERE member_key={placeholder} AND project_code={placeholder}
        """,
        (activity_id, running, start_ts, elapsed_cached, next_entered_ts, phase_name, member_key, project_code),
    )

    if meta_changed:
        save_activity_meta(db, activity_meta)

    if auto_closed_previous:
        # Calcola il tempo totale partendo dall'ultimo move verso questa attività
        activity_start_ts = find_last_move_ts(db, member_key, normalized_previous)
        if activity_start_ts is None:
            activity_start_ts = previous_entered_ts or existing["start_ts"]

        total_ms = 0
        if activity_start_ts:
            total_ms = max(0, now - activity_start_ts)
        
        pause_ms = max(0, total_ms - prev_elapsed)
        
        finish_payload = {
            "member_name": existing["member_name"],
            "activity_id": normalized_previous,
            "duration_ms": prev_elapsed,
            "total_ms": total_ms,
            "pause_ms": pause_ms,
            "auto_close": True,
            "project_code": project_code,
        }
        db.execute(
            f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
            (now, "finish_activity", member_key, json.dumps(finish_payload), project_code),
        )

    move_details = {
        "from": previous_activity,
        "to": activity_id,
        "member_name": member_name,
        "duration_ms": prev_elapsed if not phase_changed else 0,
        "project_code": project_code,
        "phase_name": phase_name,
        "from_phase": previous_phase if phase_changed else None,
    }
    db.execute(
        f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
        (now, "move", member_key, json.dumps(move_details), project_code),
    )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/start_activity")
@login_required
def api_start_activity():
    """Avvia i timer per tutti i membri di una specifica attività."""
    data = request.get_json(silent=True) or {}
    activity_id = (data.get("activity_id") or "").strip()
    
    if not activity_id:
        return jsonify({"ok": False, "error": "missing_activity_id"}), 400
    
    now = now_ms()
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Verifica che l'attività esista per questo progetto
    activity_exists = db.execute(
        f"SELECT 1 FROM activities WHERE activity_id={placeholder} AND project_code={placeholder}",
        (activity_id, project_code),
    ).fetchone()
    
    if not activity_exists:
        return jsonify({"ok": False, "error": "activity_not_found"}), 404

    # Trova tutti i membri assegnati a questa attività con timer non avviato
    rows = db.execute(
        f"SELECT member_key FROM member_state WHERE activity_id={placeholder} AND running={placeholder} AND project_code={placeholder}",
        (activity_id, RUN_STATE_PAUSED, project_code),
    ).fetchall()

    if not rows:
        return jsonify({"ok": True, "affected": 0})

    affected = 0
    for row in rows:
        db.execute(
            f"UPDATE member_state SET running={placeholder}, start_ts={placeholder}, pause_start=NULL WHERE member_key={placeholder} AND project_code={placeholder}",
            (RUN_STATE_RUNNING, now, row["member_key"], project_code),
        )
        affected += 1

    db.execute(
        f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
        (now, "start_activity", json.dumps({"activity_id": activity_id, "affected": affected}), project_code),
    )

    db.commit()
    return jsonify({"ok": True, "affected": affected})


@app.post("/api/start_member")
@login_required
def api_start_member():
    """Avvia il timer per un singolo membro."""
    data = request.get_json(silent=True) or {}
    member_key = (data.get("member_key") or "").strip()
    
    if not member_key:
        return jsonify({"ok": False, "error": "missing_member_key"}), 400
    
    now = now_ms()
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Verifica che il membro esista e abbia un'attività assegnata
    member = db.execute(
        f"SELECT member_key, member_name, activity_id, running FROM member_state WHERE member_key={placeholder} AND project_code={placeholder}",
        (member_key, project_code),
    ).fetchone()
    
    if not member:
        return jsonify({"ok": False, "error": "member_not_found"}), 404
    
    if not member["activity_id"]:
        return jsonify({"ok": False, "error": "no_activity_assigned"}), 400
    
    if member["running"] == RUN_STATE_RUNNING:
        return jsonify({"ok": False, "error": "already_running"}), 400

    # Avvia il timer
    db.execute(
        f"UPDATE member_state SET running={placeholder}, start_ts={placeholder}, pause_start=NULL WHERE member_key={placeholder} AND project_code={placeholder}",
        (RUN_STATE_RUNNING, now, member_key, project_code),
    )

    db.execute(
        f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
        (now, "start_member", json.dumps({"member_key": member_key}), project_code),
    )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/start_all")
@login_required
def api_start_all():
    """Avvia i timer per tutti i membri che hanno un'attività assegnata."""
    now = now_ms()
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Trova tutti i membri con activity_id assegnato ma non in esecuzione
    rows = db.execute(
        f"SELECT member_key FROM member_state WHERE activity_id IS NOT NULL AND running={placeholder} AND project_code={placeholder}",
        (RUN_STATE_PAUSED, project_code),
    ).fetchall()

    if not rows:
        return jsonify({"ok": True, "affected": 0})

    affected = 0
    for row in rows:
        db.execute(
            f"UPDATE member_state SET running={placeholder}, start_ts={placeholder}, pause_start=NULL WHERE member_key={placeholder} AND project_code={placeholder}",
            (RUN_STATE_RUNNING, now, row["member_key"], project_code),
        )
        affected += 1

    db.execute(
        f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
        (now, "start_all", json.dumps({"affected": affected}), project_code),
    )

    db.commit()
    return jsonify({"ok": True, "affected": affected})


@app.post("/api/pause_all")
@login_required
def api_pause_all():
    now = now_ms()
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    rows = db.execute(
        f"SELECT member_key, start_ts, elapsed_cached FROM member_state WHERE running={placeholder} AND project_code={placeholder}",
        (RUN_STATE_RUNNING, project_code),
    ).fetchall()

    for row in rows:
        start_ts = row["start_ts"] or now
        elapsed = (row["elapsed_cached"] or 0) + max(0, now - start_ts)
        db.execute(
            f"""
            UPDATE member_state
            SET running={placeholder}, start_ts=NULL, elapsed_cached={placeholder}, pause_start={placeholder}
            WHERE member_key={placeholder} AND project_code={placeholder}
            """,
            (RUN_STATE_PAUSED, elapsed, now, row["member_key"], project_code),
        )

    if rows:
        db.execute(
            f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
            (now, "pause_all", json.dumps({"affected": len(rows)}), project_code),
        )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/resume_all")
@login_required
def api_resume_all():
    now = now_ms()
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    rows = db.execute(
        f"SELECT member_key FROM member_state WHERE running={placeholder} AND pause_start IS NOT NULL AND project_code={placeholder}",
        (RUN_STATE_PAUSED, project_code),
    ).fetchall()

    for row in rows:
        db.execute(
            f"UPDATE member_state SET running={placeholder}, start_ts={placeholder}, pause_start=NULL WHERE member_key={placeholder} AND project_code={placeholder}",
            (RUN_STATE_RUNNING, now, row["member_key"], project_code),
        )

    if rows:
        db.execute(
            f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
            (now, "resume_all", json.dumps({"affected": len(rows)}), project_code),
        )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/finish_all")
@login_required
def api_finish_all():
    now = now_ms()
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    rows = db.execute(
        f"SELECT * FROM member_state WHERE activity_id IS NOT NULL AND project_code={placeholder}",
        (project_code,),
    ).fetchall()

    activity_meta = load_activity_meta(db)
    meta_changed = False

    affected = 0
    for row in rows:
        elapsed = compute_elapsed(row, now)
        if row["activity_id"] and elapsed > 0:
            meta_changed |= increment_activity_runtime(activity_meta, str(row["activity_id"]), elapsed)
        
        activity_start_ts = find_last_move_ts(db, row["member_key"], str(row["activity_id"]))
        if activity_start_ts is None:
            activity_start_ts = row["entered_ts"] or row["start_ts"]

        total_ms = 0
        if activity_start_ts:
            total_ms = max(0, now - activity_start_ts)
        
        pause_ms = max(0, total_ms - elapsed)
        
        db.execute(
            f"""
            UPDATE member_state
            SET activity_id=NULL, running={placeholder}, start_ts=NULL, elapsed_cached=0, pause_start=NULL, entered_ts=NULL
            WHERE member_key={placeholder} AND project_code={placeholder}
            """,
            (RUN_STATE_FINISHED, row["member_key"], project_code),
        )
        db.execute(
            f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
            (
                now,
                "finish_activity",
                row["member_key"],
                json.dumps(
                    {
                        "member_name": row["member_name"],
                        "activity_id": row["activity_id"],
                        "duration_ms": elapsed,
                        "total_ms": total_ms,
                        "pause_ms": pause_ms,
                    }
                ),
                project_code,
            ),
        )
        affected += 1

    if affected:
        db.execute(
            f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
            (
                now,
                "finish_all",
                json.dumps({"affected": affected}),
                project_code,
            ),
        )

    if meta_changed:
        save_activity_meta(db, activity_meta)

    db.commit()
    return jsonify({"ok": True, "affected": affected})


@app.post("/api/member/pause")
@login_required
def api_member_pause():
    data = request.get_json(silent=True) or {}
    member_key = (data.get("member_key") or "").strip()
    if not member_key:
        return jsonify({"ok": False, "error": "missing_member_key"}), 400

    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    member = fetch_member(db, member_key, project_code)
    if member is None:
        return jsonify({"ok": False, "error": "member_not_found"}), 404

    if not member["activity_id"]:
        return jsonify({"ok": False, "error": "member_not_assigned"}), 400

    if member["pause_start"] is not None:
        return jsonify({"ok": True, "already_paused": True})

    if member["running"] != RUN_STATE_RUNNING:
        return jsonify({"ok": False, "error": "member_not_running"}), 400

    now = now_ms()
    elapsed = compute_elapsed(member, now)

    db.execute(
        f"""
        UPDATE member_state
        SET running={placeholder}, start_ts=NULL, elapsed_cached={placeholder}, pause_start={placeholder}
        WHERE member_key={placeholder} AND project_code={placeholder}
        """,
        (RUN_STATE_PAUSED, elapsed, now, member_key, project_code),
    )

    db.execute(
        f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
        (
            now,
            "pause_member",
            member_key,
            json.dumps(
                {
                    "member_name": member["member_name"],
                    "activity_id": member["activity_id"],
                    "duration_ms": elapsed,
                }
            ),
            project_code,
        ),
    )

    # Genera timbratura inizio_pausa per l'operatore
    member_username = get_username_from_member_key(db, member_key)
    if member_username:
        create_supervisor_pause_timbratura(
            db,
            username=member_username,
            tipo='inizio_pausa',
            member_name=member["member_name"],
            supervisor_username=session.get("user")
        )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/member/resume")
@login_required
def api_member_resume():
    data = request.get_json(silent=True) or {}
    member_key = (data.get("member_key") or "").strip()
    if not member_key:
        return jsonify({"ok": False, "error": "missing_member_key"}), 400

    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    member = fetch_member(db, member_key, project_code)
    if member is None:
        return jsonify({"ok": False, "error": "member_not_found"}), 404

    if not member["activity_id"]:
        return jsonify({"ok": False, "error": "member_not_assigned"}), 400

    if member["running"] == RUN_STATE_RUNNING:
        return jsonify({"ok": True, "already_running": True})

    if member["pause_start"] is None:
        return jsonify({"ok": False, "error": "member_not_paused"}), 400

    now = now_ms()

    db.execute(
        f"UPDATE member_state SET running={placeholder}, start_ts={placeholder}, pause_start=NULL WHERE member_key={placeholder} AND project_code={placeholder}",
        (RUN_STATE_RUNNING, now, member_key, project_code),
    )

    db.execute(
        f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
        (
            now,
            "resume_member",
            member_key,
            json.dumps(
                {
                    "member_name": member["member_name"],
                    "activity_id": member["activity_id"],
                }
            ),
            project_code,
        ),
    )

    # Genera timbratura fine_pausa per l'operatore
    member_username = get_username_from_member_key(db, member_key)
    if member_username:
        create_supervisor_pause_timbratura(
            db,
            username=member_username,
            tipo='fine_pausa',
            member_name=member["member_name"],
            supervisor_username=session.get("user")
        )

    db.commit()
    return jsonify({"ok": True})


@app.post("/api/member/finish")
@login_required
def api_member_finish():
    data = request.get_json(silent=True) or {}
    member_key = (data.get("member_key") or "").strip()
    if not member_key:
        return jsonify({"ok": False, "error": "missing_member_key"}), 400

    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    member = fetch_member(db, member_key, project_code)
    if member is None:
        return jsonify({"ok": False, "error": "member_not_found"}), 404

    if not member["activity_id"]:
        return jsonify({"ok": False, "error": "member_not_assigned"}), 400

    now = now_ms()

    elapsed = compute_elapsed(member, now)
    activity_meta = load_activity_meta(db)
    meta_changed = False
    if member["activity_id"] and elapsed > 0:
        meta_changed = increment_activity_runtime(activity_meta, str(member["activity_id"]), elapsed)

    activity_start_ts = find_last_move_ts(db, member_key, str(member["activity_id"]))
    if activity_start_ts is None:
        activity_start_ts = member["entered_ts"] or member["start_ts"]

    total_ms = 0
    if activity_start_ts:
        total_ms = max(0, now - activity_start_ts)
    pause_ms = max(0, total_ms - elapsed)

    db.execute(
        f"""
        UPDATE member_state
        SET activity_id=NULL, running={placeholder}, start_ts=NULL, elapsed_cached=0, pause_start=NULL, entered_ts=NULL
        WHERE member_key={placeholder} AND project_code={placeholder}
        """,
        (RUN_STATE_FINISHED, member_key, project_code),
    )

    db.execute(
        f"INSERT INTO event_log(ts, kind, member_key, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder},{placeholder})",
        (
            now,
            "finish_activity",
            member_key,
            json.dumps(
                {
                    "member_name": member["member_name"],
                    "activity_id": member["activity_id"],
                    "duration_ms": elapsed,
                    "total_ms": total_ms,
                    "pause_ms": pause_ms,
                }
            ),
            project_code,
        ),
    )

    if meta_changed:
        save_activity_meta(db, activity_meta)

    # ── Marca tutte le fasi come completate quando l'ultimo membro finisce ──
    # Controlla se rimangono altri membri attivi in questa attività
    remaining = db.execute(
        f"""SELECT COUNT(*) as cnt FROM member_state
            WHERE activity_id={placeholder} AND project_code={placeholder}
              AND member_key != {placeholder}
              AND activity_id IS NOT NULL""",
        (member["activity_id"], project_code, member_key),
    ).fetchone()
    remaining_count = remaining["cnt"] if remaining else 0
    if remaining_count == 0:
        # Ultimo membro: marca tutte le fasi della funzione come completate
        try:
            _mark_all_phases_completed_for_activity(
                db, project_code, member["activity_id"],
                completed_by=member["member_name"],
            )
        except Exception as exc:
            app.logger.warning("Errore marcatura fasi su finish: %s", exc)

    db.commit()
    return jsonify({"ok": True})


# ═══════════════════════════════════════════════════════════════════════════════
#  API - Gestione operatori nel progetto (capo squadra)
# ═══════════════════════════════════════════════════════════════════════════════

@app.get("/api/project/available-operators")
@login_required
def api_project_available_operators():
    """Lista operatori disponibili (non già nel progetto) dalla tabella crew_members."""
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    
    if not project_code:
        return jsonify({"ok": False, "error": "no_project"}), 400
    
    ensure_crew_members_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Ottieni gli operatori già nel progetto
    existing_keys = set()
    existing_rows = db.execute(
        f"SELECT member_key FROM member_state WHERE project_code = {placeholder}",
        (project_code,)
    ).fetchall()
    for row in existing_rows:
        key = row["member_key"] if isinstance(row, dict) else row[0]
        existing_keys.add(key)
    
    # Ottieni tutti gli operatori attivi da crew_members
    if DB_VENDOR == "mysql":
        crew_rows = db.execute(
            "SELECT rentman_id, name FROM crew_members WHERE is_active = 1 ORDER BY name"
        ).fetchall()
    else:
        crew_rows = db.execute(
            "SELECT rentman_id, name FROM crew_members WHERE is_active = 1 ORDER BY name"
        ).fetchall()
    
    available = []
    for row in crew_rows:
        rentman_id = row["rentman_id"] if isinstance(row, dict) else row[0]
        name = row["name"] if isinstance(row, dict) else row[1]
        member_key = f"rentman-crew-{rentman_id}"
        
        # Escludi operatori già nel progetto
        if member_key not in existing_keys:
            available.append({
                "key": member_key,
                "name": name,
                "rentman_id": rentman_id
            })
    
    return jsonify({"ok": True, "operators": available})


@app.post("/api/project/add-operator")
@login_required
def api_project_add_operator():
    """Aggiunge un operatore al progetto corrente."""
    data = request.get_json(silent=True) or {}
    
    # Supporta sia l'aggiunta da crew_members (rentman_id) che un nuovo operatore manuale (name)
    rentman_id = data.get("rentman_id")
    name = (data.get("name") or "").strip()
    
    if not rentman_id and not name:
        return jsonify({"ok": False, "error": "missing_data"}), 400
    
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    
    if not project_code:
        return jsonify({"ok": False, "error": "no_project"}), 400
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now = now_ms()
    
    if rentman_id:
        # Aggiunta da crew_members
        member_key = f"rentman-crew-{rentman_id}"
        
        # Verifica che non esista già nel progetto
        existing = db.execute(
            f"SELECT 1 FROM member_state WHERE member_key = {placeholder} AND project_code = {placeholder}",
            (member_key, project_code)
        ).fetchone()
        
        if existing:
            return jsonify({"ok": False, "error": "already_in_project"}), 400
        
        # Ottieni il nome da crew_members
        if DB_VENDOR == "mysql":
            crew = db.execute(
                "SELECT name FROM crew_members WHERE rentman_id = %s", (rentman_id,)
            ).fetchone()
        else:
            crew = db.execute(
                "SELECT name FROM crew_members WHERE rentman_id = ?", (rentman_id,)
            ).fetchone()
        
        if not crew:
            return jsonify({"ok": False, "error": "operator_not_found"}), 404
        
        member_name = crew["name"] if isinstance(crew, dict) else crew[0]
    else:
        # Operatore manuale - genera una chiave unica
        base_key = f"local-{name.lower().replace(' ', '-')}"
        member_key = base_key
        counter = 1
        
        while True:
            existing = db.execute(
                f"SELECT 1 FROM member_state WHERE member_key = {placeholder} AND project_code = {placeholder}",
                (member_key, project_code)
            ).fetchone()
            if not existing:
                break
            member_key = f"{base_key}-{counter}"
            counter += 1
        
        member_name = name
    
    # Inserisci l'operatore nel progetto
    db.execute(
        f"""
        INSERT INTO member_state (member_key, project_code, member_name, activity_id, running, start_ts, elapsed_cached, pause_start, entered_ts)
        VALUES ({placeholder}, {placeholder}, {placeholder}, NULL, {placeholder}, NULL, 0, NULL, NULL)
        """,
        (member_key, project_code, member_name, RUN_STATE_PAUSED)
    )
    
    # Log evento
    db.execute(
        f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
        (now, "add_operator", json.dumps({"member_key": member_key, "member_name": member_name}), project_code)
    )
    
    db.commit()
    
    return jsonify({
        "ok": True,
        "member": {
            "key": member_key,
            "name": member_name
        }
    })


@app.post("/api/project/remove-operator")
@login_required
def api_project_remove_operator():
    """Rimuove un operatore dal progetto corrente."""
    data = request.get_json(silent=True) or {}
    member_key = (data.get("member_key") or "").strip()
    
    if not member_key:
        return jsonify({"ok": False, "error": "missing_member_key"}), 400
    
    db = get_db()
    project_code = session.get("supervisor_project_code", "")
    
    if not project_code:
        return jsonify({"ok": False, "error": "no_project"}), 400
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now = now_ms()
    
    # Verifica che l'operatore esista e non sia in attività
    member = db.execute(
        f"SELECT member_name, activity_id, running FROM member_state WHERE member_key = {placeholder} AND project_code = {placeholder}",
        (member_key, project_code)
    ).fetchone()
    
    if not member:
        return jsonify({"ok": False, "error": "member_not_found"}), 404
    
    member_name = member["member_name"] if isinstance(member, dict) else member[0]
    activity_id = member["activity_id"] if isinstance(member, dict) else member[1]
    running = member["running"] if isinstance(member, dict) else member[2]
    
    # Non permettere la rimozione se l'operatore ha un timer attivo
    if running == RUN_STATE_RUNNING:
        return jsonify({"ok": False, "error": "member_running", "message": "Ferma il timer prima di rimuovere l'operatore"}), 400
    
    # Rimuovi l'operatore
    db.execute(
        f"DELETE FROM member_state WHERE member_key = {placeholder} AND project_code = {placeholder}",
        (member_key, project_code)
    )
    
    # Log evento
    db.execute(
        f"INSERT INTO event_log(ts, kind, details, project_code) VALUES({placeholder},{placeholder},{placeholder},{placeholder})",
        (now, "remove_operator", json.dumps({"member_key": member_key, "member_name": member_name}), project_code)
    )
    
    db.commit()
    
    return jsonify({"ok": True})


@app.get("/api/export")
@login_required
def api_export():
    """Esporta i dati delle attività in formato Excel o CSV."""
    export_format = request.args.get("format", "excel").lower()
    start_date = request.args.get("start_date", "").strip()
    end_date = request.args.get("end_date", "").strip()
    project_filter = request.args.get("project_code", "").strip()

    db = get_db()
    
    # Ottieni informazioni progetto corrente
    raw_project_code = get_app_state(db, "project_code")
    project_name = get_app_state(db, "project_name") or raw_project_code or ""

    if not raw_project_code:
        return jsonify({"ok": False, "error": "no_active_project"}), 400

    project_code = str(raw_project_code)
    project_name = str(project_name or project_code)

    # Se c'è un filtro progetto e non corrisponde al progetto attivo, errore
    if project_filter and project_filter != project_code:
        return jsonify({"ok": False, "error": "project_mismatch"}), 400

    start_date_filter = parse_iso_date(start_date)
    end_date_filter = parse_iso_date(end_date)

    session_rows = build_session_rows(
        db,
        start_date=start_date_filter,
        end_date=end_date_filter,
    )

    export_data = []
    for session_row in session_rows:
        start_dt = datetime.fromtimestamp(session_row["start_ts"] / 1000, tz=timezone.utc)
        end_dt = datetime.fromtimestamp(session_row["end_ts"] / 1000, tz=timezone.utc)
        status_label = "Completato" if session_row["status"] == "completed" else "In corso"
        export_data.append(
            {
                "operatore": session_row["member_name"],
                "attivita": session_row["activity_label"],
                "data_inizio": start_dt.strftime("%d/%m/%Y"),
                "ora_inizio": start_dt.strftime("%H:%M:%S"),
                "data_fine": end_dt.strftime("%d/%m/%Y") if session_row["status"] == "completed" else "In corso",
                "ora_fine": end_dt.strftime("%H:%M:%S") if session_row["status"] == "completed" else "-",
                "durata_netta": format_duration_ms(session_row["net_ms"]) or "00:00:00",
                "tempo_pausa": format_duration_ms(session_row["pause_ms"]) or "00:00:00",
                "num_pause": str(session_row["pause_count"]),
                "stato": status_label,
            }
        )
    
    app.logger.info("Export: generati %s record per l'export", len(export_data))

    # Genera file in base al formato
    if export_format == "csv":
        return generate_csv_export(export_data, project_code, project_name)
    else:
        return generate_excel_export(export_data, project_code, project_name)


def generate_excel_export(data: List[Dict[str, Any]], project_code: str, project_name: str):
    """Genera un file Excel con template professionale."""
    wb = Workbook()
    ws_raw = wb.active
    if ws_raw is None:  # pragma: no cover - openpyxl should always provide an active sheet
        ws_raw = wb.create_sheet(title="Report Attività")
    ws: Worksheet = cast(Worksheet, ws_raw)
    ws.title = "Report Attività"

    # Stili
    header_font = Font(name="Calibri", size=14, bold=True, color="FFFFFF")
    header_fill = PatternFill(start_color="0EA5E9", end_color="0EA5E9", fill_type="solid")
    header_alignment = Alignment(horizontal="center", vertical="center")
    
    title_font = Font(name="Calibri", size=18, bold=True, color="1E293B")
    title_alignment = Alignment(horizontal="left", vertical="center")
    
    cell_font = Font(name="Calibri", size=11)
    cell_alignment = Alignment(horizontal="left", vertical="center")
    
    border_thin = Border(
        left=Side(style="thin", color="CBD5E1"),
        right=Side(style="thin", color="CBD5E1"),
        top=Side(style="thin", color="CBD5E1"),
        bottom=Side(style="thin", color="CBD5E1"),
    )

    # Titolo report
    ws["A1"] = f"🔷 JobLOG - Report Attività"
    ws.merge_cells("A1:J1")
    title_cell = ws["A1"]
    title_cell.font = title_font
    title_cell.alignment = title_alignment
    
    # Info progetto
    ws["A2"] = f"Progetto: {project_code} - {project_name or project_code}"
    ws.merge_cells("A2:J2")
    project_cell = ws["A2"]
    project_cell.font = Font(name="Calibri", size=12, color="64748B")
    project_cell.alignment = Alignment(horizontal="left", vertical="center")
    
    # Data generazione
    now = datetime.now()
    ws["A3"] = f"Generato il: {now.strftime('%d/%m/%Y alle %H:%M')}"
    ws.merge_cells("A3:J3")
    date_cell = ws["A3"]
    date_cell.font = Font(name="Calibri", size=10, color="94A3B8")
    date_cell.alignment = Alignment(horizontal="left", vertical="center")

    # Riga vuota
    ws.append([])

    # Header colonne
    headers = ["Operatore", "Attività", "Data Inizio", "Ora Inizio", "Data Fine", "Ora Fine", "Durata Netta", "Tempo Pausa", "N° Pause", "Stato"]
    ws.append(headers)
    
    header_row = ws.max_row
    for col_num, header in enumerate(headers, start=1):
        cell = ws.cell(row=header_row, column=col_num)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = border_thin

    # Dati
    for row_data in data:
        ws.append([
            row_data["operatore"],
            row_data["attivita"],
            row_data["data_inizio"],
            row_data["ora_inizio"],
            row_data["data_fine"],
            row_data["ora_fine"],
            row_data["durata_netta"],
            row_data["tempo_pausa"],
            row_data["num_pause"],
            row_data["stato"],
        ])
        
        row_num = ws.max_row
        for col_num in range(1, 11):
            cell = ws.cell(row=row_num, column=col_num)
            cell.font = cell_font
            cell.alignment = cell_alignment
            cell.border = border_thin
            
            # Alternating row colors
            if row_num % 2 == 0:
                cell.fill = PatternFill(start_color="F8FAFC", end_color="F8FAFC", fill_type="solid")

    # Totale sessioni
    total_row = ws.max_row + 2
    total_cell_ref = f"A{total_row}"
    ws[total_cell_ref] = f"Totale Sessioni: {len(data)}"
    ws.merge_cells(f"A{total_row}:I{total_row}")
    total_cell = ws[total_cell_ref]
    total_cell.font = Font(name="Calibri", size=12, bold=True, color="1E293B")
    total_cell.alignment = Alignment(horizontal="right", vertical="center")

    # Auto-fit colonne
    column_widths = {
        "A": 20,  # Operatore
        "B": 30,  # Attività
        "C": 12,  # Data Inizio
        "D": 11,  # Ora Inizio
        "E": 12,  # Data Fine
        "F": 11,  # Ora Fine
        "G": 14,  # Durata Netta
        "H": 13,  # Tempo Pausa
        "I": 10,  # N° Pause
        "J": 12,  # Stato
    }
    
    for col_letter, width in column_widths.items():
        ws.column_dimensions[col_letter].width = width

    # Salva in memoria
    output = io.BytesIO()
    wb.save(output)
    output.seek(0)

    filename = f"joblog_report_{project_code}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    return send_file(
        output,
        mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        as_attachment=True,
        download_name=filename,
    )


def generate_csv_export(data: List[Dict[str, Any]], project_code: str, project_name: str):
    """Genera un file CSV con encoding UTF-8 BOM."""
    output = io.StringIO()
    
    # UTF-8 BOM per compatibilità Excel
    output.write("\ufeff")
    
    writer = csv.writer(output, delimiter=";", quoting=csv.QUOTE_MINIMAL)
    
    # Header informativo
    writer.writerow([f"JobLOG - Report Attività"])
    writer.writerow([f"Progetto: {project_code} - {project_name or project_code}"])
    writer.writerow([f"Generato il: {datetime.now().strftime('%d/%m/%Y alle %H:%M')}"])
    writer.writerow([])  # Riga vuota
    
    # Header colonne
    writer.writerow(["Operatore", "Attività", "Data Inizio", "Ora Inizio", "Data Fine", "Ora Fine", "Durata Netta", "Tempo Pausa", "N° Pause", "Stato"])
    
    # Dati
    for row in data:
        writer.writerow([
            row["operatore"],
            row["attivita"],
            row["data_inizio"],
            row["ora_inizio"],
            row["data_fine"],
            row["ora_fine"],
            row["durata_netta"],
            row["tempo_pausa"],
            row["num_pause"],
            row["stato"],
        ])
    
    # Totale
    writer.writerow([])
    writer.writerow(["", "", "", "", "", "", "", "", f"Totale Sessioni: {len(data)}", ""])

    # Prepara per download
    output.seek(0)
    bytes_output = io.BytesIO(output.getvalue().encode("utf-8"))
    bytes_output.seek(0)

    filename = f"joblog_report_{project_code}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    
    return send_file(
        bytes_output,
        mimetype="text/csv",
        as_attachment=True,
        download_name=filename,
    )


@app.get("/admin")
@app.get("/admin/dashboard")
@login_required
def admin_dashboard_page() -> ResponseReturnValue:
    if not is_admin_or_supervisor():
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    return render_template(
        "admin_dashboard.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=bool(session.get("is_admin")),
    )


@app.get("/admin/sessions")
@login_required
def admin_sessions_page() -> ResponseReturnValue:
    if not is_admin_or_supervisor():
        abort(403)

    display_name = session.get('user_display') or session.get('user_name') or session.get('user')
    primary_name = session.get('user_name') or display_name or session.get('user')
    initials = session.get('user_initials') or compute_initials(primary_name or "")

    return render_template(
        "admin_sessions.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=bool(session.get("is_admin")),
    )


@app.get("/admin/presenze")
@login_required
def admin_presenze_page() -> ResponseReturnValue:
    """Pagina foglio presenze mensile."""
    if not is_admin_or_supervisor():
        abort(403)

    return render_template("admin_presenze.html")


@app.get("/api/admin/presenze/monthly")
@login_required
def api_admin_presenze_monthly() -> ResponseReturnValue:
    """API per ottenere i dati presenze mensili di tutti i dipendenti."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    month = _coerce_int(request.args.get("month")) or datetime.now().month
    year = _coerce_int(request.args.get("year")) or datetime.now().year
    employee_filter = request.args.get("employee") or None

    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Ottieni lista dipendenti
    if employee_filter:
        users_rows = db.execute(
            f"SELECT username, display_name, crew_id FROM users WHERE username = {placeholder}",
            (employee_filter,)
        ).fetchall()
    else:
        users_rows = db.execute(
            "SELECT username, display_name, crew_id FROM users WHERE role != 'admin' ORDER BY display_name, username"
        ).fetchall()

    # Calcola range date del mese
    first_day = datetime(year, month, 1)
    if month == 12:
        last_day = datetime(year + 1, 1, 1) - timedelta(days=1)
    else:
        last_day = datetime(year, month + 1, 1) - timedelta(days=1)
    
    start_ms = int(first_day.timestamp() * 1000)
    end_ms = int((last_day + timedelta(days=1)).timestamp() * 1000)
    start_date_str = first_day.strftime("%Y-%m-%d")
    end_date_str = last_day.strftime("%Y-%m-%d")

    employees_data = []

    for user_row in users_rows:
        username = user_row["username"]
        display_name = user_row["display_name"] or username
        crew_id = user_row["crew_id"]

        # Dizionario per i giorni del mese
        days_data = {}

        # 1. Carica sessioni squadra (da build_session_rows o event_log)
        try:
            team_sessions = db.execute(
                f"""
                SELECT DATE(FROM_UNIXTIME(start_ts/1000)) as work_date, 
                       SUM(net_ms) as total_ms
                FROM (
                    SELECT el.start_ts, 
                           COALESCE(el.elapsed, 0) as net_ms
                    FROM event_log el
                    WHERE el.kind = 'stop_member' 
                      AND el.member_key = {placeholder}
                      AND el.start_ts >= {placeholder} 
                      AND el.start_ts < {placeholder}
                ) sub
                GROUP BY work_date
                """,
                (username, start_ms, end_ms)
            ).fetchall()
        except Exception:
            team_sessions = []

        for sess in team_sessions:
            if sess["work_date"]:
                date_key = sess["work_date"].strftime("%Y-%m-%d") if hasattr(sess["work_date"], "strftime") else str(sess["work_date"])
                minutes = int((sess["total_ms"] or 0) / 60000)
                if minutes > 0:
                    days_data[date_key] = {"type": "worked", "minutes": minutes}

        # 2. Carica sessioni magazzino
        try:
            wh_sessions = db.execute(
                f"""
                SELECT DATE(FROM_UNIXTIME(created_ts/1000)) as work_date,
                       SUM(elapsed_ms) as total_ms
                FROM warehouse_sessions
                WHERE username = {placeholder}
                  AND created_ts >= {placeholder}
                  AND created_ts < {placeholder}
                GROUP BY work_date
                """,
                (username, start_ms, end_ms)
            ).fetchall()
        except Exception:
            wh_sessions = []

        for sess in wh_sessions:
            if sess["work_date"]:
                date_key = sess["work_date"].strftime("%Y-%m-%d") if hasattr(sess["work_date"], "strftime") else str(sess["work_date"])
                minutes = int((sess["total_ms"] or 0) / 60000)
                if date_key in days_data:
                    days_data[date_key]["minutes"] = days_data[date_key].get("minutes", 0) + minutes
                elif minutes > 0:
                    days_data[date_key] = {"type": "worked", "minutes": minutes}

        # 3. Carica richieste approvate (ferie, permessi, malattia)
        try:
            requests = db.execute(
                f"""
                SELECT ur.start_date, ur.end_date, ur.hours, rt.name as request_type, rt.abbreviation
                FROM user_requests ur
                JOIN request_types rt ON ur.request_type_id = rt.id
                WHERE ur.username = {placeholder}
                  AND ur.status = 'approved'
                  AND ur.start_date <= {placeholder}
                  AND ur.end_date >= {placeholder}
                """,
                (username, end_date_str, start_date_str)
            ).fetchall()
        except Exception:
            requests = []

        for req in requests:
            req_type = (req["request_type"] or "").lower()
            abbrev = req["abbreviation"] or ""
            
            # Determina tipo
            if "feri" in req_type:
                day_type = "ferie"
            elif "permess" in req_type or "rol" in req_type.lower():
                day_type = "permesso"
            elif "malatt" in req_type:
                day_type = "malattia"
            else:
                day_type = "permesso"  # Default

            # Itera sui giorni della richiesta
            start_d = req["start_date"]
            end_d = req["end_date"]
            if isinstance(start_d, str):
                start_d = datetime.strptime(start_d, "%Y-%m-%d").date()
            if isinstance(end_d, str):
                end_d = datetime.strptime(end_d, "%Y-%m-%d").date()
            
            current = start_d
            while current <= end_d:
                if current.month == month and current.year == year:
                    date_key = current.strftime("%Y-%m-%d")
                    # Se c'è anche lavoro, aggiungi ore permesso parziale
                    if date_key not in days_data or days_data[date_key].get("type") != "worked":
                        days_data[date_key] = {"type": day_type}
                        if req["hours"] and req["hours"] < 8:
                            # Permesso parziale
                            days_data[date_key]["minutes"] = int(req["hours"] * 60)
                current += timedelta(days=1)

        # 4. Carica ore da pianificazioni Rentman (se crew_id)
        if crew_id:
            try:
                plannings = db.execute(
                    f"""
                    SELECT planning_date, SUM(hours_planned) as total_hours
                    FROM rentman_plannings
                    WHERE crew_id = {placeholder}
                      AND planning_date >= {placeholder}
                      AND planning_date <= {placeholder}
                      AND is_obsolete = 0
                    GROUP BY planning_date
                    """,
                    (crew_id, start_date_str, end_date_str)
                ).fetchall()
            except Exception:
                plannings = []

            for plan in plannings:
                if plan["planning_date"]:
                    date_key = plan["planning_date"].strftime("%Y-%m-%d") if hasattr(plan["planning_date"], "strftime") else str(plan["planning_date"])
                    hours = float(plan["total_hours"] or 0)
                    if hours > 0 and date_key not in days_data:
                        days_data[date_key] = {"type": "worked", "minutes": int(hours * 60)}

        # Trova matricola (se disponibile)
        matricola = None
        try:
            mat_row = db.execute(
                f"SELECT crew_id FROM users WHERE username = {placeholder}",
                (username,)
            ).fetchone()
            if mat_row and mat_row["crew_id"]:
                matricola = mat_row["crew_id"]
        except Exception:
            pass

        employees_data.append({
            "username": username,
            "display_name": display_name,
            "matricola": matricola,
            "days": days_data
        })

    return jsonify({
        "ok": True,
        "month": month,
        "year": year,
        "employees": employees_data
    })


@app.get("/api/admin/employees")
@login_required
def api_admin_employees_list() -> ResponseReturnValue:
    """Lista dipendenti per filtri."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    rows = db.execute(
        "SELECT username, display_name, role, crew_id FROM users WHERE role != 'admin' ORDER BY display_name, username"
    ).fetchall()

    employees = []
    for row in rows:
        employees.append({
            "username": row["username"],
            "display_name": row["display_name"] or row["username"],
            "role": row["role"],
            "matricola": row["crew_id"]
        })

    return jsonify({"ok": True, "employees": employees})


# ═══════════════════════════════════════════════════════════════════
# DEBUG: SIMULATED DATE API
# ═══════════════════════════════════════════════════════════════════

@app.route("/api/admin/simulated-date", methods=["GET", "POST", "DELETE"], endpoint="api_admin_simulated_date")
@login_required
def api_admin_simulated_date() -> ResponseReturnValue:
    """
    GET: Mostra la data simulata attuale
    POST: Imposta una data simulata (es: {"date": "2026-01-10"})
    DELETE: Rimuove la data simulata (usa data reale)
    """
    global SIMULATED_DATE
    
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403
    
    if request.method == "GET":
        return jsonify({
            "simulated_date": SIMULATED_DATE,
            "real_date": datetime.now().strftime("%Y-%m-%d"),
            "effective_date": get_simulated_today().strftime("%Y-%m-%d")
        })
    
    if request.method == "DELETE":
        old_date = SIMULATED_DATE
        SIMULATED_DATE = None
        app.logger.info(f"Data simulata rimossa (era: {old_date})")
        return jsonify({
            "success": True,
            "message": "Data simulata rimossa, usando data reale",
            "effective_date": get_simulated_today().strftime("%Y-%m-%d")
        })
    
    # POST: imposta nuova data simulata
    data = request.get_json() or {}
    new_date = data.get("date")
    
    if not new_date:
        return jsonify({"error": "Specifica 'date' nel formato YYYY-MM-DD"}), 400
    
    try:
        # Valida il formato
        datetime.strptime(new_date, "%Y-%m-%d")
        SIMULATED_DATE = new_date
        app.logger.info(f"Data simulata impostata a: {SIMULATED_DATE}")
        return jsonify({
            "success": True,
            "message": f"Data simulata impostata a {new_date}",
            "simulated_date": SIMULATED_DATE,
            "effective_date": get_simulated_today().strftime("%Y-%m-%d")
        })
    except ValueError:
        return jsonify({"error": "Formato data non valido, usa YYYY-MM-DD"}), 400


@app.get("/api/admin/open-sessions")
@login_required
def api_admin_open_sessions() -> ResponseReturnValue:
    """Restituisce le sessioni aperte (timer in corso) per tutti i progetti."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now = int(datetime.now(tz=timezone.utc).timestamp() * 1000)

    # Ottieni tutti i membri con sessioni attive (running o in pausa con attività)
    rows = db.execute(
        f"""
        SELECT ms.member_key, ms.member_name, ms.activity_id, ms.running, 
               ms.start_ts, ms.elapsed_cached, ms.pause_start, ms.entered_ts,
               ms.project_code, ms.current_phase,
               a.label AS activity_label,
               a.notes AS activity_notes
        FROM member_state ms
        LEFT JOIN activities a ON ms.activity_id = a.activity_id AND ms.project_code = a.project_code
        WHERE ms.activity_id IS NOT NULL
        ORDER BY ms.project_code, ms.member_name
        """
    ).fetchall()

    # Conta le pause per ogni membro/attività dal log
    pause_counts: Dict[str, int] = {}
    pause_rows = db.execute(
        """
        SELECT member_key, COUNT(*) as pause_count
        FROM event_log
        WHERE kind = 'pause_member'
        GROUP BY member_key
        """
    ).fetchall()
    for pr in pause_rows:
        pause_counts[pr["member_key"]] = pr["pause_count"]

    # ── Carica configurazione fasi e progresso per arricchire l'attività ──
    function_phases_config = get_function_phases_config(db)
    phase_progress_by_fn: Dict[str, Dict[str, bool]] = {}  # { function_key: { phase_name: completed } }
    if function_phases_config:
        today_str = datetime.now().strftime("%Y-%m-%d")
        ensure_project_phase_progress_table(db)
        # Raccogliamo per tutti i project_code attivi
        project_codes = list({r["project_code"] for r in rows if r["project_code"]})
        for pc in project_codes:
            pp_rows = db.execute(
                f"""SELECT function_key, phase_name, completed FROM project_phase_progress
                    WHERE project_date = {placeholder} AND project_key = {placeholder}""",
                (today_str, pc)
            ).fetchall()
            for ppr in pp_rows:
                fk = ppr["function_key"]
                pn = ppr["phase_name"]
                comp = bool(ppr["completed"])
                if fk not in phase_progress_by_fn:
                    phase_progress_by_fn[fk] = {}
                phase_progress_by_fn[fk][pn] = comp

    def _resolve_current_phase(activity_label_raw: str) -> str | None:
        """Dato un activity_label come 'Montaggio [ID 18422]', restituisce la fase corrente (prima non completata)."""
        if not activity_label_raw or not function_phases_config:
            return None
        import re as _re
        func_name = _re.sub(r'\s*\[ID\s+\d+\]$', '', activity_label_raw, flags=_re.IGNORECASE).strip()
        if not func_name:
            return None
        fn_lower = func_name.lower()
        for key, template in function_phases_config.items():
            if key.lower().strip() == fn_lower:
                phases = sorted(template.get('phases', []), key=lambda x: x.get('order', 0))
                progress = phase_progress_by_fn.get(key, {})
                for ph in phases:
                    if not progress.get(ph.get('name', ''), False):
                        return ph.get('name', '')
                # Tutte completate
                if phases:
                    return "✅ Completato"
                return None
        return None

    open_sessions = []
    for row in rows:
        running_state = int(row["running"])
        real_start_ts = row["start_ts"]
        elapsed_cached = row["elapsed_cached"] or 0
        pause_start = row["pause_start"]

        # ── Skip operatori solo assegnati ma non avviati ──
        # running=0 (RUN_STATE_PAUSED=0) con start_ts=NULL e elapsed=0
        # significa che sono stati assegnati dal supervisor ma non hanno
        # ancora avviato il timer → non mostrare in "Sessioni Aperte"
        # PERÒ: se ci sono fasi completate per la funzione dell'operatore,
        # significa che ha realmente lavorato (anche se project_load ha resettato)
        if (running_state != RUN_STATE_RUNNING
                and real_start_ts is None
                and elapsed_cached == 0
                and pause_start is None):
            # Controlla se la funzione associata ha fasi completate
            has_phase_progress = False
            act_label_raw = row["activity_label"] or ""
            if act_label_raw and function_phases_config:
                import re as _re_skip
                _fn = _re_skip.sub(r'\s*\[ID\s+\d+\]$', '', act_label_raw, flags=_re_skip.IGNORECASE).strip()
                if _fn:
                    for _fk in function_phases_config:
                        if _fk.lower().strip() == _fn.lower():
                            fn_prog = phase_progress_by_fn.get(_fk, {})
                            has_phase_progress = any(fn_prog.values())
                            break
            if not has_phase_progress:
                continue

        elapsed = compute_elapsed(row, now)
        start_ts = real_start_ts or row["entered_ts"] or now
        member_key = row["member_key"]

        raw_label = row["activity_label"] or row["activity_id"]
        # Usa la fase individuale dall'operatore (current_phase in member_state)
        member_phase = row.get("current_phase") if isinstance(row, dict) else None
        if member_phase:
            display_label = f"{raw_label} — 📍 {member_phase}"
        else:
            display_label = raw_label

        # Distingui "in pausa" reale da "non ancora avviato"
        is_paused = (running_state == RUN_STATE_PAUSED
                     and (pause_start is not None or elapsed_cached > 0))

        open_sessions.append({
            "source": "team",
            "member_key": member_key,
            "member_name": row["member_name"],
            "activity_id": row["activity_id"],
            "activity_label": display_label,
            "project_code": row["project_code"],
            "running": running_state == RUN_STATE_RUNNING,
            "paused": is_paused,
            "start_ts": start_ts,
            "elapsed_ms": elapsed,
            "pause_count": pause_counts.get(member_key, 0),
            "notes": row["activity_notes"] or "",
        })

    # Aggiungi timer attivi della produzione
    ensure_warehouse_active_timers_table(db)
    wh_rows = db.execute(
        """
        SELECT username, project_code, project_name, activity_label, notes,
               running, paused, start_ts, elapsed_ms, pause_start_ts, updated_ts
        FROM warehouse_active_timers
        ORDER BY updated_ts DESC
        """
    ).fetchall()
    
    for wh in wh_rows:
        wh_elapsed = wh["elapsed_ms"] or 0
        # Se il timer è running e non in pausa, calcola il tempo aggiuntivo
        if wh["running"] and not wh["paused"] and wh["updated_ts"]:
            wh_elapsed += (now - wh["updated_ts"])
        # Se è in pausa, il tempo è già stato salvato in elapsed_ms
        
        open_sessions.append({
            "source": "magazzino",
            "member_key": f"wh_{wh['username']}",
            "member_name": wh["username"],
            "activity_id": wh["activity_label"],
            "activity_label": f"{wh['activity_label']} (Produzione)",
            "project_code": wh["project_code"],
            "project_name": wh["project_name"],
            "running": bool(wh["running"]) and not bool(wh["paused"]),
            "paused": bool(wh["paused"]),
            "start_ts": wh["start_ts"],
            "elapsed_ms": wh_elapsed,
            "pause_count": 0,
            "notes": wh["notes"] or "",
        })

    return jsonify({
        "ok": True,
        "open_sessions": open_sessions,
        "count": len(open_sessions),
    })


@app.route("/api/admin/day-sessions", methods=["GET"], endpoint="api_admin_day_sessions")
@login_required
def api_admin_day_sessions() -> ResponseReturnValue:
    """Restituisce sessioni di squadra e magazzino per il range di date indicato."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    # Supporto range date: date_start/date_end oppure date singola (retrocompatibilità)
    date_start = parse_iso_date(request.args.get("date_start")) or parse_iso_date(request.args.get("date")) or datetime.now().date()
    date_end = parse_iso_date(request.args.get("date_end")) or date_start
    project_filter = request.args.get("project") or None
    
    # Assicura che date_end >= date_start
    if date_end < date_start:
        date_start, date_end = date_end, date_start

    start_dt = datetime.combine(date_start, datetime.min.time())
    end_dt = datetime.combine(date_end, datetime.min.time()) + timedelta(days=1)
    start_ms = int(start_dt.timestamp() * 1000)
    end_ms = int(end_dt.timestamp() * 1000)

    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    team_sessions = build_session_rows(
        db,
        start_date=date_start,
        end_date=date_end,
        project_filter=project_filter,
    )

    # ── Spezza le sessioni di squadra in sotto-righe per fase (con inizio/fine per fase) ──
    _fn_phases_cfg = get_function_phases_config(db)
    if _fn_phases_cfg and team_sessions:
        import re as _re_ds
        ensure_project_phase_progress_table(db)
        _pc_set = {s["project_code"] for s in team_sessions if s.get("project_code")}

        # Struttura: { "date|pc": { fn_key: [ {name, order, completed, completed_at} ] } }
        _pp_by_date_fn: Dict[str, Dict[str, list]] = {}
        _cur = date_start
        while _cur <= date_end:
            _d_str = _cur.isoformat()
            for _pc in _pc_set:
                _ppkey = f"{_d_str}|{_pc}"
                _pp_rows = db.execute(
                    f"""SELECT function_key, phase_name, phase_order, completed, completed_at
                        FROM project_phase_progress
                        WHERE project_date = {placeholder} AND project_key = {placeholder}
                        ORDER BY function_key, phase_order""",
                    (_d_str, _pc)
                ).fetchall()
                _pp_map: Dict[str, list] = {}
                for _ppr in _pp_rows:
                    _fk = _ppr["function_key"]
                    if _fk not in _pp_map:
                        _pp_map[_fk] = []
                    _pp_map[_fk].append({
                        "name": _ppr["phase_name"],
                        "order": _ppr["phase_order"],
                        "completed": bool(_ppr["completed"]),
                        "completed_at": _coerce_int(_ppr["completed_at"]),
                    })
                _pp_by_date_fn[_ppkey] = _pp_map
            _cur += timedelta(days=1)

        def _split_session_by_phases(sess: Dict[str, Any]) -> List[Dict[str, Any]]:
            """Se la sessione ha fasi configurate, la spezza in sotto-righe per fase."""
            raw_label = sess.get("activity_label") or sess.get("activity_id") or ""
            if not raw_label:
                return [sess]
            func_name = _re_ds.sub(r'\s*\[ID\s+\d+\]$', '', raw_label, flags=_re_ds.IGNORECASE).strip()
            if not func_name:
                return [sess]

            s_ts = sess.get("start_ts") or 0
            s_date_str = datetime.fromtimestamp(s_ts / 1000).strftime("%Y-%m-%d") if s_ts else date_start.isoformat()
            s_pc = sess.get("project_code") or ""
            ppkey = f"{s_date_str}|{s_pc}"
            fn_progress_map = _pp_by_date_fn.get(ppkey, {})

            # Trova la config fasi corrispondente
            matched_key = None
            fn_lower = func_name.lower()
            for key in _fn_phases_cfg:
                if key.lower().strip() == fn_lower:
                    matched_key = key
                    break
            if not matched_key:
                return [sess]

            phase_records = fn_progress_map.get(matched_key, [])
            if not phase_records:
                # Nessun progresso registrato: usa la config template per mostrare almeno la prima fase
                template = _fn_phases_cfg[matched_key]
                tpl_phases = sorted(template.get('phases', []), key=lambda x: x.get('order', 0))
                if not tpl_phases:
                    return [sess]
                # Nessuna fase completata — mostra la sessione intera con la prima fase corrente
                first_ph = tpl_phases[0].get('name', '')
                sess_copy = dict(sess)
                sess_copy["activity_label"] = f"{raw_label} — 📍 {first_ph}"
                return [sess_copy]

            # Ordina per order
            phase_records.sort(key=lambda x: x["order"])

            sess_start = sess.get("start_ts") or 0
            sess_end = sess.get("end_ts") or 0
            sess_status = sess.get("status") or "completed"

            sub_rows: List[Dict[str, Any]] = []
            phase_start = sess_start

            for i, ph in enumerate(phase_records):
                ph_name = ph["name"]
                ph_completed = ph["completed"]
                ph_completed_at = ph["completed_at"]

                if ph_completed and ph_completed_at:
                    # Fase completata: inizio = phase_start, fine = completed_at
                    phase_end = ph_completed_at
                    phase_net_ms = max(0, phase_end - phase_start)
                    sub_rows.append(_make_phase_row(
                        sess, raw_label, ph_name, phase_start, phase_end,
                        phase_net_ms, status="completed", icon="✅"
                    ))
                    phase_start = phase_end  # La prossima fase inizia dove finisce questa
                elif not ph_completed:
                    # Fase corrente (non completata): da phase_start a session_end
                    phase_end = sess_end
                    phase_net_ms = max(0, phase_end - phase_start)
                    sub_rows.append(_make_phase_row(
                        sess, raw_label, ph_name, phase_start, phase_end,
                        phase_net_ms, status=sess_status, icon="📍"
                    ))
                    break  # Le fasi successive non sono ancora iniziate

            return sub_rows if sub_rows else [sess]

        def _make_phase_row(
            base: Dict[str, Any], raw_label: str, phase_name: str,
            start_ts: int, end_ts: int, net_ms: int,
            status: str = "completed", icon: str = "✅"
        ) -> Dict[str, Any]:
            """Crea una sotto-riga sessione per una singola fase."""
            row = dict(base)
            row["activity_label"] = f"{raw_label} — {icon} {phase_name}"
            row["start_ts"] = start_ts
            row["end_ts"] = end_ts
            row["net_ms"] = net_ms
            row["pause_ms"] = 0
            row["pause_count"] = 0
            row["status"] = status
            return row

        # Ricostruisci la lista di sessioni espandendo le fasi
        expanded: List[Dict[str, Any]] = []
        for _sess in team_sessions:
            expanded.extend(_split_session_by_phases(_sess))
        team_sessions = expanded

    ensure_warehouse_sessions_table(db)
    
    # Query magazzino con filtro progetto opzionale
    if project_filter:
        wh_rows = db.execute(
            f"""
            SELECT project_code, activity_label, elapsed_ms, username, created_ts, note, start_ts, end_ts
            FROM warehouse_sessions
            WHERE created_ts >= {placeholder} AND created_ts < {placeholder} AND project_code = {placeholder}
            ORDER BY created_ts DESC
            LIMIT 500
            """,
            (start_ms, end_ms, project_filter),
        ).fetchall()
    else:
        wh_rows = db.execute(
            f"""
            SELECT project_code, activity_label, elapsed_ms, username, created_ts, note, start_ts, end_ts
            FROM warehouse_sessions
            WHERE created_ts >= {placeholder} AND created_ts < {placeholder}
            ORDER BY created_ts DESC
            LIMIT 500
            """,
            (start_ms, end_ms),
        ).fetchall()

    magazzino_sessions = [
        {
            "project_code": row["project_code"],
            "activity_label": row["activity_label"],
            "elapsed_ms": _coerce_int(row["elapsed_ms"]) or 0,
            "username": row["username"],
            "created_ts": _coerce_int(row["created_ts"]) or 0,
            "note": row["note"] or "",
            "start_ts": _coerce_int(row["start_ts"]) if row["start_ts"] else None,
            "end_ts": _coerce_int(row["end_ts"]) if row["end_ts"] else None,
        }
        for row in wh_rows or []
    ]

    # Calcola totali
    team_total_ms = sum(_coerce_int(s.get("net_ms")) or 0 for s in team_sessions)
    magazzino_total_ms = sum(_coerce_int(s.get("elapsed_ms")) or 0 for s in magazzino_sessions)
    combined_total_ms = team_total_ms + magazzino_total_ms

    # Calcola ore pianificate per il progetto da Rentman (filtrate per data)
    planned_total_ms = 0
    activity_breakdown = []
    if project_filter:
        # Recupera ore pianificate da rentman_plannings per la data selezionata
        planned_rows = db.execute(
            f"SELECT SUM(hours_planned) as total_hours FROM rentman_plannings WHERE project_code = {placeholder} AND planning_date = {placeholder} AND is_obsolete = 0",
            (project_filter, date_start.isoformat())
        ).fetchone()
        if planned_rows and planned_rows["total_hours"]:
            # Converti ore in millisecondi
            planned_total_ms = int(float(planned_rows["total_hours"]) * 3600000)
        
        # Calcola distribuzione ore per attività (squadra + magazzino)
        activity_hours: Dict[str, int] = {}
        
        # Aggiungi ore squadra
        for s in team_sessions:
            if s.get("status") == "completed":
                act_label = s.get("activity_label") or s.get("activity_id") or "Altro"
                activity_hours[act_label] = activity_hours.get(act_label, 0) + (_coerce_int(s.get("net_ms")) or 0)
        
        # Aggiungi ore produzione
        for s in magazzino_sessions:
            act_label = s.get("activity_label") or "Produzione"
            activity_hours[act_label] = activity_hours.get(act_label, 0) + (_coerce_int(s.get("elapsed_ms")) or 0)
        
        # Converti in lista per il frontend (usa combined_total_ms per percentuali)
        for label, ms in sorted(activity_hours.items(), key=lambda x: -x[1]):
            activity_breakdown.append({
                "label": label,
                "ms": ms,
                "percent": round((ms / combined_total_ms * 100) if combined_total_ms > 0 else 0, 1)
            })

    return jsonify(
        {
            "ok": True,
            "date": date_start.isoformat() if date_start == date_end else f"{date_start.isoformat()} - {date_end.isoformat()}",
            "project_filter": project_filter,
            "team_sessions": team_sessions,
            "magazzino_sessions": magazzino_sessions,
            "team_total_ms": team_total_ms,
            "magazzino_total_ms": magazzino_total_ms,
            "combined_total_ms": combined_total_ms,
            "planned_total_ms": planned_total_ms,
            "activity_breakdown": activity_breakdown,
        }
    )


@app.get("/api/admin/projects-list")
@login_required
def api_admin_projects_list() -> ResponseReturnValue:
    """Restituisce la lista dei progetti con sessioni recenti."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Ottieni progetti da event_log (ultimi 30 giorni)
    thirty_days_ago = int((datetime.now() - timedelta(days=30)).timestamp() * 1000)
    
    projects_set = set()
    
    # Da event_log
    rows = db.execute(
        f"SELECT DISTINCT JSON_EXTRACT(details, '$.project_code') as project_code FROM event_log WHERE ts > {placeholder} AND details IS NOT NULL",
        (thirty_days_ago,)
    ).fetchall()
    for row in rows:
        pc = row["project_code"]
        if pc and pc != "null" and pc.strip('"'):
            projects_set.add(pc.strip('"'))
    
    # Da warehouse_sessions
    wh_rows = db.execute(
        f"SELECT DISTINCT project_code FROM warehouse_sessions WHERE created_ts > {placeholder}",
        (thirty_days_ago,)
    ).fetchall()
    for row in wh_rows:
        if row["project_code"]:
            projects_set.add(row["project_code"])
    
    # Da activities
    act_rows = db.execute("SELECT DISTINCT project_code FROM activities").fetchall()
    for row in act_rows:
        if row["project_code"]:
            projects_set.add(row["project_code"])
    
    projects = sorted([p for p in projects_set if p])
    
    return jsonify({
        "ok": True,
        "projects": projects,
    })


@app.route(
    "/api/admin/day-sessions/export.xlsx",
    methods=["GET"],
    endpoint="api_admin_day_sessions_export_xlsx",
)
@login_required
def api_admin_day_sessions_export_xlsx() -> ResponseReturnValue:
    """Esporta in Excel le sessioni (Squadra + Magazzino) per il range di date indicato."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    # Supporto range date: date_start/date_end oppure date singola (retrocompatibilità)
    date_start = parse_iso_date(request.args.get("date_start")) or parse_iso_date(request.args.get("date")) or datetime.now().date()
    date_end = parse_iso_date(request.args.get("date_end")) or date_start
    
    # Assicura che date_end >= date_start
    if date_end < date_start:
        date_start, date_end = date_end, date_start

    start_dt = datetime.combine(date_start, datetime.min.time())
    end_dt = datetime.combine(date_end, datetime.min.time()) + timedelta(days=1)
    start_ms = int(start_dt.timestamp() * 1000)
    end_ms = int(end_dt.timestamp() * 1000)

    db = get_db()

    team_sessions = build_session_rows(
        db,
        start_date=date_start,
        end_date=date_end,
    )

    ensure_warehouse_sessions_table(db)
    wh_rows = db.execute(
        """
        SELECT project_code, activity_label, elapsed_ms, username, created_ts
        FROM warehouse_sessions
        WHERE created_ts >= ? AND created_ts < ?
        ORDER BY created_ts DESC
        LIMIT 2000
        """,
        (start_ms, end_ms),
    ).fetchall()

    merged_rows: List[Dict[str, Any]] = []
    for s in team_sessions or []:
        # Estrai data dalla sessione (usa timezone locale)
        start_ts = s.get("start_ts") or s.get("end_ts")
        if start_ts:
            try:
                dt = datetime.fromtimestamp(start_ts / 1000)  # Timezone locale
                date_str = dt.strftime("%d/%m/%Y")
            except Exception:
                date_str = ""
        else:
            date_str = ""
        merged_rows.append(
            {
                "date": date_str,
                "source": "Squadra",
                "project_code": s.get("project_code") or "",
                "user": s.get("member_name") or s.get("member_key") or "",
                "activity": s.get("activity_label") or s.get("activity_id") or "",
                "duration_ms": _coerce_int(s.get("net_ms")) or 0,
                "sort_ts": start_ts or 0,
            }
        )

    for row in wh_rows or []:
        # Estrai data dalla sessione magazzino (usa timezone locale)
        created_ts = _coerce_int(row.get("created_ts")) or 0
        if created_ts:
            try:
                dt = datetime.fromtimestamp(created_ts / 1000)  # Timezone locale
                date_str = dt.strftime("%d/%m/%Y")
            except Exception:
                date_str = ""
        else:
            date_str = ""
        merged_rows.append(
            {
                "date": date_str,
                "source": "Magazzino",
                "project_code": row.get("project_code") or "",
                "user": row.get("username") or "",
                "activity": row.get("activity_label") or "",
                "duration_ms": _coerce_int(row.get("elapsed_ms")) or 0,
                "sort_ts": created_ts,
            }
        )
    
    # Ordina per data/timestamp (più recenti prima)
    merged_rows.sort(key=lambda x: x.get("sort_ts", 0), reverse=True)

    wb = Workbook()
    ws_raw = wb.active
    if ws_raw is None:  # pragma: no cover
        ws_raw = wb.create_sheet(title="Sessioni")
    ws: Worksheet = cast(Worksheet, ws_raw)
    ws.title = "Sessioni"

    title_font = Font(name="Calibri", size=16, bold=True, color="1E293B")
    subtitle_font = Font(name="Calibri", size=11, color="64748B")
    header_font = Font(name="Calibri", size=12, bold=True, color="FFFFFF")
    header_fill = PatternFill(start_color="0EA5E9", end_color="0EA5E9", fill_type="solid")
    header_alignment = Alignment(horizontal="center", vertical="center")
    cell_font = Font(name="Calibri", size=11)
    cell_alignment = Alignment(horizontal="left", vertical="center")
    border_thin = Border(
        left=Side(style="thin", color="CBD5E1"),
        right=Side(style="thin", color="CBD5E1"),
        top=Side(style="thin", color="CBD5E1"),
        bottom=Side(style="thin", color="CBD5E1"),
    )

    ws["A1"] = "JobLog - Export sessioni"
    ws.merge_cells("A1:F1")
    ws["A1"].font = title_font
    ws["A1"].alignment = Alignment(horizontal="left", vertical="center")

    ws["A2"] = f"Data: {date_start.strftime('%d/%m/%Y')}" if date_start == date_end else f"Periodo: {date_start.strftime('%d/%m/%Y')} - {date_end.strftime('%d/%m/%Y')}"
    ws.merge_cells("A2:F2")
    ws["A2"].font = subtitle_font
    ws["A2"].alignment = Alignment(horizontal="left", vertical="center")

    ws.append([])

    headers = ["Data", "Fonte", "Progetto", "Utente", "Attività", "Ore"]
    ws.append(headers)
    header_row = ws.max_row
    for col_num, header in enumerate(headers, start=1):
        cell = ws.cell(row=header_row, column=col_num)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = border_thin

    for item in merged_rows:
        ws.append(
            [
                item["date"],
                item["source"],
                str(item["project_code"] or ""),
                str(item["user"] or ""),
                str(item["activity"] or ""),
                format_duration_ms(item["duration_ms"]) or "00:00:00",
            ]
        )
        row_num = ws.max_row
        for col_num in range(1, 7):
            cell = ws.cell(row=row_num, column=col_num)
            cell.font = cell_font
            cell.alignment = cell_alignment
            cell.border = border_thin
            if row_num % 2 == 0:
                cell.fill = PatternFill(start_color="F8FAFC", end_color="F8FAFC", fill_type="solid")

    ws.column_dimensions[get_column_letter(1)].width = 12
    ws.column_dimensions[get_column_letter(2)].width = 12
    ws.column_dimensions[get_column_letter(3)].width = 14
    ws.column_dimensions[get_column_letter(4)].width = 22
    ws.column_dimensions[get_column_letter(5)].width = 42
    ws.column_dimensions[get_column_letter(6)].width = 12

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)

    filename = f"sessioni_{date_start.isoformat()}.xlsx" if date_start == date_end else f"sessioni_{date_start.isoformat()}_{date_end.isoformat()}.xlsx"
    return send_file(
        output,
        mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        as_attachment=True,
        download_name=filename,
    )


@app.get("/api/admin/sessions")
@login_required
def api_admin_sessions():
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    db = get_db()

    start_date = parse_iso_date(request.args.get("start_date", ""))
    end_date = parse_iso_date(request.args.get("end_date", ""))
    member_filter = request.args.get("member")
    activity_filter = request.args.get("activity_id")
    search_term = (request.args.get("search") or "").strip().lower()

    limit_param = request.args.get("limit")
    try:
        limit = int(limit_param) if limit_param else 200
    except (TypeError, ValueError):
        limit = 200
    limit = max(50, min(limit, 2000))

    # --- Sessioni squadra ---
    team_sessions = build_session_rows(
        db,
        start_date=start_date,
        end_date=end_date,
        member_filter=member_filter,
        activity_filter=activity_filter,
    )

    # --- Sessioni magazzino ---
    ensure_warehouse_sessions_table(db)
    wh_conditions: List[str] = []
    wh_params: List[Any] = []
    if start_date:
        start_dt = datetime.combine(start_date, datetime.min.time())
        wh_conditions.append("created_ts >= ?")
        wh_params.append(int(start_dt.timestamp() * 1000))
    if end_date:
        end_dt = datetime.combine(end_date, datetime.min.time()) + timedelta(days=1)
        wh_conditions.append("created_ts < ?")
        wh_params.append(int(end_dt.timestamp() * 1000))
    if member_filter:
        wh_conditions.append("username = ?")
        wh_params.append(member_filter)
    wh_where = (" WHERE " + " AND ".join(wh_conditions)) if wh_conditions else ""
    wh_rows = db.execute(
        f"""
        SELECT id, project_code, activity_label, elapsed_ms, username, created_ts
        FROM warehouse_sessions
        {wh_where}
        ORDER BY created_ts DESC
        LIMIT 1000
        """,
        tuple(wh_params),
    ).fetchall()

    # Unisci e filtra
    all_sessions: List[Dict[str, Any]] = []

    for item in team_sessions:
        all_sessions.append({**item, "_source": "Squadra", "_sort_ts": item.get("end_ts") or item.get("start_ts") or 0})

    for row in wh_rows or []:
        created_ts = _coerce_int(row["created_ts"]) or 0
        elapsed_ms = _coerce_int(row["elapsed_ms"]) or 0
        all_sessions.append({
            "_source": "Magazzino",
            "_sort_ts": created_ts,
            "member_key": row["username"] or "",
            "member_name": row["username"] or "",
            "activity_id": "",
            "activity_label": row["activity_label"] or "",
            "project_code": row["project_code"] or "",
            "start_ts": created_ts - elapsed_ms if elapsed_ms else created_ts,
            "end_ts": created_ts,
            "status": "completed",
            "net_ms": elapsed_ms,
            "pause_ms": 0,
            "pause_count": 0,
            "auto_closed": False,
            "override_id": None,
            "manual_entry": False,
            "note": "",
            "wh_id": row["id"],
        })

    # Filtra per search_term
    if search_term:
        filtered: List[Dict[str, Any]] = []
        for item in all_sessions:
            haystacks = [
                item.get("member_name", ""),
                item.get("member_key", ""),
                item.get("activity_label", ""),
                item.get("activity_id", ""),
                item.get("project_code", ""),
            ]
            if any(search_term in str(value).lower() for value in haystacks):
                filtered.append(item)
        all_sessions = filtered

    # Ordina per timestamp decrescente
    all_sessions.sort(key=lambda x: x.get("_sort_ts") or 0, reverse=True)
    all_sessions = all_sessions[:limit]

    payload = []
    for item in all_sessions:
        start_ts = item.get("start_ts") or 0
        end_ts = item.get("end_ts") or 0
        start_dt = datetime.fromtimestamp(start_ts / 1000, tz=timezone.utc) if start_ts else None
        end_dt = datetime.fromtimestamp(end_ts / 1000, tz=timezone.utc) if end_ts else None
        payload.append(
            {
                "source": item.get("_source", "Squadra"),
                "member_key": item.get("member_key", ""),
                "member_name": item.get("member_name", ""),
                "activity_id": item.get("activity_id", ""),
                "activity_label": item.get("activity_label", ""),
                "project_code": item.get("project_code", ""),
                "start_ts": start_ts,
                "end_ts": end_ts,
                "start_iso": start_dt.isoformat() if start_dt else "",
                "end_iso": end_dt.isoformat() if end_dt else "",
                "status": item.get("status", "completed"),
                "net_ms": item.get("net_ms", 0),
                "pause_ms": item.get("pause_ms", 0),
                "pause_count": item.get("pause_count", 0),
                "net_hms": format_duration_ms(item.get("net_ms")) or "00:00:00",
                "pause_hms": format_duration_ms(item.get("pause_ms")) or "00:00:00",
                "auto_closed": item.get("auto_closed", False),
                "override_id": item.get("override_id"),
                "manual_entry": bool(item.get("manual_entry")),
                "note": item.get("note") or "",
                "source_member_key": item.get("source_member_key"),
                "source_activity_id": item.get("source_activity_id"),
                "source_start_ts": item.get("source_start_ts"),
                "editable": item.get("_source") == "Squadra",
                "wh_id": item.get("wh_id"),
            }
        )

    return jsonify(
        {
            "sessions": payload,
            "count": len(payload),
            "limit": limit,
            "generated_at": now_ms(),
        }
    )


def _admin_or_supervisor() -> Optional[ResponseReturnValue]:
    """Guard per endpoint accessibili a admin e supervisor."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403
    return None


def _admin_only() -> Optional[ResponseReturnValue]:
    """Guard per endpoint accessibili solo ad admin."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403
    return None


def _json_error(message: str, status: int = 400) -> ResponseReturnValue:
    return jsonify({"error": message}), status


def _normalize_text(value: Any) -> str:
    return str(value or "").strip()


@app.post("/api/admin/sessions/save")
@login_required
def api_admin_sessions_save() -> ResponseReturnValue:
    guard = _admin_or_supervisor()
    if guard is not None:
        return guard

    data = request.get_json(silent=True) or {}
    source = _normalize_text(data.get("source")) or "Squadra"
    project_code = _normalize_text(data.get("project_code")) or ""
    member_key = _normalize_text(data.get("member_key"))
    member_name = _normalize_text(data.get("member_name")) or member_key or "Operatore"
    activity_id = _normalize_text(data.get("activity_id"))
    activity_label = _normalize_text(data.get("activity_label")) or activity_id or "Attività"
    if not member_key:
        return _json_error("member_key (ID operatore / Username) è obbligatorio")
    if not activity_label:
        return _json_error("activity_label (Descrizione attività) è obbligatoria")

    start_ts = _normalize_epoch_ms(data.get("start_ts"))
    if start_ts is None:
        return _json_error("start_ts non valido")

    end_ts_raw = data.get("end_ts")
    end_ts_value = _normalize_epoch_ms(end_ts_raw) if end_ts_raw is not None else None
    if end_ts_value is not None and end_ts_value < start_ts:
        return _json_error("end_ts deve essere successivo a start_ts")

    net_ms = _normalize_epoch_ms(data.get("net_ms"))
    if net_ms is None:
        if end_ts_value is not None:
            net_ms = max(0, end_ts_value - start_ts)
        else:
            net_ms = 0

    pause_ms = _normalize_epoch_ms(data.get("pause_ms")) or 0
    pause_count = max(0, _coerce_int(data.get("pause_count")) or 0)
    note = _normalize_text(data.get("note"))
    override_id = _coerce_int(data.get("override_id"))

    db = get_db()
    user = session.get("user") or "admin"
    now = now_ms()

    # Sessione MAGAZZINO: salva in warehouse_sessions
    if source == "Magazzino":
        ensure_warehouse_sessions_table(db)
        created_ts = end_ts_value if end_ts_value else start_ts + net_ms
        db.execute(
            """
            INSERT INTO warehouse_sessions(project_code, activity_label, elapsed_ms, username, created_ts)
            VALUES(?,?,?,?,?)
            """,
            (project_code, activity_label, net_ms, member_key, created_ts),
        )
        db.commit()
        return jsonify({"ok": True, "source": "Magazzino"})

    # Sessione SQUADRA: salva in activity_session_overrides
    if not activity_id:
        activity_id = activity_label

    source_member_key = _normalize_text(data.get("source_member_key")) or None
    source_activity_id = _normalize_text(data.get("source_activity_id")) or None
    source_start_ts = data.get("source_start_ts")
    source_start_ms = (
        _normalize_epoch_ms(source_start_ts) if source_start_ts is not None else None
    )

    manual_entry = bool(data.get("manual_entry"))
    if not manual_entry and not (source_member_key and source_activity_id and source_start_ms):
        manual_entry = True

    status = "completed" if end_ts_value is not None else "running"
    end_ts_final = end_ts_value if end_ts_value is not None else start_ts

    ensure_session_override_table(db)

    params = (
        member_key,
        member_name,
        activity_id,
        activity_label,
        project_code,
        start_ts,
        end_ts_final,
        net_ms,
        pause_ms,
        pause_count,
        status,
        source_member_key,
        source_activity_id,
        source_start_ms,
        1 if manual_entry else 0,
        note or None,
        user,
        user,
        now,
        now,
    )

    if override_id:
        existing = db.execute(
            "SELECT id FROM activity_session_overrides WHERE id=?",
            (override_id,),
        ).fetchone()
        if not existing:
            return _json_error("override non trovato", 404)
        db.execute(
            """
            UPDATE activity_session_overrides
            SET member_key=?, member_name=?, activity_id=?, activity_label=?, project_code=?,
                start_ts=?, end_ts=?, net_ms=?, pause_ms=?, pause_count=?, status=?,
                source_member_key=?, source_activity_id=?, source_start_ts=?,
                manual_entry=?, note=?, updated_by=?, updated_ts=?
            WHERE id=?
            """,
            (
                member_key,
                member_name,
                activity_id,
                activity_label,
                project_code,
                start_ts,
                end_ts_final,
                net_ms,
                pause_ms,
                pause_count,
                status,
                source_member_key,
                source_activity_id,
                source_start_ms,
                1 if manual_entry else 0,
                note or None,
                user,
                now,
                override_id,
            ),
        )
    else:
        db.execute(
            """
            INSERT INTO activity_session_overrides(
                member_key, member_name, activity_id, activity_label, project_code,
                start_ts, end_ts, net_ms, pause_ms, pause_count, status,
                source_member_key, source_activity_id, source_start_ts,
                manual_entry, note, created_by, updated_by, created_ts, updated_ts
            ) VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """,
            params,
        )
        override_id = _last_insert_id(db)

    db.commit()

    if not override_id:
        return jsonify({"ok": True})

    row = db.execute(
        "SELECT * FROM activity_session_overrides WHERE id=?",
        (override_id,),
    ).fetchone()
    if not row:
        return jsonify({"ok": True})

    payload = _override_row_to_session(dict(row))
    return jsonify({"ok": True, "session": payload})


@app.delete("/api/admin/sessions/<int:override_id>")
@login_required
def api_admin_sessions_delete(override_id: int) -> ResponseReturnValue:
    guard = _admin_only()
    if guard is not None:
        return guard

    db = get_db()
    ensure_session_override_table(db)
    existing = db.execute(
        "SELECT id FROM activity_session_overrides WHERE id=?",
        (override_id,),
    ).fetchone()
    if not existing:
        return _json_error("override non trovato", 404)

    db.execute("DELETE FROM activity_session_overrides WHERE id=?", (override_id,))
    db.commit()
    return jsonify({"ok": True})


@app.post("/api/_reset")
@login_required
def api_reset():
    db = get_db()
    seed_demo_data(db)
    db.commit()
    return jsonify({"ok": True})


# ═══════════════════════════════════════════════════════════════════════════════
#  ANALISI ATTIVITÀ CROSS-PROGETTO
# ═══════════════════════════════════════════════════════════════════════════════

@app.get("/admin/activity-analysis")
@login_required
def admin_activity_analysis_page() -> ResponseReturnValue:
    """Pagina analisi attività cross-progetto."""
    if not is_admin_or_supervisor():
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    return render_template(
        "admin_activity_analysis.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=bool(session.get("is_admin")),
    )


@app.get("/api/admin/activity-analysis")
@login_required
def api_admin_activity_analysis() -> ResponseReturnValue:
    """API per analisi cross-progetto delle attività."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    mode = request.args.get("mode", "list")  # 'list' o 'analysis'
    date_start = parse_iso_date(request.args.get("date_start")) or (datetime.now().date() - timedelta(days=30))
    date_end = parse_iso_date(request.args.get("date_end")) or datetime.now().date()

    if date_end < date_start:
        date_start, date_end = date_end, date_start

    start_dt = datetime.combine(date_start, datetime.min.time())
    end_dt = datetime.combine(date_end, datetime.min.time()) + timedelta(days=1)
    start_ms = int(start_dt.timestamp() * 1000)
    end_ms = int(end_dt.timestamp() * 1000)

    db = get_db()

    # Raccogli sessioni da squadra
    team_sessions = build_session_rows(db, start_date=date_start, end_date=date_end)

    # Raccogli sessioni magazzino
    ensure_warehouse_sessions_table(db)
    wh_rows = db.execute(
        """
        SELECT project_code, activity_label, elapsed_ms, username, created_ts
        FROM warehouse_sessions
        WHERE created_ts >= ? AND created_ts < ?
        """,
        (start_ms, end_ms),
    ).fetchall()

    # Unisci tutte le sessioni
    all_sessions: List[Dict[str, Any]] = []

    for s in team_sessions:
        all_sessions.append({
            "project": s.get("project_code") or "N/A",
            "activity": s.get("activity_label") or s.get("activity_id") or "N/A",
            "duration_ms": _coerce_int(s.get("net_ms")) or 0,
            "source": "Squadra"
        })

    for row in wh_rows or []:
        all_sessions.append({
            "project": row["project_code"] or "N/A",
            "activity": row["activity_label"] or "N/A",
            "duration_ms": _coerce_int(row["elapsed_ms"]) or 0,
            "source": "Magazzino"
        })

    if mode == "list":
        # Restituisci lista attività con statistiche aggregate
        activity_stats: Dict[str, Dict[str, Any]] = {}
        for s in all_sessions:
            act = s["activity"]
            if act not in activity_stats:
                activity_stats[act] = {
                    "name": act,
                    "total_ms": 0,
                    "sessions": 0,
                    "projects": set()
                }
            activity_stats[act]["total_ms"] += s["duration_ms"]
            activity_stats[act]["sessions"] += 1
            activity_stats[act]["projects"].add(s["project"])

        activities = sorted(
            [
                {
                    "name": v["name"],
                    "total_ms": v["total_ms"],
                    "sessions": v["sessions"],
                    "projects": len(v["projects"])
                }
                for v in activity_stats.values()
            ],
            key=lambda x: x["total_ms"],
            reverse=True
        )

        return jsonify({
            "ok": True,
            "activities": activities,
            "date_start": date_start.isoformat(),
            "date_end": date_end.isoformat()
        })

    # mode == 'analysis': analisi dettagliata per attività selezionate
    selected_activities = request.args.getlist("activity")
    if not selected_activities:
        return jsonify({"error": "Nessuna attività selezionata"}), 400

    # Filtra sessioni per attività selezionate
    filtered = [s for s in all_sessions if s["activity"] in selected_activities]

    # Raggruppa per progetto e attività
    matrix: Dict[str, Dict[str, Dict[str, Any]]] = {}
    projects_set: Set[str] = set()
    details: List[Dict[str, Any]] = []

    # Raccogli dati per matrice
    grouped: Dict[str, Dict[str, List[int]]] = {}
    for s in filtered:
        proj = s["project"]
        act = s["activity"]
        projects_set.add(proj)

        if proj not in grouped:
            grouped[proj] = {}
        if act not in grouped[proj]:
            grouped[proj][act] = []
        grouped[proj][act].append(s["duration_ms"])

    # Calcola statistiche per ogni combinazione progetto/attività
    total_ms = 0
    total_sessions = 0

    for proj, acts in grouped.items():
        if proj not in matrix:
            matrix[proj] = {}
        for act, durations in acts.items():
            n = len(durations)
            tot = sum(durations)
            avg = tot / n if n > 0 else 0
            min_d = min(durations) if durations else 0
            max_d = max(durations) if durations else 0

            # Calcola varianza percentuale (coefficiente di variazione)
            if avg > 0 and n > 1:
                variance = sum((d - avg) ** 2 for d in durations) / n
                std_dev = variance ** 0.5
                cv_pct = (std_dev / avg) * 100
            else:
                cv_pct = 0

            matrix[proj][act] = {
                "total_ms": tot,
                "sessions": n,
                "avg_ms": int(avg),
                "min_ms": min_d,
                "max_ms": max_d
            }

            details.append({
                "project": proj,
                "activity": act,
                "sessions": n,
                "total_ms": tot,
                "avg_ms": int(avg),
                "min_ms": min_d,
                "max_ms": max_d,
                "variance_pct": round(cv_pct, 1)
            })

            total_ms += tot
            total_sessions += n

    # Ordina dettagli per ore totali decrescenti
    details.sort(key=lambda x: x["total_ms"], reverse=True)

    return jsonify({
        "ok": True,
        "projects": sorted(projects_set),
        "activities": selected_activities,
        "matrix": matrix,
        "details": details,
        "total_ms": total_ms,
        "total_sessions": total_sessions,
        "date_start": date_start.isoformat(),
        "date_end": date_end.isoformat()
    })


@app.get("/api/admin/activity-analysis/export.xlsx")
@login_required
def api_admin_activity_analysis_export() -> ResponseReturnValue:
    """Esporta analisi attività in Excel."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    date_start = parse_iso_date(request.args.get("date_start")) or (datetime.now().date() - timedelta(days=30))
    date_end = parse_iso_date(request.args.get("date_end")) or datetime.now().date()
    selected_activities = request.args.getlist("activity")

    if not selected_activities:
        return jsonify({"error": "Nessuna attività selezionata"}), 400

    # Riusa la logica dell'API
    if date_end < date_start:
        date_start, date_end = date_end, date_start

    start_dt = datetime.combine(date_start, datetime.min.time())
    end_dt = datetime.combine(date_end, datetime.min.time()) + timedelta(days=1)
    start_ms = int(start_dt.timestamp() * 1000)
    end_ms = int(end_dt.timestamp() * 1000)

    db = get_db()
    team_sessions = build_session_rows(db, start_date=date_start, end_date=date_end)

    ensure_warehouse_sessions_table(db)
    wh_rows = db.execute(
        """
        SELECT project_code, activity_label, elapsed_ms
        FROM warehouse_sessions
        WHERE created_ts >= ? AND created_ts < ?
        """,
        (start_ms, end_ms),
    ).fetchall()

    all_sessions: List[Dict[str, Any]] = []
    for s in team_sessions:
        all_sessions.append({
            "project": s.get("project_code") or "N/A",
            "activity": s.get("activity_label") or "N/A",
            "duration_ms": _coerce_int(s.get("net_ms")) or 0,
        })
    for row in wh_rows or []:
        all_sessions.append({
            "project": row["project_code"] or "N/A",
            "activity": row["activity_label"] or "N/A",
            "duration_ms": _coerce_int(row["elapsed_ms"]) or 0,
        })

    filtered = [s for s in all_sessions if s["activity"] in selected_activities]

    # Raggruppa e calcola statistiche
    grouped: Dict[str, Dict[str, List[int]]] = {}
    for s in filtered:
        proj, act = s["project"], s["activity"]
        if proj not in grouped:
            grouped[proj] = {}
        if act not in grouped[proj]:
            grouped[proj][act] = []
        grouped[proj][act].append(s["duration_ms"])

    rows_data: List[Dict[str, Any]] = []
    for proj, acts in grouped.items():
        for act, durations in acts.items():
            n = len(durations)
            tot = sum(durations)
            avg = tot / n if n > 0 else 0
            rows_data.append({
                "project": proj,
                "activity": act,
                "sessions": n,
                "total_ms": tot,
                "avg_ms": int(avg),
                "min_ms": min(durations) if durations else 0,
                "max_ms": max(durations) if durations else 0,
            })

    rows_data.sort(key=lambda x: x["total_ms"], reverse=True)

    # Genera Excel
    wb = Workbook()
    ws_raw = wb.active
    if ws_raw is None:
        ws_raw = wb.create_sheet(title="Analisi Attività")
    ws: Worksheet = cast(Worksheet, ws_raw)
    ws.title = "Analisi Attività"

    title_font = Font(name="Calibri", size=16, bold=True, color="1E293B")
    subtitle_font = Font(name="Calibri", size=11, color="64748B")
    header_font = Font(name="Calibri", size=12, bold=True, color="FFFFFF")
    header_fill = PatternFill(start_color="7C3AED", end_color="7C3AED", fill_type="solid")
    header_alignment = Alignment(horizontal="center", vertical="center")
    cell_font = Font(name="Calibri", size=11)
    cell_alignment = Alignment(horizontal="left", vertical="center")
    border_thin = Border(
        left=Side(style="thin", color="CBD5E1"),
        right=Side(style="thin", color="CBD5E1"),
        top=Side(style="thin", color="CBD5E1"),
        bottom=Side(style="thin", color="CBD5E1"),
    )

    ws["A1"] = "🔬 JobLog - Analisi Attività Cross-Progetto"
    ws.merge_cells("A1:G1")
    ws["A1"].font = title_font

    period_str = f"Periodo: {date_start.strftime('%d/%m/%Y')} - {date_end.strftime('%d/%m/%Y')}"
    ws["A2"] = period_str
    ws.merge_cells("A2:G2")
    ws["A2"].font = subtitle_font

    ws["A3"] = f"Attività analizzate: {', '.join(selected_activities)}"
    ws.merge_cells("A3:G3")
    ws["A3"].font = subtitle_font

    ws.append([])

    headers = ["Progetto", "Attività", "Sessioni", "Ore Totali", "Media", "Min", "Max"]
    ws.append(headers)
    header_row = ws.max_row
    for col_num, header in enumerate(headers, start=1):
        cell = ws.cell(row=header_row, column=col_num)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = border_thin

    for item in rows_data:
        ws.append([
            item["project"],
            item["activity"],
            item["sessions"],
            format_duration_ms(item["total_ms"]) or "00:00:00",
            format_duration_ms(item["avg_ms"]) or "00:00:00",
            format_duration_ms(item["min_ms"]) or "00:00:00",
            format_duration_ms(item["max_ms"]) or "00:00:00",
        ])
        row_num = ws.max_row
        for col_num in range(1, 8):
            cell = ws.cell(row=row_num, column=col_num)
            cell.font = cell_font
            cell.alignment = cell_alignment
            cell.border = border_thin
            if row_num % 2 == 0:
                cell.fill = PatternFill(start_color="F8FAFC", end_color="F8FAFC", fill_type="solid")

    for col_letter, width in {"A": 18, "B": 30, "C": 12, "D": 14, "E": 12, "F": 12, "G": 12}.items():
        ws.column_dimensions[col_letter].width = width

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)

    filename = f"analisi_attivita_{date_start.isoformat()}_{date_end.isoformat()}.xlsx"
    return send_file(
        output,
        mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        as_attachment=True,
        download_name=filename,
    )


# Registrazione lazy del worker: si assicura che il thread sia attivo al primo accesso
@app.before_request
def _ensure_notification_worker() -> None:
    if _NOTIFICATION_THREAD is None or not _NOTIFICATION_THREAD.is_alive():
        start_notification_worker()


atexit.register(stop_notification_worker)


# Registrazione lazy del worker CedolinoWeb per retry timbrate
@app.before_request
def _ensure_cedolino_retry_worker() -> None:
    if _CEDOLINO_RETRY_THREAD is None or not _CEDOLINO_RETRY_THREAD.is_alive():
        start_cedolino_retry_worker()


# ═══════════════════════════════════════════════════════════════════════════════
#  CREW MEMBERS - DATABASE (Operatori Rentman)
# ═══════════════════════════════════════════════════════════════════════════════

CREW_MEMBERS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS crew_members (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rentman_id INT NOT NULL UNIQUE,
    name VARCHAR(255) NOT NULL,
    external_id VARCHAR(255) DEFAULT NULL,
    external_group_id VARCHAR(255) DEFAULT NULL,
    group_id INT DEFAULT NULL COMMENT 'FK a user_groups per sede GPS',
    email VARCHAR(255) DEFAULT NULL,
    phone VARCHAR(50) DEFAULT NULL,
    is_active TINYINT(1) DEFAULT 1,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    INDEX idx_crew_external (external_id),
    INDEX idx_crew_external_group (external_group_id),
    INDEX idx_crew_group (group_id),
    INDEX idx_crew_active (is_active)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

CREW_MEMBERS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS crew_members (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    rentman_id INTEGER NOT NULL UNIQUE,
    name TEXT NOT NULL,
    external_id TEXT DEFAULT NULL,
    external_group_id TEXT DEFAULT NULL,
    group_id INTEGER DEFAULT NULL,
    email TEXT DEFAULT NULL,
    phone TEXT DEFAULT NULL,
    is_active INTEGER DEFAULT 1,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_crew_external ON crew_members(external_id);
CREATE INDEX IF NOT EXISTS idx_crew_external_group ON crew_members(external_group_id);
CREATE INDEX IF NOT EXISTS idx_crew_group ON crew_members(group_id);
CREATE INDEX IF NOT EXISTS idx_crew_active ON crew_members(is_active);
"""


def ensure_crew_members_table(db: DatabaseLike) -> None:
    """Crea la tabella crew_members se non esiste."""
    statement = (
        CREW_MEMBERS_TABLE_MYSQL if DB_VENDOR == "mysql" else CREW_MEMBERS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        try:
            cursor = db.execute(sql)
            try:
                cursor.close()
            except AttributeError:
                pass
        except Exception:
            pass  # Tabella/indice già esistente
    
    # Migrazione: aggiunge colonna external_group_id se non esiste
    try:
        if DB_VENDOR == "mysql":
            # Verifica se la colonna esiste già
            check = db.execute(
                "SELECT COUNT(*) FROM information_schema.columns WHERE table_name='crew_members' AND column_name='external_group_id'"
            ).fetchone()
            col_exists = (check[0] if check else 0) > 0
            if not col_exists:
                db.execute("ALTER TABLE crew_members ADD COLUMN external_group_id VARCHAR(255) DEFAULT NULL AFTER external_id")
                db.commit()
                app.logger.info("Colonna external_group_id aggiunta a crew_members")
        else:
            # SQLite: verifica tramite PRAGMA
            cols = db.execute("PRAGMA table_info(crew_members)").fetchall()
            col_names = [c[1] for c in cols]
            if "external_group_id" not in col_names:
                db.execute("ALTER TABLE crew_members ADD COLUMN external_group_id TEXT DEFAULT NULL")
                db.commit()
                app.logger.info("Colonna external_group_id aggiunta a crew_members")
    except Exception as e:
        app.logger.warning("Migrazione external_group_id: %s", e)
    
    # Migrazione: aggiunge colonna timbratura_override per eccezioni per operatore
    try:
        if DB_VENDOR == "mysql":
            check = db.execute(
                "SELECT COUNT(*) FROM information_schema.columns WHERE table_name='crew_members' AND column_name='timbratura_override'"
            ).fetchone()
            col_exists = (check[0] if check else 0) > 0
            if not col_exists:
                db.execute("ALTER TABLE crew_members ADD COLUMN timbratura_override TEXT DEFAULT NULL")
                db.commit()
                app.logger.info("Colonna timbratura_override aggiunta a crew_members")
        else:
            cols = db.execute("PRAGMA table_info(crew_members)").fetchall()
            col_names = [c[1] for c in cols]
            if "timbratura_override" not in col_names:
                db.execute("ALTER TABLE crew_members ADD COLUMN timbratura_override TEXT DEFAULT NULL")
                db.commit()
                app.logger.info("Colonna timbratura_override aggiunta a crew_members")
    except Exception as e:
        app.logger.warning("Migrazione timbratura_override: %s", e)
    
    # Migrazione: aggiunge colonna group_id per collegamento a user_groups (sede GPS)
    try:
        if DB_VENDOR == "mysql":
            check = db.execute(
                "SELECT COUNT(*) FROM information_schema.columns WHERE table_name='crew_members' AND column_name='group_id'"
            ).fetchone()
            col_exists = (check[0] if check else 0) > 0
            if not col_exists:
                db.execute("ALTER TABLE crew_members ADD COLUMN group_id INT DEFAULT NULL COMMENT 'FK a user_groups per sede GPS'")
                db.execute("CREATE INDEX idx_crew_group ON crew_members(group_id)")
                db.commit()
                app.logger.info("Colonna group_id aggiunta a crew_members")
        else:
            cols = db.execute("PRAGMA table_info(crew_members)").fetchall()
            col_names = [c[1] for c in cols]
            if "group_id" not in col_names:
                db.execute("ALTER TABLE crew_members ADD COLUMN group_id INTEGER DEFAULT NULL")
                db.execute("CREATE INDEX IF NOT EXISTS idx_crew_group ON crew_members(group_id)")
                db.commit()
                app.logger.info("Colonna group_id aggiunta a crew_members")
    except Exception as e:
        app.logger.warning("Migrazione group_id: %s", e)


def sync_crew_member_from_rentman(db: DatabaseLike, rentman_id: int, name: str) -> None:
    """Sincronizza un operatore da Rentman nel database locale (insert or update name)."""
    now = now_ms()
    if DB_VENDOR == "mysql":
        existing = db.execute(
            "SELECT id FROM crew_members WHERE rentman_id = %s", (rentman_id,)
        ).fetchone()
        if existing:
            db.execute(
                "UPDATE crew_members SET name = %s, updated_ts = %s WHERE rentman_id = %s",
                (name, now, rentman_id)
            )
        else:
            db.execute(
                "INSERT INTO crew_members (rentman_id, name, created_ts, updated_ts) VALUES (%s, %s, %s, %s)",
                (rentman_id, name, now, now)
            )
    else:
        existing = db.execute(
            "SELECT id FROM crew_members WHERE rentman_id = ?", (rentman_id,)
        ).fetchone()
        if existing:
            db.execute(
                "UPDATE crew_members SET name = ?, updated_ts = ? WHERE rentman_id = ?",
                (name, now, rentman_id)
            )
        else:
            db.execute(
                "INSERT INTO crew_members (rentman_id, name, created_ts, updated_ts) VALUES (?, ?, ?, ?)",
                (rentman_id, name, now, now)
            )


# ═══════════════════════════════════════════════════════════════════════════════
#  CEDOLINO WEB - Funzioni di integrazione
# ═══════════════════════════════════════════════════════════════════════════════

def _get_pending_overtime_request_id(db: DatabaseLike, username: str, date_str: str) -> Optional[int]:
    """
    Verifica se esiste una richiesta di Extra Turno pending per un utente in una data specifica.
    
    Args:
        db: connessione database
        username: username dell'utente
        date_str: data in formato YYYY-MM-DD
    
    Returns:
        ID della richiesta Extra Turno pending, o None se non esiste
    """
    try:
        # Ottieni l'ID del tipo "Extra Turno"
        overtime_type_id = get_overtime_request_type_id(db)
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        app.logger.info(f"Checking pending overtime for user={username}, date={date_str}, type_id={overtime_type_id}")
        
        row = db.execute(f"""
            SELECT id FROM user_requests 
            WHERE username = {placeholder} 
              AND request_type_id = {placeholder} 
              AND date_from = {placeholder} 
              AND status = 'pending'
            ORDER BY created_ts DESC
            LIMIT 1
        """, (username, overtime_type_id, date_str)).fetchone()
        
        if row:
            result_id = row['id'] if isinstance(row, Mapping) else row[0]
            app.logger.info(f"Found pending overtime request id={result_id} for {username} on {date_str}")
            return result_id
        
        app.logger.info(f"No pending overtime found for {username} on {date_str}")
        return None
    except Exception as e:
        app.logger.warning(f"Errore verifica Extra Turno pending: {e}")
        return None


def ensure_cedolino_timbrature_table(db: DatabaseLike) -> None:
    """Crea la tabella cedolino_timbrature se non esiste."""
    statement = (
        CEDOLINO_TIMBRATURE_TABLE_MYSQL if DB_VENDOR == "mysql" else CEDOLINO_TIMBRATURE_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        try:
            cursor = db.execute(sql)
            try:
                cursor.close()
            except AttributeError:
                pass
        except Exception:
            pass
    
    # Migrazioni: aggiungi colonne se non esistono
    if DB_VENDOR == "mysql":
        migrations = [
            "ALTER TABLE cedolino_timbrature ADD COLUMN username VARCHAR(190) DEFAULT NULL",
            "ALTER TABLE cedolino_timbrature ADD COLUMN ora_originale TIME DEFAULT NULL",
            "ALTER TABLE cedolino_timbrature ADD COLUMN ora_modificata TIME DEFAULT NULL",
            "ALTER TABLE cedolino_timbrature ADD COLUMN data_riferimento DATE DEFAULT NULL",
            "ALTER TABLE cedolino_timbrature ADD COLUMN overtime_request_id INT DEFAULT NULL COMMENT 'ID richiesta straordinario collegata'",
            "CREATE INDEX idx_cedolino_overtime ON cedolino_timbrature(overtime_request_id)",
        ]
        for migration in migrations:
            try:
                db.execute(migration)
                db.commit()
            except Exception:
                pass  # Colonna già esistente
    else:
        migrations = [
            "ALTER TABLE cedolino_timbrature ADD COLUMN username TEXT",
            "ALTER TABLE cedolino_timbrature ADD COLUMN ora_originale TEXT",
            "ALTER TABLE cedolino_timbrature ADD COLUMN ora_modificata TEXT",
            "ALTER TABLE cedolino_timbrature ADD COLUMN data_riferimento TEXT",
            "ALTER TABLE cedolino_timbrature ADD COLUMN overtime_request_id INTEGER DEFAULT NULL",
        ]
        for migration in migrations:
            try:
                db.execute(migration)
                db.commit()
            except Exception:
                pass
        # Indice separato per SQLite
        try:
            db.execute("CREATE INDEX IF NOT EXISTS idx_cedolino_overtime ON cedolino_timbrature(overtime_request_id)")
            db.commit()
        except Exception:
            pass


def get_cedolino_settings() -> Optional[Dict[str, Any]]:
    """
    Restituisce le impostazioni CedolinoWeb dal config.json.
    La sincronizzazione è attiva solo se:
    1. config.json ha cedolino_web.enabled = true
    2. company_settings.custom_settings.cedolino_sync_enabled = true (se configurato)
    """
    config = load_config()
    section = config.get("cedolino_web")
    if not section or not isinstance(section, dict):
        return None
    if not section.get("enabled"):
        return None
    
    # Verifica anche l'impostazione nel database (se presente)
    try:
        db = get_db()
        settings = get_company_settings(db)
        custom_settings = settings.get("custom_settings", {})
        # Se il flag esiste nel database e è False, disabilita la sincronizzazione
        if "cedolino_sync_enabled" in custom_settings:
            if not custom_settings.get("cedolino_sync_enabled"):
                return None
    except Exception as e:
        # Se c'è un errore nel database, usa solo il config.json
        app.logger.warning(f"Errore verifica cedolino_sync_enabled da DB: {e}")
    
    return section


def get_external_id_for_member(db: DatabaseLike, member_key: str) -> Optional[str]:
    """
    Recupera l'external_id (ID CedolinoWeb) per un operatore dato il member_key.
    Il member_key ha formato 'rentman-crew-{rentman_id}'.
    """
    if not member_key:
        return None
    
    # Estrai rentman_id dal member_key
    if not member_key.startswith("rentman-crew-"):
        app.logger.warning("CedolinoWeb: member_key non valido (formato atteso: rentman-crew-ID): %s", member_key)
        return None
    
    try:
        rentman_id = int(member_key.replace("rentman-crew-", ""))
    except ValueError:
        app.logger.warning("CedolinoWeb: impossibile estrarre rentman_id da %s", member_key)
        return None
    
    # Cerca l'external_id nella tabella crew_members
    if DB_VENDOR == "mysql":
        row = db.execute(
            "SELECT external_id FROM crew_members WHERE rentman_id = %s",
            (rentman_id,)
        ).fetchone()
    else:
        row = db.execute(
            "SELECT external_id FROM crew_members WHERE rentman_id = ?",
            (rentman_id,)
        ).fetchone()
    
    if not row:
        app.logger.debug("CedolinoWeb: nessun operatore trovato per rentman_id %s", rentman_id)
        return None
    
    external_id = row["external_id"] if isinstance(row, dict) else row[0]
    return external_id if external_id else None


def get_username_from_member_key(db: DatabaseLike, member_key: str) -> Optional[str]:
    """
    Recupera lo username dell'utente associato a un member_key.
    Il member_key ha formato 'rentman-crew-{rentman_id}' dove rentman_id è l'ID
    dell'assignment Rentman (non il crew_id).
    
    Il mapping avviene in due passi:
    1. Cerca il crew_id dalla tabella rentman_plannings tramite rentman_id
    2. Cerca lo username dalla tabella app_users tramite rentman_crew_id = crew_id
    
    Args:
        db: connessione database
        member_key: chiave operatore (es. rentman-crew-1903)
    
    Returns:
        username se trovato, None altrimenti
    """
    if not member_key:
        return None
    
    # Estrai rentman_id (assignment_id) dal member_key
    if not member_key.startswith("rentman-crew-"):
        app.logger.debug("get_username_from_member_key: member_key non valido (formato atteso: rentman-crew-ID): %s", member_key)
        return None
    
    try:
        rentman_id = int(member_key.replace("rentman-crew-", ""))
    except ValueError:
        app.logger.warning("get_username_from_member_key: impossibile estrarre rentman_id da %s", member_key)
        return None
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Step 1: Cerca il crew_id dalla tabella rentman_plannings tramite rentman_id
    planning_row = db.execute(
        f"SELECT crew_id FROM rentman_plannings WHERE rentman_id = {placeholder} LIMIT 1",
        (rentman_id,)
    ).fetchone()
    
    if not planning_row:
        app.logger.debug("get_username_from_member_key: nessun planning trovato per rentman_id %s", rentman_id)
        return None
    
    crew_id = planning_row["crew_id"] if isinstance(planning_row, dict) else planning_row[0]
    if not crew_id:
        app.logger.debug("get_username_from_member_key: crew_id nullo per rentman_id %s", rentman_id)
        return None
    
    # Step 2: Cerca lo username dalla tabella app_users tramite rentman_crew_id = crew_id
    user_row = db.execute(
        f"SELECT username FROM app_users WHERE rentman_crew_id = {placeholder} AND is_active = 1",
        (crew_id,)
    ).fetchone()
    
    if not user_row:
        app.logger.debug("get_username_from_member_key: nessun utente trovato per crew_id %s (rentman_id=%s)", crew_id, rentman_id)
        return None
    
    username = user_row["username"] if isinstance(user_row, dict) else user_row[0]
    app.logger.debug("get_username_from_member_key: trovato username '%s' per member_key '%s' (rentman_id=%s, crew_id=%s)", 
                     username, member_key, rentman_id, crew_id)
    return username


def create_supervisor_pause_timbratura(
    db: DatabaseLike,
    username: str,
    tipo: str,
    member_name: Optional[str] = None,
    supervisor_username: Optional[str] = None
) -> bool:
    """
    Genera una timbratura di pausa (inizio_pausa o fine_pausa) quando il supervisor
    mette in pausa o riprende un operatore.
    
    Args:
        db: connessione database
        username: username dell'operatore
        tipo: 'inizio_pausa' o 'fine_pausa'
        member_name: nome visualizzato dell'operatore (per logging)
        supervisor_username: username del supervisor che ha generato la timbratura
    
    Returns:
        True se la timbratura è stata creata, False altrimenti
    """
    if not username:
        return False
    
    if tipo not in ('inizio_pausa', 'fine_pausa'):
        app.logger.error("create_supervisor_pause_timbratura: tipo non valido: %s", tipo)
        return False
    
    # Data e ora correnti
    today = datetime.now().strftime("%Y-%m-%d")
    ora = datetime.now().strftime("%H:%M:%S")
    created_ts = now_ms()
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Calcola ora_mod in base alle regole
    ora_mod = ora
    
    # Recupera le regole di timbratura dell'utente
    try:
        rules = get_user_timbratura_rules(db, username)
    except Exception as e:
        app.logger.warning(f"Errore recupero regole timbratura: {e}, uso default")
        rules = {
            'pausa_blocco_minimo_minuti': 30,
            'pausa_incremento_minuti': 15,
            'pausa_tolleranza_minuti': 5
        }
    
    # Per fine_pausa, calcola ora_mod basato sulla durata della pausa
    if tipo == 'fine_pausa':
        try:
            # Recupera l'ora di inizio pausa (l'ultima non chiusa)
            inizio_pausa_row = db.execute(
                f"""SELECT ora, ora_mod FROM timbrature 
                   WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'inizio_pausa'
                   ORDER BY created_ts DESC LIMIT 1""",
                (username, today)
            ).fetchone()
            
            if inizio_pausa_row:
                inizio_ora_mod = inizio_pausa_row['ora_mod'] if isinstance(inizio_pausa_row, dict) else inizio_pausa_row[1]
                if not inizio_ora_mod:
                    inizio_ora_mod = inizio_pausa_row['ora'] if isinstance(inizio_pausa_row, dict) else inizio_pausa_row[0]
                
                # Formatta l'ora di inizio pausa
                if hasattr(inizio_ora_mod, 'strftime'):
                    inizio_str = inizio_ora_mod.strftime("%H:%M")
                elif hasattr(inizio_ora_mod, 'total_seconds'):
                    # È un timedelta (MySQL TIME restituisce timedelta)
                    total_sec = int(inizio_ora_mod.total_seconds())
                    inizio_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
                else:
                    inizio_str = str(inizio_ora_mod)[:5]
                
                # Calcola durata modificata usando le regole pause
                durata_mod = calcola_pausa_mod(inizio_str, ora[:5], rules)
                
                # Calcola ora_mod di fine_pausa = inizio_pausa_mod + durata_mod
                inizio_parts = inizio_str.split(':')
                inizio_min = int(inizio_parts[0]) * 60 + int(inizio_parts[1])
                fine_mod_min = inizio_min + durata_mod
                
                h = fine_mod_min // 60
                m = fine_mod_min % 60
                ora_mod = f"{h:02d}:{m:02d}:00"
                
                # Calcola durata effettiva per il log
                ora_parts = ora[:5].split(':')
                ora_min = int(ora_parts[0]) * 60 + int(ora_parts[1])
                durata_effettiva = ora_min - inizio_min
                
                app.logger.info(
                    f"Pausa supervisor: {inizio_str} -> {ora[:5]} (durata effettiva {durata_effettiva} min, durata mod {durata_mod} min, fine mod {ora_mod})"
                )
        except Exception as e:
            app.logger.warning(f"Errore calcolo ora_mod pausa: {e}, uso ora originale")
            ora_mod = ora
    
    # Inserisce la timbratura di pausa
    try:
        db.execute(
            f"""
            INSERT INTO timbrature (username, tipo, data, ora, ora_mod, created_ts, method, created_by)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            """,
            (username, tipo, today, ora, ora_mod, created_ts, "supervisor", supervisor_username)
        )
        
        app.logger.info(
            "Timbratura %s generata da supervisor per %s (%s) alle %s (ora_mod: %s)",
            tipo, username, member_name or username, ora, ora_mod
        )
        
        # Invia a CedolinoWeb
        timeframe_id = TIMEFRAME_INIZIO_PAUSA if tipo == 'inizio_pausa' else TIMEFRAME_FINE_PAUSA
        
        # Recupera display_name per CedolinoWeb
        user_row = db.execute(
            f"SELECT display_name FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        display_name = username
        if user_row:
            display_name = (user_row['display_name'] if isinstance(user_row, dict) else user_row[0]) or username
        
        send_timbrata_utente(
            db,
            username=username,
            member_name=display_name,
            timeframe_id=timeframe_id,
            data_riferimento=today,
            ora_originale=ora,
            ora_modificata=ora_mod,
        )
        
        return True
        
    except Exception as e:
        app.logger.error("create_supervisor_pause_timbratura: errore inserimento timbratura: %s", e)
        return False


def get_external_id_for_username(db: DatabaseLike, username: str, return_reason: bool = False):
    """
    Recupera l'external_id (ID CedolinoWeb) per un utente dato il suo username.
    
    L'external_id viene cercato SOLO nella tabella app_users.
    
    Args:
        db: connessione database
        username: username dell'utente
        return_reason: se True, ritorna anche il motivo in caso di errore
    
    Returns:
        Se return_reason=False: external_id o None
        Se return_reason=True: (external_id, reason) dove reason spiega il problema
    """
    if not username:
        if return_reason:
            return None, "Username non fornito"
        return None
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera external_id dalla tabella app_users
    user_row = db.execute(
        f"SELECT external_id FROM app_users WHERE username = {placeholder}",
        (username,)
    ).fetchone()
    
    if not user_row:
        app.logger.debug("CedolinoWeb: utente %s non trovato", username)
        if return_reason:
            return None, "Utente non trovato nel database"
        return None
    
    # Estrai il valore
    if isinstance(user_row, dict):
        external_id = user_row.get('external_id')
    else:
        external_id = user_row[0]
    
    if external_id:
        app.logger.debug("CedolinoWeb: utente %s ha external_id: %s", username, external_id)
        if return_reason:
            return external_id, ""
        return external_id
    
    # Nessun external_id configurato
    app.logger.debug("CedolinoWeb: utente %s non ha external_id configurato", username)
    if return_reason:
        return None, "Utente non ha l'ID Esterno CedolinoWeb configurato. Vai in Gestione Utenti e inserisci l'ID Esterno."
    return None


def get_external_group_id_for_username(db: DatabaseLike, username: str) -> Optional[str]:
    """
    Recupera l'external_group_id (Gruppo ID CedolinoWeb) per un utente dato il suo username.
    
    Ordine di ricerca:
    1. Prima cerca external_group_id direttamente in app_users (override utente)
    2. Se non trovato, cerca cedolino_group_id dalla tabella user_groups tramite group_id
    """
    if not username:
        return None
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Prima cerca external_group_id diretto dall'utente E il group_id per fallback
    user_row = db.execute(
        f"SELECT external_group_id, group_id FROM app_users WHERE username = {placeholder}",
        (username,)
    ).fetchone()
    
    if not user_row:
        return None
    
    # Estrai i valori
    if isinstance(user_row, dict):
        external_group_id = user_row.get('external_group_id')
        group_id = user_row.get('group_id')
    else:
        external_group_id = user_row[0]
        group_id = user_row[1]
    
    # Se l'utente ha un external_group_id diretto, usalo
    if external_group_id:
        app.logger.info(f"CedolinoWeb gruppo: utente {username} ha external_group_id diretto: {external_group_id}")
        return external_group_id
    
    # Altrimenti cerca il cedolino_group_id dal gruppo associato
    if group_id:
        group_row = db.execute(
            f"SELECT cedolino_group_id FROM user_groups WHERE id = {placeholder}",
            (group_id,)
        ).fetchone()
        
        if group_row:
            if isinstance(group_row, dict):
                cedolino_group_id = group_row.get('cedolino_group_id')
            else:
                cedolino_group_id = group_row[0]
            
            if cedolino_group_id:
                app.logger.info(f"CedolinoWeb gruppo: utente {username} usa cedolino_group_id dal gruppo: {cedolino_group_id}")
                return cedolino_group_id
    
    app.logger.warning(f"CedolinoWeb gruppo: utente {username} non ha gruppo_id associato")
    return None


# ═══════════════════════════════════════════════════════════════════
# TEST PAYLOAD - Imposta a True per vedere il payload completo nei log
# ═══════════════════════════════════════════════════════════════════
CEDOLINO_TEST_PAYLOAD = False  # <-- Cambia a True per attivare


def call_cedolino_webservice(
    external_id: str,
    timeframe_id: int,
    data_riferimento: str,
    data_originale: str,
    data_modificata: str,
    endpoint: Optional[str] = None,
    gruppo_id: Optional[str] = None
) -> Tuple[bool, Optional[str], str]:
    """
    Chiama il webservice CedolinoWeb per registrare una timbrata.
    
    Args:
        external_id: ID esterno dell'operatore (codice_utente e assunzione_id)
        timeframe_id: tipo di timbrata (1=inizio, 3=pausa, 4=fine pausa, 8=fine)
        data_riferimento: data di riferimento (formato YYYY-MM-DD)
        data_originale: data/ora originale (formato YYYY-MM-DD HH:MM:SS)
        data_modificata: data/ora modificata (formato YYYY-MM-DD HH:MM:SS)
        endpoint: URL del webservice (default: CEDOLINO_WEB_ENDPOINT)
        gruppo_id: ID del gruppo esterno (default: NULL)
    
    Returns:
        Tuple (success: bool, error_message: Optional[str], request_url: str)
    """
    import requests
    
    if not endpoint:
        endpoint = CEDOLINO_WEB_ENDPOINT
    
    params = {
        "data_riferimento": data_riferimento,
        "data_originale": data_originale,
        "data_modificata": data_modificata,
        "codice_utente": external_id,
        "codice_terminale": CEDOLINO_CODICE_TERMINALE,
        "timeframe_id": str(timeframe_id),
        "assunzione_id": external_id,
        "terminale_id": "NULL",
        "gruppo_id": gruppo_id if gruppo_id else "NULL",
        "turno_id": "NULL",
        "note": "",
        "validata": "true",
    }
    
    # Costruisci URL completo per debug
    from urllib.parse import urlencode
    full_url = f"{endpoint}?{urlencode(params)}"
    
    # ═══════════════════════════════════════════════════════════════════
    # TEST PAYLOAD LOG - Mostra payload dettagliato
    # ═══════════════════════════════════════════════════════════════════
    if CEDOLINO_TEST_PAYLOAD:
        app.logger.info("=" * 80)
        app.logger.info("🧪 CEDOLINO TEST PAYLOAD 🧪")
        app.logger.info("=" * 80)
        app.logger.info("ENDPOINT: %s", endpoint)
        app.logger.info("-" * 40)
        app.logger.info("PAYLOAD PARAMETERS:")
        for key, value in params.items():
            app.logger.info("  %-20s : %s", key, value)
        app.logger.info("-" * 40)
        app.logger.info("FULL URL: %s", full_url)
        app.logger.info("=" * 80)
    else:
        app.logger.info("CedolinoWeb REQUEST URL: %s", full_url)
    
    try:
        app.logger.info(
            "CedolinoWeb: invio timbrata per %s, timeframe=%s, originale=%s, modificata=%s",
            external_id, timeframe_id, data_originale, data_modificata
        )
        response = requests.get(endpoint, params=params, timeout=30)
        
        # Log della risposta
        app.logger.info("CedolinoWeb RESPONSE: status=%s, body=%s", response.status_code, response.text[:500] if response.text else "(vuoto)")
        
        if response.status_code == 200:
            app.logger.info("CedolinoWeb: timbrata registrata con successo per %s", external_id)
            return True, None, full_url
        else:
            error_msg = f"HTTP {response.status_code}: {response.text[:200]}"
            app.logger.warning("CedolinoWeb: errore HTTP - %s", error_msg)
            return False, error_msg, full_url
            
    except requests.Timeout:
        error_msg = "Timeout durante la connessione"
        app.logger.warning("CedolinoWeb: %s", error_msg)
        return False, error_msg, full_url
    except requests.RequestException as e:
        error_msg = f"Errore di rete: {str(e)}"
        app.logger.warning("CedolinoWeb: %s", error_msg)
        return False, error_msg, full_url
    except Exception as e:
        error_msg = f"Errore imprevisto: {str(e)}"
        app.logger.exception("CedolinoWeb: errore imprevisto")
        return False, error_msg, full_url


def send_timbrata(
    db: DatabaseLike,
    member_key: str,
    member_name: str,
    timeframe_id: int,
    timestamp_ms: Optional[int] = None,
    project_code: Optional[str] = None,
    activity_id: Optional[str] = None,
) -> Tuple[bool, Optional[str], Optional[str]]:
    """
    Registra una timbrata operatore e tenta l'invio a CedolinoWeb.
    Per le timbrature operatori usa lo stesso orario per originale e modificato.
    
    Args:
        db: connessione database
        member_key: chiave operatore (es. rentman-crew-1656)
        member_name: nome operatore
        timeframe_id: tipo timbrata (1, 3, 4, 8)
        timestamp_ms: timestamp (default: now)
        project_code: codice progetto corrente
        activity_id: ID attività corrente
    
    Returns:
        Tuple (success: bool, external_id: Optional[str], error: Optional[str])
        - success=True se timbrata inviata o CedolinoWeb disabilitato
        - external_id=None se operatore non ha ID esterno
        - error=messaggio se fallito
    """
    settings = get_cedolino_settings()
    
    # Se CedolinoWeb non è configurato/abilitato, ritorna OK silenziosamente
    if not settings:
        return True, None, None
    
    if timestamp_ms is None:
        timestamp_ms = now_ms()
    
    # Recupera external_id
    external_id = get_external_id_for_member(db, member_key)
    if not external_id:
        # Operatore senza ID esterno - blocca l'operazione
        return False, None, "Operatore senza ID esterno CedolinoWeb"
    
    # Calcola data_riferimento e ora
    dt = datetime.fromtimestamp(timestamp_ms / 1000.0)
    data_riferimento = dt.strftime("%Y-%m-%d")
    ora = dt.strftime("%H:%M:%S")
    data_ora_completa = f"{data_riferimento} {ora}"
    
    # Assicurati che la tabella esista
    ensure_cedolino_timbrature_table(db)
    
    now = now_ms()
    
    # Salva la timbrata nel database
    if DB_VENDOR == "mysql":
        db.execute(
            """
            INSERT INTO cedolino_timbrature 
            (member_key, member_name, username, external_id, timeframe_id, timestamp_ms, 
             data_riferimento, ora_originale, ora_modificata, project_code, activity_id, created_ts)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """,
            (member_key, member_name, None, external_id, timeframe_id, timestamp_ms,
             data_riferimento, ora, ora, project_code, activity_id, now)
        )
    else:
        db.execute(
            """
            INSERT INTO cedolino_timbrature 
            (member_key, member_name, username, external_id, timeframe_id, timestamp_ms, 
             data_riferimento, ora_originale, ora_modificata, project_code, activity_id, created_ts)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (member_key, member_name, None, external_id, timeframe_id, timestamp_ms,
             data_riferimento, ora, ora, project_code, activity_id, now)
        )
    
    # Recupera l'ID appena inserito
    timbrata_id = _last_insert_id(db)
    
    # Tenta l'invio al webservice
    endpoint = settings.get("endpoint") or CEDOLINO_WEB_ENDPOINT
    success, error, _url = call_cedolino_webservice(
        external_id, timeframe_id, data_riferimento, data_ora_completa, data_ora_completa, endpoint
    )
    
    # Aggiorna lo stato di sincronizzazione
    if success:
        if DB_VENDOR == "mysql":
            db.execute(
                "UPDATE cedolino_timbrature SET synced_ts = %s WHERE id = %s",
                (now_ms(), timbrata_id)
            )
        else:
            db.execute(
                "UPDATE cedolino_timbrature SET synced_ts = ? WHERE id = ?",
                (now_ms(), timbrata_id)
            )
    else:
        if DB_VENDOR == "mysql":
            db.execute(
                "UPDATE cedolino_timbrature SET sync_error = %s, sync_attempts = 1 WHERE id = %s",
                (error, timbrata_id)
            )
        else:
            db.execute(
                "UPDATE cedolino_timbrature SET sync_error = ?, sync_attempts = 1 WHERE id = ?",
                (error, timbrata_id)
            )
    
    return success, external_id, error


def send_timbrata_utente(
    db: DatabaseLike,
    username: str,
    member_name: str,
    timeframe_id: int,
    data_riferimento: str,
    ora_originale: str,
    ora_modificata: str,
    overtime_request_id: Optional[int] = None,
) -> Tuple[bool, Optional[str], Optional[str], Optional[str]]:
    """
    Registra una timbrata utente e tenta l'invio a CedolinoWeb.
    Usa ora_originale e ora_modificata dalla tabella timbrature.
    
    Se overtime_request_id è specificato, la timbrata viene salvata ma NON sincronizzata
    fino a quando la richiesta di straordinario non viene revisionata.
    
    Args:
        db: connessione database
        username: username dell'utente
        member_name: nome operatore/utente
        timeframe_id: tipo timbrata (1, 3, 4, 8)
        data_riferimento: data della timbrata (YYYY-MM-DD)
        ora_originale: orario reale della timbrata (HH:MM:SS)
        ora_modificata: orario modificato/arrotondato (HH:MM:SS)
        overtime_request_id: ID richiesta straordinario (se presente, blocca sincronizzazione)
    
    Returns:
        Tuple (success: bool, external_id: Optional[str], error: Optional[str], request_url: Optional[str])
        - success=True se timbrata inviata o CedolinoWeb disabilitato o bloccata per straordinario
        - external_id=None se operatore non ha ID esterno
        - error=messaggio se fallito
        - request_url=URL completo della chiamata (per debug)
    """
    settings = get_cedolino_settings()
    
    # Se CedolinoWeb non è configurato/abilitato, ritorna OK silenziosamente
    if not settings:
        return True, None, None, None
    
    # Recupera external_id dall'username con motivo dettagliato
    external_id, reason = get_external_id_for_username(db, username, return_reason=True)
    if not external_id:
        # Utente senza ID esterno - blocca l'operazione
        return False, None, reason or "Utente senza ID esterno CedolinoWeb", None
    
    # Recupera external_group_id dall'username
    external_group_id = get_external_group_id_for_username(db, username)
    
    # Assicurati che ora_modificata abbia valore (fallback a ora_originale)
    if not ora_modificata:
        ora_modificata = ora_originale
    
    # Componi data_originale e data_modificata
    data_originale = f"{data_riferimento} {ora_originale}"
    data_modificata = f"{data_riferimento} {ora_modificata}"
    
    # Timestamp in millisecondi
    try:
        dt = datetime.strptime(f"{data_riferimento} {ora_originale}", "%Y-%m-%d %H:%M:%S")
        timestamp_ms = int(dt.timestamp() * 1000)
    except ValueError:
        # Prova con formato senza secondi
        try:
            dt = datetime.strptime(f"{data_riferimento} {ora_originale}", "%Y-%m-%d %H:%M")
            timestamp_ms = int(dt.timestamp() * 1000)
        except ValueError:
            timestamp_ms = now_ms()
    
    # Assicurati che la tabella esista
    ensure_cedolino_timbrature_table(db)
    
    now = now_ms()
    
    # Salva la timbrata nel database (con overtime_request_id se presente)
    if DB_VENDOR == "mysql":
        db.execute(
            """
            INSERT INTO cedolino_timbrature 
            (member_key, member_name, username, external_id, timeframe_id, timestamp_ms, 
             data_riferimento, ora_originale, ora_modificata, project_code, activity_id, 
             overtime_request_id, created_ts)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """,
            (None, member_name, username, external_id, timeframe_id, timestamp_ms,
             data_riferimento, ora_originale, ora_modificata, None, None, overtime_request_id, now)
        )
    else:
        db.execute(
            """
            INSERT INTO cedolino_timbrature 
            (member_key, member_name, username, external_id, timeframe_id, timestamp_ms, 
             data_riferimento, ora_originale, ora_modificata, project_code, activity_id, 
             overtime_request_id, created_ts)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (None, member_name, username, external_id, timeframe_id, timestamp_ms,
             data_riferimento, ora_originale, ora_modificata, None, None, overtime_request_id, now)
        )
    
    # Recupera l'ID appena inserito
    timbrata_id = _last_insert_id(db)
    
    # Se c'è un overtime_request_id, NON sincronizzare ora - sarà fatto dopo la revisione
    if overtime_request_id:
        app.logger.info(
            "CedolinoWeb: timbrata %s per %s bloccata in attesa di revisione (request_id=%s)",
            timbrata_id, username, overtime_request_id
        )
        # Salva un messaggio informativo nell'errore
        if DB_VENDOR == "mysql":
            db.execute(
                "UPDATE cedolino_timbrature SET sync_error = %s WHERE id = %s",
                ("In attesa di revisione", timbrata_id)
            )
        else:
            db.execute(
                "UPDATE cedolino_timbrature SET sync_error = ? WHERE id = ?",
                ("In attesa di revisione", timbrata_id)
            )
        # Ritorna success=True perché la timbrata è stata salvata correttamente
        return True, external_id, None, None
    
    # Tenta l'invio al webservice
    endpoint = settings.get("endpoint") or CEDOLINO_WEB_ENDPOINT
    success, error, request_url = call_cedolino_webservice(
        external_id, timeframe_id, data_riferimento, data_originale, data_modificata, endpoint, external_group_id
    )
    
    # Aggiorna lo stato di sincronizzazione
    if success:
        if DB_VENDOR == "mysql":
            db.execute(
                "UPDATE cedolino_timbrature SET synced_ts = %s WHERE id = %s",
                (now_ms(), timbrata_id)
            )
        else:
            db.execute(
                "UPDATE cedolino_timbrature SET synced_ts = ? WHERE id = ?",
                (now_ms(), timbrata_id)
            )
    else:
        if DB_VENDOR == "mysql":
            db.execute(
                "UPDATE cedolino_timbrature SET sync_error = %s, sync_attempts = 1 WHERE id = %s",
                (error, timbrata_id)
            )
        else:
            db.execute(
                "UPDATE cedolino_timbrature SET sync_error = ?, sync_attempts = 1 WHERE id = ?",
                (error, timbrata_id)
            )
    
    return success, external_id, error, request_url


def retry_pending_timbrature(db: DatabaseLike, max_attempts: int = 5) -> int:
    """
    Ritenta l'invio delle timbrate non sincronizzate.
    Esclude le timbrature bloccate per straordinario in attesa di revisione.
    
    Args:
        db: connessione database
        max_attempts: numero massimo di tentativi
    
    Returns:
        Numero di timbrate sincronizzate con successo
    """
    # Assicura che la tabella esista con tutte le colonne (migrazioni)
    ensure_cedolino_timbrature_table(db)
    
    settings = get_cedolino_settings()
    if not settings:
        return 0
    
    endpoint = settings.get("endpoint") or CEDOLINO_WEB_ENDPOINT
    
    # Recupera timbrate non sincronizzate con tentativi < max
    # IMPORTANTE: Esclude TUTTE quelle con overtime_request_id - vengono gestite
    # esclusivamente da _sync_overtime_blocked_timbrature dopo la revisione dell'admin
    if DB_VENDOR == "mysql":
        rows = db.execute(
            """
            SELECT ct.id, ct.external_id, ct.timeframe_id, ct.data_riferimento, 
                   ct.ora_originale, ct.ora_modificata, ct.sync_attempts, ct.username
            FROM cedolino_timbrature ct
            WHERE ct.synced_ts IS NULL 
              AND ct.sync_attempts < %s
              AND ct.overtime_request_id IS NULL
            ORDER BY ct.created_ts ASC
            LIMIT 50
            """,
            (max_attempts,)
        ).fetchall()
    else:
        rows = db.execute(
            """
            SELECT ct.id, ct.external_id, ct.timeframe_id, ct.data_riferimento, 
                   ct.ora_originale, ct.ora_modificata, ct.sync_attempts, ct.username
            FROM cedolino_timbrature ct
            WHERE ct.synced_ts IS NULL 
              AND ct.sync_attempts < ?
              AND ct.overtime_request_id IS NULL
            ORDER BY ct.created_ts ASC
            LIMIT 50
            """,
            (max_attempts,)
        ).fetchall()
    
    synced_count = 0
    for row in rows:
        timbrata_id = row["id"] if isinstance(row, dict) else row[0]
        external_id = row["external_id"] if isinstance(row, dict) else row[1]
        timeframe_id = row["timeframe_id"] if isinstance(row, dict) else row[2]
        data_rif = row["data_riferimento"] if isinstance(row, dict) else row[3]
        ora_orig = row["ora_originale"] if isinstance(row, dict) else row[4]
        ora_mod = row["ora_modificata"] if isinstance(row, dict) else row[5]
        attempts = row["sync_attempts"] if isinstance(row, dict) else row[6]
        
        # Formatta data_riferimento come stringa se necessario
        if hasattr(data_rif, 'strftime'):
            data_riferimento = data_rif.strftime("%Y-%m-%d")
        else:
            data_riferimento = str(data_rif)
        
        # Formatta ora come stringa se necessario
        if hasattr(ora_orig, 'strftime'):
            ora_originale = ora_orig.strftime("%H:%M:%S")
        else:
            ora_originale = str(ora_orig)
        
        if hasattr(ora_mod, 'strftime'):
            ora_modificata = ora_mod.strftime("%H:%M:%S")
        else:
            ora_modificata = str(ora_mod) if ora_mod else ora_originale
        
        # Componi data_originale e data_modificata
        data_originale = f"{data_riferimento} {ora_originale}"
        data_modificata = f"{data_riferimento} {ora_modificata}"
        
        success, error, _url = call_cedolino_webservice(
            external_id, timeframe_id, data_riferimento, data_originale, data_modificata, endpoint
        )
        
        if success:
            if DB_VENDOR == "mysql":
                db.execute(
                    "UPDATE cedolino_timbrature SET synced_ts = %s, sync_error = NULL WHERE id = %s",
                    (now_ms(), timbrata_id)
                )
            else:
                db.execute(
                    "UPDATE cedolino_timbrature SET synced_ts = ?, sync_error = NULL WHERE id = ?",
                    (now_ms(), timbrata_id)
                )
            synced_count += 1
        else:
            if DB_VENDOR == "mysql":
                db.execute(
                    "UPDATE cedolino_timbrature SET sync_error = %s, sync_attempts = %s WHERE id = %s",
                    (error, attempts + 1, timbrata_id)
                )
            else:
                db.execute(
                    "UPDATE cedolino_timbrature SET sync_error = ?, sync_attempts = ? WHERE id = ?",
                    (error, attempts + 1, timbrata_id)
                )
    
    if rows:
        db.commit()
    
    return synced_count


def _cedolino_retry_worker(stop_event: Event) -> None:
    """Worker thread per ritentare l'invio delle timbrate CedolinoWeb non sincronizzate."""
    app.logger.info(
        "CedolinoWeb retry worker: avviato (intervallo %ss)", CEDOLINO_RETRY_INTERVAL_SECONDS
    )
    
    while not stop_event.is_set():
        try:
            with app.app_context():
                settings = get_cedolino_settings()
                if not settings:
                    app.logger.debug("CedolinoWeb retry worker: integrazione disabilitata")
                else:
                    max_attempts = settings.get("max_retry_attempts", 10)
                    db = get_db()
                    synced = retry_pending_timbrature(db, max_attempts)
                    if synced > 0:
                        app.logger.info("CedolinoWeb retry worker: sincronizzate %s timbrate", synced)
        except Exception as exc:
            app.logger.exception("CedolinoWeb retry worker: errore", exc_info=exc)
        finally:
            stop_event.wait(CEDOLINO_RETRY_INTERVAL_SECONDS)


def start_cedolino_retry_worker() -> None:
    """Avvia il worker per i retry CedolinoWeb."""
    global _CEDOLINO_RETRY_THREAD, _CEDOLINO_RETRY_STOP
    
    if _CEDOLINO_RETRY_THREAD and _CEDOLINO_RETRY_THREAD.is_alive():
        return
    
    _CEDOLINO_RETRY_STOP = Event()
    _CEDOLINO_RETRY_THREAD = Thread(
        target=_cedolino_retry_worker,
        args=(_CEDOLINO_RETRY_STOP,),
        name="joblog-cedolino-retry",
        daemon=True
    )
    _CEDOLINO_RETRY_THREAD.start()
    app.logger.info("CedolinoWeb retry worker: thread avviato")


def stop_cedolino_retry_worker() -> None:
    """Ferma il worker per i retry CedolinoWeb."""
    global _CEDOLINO_RETRY_THREAD, _CEDOLINO_RETRY_STOP
    
    stop_event = _CEDOLINO_RETRY_STOP
    thread = _CEDOLINO_RETRY_THREAD
    
    if stop_event is not None:
        stop_event.set()
    
    if thread and thread.is_alive():
        thread.join(timeout=5)
    
    _CEDOLINO_RETRY_THREAD = None
    _CEDOLINO_RETRY_STOP = None


atexit.register(stop_cedolino_retry_worker)


# ═══════════════════════════════════════════════════════════════════════════════
#  PIANIFICAZIONI RENTMAN - DATABASE
# ═══════════════════════════════════════════════════════════════════════════════

RENTMAN_PLANNINGS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS rentman_plannings (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rentman_id INT NOT NULL,
    planning_date DATE NOT NULL,
    crew_id INT,
    crew_name VARCHAR(255),
    function_id INT,
    function_name VARCHAR(255),
    project_id INT,
    project_name VARCHAR(500),
    project_code VARCHAR(128),
    subproject_id INT,
    location_id INT,
    location_name VARCHAR(500),
    location_address VARCHAR(500),
    custom_location_ids TEXT DEFAULT NULL COMMENT 'JSON array di ID location_cache assegnate',
    location_lat DECIMAL(12,8) DEFAULT NULL COMMENT 'Latitudine location',
    location_lon DECIMAL(12,8) DEFAULT NULL COMMENT 'Longitudine location',
    timbratura_gps_mode VARCHAR(20) DEFAULT 'group',
    gps_timbratura_location VARCHAR(255),
    plan_start DATETIME,
    plan_end DATETIME,
    break_start TIME DEFAULT NULL COMMENT 'Inizio pausa',
    break_end TIME DEFAULT NULL COMMENT 'Fine pausa',
    break_minutes INT DEFAULT NULL COMMENT 'Durata pausa in minuti',
    hours_planned DECIMAL(10,2),
    hours_registered DECIMAL(10,2),
    remark TEXT,
    remark_planner TEXT,
    is_leader TINYINT(1) DEFAULT 0,
    transport VARCHAR(50),
    project_manager_name VARCHAR(255) DEFAULT NULL COMMENT 'Capo progetto (da account_manager Rentman)',
    vehicle_names TEXT DEFAULT NULL COMMENT 'Veicoli assegnati al progetto',
    vehicle_data TEXT DEFAULT NULL COMMENT 'Veicoli strutturati JSON [{id,name,plate}]',
    sent_to_webservice TINYINT(1) DEFAULT 0,
    sent_ts BIGINT DEFAULT NULL,
    webservice_response TEXT,
    is_obsolete TINYINT(1) DEFAULT 0 COMMENT 'Turno rimosso da Rentman',
    gestione_squadra TINYINT(1) DEFAULT 0 COMMENT 'Gestione attività a squadre (indipendente da is_leader)',
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    UNIQUE KEY uniq_rentman_planning (rentman_id, planning_date),
    INDEX idx_planning_date (planning_date),
    INDEX idx_planning_crew (crew_id),
    INDEX idx_planning_project (project_code),
    INDEX idx_planning_sent (sent_to_webservice),
    INDEX idx_planning_obsolete (is_obsolete)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

RENTMAN_PLANNINGS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS rentman_plannings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    rentman_id INTEGER NOT NULL,
    planning_date TEXT NOT NULL,
    crew_id INTEGER,
    crew_name TEXT,
    function_id INTEGER,
    function_name TEXT,
    project_id INTEGER,
    project_name TEXT,
    project_code TEXT,
    subproject_id INTEGER,
    location_id INTEGER,
    location_name TEXT,
    location_address TEXT,
    custom_location_ids TEXT DEFAULT NULL,
    location_lat REAL DEFAULT NULL,
    location_lon REAL DEFAULT NULL,
    timbratura_gps_mode TEXT DEFAULT 'group',
    gps_timbratura_location TEXT,
    plan_start TEXT,
    plan_end TEXT,
    break_start TEXT DEFAULT NULL,
    break_end TEXT DEFAULT NULL,
    break_minutes INTEGER DEFAULT NULL,
    hours_planned REAL,
    hours_registered REAL,
    remark TEXT,
    remark_planner TEXT,
    is_leader INTEGER DEFAULT 0,
    transport TEXT,
    project_manager_name TEXT DEFAULT NULL,
    vehicle_names TEXT DEFAULT NULL,
    vehicle_data TEXT DEFAULT NULL,
    sent_to_webservice INTEGER DEFAULT 0,
    sent_ts INTEGER DEFAULT NULL,
    webservice_response TEXT,
    is_obsolete INTEGER DEFAULT 0,
    gestione_squadra INTEGER DEFAULT 0,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL,
    UNIQUE(rentman_id, planning_date)
);
CREATE INDEX IF NOT EXISTS idx_planning_date ON rentman_plannings(planning_date);
CREATE INDEX IF NOT EXISTS idx_planning_crew ON rentman_plannings(crew_id);
CREATE INDEX IF NOT EXISTS idx_planning_project ON rentman_plannings(project_code);
CREATE INDEX IF NOT EXISTS idx_planning_sent ON rentman_plannings(sent_to_webservice);
CREATE INDEX IF NOT EXISTS idx_planning_obsolete ON rentman_plannings(is_obsolete);
"""

VEHICLE_DRIVERS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS vehicle_driver_assignments (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_id INT NOT NULL,
    planning_date DATE NOT NULL,
    vehicle_id INT NOT NULL,
    vehicle_name VARCHAR(255),
    driver_crew_id INT,
    driver_name VARCHAR(255),
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    UNIQUE KEY uniq_vehicle_driver (project_id, planning_date, vehicle_id),
    INDEX idx_vda_date (planning_date),
    INDEX idx_vda_project (project_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

VEHICLE_DRIVERS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS vehicle_driver_assignments (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id INTEGER NOT NULL,
    planning_date TEXT NOT NULL,
    vehicle_id INTEGER NOT NULL,
    vehicle_name TEXT,
    driver_crew_id INTEGER,
    driver_name TEXT,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL,
    UNIQUE(project_id, planning_date, vehicle_id)
);
CREATE INDEX IF NOT EXISTS idx_vda_date ON vehicle_driver_assignments(planning_date);
CREATE INDEX IF NOT EXISTS idx_vda_project ON vehicle_driver_assignments(project_id);
"""


# ═══════════════════════════════════════════════════════════════════════════════
#  FASI FUNZIONE - Sotto-attività per funzioni di pianificazione
# ═══════════════════════════════════════════════════════════════════════════════

PROJECT_PHASE_PROGRESS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS project_phase_progress (
    id INT AUTO_INCREMENT PRIMARY KEY,
    project_date DATE NOT NULL,
    project_key VARCHAR(300) NOT NULL COMMENT 'Identificativo progetto (project_code o project_name)',
    function_key VARCHAR(200) NOT NULL COMMENT 'Chiave template fasi (es. Montaggio)',
    phase_name VARCHAR(200) NOT NULL,
    phase_order INT NOT NULL DEFAULT 0,
    completed TINYINT(1) DEFAULT 0,
    completed_at BIGINT DEFAULT NULL,
    completed_by VARCHAR(100) DEFAULT NULL,
    notes TEXT DEFAULT NULL,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    UNIQUE KEY uq_project_phase (project_date, project_key, function_key, phase_name),
    INDEX idx_pp_date (project_date),
    INDEX idx_pp_project (project_key)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

PROJECT_PHASE_PROGRESS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS project_phase_progress (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_date TEXT NOT NULL,
    project_key TEXT NOT NULL,
    function_key TEXT NOT NULL,
    phase_name TEXT NOT NULL,
    phase_order INTEGER NOT NULL DEFAULT 0,
    completed INTEGER DEFAULT 0,
    completed_at INTEGER DEFAULT NULL,
    completed_by TEXT DEFAULT NULL,
    notes TEXT DEFAULT NULL,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL,
    UNIQUE(project_date, project_key, function_key, phase_name)
);
CREATE INDEX IF NOT EXISTS idx_pp_date ON project_phase_progress(project_date);
CREATE INDEX IF NOT EXISTS idx_pp_project ON project_phase_progress(project_key);
"""


# ═══════════════════════════════════════════════════════════════════════════════
#  REQUEST TYPES - TIPOLOGIE RICHIESTE (ferie, permessi, rimborsi, ecc.)
# ═══════════════════════════════════════════════════════════════════════════════

REQUEST_TYPES_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS request_types (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    value_type ENUM('hours', 'days', 'amount', 'km', 'minutes', 'timbratura') NOT NULL,
    external_id VARCHAR(100),
    abbreviation VARCHAR(10),
    description TEXT,
    active TINYINT(1) DEFAULT 1,
    sort_order INT DEFAULT 0,
    is_giustificativo TINYINT(1) DEFAULT 0,
    created_ts BIGINT NOT NULL DEFAULT 0,
    updated_ts BIGINT NOT NULL DEFAULT 0,
    INDEX idx_request_type_active (active),
    INDEX idx_request_type_value (value_type)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

REQUEST_TYPES_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS request_types (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    value_type TEXT NOT NULL CHECK(value_type IN ('hours', 'days', 'amount', 'km', 'minutes', 'timbratura')),
    external_id TEXT,
    abbreviation TEXT,
    description TEXT,
    active INTEGER DEFAULT 1,
    sort_order INTEGER DEFAULT 0,
    is_giustificativo INTEGER DEFAULT 0,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_request_type_active ON request_types(active);
CREATE INDEX IF NOT EXISTS idx_request_type_value ON request_types(value_type);
"""

# Tabella per le richieste degli utenti
USER_REQUESTS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS user_requests (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    username VARCHAR(100) NOT NULL,
    request_type_id INT NOT NULL,
    date_from DATE NOT NULL,
    date_to DATE,
    value_amount DECIMAL(10,2) NOT NULL,
    notes TEXT,
    cdc VARCHAR(100),
    attachment_path VARCHAR(500),
    status ENUM('pending', 'approved', 'rejected') DEFAULT 'pending',
    reviewed_by VARCHAR(100),
    reviewed_ts BIGINT,
    review_notes TEXT,
    created_ts BIGINT NOT NULL DEFAULT 0,
    updated_ts BIGINT NOT NULL DEFAULT 0,
    INDEX idx_request_user (user_id),
    INDEX idx_request_username (username),
    INDEX idx_request_status (status),
    INDEX idx_request_date (date_from),
    INDEX idx_request_type (request_type_id),
    FOREIGN KEY (request_type_id) REFERENCES request_types(id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

USER_REQUESTS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS user_requests (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    username TEXT NOT NULL,
    request_type_id INTEGER NOT NULL,
    date_from TEXT NOT NULL,
    date_to TEXT,
    value_amount REAL NOT NULL,
    notes TEXT,
    cdc TEXT,
    attachment_path TEXT,
    status TEXT DEFAULT 'pending' CHECK(status IN ('pending', 'approved', 'rejected')),
    reviewed_by TEXT,
    reviewed_ts INTEGER,
    review_notes TEXT,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL,
    FOREIGN KEY (request_type_id) REFERENCES request_types(id)
);
CREATE INDEX IF NOT EXISTS idx_request_user ON user_requests(user_id);
CREATE INDEX IF NOT EXISTS idx_request_username ON user_requests(username);
CREATE INDEX IF NOT EXISTS idx_request_status ON user_requests(status);
CREATE INDEX IF NOT EXISTS idx_request_date ON user_requests(date_from);
CREATE INDEX IF NOT EXISTS idx_request_type ON user_requests(request_type_id);
"""

# Tabella per i documenti aziendali (circolari, comunicazioni, buste paga)
USER_DOCUMENTS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS user_documents (
    id INT AUTO_INCREMENT PRIMARY KEY,
    category ENUM('circolare', 'comunicazione', 'busta_paga') NOT NULL,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    file_path VARCHAR(500),
    file_name VARCHAR(255),
    target_users JSON DEFAULT NULL,
    target_all BOOLEAN DEFAULT TRUE,
    created_by VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_doc_category (category),
    INDEX idx_doc_created (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

USER_DOCUMENTS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS user_documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    category TEXT NOT NULL CHECK(category IN ('circolare', 'comunicazione', 'busta_paga')),
    title TEXT NOT NULL,
    description TEXT,
    file_path TEXT,
    file_name TEXT,
    target_users TEXT DEFAULT NULL,
    target_all INTEGER DEFAULT 1,
    created_by TEXT NOT NULL,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP
);
CREATE INDEX IF NOT EXISTS idx_doc_category ON user_documents(category);
CREATE INDEX IF NOT EXISTS idx_doc_created ON user_documents(created_at);
"""

# Tabella per tracciare lettura documenti
USER_DOCUMENTS_READ_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS user_documents_read (
    id INT AUTO_INCREMENT PRIMARY KEY,
    document_id INT NOT NULL,
    username VARCHAR(100) NOT NULL,
    read_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY unique_read (document_id, username),
    FOREIGN KEY (document_id) REFERENCES user_documents(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

USER_DOCUMENTS_READ_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS user_documents_read (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id INTEGER NOT NULL,
    username TEXT NOT NULL,
    read_at TEXT DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(document_id, username),
    FOREIGN KEY (document_id) REFERENCES user_documents(id) ON DELETE CASCADE
)
"""

# ═══════════════════════════════════════════════════════════════════════════════
# STRAORDINARI (OVERTIME) - Tabelle e funzioni
# ═══════════════════════════════════════════════════════════════════════════════

OVERTIME_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS overtime_requests (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(100) NOT NULL,
    date DATE NOT NULL,
    session_id INT,
    planning_id INT,
    shift_source ENUM('rentman', 'manual', 'none') DEFAULT 'none',
    planned_start TIME,
    planned_end TIME,
    actual_start TIME,
    actual_end TIME,
    extra_minutes_before INT DEFAULT 0,
    extra_minutes_after INT DEFAULT 0,
    total_extra_minutes INT NOT NULL,
    overtime_type ENUM('before_shift', 'after_shift', 'both', 'extra_day') DEFAULT 'after_shift',
    notes TEXT,
    status ENUM('pending', 'approved', 'rejected') DEFAULT 'pending',
    reviewed_by VARCHAR(100),
    reviewed_ts BIGINT,
    review_notes TEXT,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    INDEX idx_overtime_user (username),
    INDEX idx_overtime_date (date),
    INDEX idx_overtime_status (status),
    INDEX idx_overtime_session (session_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

OVERTIME_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS overtime_requests (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT NOT NULL,
    date TEXT NOT NULL,
    session_id INTEGER,
    planning_id INTEGER,
    shift_source TEXT DEFAULT 'none' CHECK(shift_source IN ('rentman', 'manual', 'none')),
    planned_start TEXT,
    planned_end TEXT,
    actual_start TEXT,
    actual_end TEXT,
    extra_minutes_before INTEGER DEFAULT 0,
    extra_minutes_after INTEGER DEFAULT 0,
    total_extra_minutes INTEGER NOT NULL,
    overtime_type TEXT DEFAULT 'after_shift' CHECK(overtime_type IN ('before_shift', 'after_shift', 'both', 'extra_day')),
    notes TEXT,
    status TEXT DEFAULT 'pending' CHECK(status IN ('pending', 'approved', 'rejected')),
    reviewed_by TEXT,
    reviewed_ts INTEGER,
    review_notes TEXT,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_overtime_user ON overtime_requests(username);
CREATE INDEX IF NOT EXISTS idx_overtime_date ON overtime_requests(date);
CREATE INDEX IF NOT EXISTS idx_overtime_status ON overtime_requests(status);
CREATE INDEX IF NOT EXISTS idx_overtime_session ON overtime_requests(session_id);
"""


def ensure_overtime_table(db: DatabaseLike) -> None:
    """Crea la tabella overtime_requests se non esiste."""
    statement = (
        OVERTIME_TABLE_MYSQL if DB_VENDOR == "mysql" else OVERTIME_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    db.commit()


def _ensure_overtime_request_type(db: DatabaseLike) -> int:
    """
    Assicura che esista il tipo richiesta 'Extra Turno' e ritorna il suo ID.
    Questo tipo viene usato per le richieste di Extra Turno automatiche e manuali.
    
    Nota: Migra automaticamente il vecchio nome 'Straordinario' a 'Extra Turno'.
    """
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Prima cerca se esiste con il nuovo nome
    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Extra Turno",)
    ).fetchone()
    
    if row:
        return row["id"] if isinstance(row, Mapping) else row[0]
    
    # Cerca se esiste con il vecchio nome e rinominalo
    old_row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Straordinario",)
    ).fetchone()
    
    if old_row:
        # Rinomina da "Straordinario" a "Extra Turno"
        old_id = old_row["id"] if isinstance(old_row, Mapping) else old_row[0]
        db.execute(f"""
            UPDATE request_types 
            SET name = {placeholder}, description = {placeholder}
            WHERE id = {placeholder}
        """, ("Extra Turno", "Richiesta di riconoscimento ore di Extra Turno", old_id))
        db.commit()
        app.logger.info(f"Migrato tipo richiesta 'Straordinario' → 'Extra Turno' (id={old_id})")
        return old_id
    
    # Crea il tipo se non esiste
    db.execute(f"""
        INSERT INTO request_types (name, value_type, description, active, sort_order)
        VALUES ({placeholder}, {placeholder}, {placeholder}, 1, 100)
    """, ("Extra Turno", "minutes", "Richiesta di riconoscimento ore di Extra Turno"))
    db.commit()
    
    # Recupera l'ID appena creato
    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Extra Turno",)
    ).fetchone()
    
    return row["id"] if isinstance(row, Mapping) else row[0]


def _ensure_missed_punch_request_type(db: DatabaseLike) -> int:
    """
    Assicura che esista il tipo richiesta 'Mancata Timbratura' e ritorna il suo ID.
    """
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Cerca se esiste già
    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Mancata Timbratura",)
    ).fetchone()
    
    if row:
        return row["id"] if isinstance(row, Mapping) else row[0]
    
    # Crea il tipo se non esiste
    db.execute(f"""
        INSERT INTO request_types (name, value_type, description, active, sort_order)
        VALUES ({placeholder}, {placeholder}, {placeholder}, 1, 4)
    """, ("Mancata Timbratura", "timbratura", "Richiesta di inserimento timbratura mancante"))
    db.commit()
    
    # Recupera l'ID appena creato
    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Mancata Timbratura",)
    ).fetchone()
    
    return row["id"] if isinstance(row, Mapping) else row[0]


def _ensure_late_arrival_request_type(db: DatabaseLike) -> int:
    """
    Assicura che esista il tipo richiesta 'Giustificazione Ritardo' e ritorna il suo ID.
    """
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Cerca se esiste già
    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Giustificazione Ritardo",)
    ).fetchone()
    
    if row:
        return row["id"] if isinstance(row, Mapping) else row[0]
    
    # Crea il tipo se non esiste
    db.execute(f"""
        INSERT INTO request_types (name, value_type, description, active, sort_order)
        VALUES ({placeholder}, {placeholder}, {placeholder}, 1, 5)
    """, ("Giustificazione Ritardo", "minutes", "Giustificazione per timbratura in ritardo"))
    db.commit()
    
    # Recupera l'ID appena creato
    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Giustificazione Ritardo",)
    ).fetchone()
    
    return row["id"] if isinstance(row, Mapping) else row[0]


def get_overtime_request_type_id(db: DatabaseLike) -> int:
    """Ritorna l'ID del tipo richiesta 'Extra Turno', creandolo se necessario."""
    ensure_request_types_table(db)
    return _ensure_overtime_request_type(db)


def ensure_request_types_table(db: DatabaseLike) -> None:
    """Crea la tabella request_types se non esiste."""
    statement = (
        REQUEST_TYPES_TABLE_MYSQL if DB_VENDOR == "mysql" else REQUEST_TYPES_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Migrazione MySQL: aggiungi DEFAULT alle colonne timestamp se mancante
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE request_types MODIFY COLUMN created_ts BIGINT NOT NULL DEFAULT 0")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE request_types MODIFY COLUMN updated_ts BIGINT NOT NULL DEFAULT 0")
            db.commit()
        except Exception:
            pass
        # Poi aggiungi 'minutes' e 'timbratura' all'ENUM
        try:
            db.execute("""
                ALTER TABLE request_types 
                MODIFY COLUMN value_type ENUM('hours', 'days', 'amount', 'km', 'minutes', 'timbratura') NOT NULL
            """)
            db.commit()
            app.logger.info("Migrazione ENUM value_type completata con successo")
        except Exception as e:
            app.logger.warning(f"Migrazione ENUM value_type: {e}")
        
        # Migrazione: aggiungi colonna abbreviation se non esiste
        try:
            db.execute("ALTER TABLE request_types ADD COLUMN abbreviation VARCHAR(10)")
            db.commit()
            app.logger.info("Migrazione: aggiunta colonna abbreviation a request_types")
        except Exception:
            pass  # Colonna già esiste
        
        # Migrazione: aggiungi colonna external_id se non esiste
        try:
            db.execute("ALTER TABLE request_types ADD COLUMN external_id VARCHAR(100)")
            db.commit()
            app.logger.info("Migrazione: aggiunta colonna external_id a request_types")
        except Exception:
            pass  # Colonna già esiste
        
        # Migrazione: aggiungi colonna is_giustificativo se non esiste
        try:
            db.execute("ALTER TABLE request_types ADD COLUMN is_giustificativo TINYINT(1) DEFAULT 0")
            db.commit()
            app.logger.info("Migrazione: aggiunta colonna is_giustificativo a request_types")
        except Exception:
            pass  # Colonna già esiste
    
    # Assicura che esista il tipo "Extra Turno" per le richieste automatiche
    _ensure_overtime_request_type(db)
    
    # Assicura che esista il tipo "Mancata Timbratura"
    _ensure_missed_punch_request_type(db)
    
    # Assicura che esista il tipo "Giustificazione Ritardo"
    _ensure_late_arrival_request_type(db)

    # Assicura che esista il tipo "Deroga Pausa Ridotta"
    _ensure_break_reduction_request_type(db)


def ensure_user_requests_table(db: DatabaseLike) -> None:
    """Crea la tabella user_requests se non esiste e aggiunge colonne mancanti."""
    statement = (
        USER_REQUESTS_TABLE_MYSQL if DB_VENDOR == "mysql" else USER_REQUESTS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Migrazione MySQL: aggiungi DEFAULT alle colonne timestamp se mancante
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE user_requests MODIFY COLUMN created_ts BIGINT NOT NULL DEFAULT 0")
            db.commit()
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE user_requests MODIFY COLUMN updated_ts BIGINT NOT NULL DEFAULT 0")
            db.commit()
        except Exception:
            pass
    
    # Aggiungi colonne mancanti se la tabella esisteva già
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE user_requests ADD COLUMN cdc VARCHAR(100)")
            db.commit()
    except Exception:
        pass  # Colonna già esiste
    
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE user_requests ADD COLUMN attachment_path VARCHAR(500)")
            db.commit()
    except Exception:
        pass  # Colonna già esiste
    
    # Migrazione: aggiungi colonna tratte per rimborsi km
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE user_requests ADD COLUMN tratte JSON DEFAULT NULL")
        else:
            db.execute("ALTER TABLE user_requests ADD COLUMN tratte TEXT DEFAULT NULL")
        db.commit()
    except Exception:
        pass  # Colonna già esiste
    
    # Migrazione: aggiungi colonna extra_data per dati aggiuntivi (es. straordinari)
    try:
        if DB_VENDOR == "mysql":
            db.execute("ALTER TABLE user_requests ADD COLUMN extra_data JSON DEFAULT NULL")
        else:
            db.execute("ALTER TABLE user_requests ADD COLUMN extra_data TEXT DEFAULT NULL")
        db.commit()
    except Exception:
        pass  # Colonna già esiste


def ensure_user_documents_table(db: DatabaseLike) -> None:
    """Crea le tabelle user_documents e user_documents_read se non esistono."""
    # Tabella documenti
    statement = (
        USER_DOCUMENTS_TABLE_MYSQL if DB_VENDOR == "mysql" else USER_DOCUMENTS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Aggiungi colonna notified_at se non esiste
    existing = _get_existing_columns(db, "user_documents")
    if "notified_at" not in existing:
        col_type = "BIGINT" if DB_VENDOR == "mysql" else "INTEGER"
        try:
            db.execute(f"ALTER TABLE user_documents ADD COLUMN notified_at {col_type} DEFAULT NULL")
            db.commit()
        except Exception:
            pass
    
    # Tabella letture
    statement = (
        USER_DOCUMENTS_READ_TABLE_MYSQL if DB_VENDOR == "mysql" else USER_DOCUMENTS_READ_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass


def ensure_rentman_plannings_table(db: DatabaseLike) -> None:
    """Crea la tabella rentman_plannings se non esiste."""
    statement = (
        RENTMAN_PLANNINGS_TABLE_MYSQL if DB_VENDOR == "mysql" else RENTMAN_PLANNINGS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    
    # Migrazione: aggiungi colonne location se non esistono
    if DB_VENDOR == "mysql":
        try:
            # Verifica se la colonna esiste già
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'location_id'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN subproject_id INT AFTER project_code")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN location_id INT AFTER subproject_id")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN location_name VARCHAR(500) AFTER location_id")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN location_address VARCHAR(500) AFTER location_name")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunte colonne location")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings location: {e}")
        
        # Migrazione: aggiungi colonne plan_start e plan_end se non esistono
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'plan_start'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN plan_start DATETIME DEFAULT NULL AFTER location_address")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN plan_end DATETIME DEFAULT NULL AFTER plan_start")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunte colonne plan_start e plan_end")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings plan_start/plan_end: {e}")
        
        # Migrazione: aggiungi colonne pausa se non esistono
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'break_start'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN break_start TIME DEFAULT NULL AFTER plan_end")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN break_end TIME DEFAULT NULL AFTER break_start")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN break_minutes INT DEFAULT NULL AFTER break_end")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunte colonne pausa")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings pausa: {e}")
        
        # Migrazione: aggiungi colonna custom_location_ids se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'custom_location_ids'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN custom_location_ids TEXT AFTER location_address")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna custom_location_ids")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings custom_location_ids: {e}")

        # Migrazione: aggiungi colonna timbratura_gps_mode se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'timbratura_gps_mode'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN timbratura_gps_mode VARCHAR(20) DEFAULT 'group' AFTER location_address")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna timbratura_gps_mode")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings timbratura_gps_mode: {e}")

        # Migrazione: aggiungi colonna gps_timbratura_location se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'gps_timbratura_location'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN gps_timbratura_location VARCHAR(255) AFTER timbratura_gps_mode")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna gps_timbratura_location")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings gps_timbratura_location: {e}")
        # Migrazione: aggiungi colonna is_obsolete se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'is_obsolete'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN is_obsolete TINYINT(1) DEFAULT 0 AFTER webservice_response")
                db.execute("CREATE INDEX idx_planning_obsolete ON rentman_plannings(is_obsolete)")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna is_obsolete")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings is_obsolete: {e}")
    # fine if DB_VENDOR mysql
    else:
        # SQLite migrations for additional columns
        try:
            db.execute("ALTER TABLE rentman_plannings ADD COLUMN custom_location_ids TEXT")
        except Exception:
            pass
        
        # Migrazione: aggiungi colonne location_lat e location_lon se non esistono
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'location_lat'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN location_lat DECIMAL(12,8) DEFAULT NULL AFTER location_address")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN location_lon DECIMAL(12,8) DEFAULT NULL AFTER location_lat")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunte colonne location_lat e location_lon")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings location_lat/lon: {e}")
        
        # Migrazione: aggiungi colonna remark_planner se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'remark_planner'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN remark_planner TEXT AFTER remark")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna remark_planner")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings remark_planner: {e}")

        # Migrazione: aggiungi colonne project_manager_name e vehicle_names se non esistono
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'project_manager_name'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN project_manager_name VARCHAR(255) DEFAULT NULL AFTER transport")
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN vehicle_names TEXT DEFAULT NULL AFTER project_manager_name")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunte colonne project_manager_name e vehicle_names")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings project_manager/vehicle: {e}")

        # Migrazione: aggiungi colonna vehicle_data se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'vehicle_data'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN vehicle_data TEXT DEFAULT NULL AFTER vehicle_names")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna vehicle_data")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings vehicle_data: {e}")

        # Migrazione: aggiungi colonna gestione_squadra se non esiste
        try:
            cursor = db.execute("SHOW COLUMNS FROM rentman_plannings LIKE 'gestione_squadra'")
            if not cursor.fetchone():
                db.execute("ALTER TABLE rentman_plannings ADD COLUMN gestione_squadra TINYINT(1) DEFAULT 0")
                db.commit()
                app.logger.info("Migrazione rentman_plannings: aggiunta colonna gestione_squadra")
        except Exception as e:
            app.logger.warning(f"Migrazione rentman_plannings gestione_squadra: {e}")
    # SQLite migrations (quando non Mysql)
    if DB_VENDOR != "mysql":
        migrations_sqlite = [
            "ALTER TABLE rentman_plannings ADD COLUMN break_start TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN break_end TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN break_minutes INTEGER DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN timbratura_gps_mode TEXT DEFAULT 'group'",
            "ALTER TABLE rentman_plannings ADD COLUMN gps_timbratura_location TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN is_obsolete INTEGER DEFAULT 0",
            "ALTER TABLE rentman_plannings ADD COLUMN location_lat REAL DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN location_lon REAL DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN remark_planner TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN project_manager_name TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN vehicle_names TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN vehicle_data TEXT DEFAULT NULL",
            "ALTER TABLE rentman_plannings ADD COLUMN gestione_squadra INTEGER DEFAULT 0",
        ]
        for migration in migrations_sqlite:
            try:
                db.execute(migration)
                db.commit()
            except Exception:
                pass  # Colonna già esistente


def ensure_vehicle_drivers_table(db: DatabaseLike) -> None:
    """Crea la tabella vehicle_driver_assignments se non esiste."""
    statement = (
        VEHICLE_DRIVERS_TABLE_MYSQL if DB_VENDOR == "mysql" else VEHICLE_DRIVERS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        try:
            cursor = db.execute(sql)
            try:
                cursor.close()
            except AttributeError:
                pass
        except Exception:
            pass


def ensure_project_phase_progress_table(db: DatabaseLike) -> None:
    """Crea la tabella project_phase_progress se non esiste."""
    statement = (
        PROJECT_PHASE_PROGRESS_TABLE_MYSQL if DB_VENDOR == "mysql" else PROJECT_PHASE_PROGRESS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        try:
            cursor = db.execute(sql)
            try:
                cursor.close()
            except AttributeError:
                pass
        except Exception:
            pass
    db.commit()


def get_function_phases_config(db: DatabaseLike) -> dict:
    """Legge la configurazione fasi funzione da custom_settings.
    
    Returns:
        dict con chiave = nome funzione, valore = { 'match_mode': 'contains'|'exact',
                                                      'phases': [{'name': str, 'order': int}] }
    """
    settings = get_company_settings(db)
    custom = settings.get('custom_settings', {}) if isinstance(settings.get('custom_settings'), dict) else {}
    return custom.get('function_phases', {})


def get_phases_for_function(db: DatabaseLike, function_name: str) -> list:
    """Trova le fasi applicabili a una funzione, in base al matching.
    
    Returns:
        list di {'name': str, 'order': int, 'function_key': str} ordinate per order.
        Vuoto se nessun template corrisponde.
    """
    if not function_name:
        return []
    config = get_function_phases_config(db)
    fn_lower = function_name.lower().strip()
    
    for key, template in config.items():
        key_lower = key.lower().strip()
        
        if fn_lower == key_lower:
            phases = template.get('phases', [])
            result = []
            for p in phases:
                result.append({
                    'name': p.get('name', ''),
                    'order': p.get('order', 0),
                    'function_key': key
                })
            result.sort(key=lambda x: x['order'])
            return result
    
    return []


# ═══════════════════════════════════════════════════════════════════════════════
#  PIANIFICAZIONI RENTMAN - ROUTES
# ═══════════════════════════════════════════════════════════════════════════════


def get_joblog_hours_for_date(db: DatabaseLike, target_date: str) -> Dict[str, float]:
    """
    Calcola le ore registrate in JobLog per ogni operatore in una data specifica.
    
    Returns:
        Dict con member_name.lower() come chiave e ore totali come valore.
    """
    try:
        from datetime import datetime as dt_parse
        # Parse target date
        target_dt = dt_parse.strptime(target_date, "%Y-%m-%d").date()
    except ValueError:
        app.logger.warning(f"Data non valida per JobLog hours: {target_date}")
        return {}
    
    # Calcola timestamp inizio e fine giornata
    start_of_day = dt_parse.combine(target_dt, dt_parse.min.time())
    end_of_day = dt_parse.combine(target_dt, dt_parse.max.time())
    start_ts = int(start_of_day.timestamp() * 1000)
    end_ts = int(end_of_day.timestamp() * 1000)
    
    # Query per eventi finish_activity con duration_ms
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    query = f"""
        SELECT el.ts, el.member_key, el.details, ms.member_name
        FROM event_log el
        LEFT JOIN member_state ms ON el.member_key = ms.member_key AND el.project_code = ms.project_code
        WHERE el.kind = 'finish_activity'
        AND el.ts >= {placeholder} AND el.ts <= {placeholder}
    """
    
    try:
        rows = db.execute(query, (start_ts, end_ts)).fetchall()
    except Exception as exc:
        app.logger.error(f"Errore query JobLog hours: {exc}")
        return {}
    
    # Accumula ore per operatore
    hours_by_member: Dict[str, float] = {}
    
    for row in rows:
        try:
            details = json.loads(row["details"]) if row["details"] else {}
        except json.JSONDecodeError:
            continue
        
        duration_ms = details.get("duration_ms", 0)
        if not duration_ms:
            continue
        
        # Usa member_name dalla tabella member_state o dai dettagli evento
        member_name = row["member_name"] or details.get("member_name") or row["member_key"]
        if not member_name:
            continue
        
        # Normalizza il nome (lowercase) per il matching
        member_name_lower = member_name.strip().lower()
        
        # Converti ms in ore
        hours = duration_ms / (1000 * 60 * 60)
        
        if member_name_lower in hours_by_member:
            hours_by_member[member_name_lower] += hours
        else:
            hours_by_member[member_name_lower] = hours
    
    return hours_by_member


def match_crew_name_to_joblog(crew_name: str, joblog_hours: Dict[str, float]) -> Optional[float]:
    """
    Cerca di matchare un nome operatore Rentman con i dati JobLog.
    Usa matching esatto e fuzzy sul nome.
    """
    if not crew_name:
        return None
    
    crew_lower = crew_name.strip().lower()
    
    # 1. Match esatto
    if crew_lower in joblog_hours:
        return joblog_hours[crew_lower]
    
    # 2. Prova a confrontare parti del nome
    crew_parts = set(crew_lower.split())
    
    for member_name, hours in joblog_hours.items():
        member_parts = set(member_name.split())
        
        # Se almeno 2 parole coincidono, o se una parola è contenuta nell'altra
        common = crew_parts & member_parts
        if len(common) >= 2:
            return hours
        
        # Se il nome completo è contenuto
        if crew_lower in member_name or member_name in crew_lower:
            return hours
        
        # Match su cognome (tipicamente la seconda parola)
        crew_words = crew_lower.split()
        member_words = member_name.split()
        
        # Se hanno almeno 2 parole e la seconda (cognome) coincide
        if len(crew_words) >= 2 and len(member_words) >= 2:
            if crew_words[1] == member_words[1]:
                return hours
    
    return None


@app.get("/admin/rentman-planning")
@login_required
def admin_rentman_planning_page() -> ResponseReturnValue:
    """Pagina pianificazioni Rentman."""
    if not is_admin_or_supervisor():
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    return render_template(
        "admin_rentman_planning.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=bool(session.get("is_admin")),
    )


@app.get("/admin/locations")
@login_required
def admin_locations_page() -> ResponseReturnValue:
    """Pagina gestione location GPS."""
    if not is_admin_or_supervisor():
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    return render_template(
        "admin_locations.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=bool(session.get("is_admin")),
    )


@app.get("/api/admin/locations")
@login_required
def api_admin_locations_list() -> ResponseReturnValue:
    """Restituisce tutte le location (da Rentman + custom) con stato coordinate."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    db = get_db()
    ensure_rentman_plannings_table(db)
    ensure_location_cache_table(db)

    # Recupera tutte le location univoche da Rentman (location_name non NULL)
    locations_rows = db.execute("""
        SELECT DISTINCT location_name, location_address
        FROM rentman_plannings
        WHERE location_name IS NOT NULL AND location_name != ''
        ORDER BY location_name
    """).fetchall()

    locations = []
    seen_names = set()
    for row in locations_rows:
        location_name = row["location_name"] if isinstance(row, dict) else row[0]
        location_address = row["location_address"] if isinstance(row, dict) else row[1]

        # Controlla se ha coordinate in cache (ora restituisce anche il raggio)
        cached = get_location_cache(db, location_name)

        locations.append({
            "name": location_name,
            "address": location_address or "",
            "has_cache": cached is not None,
            "latitude": cached[0] if cached else None,
            "longitude": cached[1] if cached else None,
            "radius_meters": cached[2] if cached else 300,
            "is_custom": False,
        })
        seen_names.add(location_name)

    # Aggiungi le location custom dalla tabella location_cache
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    custom_rows = db.execute(
        "SELECT id, location_name, latitude, longitude, radius_meters, address FROM location_cache WHERE is_custom = 1 ORDER BY location_name"
    ).fetchall()
    for row in custom_rows:
        loc_name = row["location_name"] if isinstance(row, dict) else row[1]
        if loc_name in seen_names:
            continue
        loc_lat = row["latitude"] if isinstance(row, dict) else row[2]
        loc_lon = row["longitude"] if isinstance(row, dict) else row[3]
        loc_radius = row["radius_meters"] if isinstance(row, dict) else row[4]
        loc_address = row["address"] if isinstance(row, dict) else row[5]
        loc_id = row["id"] if isinstance(row, dict) else row[0]
        locations.append({
            "name": loc_name,
            "address": loc_address or "",
            "has_cache": True,
            "latitude": float(loc_lat) if loc_lat else None,
            "longitude": float(loc_lon) if loc_lon else None,
            "radius_meters": int(loc_radius) if loc_radius else 300,
            "is_custom": True,
            "custom_id": loc_id,
        })

    return jsonify({"locations": locations})


@app.post("/api/admin/locations/<location_name>")
@login_required
def api_admin_locations_save(location_name: str) -> ResponseReturnValue:
    """Salva le coordinate e il raggio per una location."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    data = request.get_json() or {}
    latitude = data.get("latitude")
    longitude = data.get("longitude")
    radius_meters = data.get("radius_meters", 300)

    if latitude is None or longitude is None:
        return jsonify({"error": "Latitudine e longitudine richieste"}), 400

    try:
        latitude = float(latitude)
        longitude = float(longitude)
        radius_meters = int(radius_meters) if radius_meters else 300
    except (ValueError, TypeError):
        return jsonify({"error": "Coordinate non valide"}), 400

    db = get_db()
    save_location_cache(db, location_name, latitude, longitude, radius_meters=radius_meters)

    return jsonify({"ok": True, "message": f"Coordinate salvate per {location_name} (raggio: {radius_meters}m)"})


@app.post("/api/admin/locations/custom")
@login_required
def api_admin_locations_create_custom() -> ResponseReturnValue:
    """Crea una nuova location custom (non da Rentman)."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    data = request.get_json() or {}
    location_name = (data.get("name") or "").strip()
    latitude = data.get("latitude")
    longitude = data.get("longitude")
    radius_meters = data.get("radius_meters", 300)
    address = (data.get("address") or "").strip()

    if not location_name:
        return jsonify({"error": "Nome location richiesto"}), 400
    if latitude is None or longitude is None:
        return jsonify({"error": "Latitudine e longitudine richieste"}), 400

    try:
        latitude = float(latitude)
        longitude = float(longitude)
        radius_meters = int(radius_meters) if radius_meters else 300
    except (ValueError, TypeError):
        return jsonify({"error": "Coordinate non valide"}), 400

    if latitude < -90 or latitude > 90:
        return jsonify({"error": "Latitudine non valida (-90 a 90)"}), 400
    if longitude < -180 or longitude > 180:
        return jsonify({"error": "Longitudine non valida (-180 a 180)"}), 400

    db = get_db()
    ensure_location_cache_table(db)

    # Controlla se esiste già una location con lo stesso nome
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    existing = db.execute(
        f"SELECT id FROM location_cache WHERE location_name = {placeholder}",
        (location_name,)
    ).fetchone()
    if existing:
        return jsonify({"error": f"Una location con il nome '{location_name}' esiste già"}), 409

    save_location_cache(db, location_name, latitude, longitude, radius_meters=radius_meters, is_custom=1, address=address)
    app.logger.info(f"📍 Location custom creata: {location_name} ({latitude}, {longitude}), raggio={radius_meters}m")

    return jsonify({"ok": True, "message": f"Location custom '{location_name}' creata con successo"})


@app.put("/api/admin/locations/custom/<int:location_id>")
@login_required
def api_admin_locations_update_custom(location_id: int) -> ResponseReturnValue:
    """Aggiorna una location custom esistente."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    data = request.get_json() or {}
    location_name = (data.get("name") or "").strip()
    latitude = data.get("latitude")
    longitude = data.get("longitude")
    radius_meters = data.get("radius_meters", 300)
    address = (data.get("address") or "").strip()

    if not location_name:
        return jsonify({"error": "Nome location richiesto"}), 400
    if latitude is None or longitude is None:
        return jsonify({"error": "Latitudine e longitudine richieste"}), 400

    try:
        latitude = float(latitude)
        longitude = float(longitude)
        radius_meters = int(radius_meters) if radius_meters else 300
    except (ValueError, TypeError):
        return jsonify({"error": "Coordinate non valide"}), 400

    db = get_db()
    ensure_location_cache_table(db)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now = int(datetime.now().timestamp() * 1000)

    db.execute(
        f"UPDATE location_cache SET location_name = {placeholder}, latitude = {placeholder}, longitude = {placeholder}, radius_meters = {placeholder}, address = {placeholder}, updated_ts = {placeholder} WHERE id = {placeholder} AND is_custom = 1",
        (location_name, latitude, longitude, radius_meters, address, now, location_id)
    )
    db.commit()

    return jsonify({"ok": True, "message": f"Location custom '{location_name}' aggiornata"})


@app.delete("/api/admin/locations/custom/<int:location_id>")
@login_required
def api_admin_locations_delete_custom(location_id: int) -> ResponseReturnValue:
    """Elimina una location custom."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    db = get_db()
    ensure_location_cache_table(db)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    # Verifica che sia davvero una location custom
    row = db.execute(
        f"SELECT location_name FROM location_cache WHERE id = {placeholder} AND is_custom = 1",
        (location_id,)
    ).fetchone()

    if not row:
        return jsonify({"error": "Location custom non trovata"}), 404

    location_name = row["location_name"] if isinstance(row, dict) else row[0]

    db.execute(
        f"DELETE FROM location_cache WHERE id = {placeholder} AND is_custom = 1",
        (location_id,)
    )
    db.commit()

    app.logger.info(f"🗑️ Location custom eliminata: {location_name} (id={location_id})")
    return jsonify({"ok": True, "message": f"Location custom '{location_name}' eliminata"})


@app.get("/api/admin/locations/custom")
@login_required
def api_admin_locations_list_custom() -> ResponseReturnValue:
    """Restituisce solo le location custom (per il selettore nel planning)."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "Accesso negato"}), 403

    db = get_db()
    ensure_location_cache_table(db)

    rows = db.execute(
        "SELECT id, location_name, latitude, longitude, radius_meters, address FROM location_cache WHERE is_custom = 1 ORDER BY location_name"
    ).fetchall()

    locations = []
    for row in rows:
        locations.append({
            "id": row["id"] if isinstance(row, dict) else row[0],
            "name": row["location_name"] if isinstance(row, dict) else row[1],
            "latitude": float(row["latitude"] if isinstance(row, dict) else row[2]),
            "longitude": float(row["longitude"] if isinstance(row, dict) else row[3]),
            "radius_meters": int(row["radius_meters"] if isinstance(row, dict) else row[4]) if (row["radius_meters"] if isinstance(row, dict) else row[4]) else 300,
            "address": (row["address"] if isinstance(row, dict) else row[5]) or "",
        })

    return jsonify({"locations": locations})


@app.get("/api/admin/rentman-planning")
@login_required
def api_admin_rentman_planning() -> ResponseReturnValue:
    """API per recuperare pianificazioni Rentman per una data."""
    app.logger.warning("🔴🔴🔴 INIZIO /api/admin/rentman-planning")
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    target_date = request.args.get("date")
    if not target_date:
        target_date = datetime.now().date().isoformat()
    
    app.logger.warning(f"🔴 API rentman-planning: target_date={target_date}")

    try:
        from rentman_client import RentmanClient, RentmanError
        client = RentmanClient()
    except Exception as exc:
        app.logger.warning("Rentman client non disponibile: %s", exc)
        return jsonify({"error": "Rentman non configurato", "details": str(exc)}), 500

    try:
        plannings = client.get_crew_plannings_by_date(target_date)
    except ValueError as exc:
        return jsonify({"error": str(exc)}), 400
    except RentmanError as exc:
        return jsonify({"error": "Errore Rentman", "details": str(exc)}), 500

    app.logger.info(f"📥 RENTMAN: Ricevuti {len(plannings)} turni per {target_date}")
    for idx, p in enumerate(plannings):
        crew_name = p.get("displayname", "?")
        start = p.get("planperiod_start", "?")
        end = p.get("planperiod_end", "?")
        app.logger.info(f"  [{idx}] {crew_name}: {start} - {end}")

    # DEBUG: Log tutti i campi della prima pianificazione per capire la struttura
    if plannings:
        app.logger.info("Rentman planning fields: %s", list(plannings[0].keys()))
        app.logger.info("Rentman first planning data: %s", plannings[0])

    # Calcola ore JobLog per questa data
    db = get_db()
    joblog_hours = get_joblog_hours_for_date(db, target_date)

    # Arricchisci i dati con info su crew e progetto
    # Cache per evitare chiamate duplicate
    crew_cache: Dict[int, Dict[str, Any]] = {}
    function_cache: Dict[int, Dict[str, Any]] = {}
    project_cache: Dict[int, Dict[str, Any]] = {}
    subproject_cache: Dict[int, Dict[str, Any]] = {}
    contact_cache: Dict[int, Dict[str, Any]] = {}
    vehicle_cache: Dict[int, Any] = {}  # vehicle_id -> vehicle data
    project_vehicles_cache: Dict[int, str] = {}  # project_id -> vehicle names string
    project_manager_cache: Dict[int, str] = {}  # project_id -> manager name
    function_group_cache: Dict[int, Dict[str, Any]] = {}  # function_group_id -> group data
    project_function_groups_loaded: Set[int] = set()  # project_ids già caricati
    
    # Pre-carica mapping rentman_crew_id -> group_id da app_users
    ensure_user_groups_table(db)
    
    # Carica utenti JobLog con il loro rentman_crew_id e group_id
    crew_group_map: Dict[int, int] = {}  # rentman_crew_id -> group_id
    if DB_VENDOR == "mysql":
        user_rows = db.execute("SELECT rentman_crew_id, group_id FROM app_users WHERE rentman_crew_id IS NOT NULL AND group_id IS NOT NULL").fetchall()
    else:
        user_rows = db.execute("SELECT rentman_crew_id, group_id FROM app_users WHERE rentman_crew_id IS NOT NULL AND group_id IS NOT NULL").fetchall()
    for row in user_rows:
        rentman_crew_id = row["rentman_crew_id"] if isinstance(row, Mapping) else row[0]
        group_id = row["group_id"] if isinstance(row, Mapping) else row[1]
        if rentman_crew_id and group_id:
            crew_group_map[rentman_crew_id] = group_id
    
    app.logger.info("crew_group_map (da app_users): %s", crew_group_map)
    
    # Carica tutti i gruppi con la loro sede GPS
    group_gps_map: Dict[int, str] = {}  # group_id -> gps_location_name
    if DB_VENDOR == "mysql":
        group_rows = db.execute("SELECT id, gps_location_name FROM user_groups WHERE gps_location_name IS NOT NULL AND gps_location_name != ''").fetchall()
    else:
        group_rows = db.execute("SELECT id, gps_location_name FROM user_groups WHERE gps_location_name IS NOT NULL AND gps_location_name != ''").fetchall()
    for row in group_rows:
        group_id = row["id"] if isinstance(row, Mapping) else row[0]
        gps_loc = row["gps_location_name"] if isinstance(row, Mapping) else row[1]
        if group_id and gps_loc:
            group_gps_map[group_id] = gps_loc
    
    app.logger.info("group_gps_map: %s", group_gps_map)

    results = []
    for planning in plannings:
        # Estrai ID dal riferimento (es. "/crew/123" -> 123)
        crew_ref = planning.get("crewmember", "")
        crew_id = None
        if crew_ref and "/" in crew_ref:
            try:
                crew_id = int(crew_ref.split("/")[-1])
            except (ValueError, IndexError):
                pass

        function_ref = planning.get("function", "")
        function_id = None
        if function_ref and "/" in function_ref:
            try:
                function_id = int(function_ref.split("/")[-1])
            except (ValueError, IndexError):
                pass

        # Recupera dettagli crew
        crew_name = planning.get("displayname", "")
        if crew_id and crew_id not in crew_cache:
            crew_data = client.get_crew_member(crew_id)
            if crew_data:
                crew_cache[crew_id] = crew_data
        if crew_id and crew_id in crew_cache:
            cd = crew_cache[crew_id]
            crew_name = cd.get("displayname") or f"{cd.get('firstname', '')} {cd.get('lastname', '')}".strip() or crew_name

        # Recupera dettagli funzione, progetto e location
        project_name = ""
        project_code = ""
        project_id = None
        function_name = ""
        function_group_name = ""
        subproject_id = None
        location_id = None
        location_name = ""
        location_address = ""
        location_lat = None
        location_lon = None
        
        if function_id and function_id not in function_cache:
            func_data = client.get_project_function(function_id)
            if func_data:
                function_cache[function_id] = func_data
        if function_id and function_id in function_cache:
            fd = function_cache[function_id]
            function_name = fd.get("name") or fd.get("displayname") or ""
            
            # Estrai function group (fase) dalla funzione
            group_ref = fd.get("group", "")
            if group_ref and "/projectfunctiongroups/" in str(group_ref):
                try:
                    fg_id = int(str(group_ref).split("/")[-1])
                    if fg_id in function_group_cache:
                        function_group_name = function_group_cache[fg_id].get("name", "")
                except (ValueError, IndexError):
                    pass
            
            # Estrai subproject dalla funzione
            subproject_ref = fd.get("subproject", "")
            if subproject_ref and "/" in subproject_ref:
                try:
                    subproject_id = int(subproject_ref.split("/")[-1])
                    if subproject_id not in subproject_cache:
                        subproj_data = client.get_subproject(subproject_id)
                        if subproj_data:
                            subproject_cache[subproject_id] = subproj_data
                    if subproject_id in subproject_cache:
                        sp = subproject_cache[subproject_id]
                        # Estrai location dal subproject (è un riferimento a /contacts/ID)
                        location_ref = sp.get("location", "")
                        if location_ref and "/" in location_ref:
                            try:
                                location_id = int(location_ref.split("/")[-1])
                                if location_id not in contact_cache:
                                    contact_data = client.get_contact(location_id)
                                    if contact_data:
                                        contact_cache[location_id] = contact_data
                                if location_id in contact_cache:
                                    ct = contact_cache[location_id]
                                    location_name = ct.get("displayname") or ct.get("name") or ""
                                    # Costruisci indirizzo completo dai campi visit_*
                                    addr_parts = []
                                    if ct.get("visit_street"):
                                        addr_parts.append(ct.get("visit_street"))
                                        if ct.get("visit_number") and ct.get("visit_number") != "S.n.":
                                            addr_parts[-1] += " " + ct.get("visit_number")
                                    if ct.get("visit_postalcode"):
                                        addr_parts.append(ct.get("visit_postalcode"))
                                    if ct.get("visit_city"):
                                        addr_parts.append(ct.get("visit_city"))
                                    if ct.get("visit_state"):
                                        addr_parts.append(f"({ct.get('visit_state')})")
                                    location_address = ", ".join(addr_parts) if addr_parts else ""
                                    # Recupera coordinate se disponibili (non null)
                                    lat = ct.get("latitude")
                                    lon = ct.get("longitude")
                                    if lat is not None and lon is not None:
                                        try:
                                            location_lat = float(lat)
                                            location_lon = float(lon)
                                        except (ValueError, TypeError):
                                            pass
                                    elif location_address:
                                        # Rentman non fornisce coordinate, prova geocoding dall'indirizzo
                                        coords = geocode_address(location_address)
                                        if coords:
                                            location_lat, location_lon = coords
                            except (ValueError, IndexError):
                                pass
                except (ValueError, IndexError):
                    pass
            
            # Estrai progetto dalla funzione
            project_ref = fd.get("project", "")
            if project_ref and "/" in project_ref:
                try:
                    project_id = int(project_ref.split("/")[-1])
                    if project_id not in project_cache:
                        proj_data = client.get_project(project_id)
                        if proj_data:
                            project_cache[project_id] = proj_data
                    if project_id in project_cache:
                        pd = project_cache[project_id]
                        project_name = pd.get("name") or pd.get("displayname") or ""
                        project_code = pd.get("number") or pd.get("reference") or ""
                        
                        # Carica function groups (fasi) per questo progetto (una volta sola)
                        if project_id not in project_function_groups_loaded:
                            project_function_groups_loaded.add(project_id)
                            try:
                                fgroups = client.get_project_function_groups(project_id)
                                for fg in fgroups:
                                    fg_id = fg.get("id")
                                    if isinstance(fg_id, int) and fg_id not in function_group_cache:
                                        function_group_cache[fg_id] = fg
                                app.logger.info("Rentman: function groups per progetto %s: %d", project_id, len(fgroups))
                            except Exception as exc:
                                app.logger.warning("Rentman: errore caricando function groups per progetto %s: %s", project_id, exc)
                            # Aggiorna function_group_name se il lookup precedente non l'aveva trovato
                            if not function_group_name and function_id and function_id in function_cache:
                                fd2 = function_cache[function_id]
                                gr2 = fd2.get("group", "")
                                if gr2 and "/projectfunctiongroups/" in str(gr2):
                                    try:
                                        fg_id2 = int(str(gr2).split("/")[-1])
                                        if fg_id2 in function_group_cache:
                                            function_group_name = function_group_cache[fg_id2].get("name", "")
                                    except (ValueError, IndexError):
                                        pass

                        # Fallback: se non abbiamo location dal subproject, prova dal progetto
                        if not location_id:
                            proj_location_ref = pd.get("location", "")
                            if proj_location_ref and "/" in proj_location_ref:
                                try:
                                    location_id = int(proj_location_ref.split("/")[-1])
                                    if location_id not in contact_cache:
                                        contact_data = client.get_contact(location_id)
                                        if contact_data:
                                            contact_cache[location_id] = contact_data
                                    if location_id in contact_cache:
                                        ct = contact_cache[location_id]
                                        location_name = ct.get("displayname") or ct.get("name") or ""
                                        # Costruisci indirizzo completo
                                        addr_parts = []
                                        if ct.get("visit_street"):
                                            addr_parts.append(ct.get("visit_street"))
                                            if ct.get("visit_number") and ct.get("visit_number") != "S.n.":
                                                addr_parts[-1] += " " + str(ct.get("visit_number"))
                                        if ct.get("visit_postalcode"):
                                            addr_parts.append(ct.get("visit_postalcode"))
                                        if ct.get("visit_city"):
                                            addr_parts.append(ct.get("visit_city"))
                                        if ct.get("visit_state"):
                                            addr_parts.append(f"({ct.get('visit_state')})")
                                        location_address = ", ".join(addr_parts) if addr_parts else ""
                                        # Coordinate
                                        lat = ct.get("latitude")
                                        lon = ct.get("longitude")
                                        if lat is not None and lon is not None:
                                            try:
                                                location_lat = float(lat)
                                                location_lon = float(lon)
                                            except (ValueError, TypeError):
                                                pass
                                        elif location_address:
                                            # Geocoding dall'indirizzo
                                            coords = geocode_address(location_address)
                                            if coords:
                                                location_lat, location_lon = coords
                                except (ValueError, IndexError):
                                    pass
                except (ValueError, IndexError):
                    pass

        # CONTROLLO CACHE GLOBALE: se le coordinate sono salvate nella cache, usa quelle
        location_radius = 300
        if location_name:
            ensure_location_cache_table(db)
            cached_coords = get_location_cache(db, location_name, location_id)
            if cached_coords:
                location_lat, location_lon, location_radius = cached_coords
                app.logger.info(f"✅ Location '{location_name}' (id={location_id}): usando coordinate dalla cache globale: {location_lat}, {location_lon}, raggio={location_radius}m")
            else:
                app.logger.info(f"⚠️ Location '{location_name}' (id={location_id}): nessuna cache, usando coordinate da Rentman (lat={location_lat}, lon={location_lon})")
        
        # Calcola ore JobLog per questo operatore
        joblog_registered = match_crew_name_to_joblog(crew_name, joblog_hours)
        
        # Calcola la pausa dalla differenza tra durata turno e ore pianificate
        # Rentman non fornisce un campo specifico per la pausa, ma la include già
        # nelle hours_planned (che sono al netto della pausa)
        break_minutes = None
        plan_start_str = planning.get("planperiod_start")
        plan_end_str = planning.get("planperiod_end")
        hours_planned_raw = planning.get("hours_planned")
        
        if plan_start_str and plan_end_str and hours_planned_raw is not None:
            try:
                from datetime import datetime as dt_parse
                # Parse datetime ISO - rimuovi timezone per semplificare
                start_clean = plan_start_str.split("+")[0].replace("Z", "")
                end_clean = plan_end_str.split("+")[0].replace("Z", "")
                
                start_dt = dt_parse.fromisoformat(start_clean)
                end_dt = dt_parse.fromisoformat(end_clean)
                
                # Calcola durata totale in minuti
                total_duration_minutes = (end_dt - start_dt).total_seconds() / 60
                
                # hours_planned è in secondi, converti in minuti
                hours_planned_val = float(hours_planned_raw)
                if hours_planned_val > 100:  # È in secondi
                    planned_minutes = hours_planned_val / 60
                else:  # È già in ore
                    planned_minutes = hours_planned_val * 60
                
                # La pausa è la differenza
                calculated_break = total_duration_minutes - planned_minutes
                
                if calculated_break > 0:
                    break_minutes = int(round(calculated_break))
            except Exception as e:
                app.logger.warning(f"Errore calcolo pausa: {e}")
        
        # Recupera sede GPS di timbratura dal gruppo dell'operatore
        gps_timbratura_location = None
        if crew_id and crew_id in crew_group_map:
            group_id = crew_group_map[crew_id]
            if group_id in group_gps_map:
                gps_timbratura_location = group_gps_map[group_id]
        
        # CONTROLLO CACHE GLOBALE: se le coordinate sono salvate nella cache, usa quelle
        location_radius = 300
        if location_name:
            ensure_location_cache_table(db)
            cached_coords = get_location_cache(db, location_name, location_id)
            if cached_coords:
                location_lat, location_lon, location_radius = cached_coords
                app.logger.info(f"✅ Location '{location_name}' (id={location_id}): usando coordinate dalla cache globale: {location_lat}, {location_lon}, raggio={location_radius}m")
            else:
                app.logger.info(f"⚠️ Location '{location_name}' (id={location_id}): nessuna cache, usando coordinate da Rentman (lat={location_lat}, lon={location_lon})")

        # Recupera capo progetto e veicoli assegnati (una volta per progetto)
        project_manager_name = ""
        vehicle_names = ""
        vehicle_data = ""

        if project_id:
            # Capo progetto da account_manager del progetto
            if project_id not in project_manager_cache:
                manager_name = ""
                if project_id in project_cache:
                    pd = project_cache[project_id]
                    account_manager_ref = pd.get("account_manager", "")
                    if account_manager_ref and "/" in account_manager_ref:
                        try:
                            manager_crew_id = int(account_manager_ref.split("/")[-1])
                            if manager_crew_id not in crew_cache:
                                manager_data = client.get_crew_member(manager_crew_id)
                                if manager_data:
                                    crew_cache[manager_crew_id] = manager_data
                            if manager_crew_id in crew_cache:
                                mc = crew_cache[manager_crew_id]
                                manager_name = mc.get("displayname") or f"{mc.get('firstname', '')} {mc.get('lastname', '')}".strip()
                        except (ValueError, IndexError):
                            pass
                project_manager_cache[project_id] = manager_name
                app.logger.info(f"Capo progetto per project_id={project_id}: '{manager_name}'")
            project_manager_name = project_manager_cache[project_id]

            # Veicoli assegnati al progetto (strutturato con id/nome/targa)
            if project_id not in project_vehicles_cache:
                vehicle_list = []  # lista di dict {id, name, plate}
                seen_vehicle_ids: set = set()  # deduplicazione per vehicle id
                try:
                    proj_vehicles = client.get_project_vehicles(project_id)
                    for pv in proj_vehicles:
                        vehicle_ref = pv.get("vehicle", "")
                        if vehicle_ref and "/" in vehicle_ref:
                            try:
                                vid = int(vehicle_ref.split("/")[-1])
                                if vid in seen_vehicle_ids:
                                    continue  # skip duplicato
                                if vid not in vehicle_cache:
                                    v_data = client.get_vehicle(vid)
                                    if v_data:
                                        vehicle_cache[vid] = v_data
                                if vid in vehicle_cache:
                                    vd = vehicle_cache[vid]
                                    v_name = vd.get("name") or vd.get("displayname") or ""
                                    v_plate = vd.get("licenseplate") or ""
                                    if v_name or v_plate:
                                        vehicle_list.append({"id": vid, "name": v_name, "plate": v_plate})
                                        seen_vehicle_ids.add(vid)
                            except (ValueError, IndexError):
                                pass
                except Exception as e:
                    app.logger.warning(f"Errore recupero veicoli per progetto {project_id}: {e}")
                # Salva sia la lista strutturata che la stringa per il DB
                project_vehicles_cache[project_id] = vehicle_list
                app.logger.info(f"Veicoli per project_id={project_id}: {len(vehicle_list)} veicoli")
            cached_vehicles = project_vehicles_cache[project_id]
            # vehicle_names resta stringa per compatibilità DB
            vehicle_names = ", ".join(
                f"{v['name']} {v['plate']}" if v['name'] and v['plate']
                else v['name'] or v['plate']
                for v in cached_vehicles
            )
            # vehicle_data è la lista strutturata per il frontend
            vehicle_data = json.dumps(cached_vehicles) if cached_vehicles else ""
        
        results.append({
            "id": planning.get("id"),
            "rentman_id": planning.get("id"),  # Aggiungi rentman_id esplicitamente
            "crew_id": crew_id,
            "crew_name": crew_name,
            "function_name": function_name,
            "function_group_name": function_group_name,
            "project_name": project_name,
            "project_code": project_code,
            "project_id": project_id,
            "subproject_id": subproject_id,
            "location_id": location_id,
            "location_name": location_name,
            "location_address": location_address,
            "location_lat": location_lat,
            "location_lon": location_lon,
            "gps_timbratura_location": gps_timbratura_location,
            "plan_start": planning.get("planperiod_start"),
            "plan_end": planning.get("planperiod_end"),
            "break_minutes": break_minutes,
            "hours_planned": planning.get("hours_planned"),
            "hours_registered": round(joblog_registered, 2) if joblog_registered is not None else 0,
            "hours_rentman": planning.get("hours_registered"),  # Mantieni valore originale Rentman per riferimento
            "remark": planning.get("remark", ""),
            "remark_planner": planning.get("remark_planner", ""),  # Nota al pianificatore
            "is_leader": planning.get("project_leader", False),
            "transport": planning.get("transport", ""),
            "project_manager_name": project_manager_name,
            "vehicle_names": vehicle_names,
            "vehicle_data": vehicle_data,
        })

    # Ordina per orario di inizio e poi per nome crew
    results.sort(key=lambda x: (x.get("start") or "", x.get("crew_name") or ""))

    # Merge con dati salvati nel DB per preservare sent_to_webservice e rilevare modifiche
    db = get_db()
    ensure_rentman_plannings_table(db)
    
    if DB_VENDOR == "mysql":
        saved_rows = db.execute(
            "SELECT rentman_id, sent_to_webservice, plan_start, plan_end, project_name, sent_ts, break_start, break_end, break_minutes, gps_timbratura_location, timbratura_gps_mode FROM rentman_plannings WHERE planning_date = %s",
            (target_date,)
        ).fetchall()
    else:
        saved_rows = db.execute(
            "SELECT rentman_id, sent_to_webservice, plan_start, plan_end, project_name, sent_ts, break_start, break_end, break_minutes, gps_timbratura_location, timbratura_gps_mode FROM rentman_plannings WHERE planning_date = ?",
            (target_date,)
        ).fetchall()
    
    # Crea mappa rentman_id -> {sent, old_start, old_end, old_project, sent_ts, break_*, gps}
    saved_map = {}
    for row in saved_rows:
        if isinstance(row, Mapping):
            saved_map[row["rentman_id"]] = {
                "sent": bool(row["sent_to_webservice"]),
                "old_start": row["plan_start"],
                "old_end": row["plan_end"],
                "old_project": row["project_name"],
                "sent_ts": row["sent_ts"],
                "break_start": row.get("break_start"),
                "break_end": row.get("break_end"),
                "break_minutes": row.get("break_minutes"),
                "gps_timbratura_location": row.get("gps_timbratura_location"),
                "timbratura_gps_mode": row.get("timbratura_gps_mode"),
            }
        else:
            saved_map[row[0]] = {
                "sent": bool(row[1]),
                "old_start": row[2],
                "old_end": row[3],
                "old_project": row[4],
                "sent_ts": row[5],
                "break_start": row[6] if len(row) > 6 else None,
                "break_end": row[7] if len(row) > 7 else None,
                "break_minutes": row[8] if len(row) > 8 else None,
                "gps_timbratura_location": row[9] if len(row) > 9 else None,
                "timbratura_gps_mode": row[10] if len(row) > 10 else None,
            }
    
    # Arricchisci i risultati con info invio e modifiche
    for r in results:
        rentman_id = r.get("id")
        if rentman_id in saved_map:
            saved = saved_map[rentman_id]
            r["sent_to_webservice"] = saved["sent"]
            
            # Recupera pausa salvata se non presente da Rentman
            if not r.get("break_start") and saved.get("break_start"):
                r["break_start"] = saved["break_start"]
            if not r.get("break_end") and saved.get("break_end"):
                r["break_end"] = saved["break_end"]
            if not r.get("break_minutes") and saved.get("break_minutes"):
                r["break_minutes"] = saved["break_minutes"]
            
            # Preserva coordinate manuali se Rentman non le ha (null)
            rentman_lat = r.get("location_lat")
            rentman_lon = r.get("location_lon")
            saved_lat = saved.get("location_lat")
            saved_lon = saved.get("location_lon")
            rentman_has_coords = rentman_lat is not None and rentman_lon is not None
            saved_has_coords = saved_lat is not None and saved_lon is not None
            
            if not rentman_has_coords and saved_has_coords:
                r["location_lat"] = saved["location_lat"]
                r["location_lon"] = saved["location_lon"]
            
            # Preserva gps_timbratura_location e mode dal DB se non calcolato
            if saved.get("gps_timbratura_location") and not r.get("gps_timbratura_location"):
                r["gps_timbratura_location"] = saved["gps_timbratura_location"]
            if saved.get("timbratura_gps_mode"):
                r["timbratura_gps_mode"] = saved["timbratura_gps_mode"]
            
            # Aggiungi timestamp invio formattato
            if saved["sent_ts"]:
                try:
                    ts_val = saved["sent_ts"]
                    if isinstance(ts_val, (int, float)):
                        # sent_ts è in millisecondi (es: 1735634845125)
                        ts_sec = ts_val / 1000 if ts_val > 1e12 else ts_val
                        r["sent_ts"] = datetime.fromtimestamp(ts_sec).strftime("%d/%m/%Y %H:%M:%S")
                    elif isinstance(ts_val, str):
                        # Potrebbe essere ISO string (es: 2025-12-31T08:47:25.125Z)
                        ts_clean = ts_val.replace("Z", "+00:00")
                        dt = datetime.fromisoformat(ts_clean)
                        r["sent_ts"] = dt.strftime("%d/%m/%Y %H:%M:%S")
                    elif hasattr(ts_val, 'strftime'):
                        # È già un datetime
                        r["sent_ts"] = ts_val.strftime("%d/%m/%Y %H:%M:%S")
                    else:
                        r["sent_ts"] = str(ts_val)  # Fallback: converti a stringa
                except Exception:
                    r["sent_ts"] = None
            else:
                r["sent_ts"] = None
            
            # Rileva se è stato modificato rispetto all'ultimo invio
            if saved["sent"]:
                # Confronta orari e progetto
                # Gestisci sia stringhe che datetime objects
                new_start_raw = r.get("start", "")
                new_start = str(new_start_raw)[:16] if new_start_raw else ""
                old_start_raw = saved["old_start"]
                old_start = str(old_start_raw)[:16] if old_start_raw else ""
                new_end_raw = r.get("end", "")
                new_end = str(new_end_raw)[:16] if new_end_raw else ""
                old_end_raw = saved["old_end"]
                old_end = str(old_end_raw)[:16] if old_end_raw else ""
                
                is_modified = (
                    new_start != old_start or 
                    new_end != old_end or 
                    r.get("project_name", "") != (saved["old_project"] or "")
                )
                r["is_modified"] = is_modified
            else:
                r["is_modified"] = False
        else:
            r["sent_to_webservice"] = False
            r["is_modified"] = False
            r["sent_ts"] = None

    # Carica assegnazioni autisti per i veicoli di questa data
    ensure_vehicle_drivers_table(db)
    driver_assignments = {}
    try:
        if DB_VENDOR == "mysql":
            driver_rows = db.execute(
                "SELECT project_id, vehicle_id, driver_crew_id, driver_name FROM vehicle_driver_assignments WHERE planning_date = %s",
                (target_date,)
            ).fetchall()
        else:
            driver_rows = db.execute(
                "SELECT project_id, vehicle_id, driver_crew_id, driver_name FROM vehicle_driver_assignments WHERE planning_date = ?",
                (target_date,)
            ).fetchall()
        for dr in driver_rows:
            if isinstance(dr, dict):
                key = f"{dr['project_id']}_{dr['vehicle_id']}"
                driver_assignments[key] = {"crew_id": dr["driver_crew_id"], "name": dr["driver_name"]}
            else:
                key = f"{dr[0]}_{dr[1]}"
                driver_assignments[key] = {"crew_id": dr[2], "name": dr[3]}
    except Exception as e:
        app.logger.warning(f"Errore caricamento assegnazioni autisti: {e}")

    # Arricchisci vehicle_data con autista assegnato
    for r in results:
        vd_str = r.get("vehicle_data", "")
        pid = r.get("project_id")
        if vd_str and pid:
            try:
                vehicles = json.loads(vd_str)
                for v in vehicles:
                    vkey = f"{pid}_{v['id']}"
                    if vkey in driver_assignments:
                        v["driver_crew_id"] = driver_assignments[vkey]["crew_id"]
                        v["driver_name"] = driver_assignments[vkey]["name"]
                r["vehicle_data"] = json.dumps(vehicles)
            except (json.JSONDecodeError, KeyError):
                pass

    return jsonify({
        "ok": True,
        "date": target_date,
        "count": len(results),
        "plannings": results,
    })


@app.post("/api/admin/rentman/planning/update-break")
@login_required
def api_admin_rentman_planning_update_break() -> ResponseReturnValue:
    """Aggiorna solo i campi pausa di una pianificazione."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json() or {}
    rentman_id = data.get("rentman_id")
    target_date = data.get("date")
    break_start = data.get("break_start")
    break_end = data.get("break_end")
    break_minutes = data.get("break_minutes")

    app.logger.info(f"update-break chiamato con: rentman_id={rentman_id}, date={target_date}")

    if not rentman_id or not target_date:
        return jsonify({"error": "rentman_id e date richiesti"}), 400

    db = get_db()
    ensure_rentman_plannings_table(db)

    # Verifica che il record esista - cerca anche per id diretto (potrebbe essere l'id del DB)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    existing = db.execute(
        f"SELECT id, rentman_id FROM rentman_plannings WHERE (rentman_id = {placeholder} OR id = {placeholder}) AND planning_date = {placeholder}",
        (rentman_id, rentman_id, target_date)
    ).fetchone()

    if not existing:
        app.logger.warning(f"Pianificazione non trovata per rentman_id={rentman_id}, date={target_date}")
        return jsonify({"error": "Pianificazione non trovata. Salva prima le pianificazioni."}), 404

    record_id = existing['id'] if isinstance(existing, dict) else existing[0]
    actual_rentman_id = existing['rentman_id'] if isinstance(existing, dict) else existing[1]
    app.logger.info(f"Trovato record: id={record_id}, rentman_id={actual_rentman_id}")

    # Aggiorna solo i campi pausa
    now_ms = int(time.time() * 1000)
    
    db.execute(f"""
        UPDATE rentman_plannings 
        SET break_start = {placeholder}, break_end = {placeholder}, break_minutes = {placeholder}, updated_ts = {placeholder}
        WHERE id = {placeholder}
    """, (break_start, break_end, break_minutes, now_ms, record_id))

    db.commit()

    app.logger.info(f"Pausa aggiornata per id={record_id}: start={break_start}, end={break_end}, minutes={break_minutes}")

    return jsonify({"success": True, "message": "Pausa aggiornata"})


@app.post("/api/admin/rentman/planning/update-gps-mode")
@login_required
def api_admin_rentman_planning_update_gps_mode() -> ResponseReturnValue:
    """Aggiorna la modalità GPS per la timbratura (sede gruppo vs location progetto)."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json() or {}
    planning_id = data.get("id")
    rentman_id = data.get("rentman_id")
    gps_mode = data.get("timbratura_gps_mode")

    app.logger.info(f"update-gps-mode: id={planning_id}, rentman_id={rentman_id}, mode={gps_mode}")

    if not planning_id and not rentman_id:
        return jsonify({"error": "ID pianificazione richiesto"}), 400

    if gps_mode not in ("group", "location"):
        return jsonify({"error": "Modalità GPS non valida. Usa 'group' o 'location'"}), 400

    db = get_db()
    now_ms = int(time.time() * 1000)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Converti in int se possibile
    try:
        if planning_id:
            planning_id = int(planning_id)
        if rentman_id:
            rentman_id = int(rentman_id)
    except (ValueError, TypeError):
        pass

    # Trova il record - prova prima con id, poi con rentman_id
    existing = None
    
    if planning_id:
        existing = db.execute(
            f"SELECT id FROM rentman_plannings WHERE id = {placeholder}",
            (planning_id,)
        ).fetchone()
        app.logger.info(f"Cercato per id={planning_id}: {'trovato' if existing else 'non trovato'}")
    
    if not existing and rentman_id:
        existing = db.execute(
            f"SELECT id FROM rentman_plannings WHERE rentman_id = {placeholder}",
            (rentman_id,)
        ).fetchone()
        app.logger.info(f"Cercato per rentman_id={rentman_id}: {'trovato' if existing else 'non trovato'}")
    
    if not existing and planning_id:
        # Prova planning_id come rentman_id
        existing = db.execute(
            f"SELECT id FROM rentman_plannings WHERE rentman_id = {placeholder}",
            (planning_id,)
        ).fetchone()
        app.logger.info(f"Cercato per planning_id come rentman_id={planning_id}: {'trovato' if existing else 'non trovato'}")

    if not existing:
        app.logger.warning(f"Pianificazione non trovata: id={planning_id}, rentman_id={rentman_id}")
        return jsonify({"error": "Pianificazione non trovata"}), 404

    # Recupera l'ID del record trovato
    record_id = existing["id"] if isinstance(existing, dict) else existing[0]
    
    # Aggiorna
    db.execute(f"""
        UPDATE rentman_plannings 
        SET timbratura_gps_mode = {placeholder}, updated_ts = {placeholder}
        WHERE id = {placeholder}
    """, (gps_mode, now_ms, record_id))
    
    db.commit()

    mode_label = "Sede Gruppo" if gps_mode == "group" else "Location Progetto"
    app.logger.info(f"✅ Modalità GPS aggiornata per id={record_id}: {mode_label}")

    # Verifica che il salvataggio sia andato a buon fine
    verify = db.execute(f"SELECT timbratura_gps_mode FROM rentman_plannings WHERE id = {placeholder}", (record_id,)).fetchone()
    saved_mode = verify['timbratura_gps_mode'] if isinstance(verify, dict) else (verify[0] if verify else None)
    app.logger.info(f"🔍 Verifica dopo save: mode nel DB = {saved_mode}")

    return jsonify({"success": True, "message": f"Modalità GPS impostata a: {mode_label}"})


@app.post("/api/admin/rentman/planning/toggle-gestione-squadra")
@login_required
def api_admin_rentman_planning_toggle_gestione_squadra() -> ResponseReturnValue:
    """Attiva/disattiva la gestione squadra per un progetto in una data specifica.
    
    Aggiorna TUTTE le righe del progetto nella stessa data, perché
    la gestione squadra è un concetto a livello di progetto.
    """
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json() or {}
    project_code = data.get("project_code")
    planning_date = data.get("date")
    gestione_squadra = data.get("gestione_squadra")  # 0 o 1

    if not project_code or not planning_date:
        return jsonify({"error": "project_code e date sono richiesti"}), 400

    if gestione_squadra not in (0, 1, True, False):
        return jsonify({"error": "gestione_squadra deve essere 0 o 1"}), 400

    gs_value = 1 if gestione_squadra else 0
    db = get_db()
    now_ms = int(time.time() * 1000)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    result = db.execute(f"""
        UPDATE rentman_plannings
        SET gestione_squadra = {placeholder}, updated_ts = {placeholder}
        WHERE project_code = {placeholder} AND planning_date = {placeholder}
          AND (is_obsolete = 0 OR is_obsolete IS NULL)
    """, (gs_value, now_ms, project_code, planning_date))

    rows_updated = result.rowcount if hasattr(result, 'rowcount') else 0
    db.commit()

    label = "Gestione squadra attiva" if gs_value else "Attività individuale"
    app.logger.info(f"✅ Gestione squadra aggiornata: project_code={project_code}, date={planning_date}, valore={gs_value}, righe={rows_updated}")

    return jsonify({"success": True, "gestione_squadra": gs_value, "rows_updated": rows_updated, "message": label})


@app.post("/api/admin/rentman/planning/update-vehicle-driver")
@login_required
def api_admin_rentman_planning_update_vehicle_driver() -> ResponseReturnValue:
    """Aggiorna l'autista assegnato a un veicolo per un progetto/data."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json() or {}
    project_id = data.get("project_id")
    planning_date = data.get("date")
    vehicle_id = data.get("vehicle_id")
    vehicle_name = data.get("vehicle_name", "")
    driver_crew_id = data.get("driver_crew_id")  # None se si vuole rimuovere
    driver_name = data.get("driver_name", "")

    if not project_id or not planning_date or not vehicle_id:
        return jsonify({"error": "project_id, date e vehicle_id richiesti"}), 400

    db = get_db()
    ensure_vehicle_drivers_table(db)
    now_ms = int(datetime.now().timestamp() * 1000)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    if driver_crew_id:
        # Upsert: inserisci o aggiorna
        if DB_VENDOR == "mysql":
            db.execute(f"""
                INSERT INTO vehicle_driver_assignments
                    (project_id, planning_date, vehicle_id, vehicle_name, driver_crew_id, driver_name, created_ts, updated_ts)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
                ON DUPLICATE KEY UPDATE
                    driver_crew_id = VALUES(driver_crew_id),
                    driver_name = VALUES(driver_name),
                    vehicle_name = VALUES(vehicle_name),
                    updated_ts = VALUES(updated_ts)
            """, (project_id, planning_date, vehicle_id, vehicle_name, driver_crew_id, driver_name, now_ms, now_ms))
        else:
            db.execute(f"""
                INSERT INTO vehicle_driver_assignments
                    (project_id, planning_date, vehicle_id, vehicle_name, driver_crew_id, driver_name, created_ts, updated_ts)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
                ON CONFLICT(project_id, planning_date, vehicle_id) DO UPDATE SET
                    driver_crew_id = excluded.driver_crew_id,
                    driver_name = excluded.driver_name,
                    vehicle_name = excluded.vehicle_name,
                    updated_ts = excluded.updated_ts
            """, (project_id, planning_date, vehicle_id, vehicle_name, driver_crew_id, driver_name, now_ms, now_ms))
    else:
        # Rimuovi assegnazione
        db.execute(f"""
            DELETE FROM vehicle_driver_assignments
            WHERE project_id = {placeholder} AND planning_date = {placeholder} AND vehicle_id = {placeholder}
        """, (project_id, planning_date, vehicle_id))

    db.commit()
    app.logger.info(f"Autista veicolo aggiornato: project={project_id}, date={planning_date}, vehicle={vehicle_id}, driver={driver_name}")

    return jsonify({"success": True, "message": f"Autista aggiornato: {driver_name}" if driver_name else "Assegnazione rimossa"})


@app.post("/api/admin/rentman-planning/save")
@login_required
def api_admin_rentman_planning_save() -> ResponseReturnValue:
    """Salva le pianificazioni Rentman nel database locale."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json() or {}
    target_date = data.get("date")
    plannings = data.get("plannings", [])

    if not target_date:
        return jsonify({"error": "Data richiesta"}), 400

    if not plannings:
        return jsonify({"error": "Nessuna pianificazione da salvare"}), 400

    db = get_db()
    ensure_rentman_plannings_table(db)
    ensure_crew_members_table(db)  # Assicura che la tabella operatori esista

    now_ms = int(time.time() * 1000)
    saved = 0
    updated = 0
    synced_crews = set()  # Track già sincronizzati per evitare duplicati

    def parse_iso_datetime(dt_str: str | None) -> str | None:
        """Converte datetime ISO o HTTP-date in formato MySQL compatibile."""
        if not dt_str:
            return None
        # Se è già un oggetto datetime (non stringa), convertilo
        if hasattr(dt_str, 'strftime'):
            return dt_str.strftime('%Y-%m-%d %H:%M:%S')
        dt_str = str(dt_str).strip()
        # Già nel formato MySQL? (YYYY-MM-DD HH:MM:SS)
        import re as _re
        if _re.match(r'^\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}$', dt_str):
            return dt_str.replace('T', ' ')
        try:
            from datetime import datetime as dt_parse
            # Gestisci formato HTTP-date RFC 2822 (es. "Sat, 21 Feb 2026 07:30:00 GMT")
            if ',' in dt_str and 'GMT' in dt_str:
                from email.utils import parsedate_to_datetime
                parsed = parsedate_to_datetime(dt_str)
                return parsed.strftime('%Y-%m-%d %H:%M:%S')
            # Prova a parsare datetime ISO con timezone
            # Rimuovi timezone se presente e converti
            if '+' in dt_str:
                dt_str = dt_str.split('+')[0]
            elif dt_str.endswith('Z'):
                dt_str = dt_str[:-1]
            # Converti in formato MySQL
            parsed = dt_parse.fromisoformat(dt_str)
            return parsed.strftime('%Y-%m-%d %H:%M:%S')
        except Exception as e:
            app.logger.warning(f"⚠️ parse_iso_datetime fallito per '{dt_str}': {e}")
            return dt_str

    for p in plannings:
      try:
        # IMPORTANTE: usa rentman_id se presente, altrimenti id
        # Quando i dati vengono dal merge frontend, 'id' è l'ID del DB
        rentman_id = p.get("rentman_id") or p.get("id")

        if not rentman_id:
            continue

        # Sincronizza operatore nel database locale (una volta sola per crew_id)
        crew_id = p.get("crew_id")
        crew_name = p.get("crew_name")
        if crew_id and crew_id not in synced_crews:
            sync_crew_member_from_rentman(db, crew_id, crew_name or f"Crew {crew_id}")
            synced_crews.add(crew_id)
            # NON fare continue qui! Devo comunque salvare la pianificazione

        # Converti hours da secondi a ore se necessario
        hours_planned = p.get("hours_planned")
        if hours_planned and float(hours_planned) > 100:
            hours_planned = float(hours_planned) / 3600

        hours_registered = p.get("hours_registered")
        if hours_registered and float(hours_registered) > 100:
            hours_registered = float(hours_registered) / 3600

        # Converti datetime in formato MySQL compatibile
        plan_start = parse_iso_datetime(p.get("plan_start"))
        plan_end = parse_iso_datetime(p.get("plan_end"))
        
        # Normalizza anche break_start/break_end (possono arrivare come timedelta o stringhe varie)
        break_start_val = p.get("break_start")
        break_end_val = p.get("break_end")
        if break_start_val and hasattr(break_start_val, 'total_seconds'):
            break_start_val = str(break_start_val)
        if break_end_val and hasattr(break_end_val, 'total_seconds'):
            break_end_val = str(break_end_val)
        
        app.logger.info(f"💾 SAVE: rentman_id={rentman_id}, plan_start={plan_start}, custom_location_ids={p.get('custom_location_ids')}")

        # Estrai project_id dalla funzione (se disponibile)
        project_id = p.get("project_id")
        function_id = p.get("function_id")

        # Check if exists
        if DB_VENDOR == "mysql":
            existing = db.execute(
                "SELECT id, sent_to_webservice, plan_start, plan_end, custom_location_ids FROM rentman_plannings WHERE rentman_id = %s AND planning_date = %s",
                (rentman_id, target_date)
            ).fetchone()
        else:
            existing = db.execute(
                "SELECT id, sent_to_webservice, plan_start, plan_end, custom_location_ids FROM rentman_plannings WHERE rentman_id = ? AND planning_date = ?",
                (rentman_id, target_date)
            ).fetchone()

        if existing:
            # Update existing record (but preserve sent status and timbratura_gps_mode!)
            app.logger.warning(f"🔴 SAVE UPDATE DB: rentman_id={rentman_id}, location_name={p.get('location_name')}, lat={p.get('location_lat')}, lon={p.get('location_lon')}")
            
            # Nota: preserva le note esistenti se quelle da Rentman sono vuote
            new_remark = p.get("remark") or None
            new_remark_planner = p.get("remark_planner") or None
            # Prepara JSON per custom_location_ids — preserva quelli esistenti nel DB se non arrivano dal client
            incoming_custom_ids = p.get("custom_location_ids")
            if incoming_custom_ids:
                custom_ids_json = json.dumps(incoming_custom_ids)
            else:
                # Preserva il valore già salvato nel DB (es. durante sync da Rentman)
                existing_custom = existing[4] if existing and len(existing) > 4 else None
                if existing_custom:
                    custom_ids_json = existing_custom if isinstance(existing_custom, str) else json.dumps(existing_custom)
                else:
                    custom_ids_json = json.dumps([])
            
            if DB_VENDOR == "mysql":
                db.execute("""
                    UPDATE rentman_plannings SET
                        crew_id = %s, crew_name = %s, function_id = %s, function_name = %s,
                        project_id = %s, project_name = %s, project_code = %s,
                        subproject_id = %s, location_id = %s, location_name = %s, location_address = %s,
                        custom_location_ids = %s,
                        location_lat = %s, location_lon = %s,
                        gps_timbratura_location = %s,
                        plan_start = %s, plan_end = %s,
                        break_start = %s, break_end = %s, break_minutes = %s,
                        hours_planned = %s, hours_registered = %s,
                        remark = COALESCE(%s, remark), remark_planner = COALESCE(%s, remark_planner),
                        is_leader = %s, transport = %s,
                        project_manager_name = %s, vehicle_names = %s, vehicle_data = %s,
                        updated_ts = %s,
                        is_obsolete = 0
                    WHERE rentman_id = %s AND planning_date = %s
                """, (
                    p.get("crew_id"), p.get("crew_name"), function_id, p.get("function_name"),
                    project_id, p.get("project_name"), p.get("project_code"),
                    p.get("subproject_id"), p.get("location_id"), p.get("location_name"), p.get("location_address"),
                    custom_ids_json,
                    p.get("location_lat"), p.get("location_lon"),
                    p.get("gps_timbratura_location"),
                    plan_start, plan_end,
                    break_start_val, break_end_val, p.get("break_minutes"),
                    hours_planned, hours_registered,
                    new_remark, new_remark_planner, 1 if p.get("is_leader") else 0, p.get("transport"),
                    p.get("project_manager_name"), p.get("vehicle_names"), p.get("vehicle_data"),
                    now_ms,
                    rentman_id, target_date
                ))
            else:
                db.execute("""
                    UPDATE rentman_plannings SET
                        crew_id = ?, crew_name = ?, function_id = ?, function_name = ?,
                        project_id = ?, project_name = ?, project_code = ?,
                        subproject_id = ?, location_id = ?, location_name = ?, location_address = ?,
                        custom_location_ids = ?,
                        location_lat = ?, location_lon = ?,
                        gps_timbratura_location = ?,
                        plan_start = ?, plan_end = ?,
                        break_start = ?, break_end = ?, break_minutes = ?,
                        hours_planned = ?, hours_registered = ?,
                        remark = COALESCE(?, remark), remark_planner = COALESCE(?, remark_planner),
                        is_leader = ?, transport = ?,
                        project_manager_name = ?, vehicle_names = ?, vehicle_data = ?,
                        updated_ts = ?,
                        is_obsolete = 0
                    WHERE rentman_id = ? AND planning_date = ?
                """, (
                    p.get("crew_id"), p.get("crew_name"), function_id, p.get("function_name"),
                    project_id, p.get("project_name"), p.get("project_code"),
                    p.get("subproject_id"), p.get("location_id"), p.get("location_name"), p.get("location_address"),
                    custom_ids_json,
                    p.get("location_lat"), p.get("location_lon"),
                    p.get("gps_timbratura_location"),
                    plan_start, plan_end,
                    break_start_val, break_end_val, p.get("break_minutes"),
                    hours_planned, hours_registered,
                    new_remark, new_remark_planner, 1 if p.get("is_leader") else 0, p.get("transport"),
                    p.get("project_manager_name"), p.get("vehicle_names"), p.get("vehicle_data"),
                    now_ms,
                    rentman_id, target_date
                ))
            updated += 1
        else:
            # Insert new record
            app.logger.warning(f"🔴 SAVE INSERT DB: rentman_id={rentman_id}, location_name={p.get('location_name')}, lat={p.get('location_lat')}, lon={p.get('location_lon')}")
            if DB_VENDOR == "mysql":
                db.execute("""
                    INSERT INTO rentman_plannings (
                        rentman_id, planning_date, crew_id, crew_name, function_id, function_name,
                        project_id, project_name, project_code, subproject_id, location_id, location_name, location_address,
                        custom_location_ids,
                        location_lat, location_lon,
                        gps_timbratura_location, timbratura_gps_mode,
                        plan_start, plan_end, break_start, break_end, break_minutes,
                        hours_planned, hours_registered, remark, remark_planner, is_leader, transport,
                        project_manager_name, vehicle_names, vehicle_data,
                        sent_to_webservice, created_ts, updated_ts
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 0, %s, %s)
                """, (
                    rentman_id, target_date, p.get("crew_id"), p.get("crew_name"),
                    function_id, p.get("function_name"), project_id, p.get("project_name"),
                    p.get("project_code"), p.get("subproject_id"), p.get("location_id"), p.get("location_name"), p.get("location_address"),
                    json.dumps(p.get("custom_location_ids") or []),
                    p.get("location_lat"), p.get("location_lon"),
                    p.get("gps_timbratura_location"), p.get("timbratura_gps_mode") or "group",
                    plan_start, plan_end, break_start_val, break_end_val, p.get("break_minutes"),
                    hours_planned, hours_registered, p.get("remark"), p.get("remark_planner"),
                    1 if p.get("is_leader") else 0, p.get("transport"),
                    p.get("project_manager_name"), p.get("vehicle_names"), p.get("vehicle_data"),
                    now_ms, now_ms
                ))
            else:
                db.execute("""
                    INSERT INTO rentman_plannings (
                        rentman_id, planning_date, crew_id, crew_name, function_id, function_name,
                        project_id, project_name, project_code, subproject_id, location_id, location_name, location_address,
                        custom_location_ids,
                        location_lat, location_lon,
                        gps_timbratura_location, timbratura_gps_mode,
                        plan_start, plan_end, break_start, break_end, break_minutes,
                        hours_planned, hours_registered, remark, remark_planner, is_leader, transport,
                        project_manager_name, vehicle_names, vehicle_data,
                        sent_to_webservice, created_ts, updated_ts
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 0, ?, ?)
                """, (
                    rentman_id, target_date, p.get("crew_id"), p.get("crew_name"),
                    function_id, p.get("function_name"), project_id, p.get("project_name"),
                    p.get("project_code"), p.get("subproject_id"), p.get("location_id"), p.get("location_name"), p.get("location_address"),
                    json.dumps(p.get("custom_location_ids") or []),
                    p.get("location_lat"), p.get("location_lon"),
                    p.get("gps_timbratura_location"), p.get("timbratura_gps_mode") or "group",
                    plan_start, plan_end, break_start_val, break_end_val, p.get("break_minutes"),
                    hours_planned, hours_registered, p.get("remark"), p.get("remark_planner"),
                    1 if p.get("is_leader") else 0, p.get("transport"),
                    p.get("project_manager_name"), p.get("vehicle_names"), p.get("vehicle_data"),
                    now_ms, now_ms
                ))
            saved += 1
      except Exception as save_err:
        app.logger.error(f"❌ Errore salvataggio planning rentman_id={p.get('rentman_id') or p.get('id')}: {save_err}")

    # Raccogli tutti i rentman_id ricevuti dalla sincronizzazione
    # IMPORTANTE: il frontend invia sia 'rentman_id' (originale Rentman) che 'id' (può essere DB id o Rentman id)
    # Preferisci 'rentman_id' se presente, altrimenti usa 'id'
    synced_rentman_ids = []
    for p in plannings:
        rid = p.get("rentman_id") or p.get("id")
        if rid:
            synced_rentman_ids.append(rid)
    app.logger.info(f"🔴 synced_rentman_ids raccolti: {synced_rentman_ids}")
    
    # Rimuovi i turni NON PIÙ INVIATI (sent_to_webservice = 0) che non sono nella sincronizzazione
    # Marca come obsoleti i turni già inviati (sent_to_webservice = 1) che non sono più in Rentman
    removed = 0
    marked_obsolete = 0
    
    if synced_rentman_ids:
        if DB_VENDOR == "mysql":
            placeholders = ",".join(["%s"] * len(synced_rentman_ids))
            # Rimuovi turni non più presenti che NON sono stati ancora inviati
            result = db.execute(f"""
                DELETE FROM rentman_plannings 
                WHERE planning_date = %s 
                  AND sent_to_webservice = 0
                  AND rentman_id NOT IN ({placeholders})
            """, (target_date, *synced_rentman_ids))
            removed = result.rowcount if hasattr(result, 'rowcount') else 0
            
            # Marca come obsoleti i turni già inviati che non sono più in Rentman
            result_obsolete = db.execute(f"""
                UPDATE rentman_plannings
                SET is_obsolete = 1, updated_ts = %s
                WHERE planning_date = %s 
                  AND sent_to_webservice = 1
                  AND rentman_id NOT IN ({placeholders})
            """, (now_ms, target_date, *synced_rentman_ids))
            marked_obsolete = result_obsolete.rowcount if hasattr(result_obsolete, 'rowcount') else 0
        else:
            placeholders = ",".join(["?"] * len(synced_rentman_ids))
            result = db.execute(f"""
                DELETE FROM rentman_plannings 
                WHERE planning_date = ? 
                  AND sent_to_webservice = 0
                  AND rentman_id NOT IN ({placeholders})
            """, (target_date, *synced_rentman_ids))
            removed = result.rowcount if hasattr(result, 'rowcount') else 0
            
            # Marca come obsoleti i turni già inviati che non sono più in Rentman
            result_obsolete = db.execute(f"""
                UPDATE rentman_plannings
                SET is_obsolete = 1, updated_ts = ?
                WHERE planning_date = ? 
                  AND sent_to_webservice = 1
                  AND rentman_id NOT IN ({placeholders})
            """, (now_ms, target_date, *synced_rentman_ids))
            marked_obsolete = result_obsolete.rowcount if hasattr(result_obsolete, 'rowcount') else 0
    
    db.commit()

    return jsonify({
        "ok": True,
        "saved": saved,
        "updated": updated,
        "removed": removed,
        "marked_obsolete": marked_obsolete,
        "total": saved + updated,
    })


@app.get("/api/admin/rentman-planning/saved")
@login_required
def api_admin_rentman_planning_saved() -> ResponseReturnValue:
    """Recupera le pianificazioni salvate dal database locale."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    target_date = request.args.get("date")
    if not target_date:
        target_date = datetime.now().date().isoformat()

    db = get_db()
    ensure_rentman_plannings_table(db)

    if DB_VENDOR == "mysql":
        rows = db.execute(
            "SELECT * FROM rentman_plannings WHERE planning_date = %s AND is_obsolete = 0 ORDER BY plan_start, crew_name",
            (target_date,)
        ).fetchall()
    else:
        rows = db.execute(
            "SELECT * FROM rentman_plannings WHERE planning_date = ? AND is_obsolete = 0 ORDER BY plan_start, crew_name",
            (target_date,)
        ).fetchall()

    plannings = []
    for row in rows:
        if isinstance(row, Mapping):
            plannings.append(dict(row))
        else:
            # SQLite row to dict - ordine colonne deve corrispondere alla tabella
            cols = ["id", "rentman_id", "planning_date", "crew_id", "crew_name", "function_id",
                    "function_name", "project_id", "project_name", "project_code",
                    "subproject_id", "location_id", "location_name", "location_address",
                    "custom_location_ids",
                    "location_lat", "location_lon",
                    "timbratura_gps_mode", "gps_timbratura_location",
                    "plan_start", "plan_end", "break_start", "break_end", "break_minutes",
                    "hours_planned", "hours_registered", "remark", "remark_planner", "is_leader",
                    "transport", "project_manager_name", "vehicle_names", "vehicle_data",
                    "sent_to_webservice", "sent_ts", "webservice_response",
                    "is_obsolete", "gestione_squadra",
                    "created_ts", "updated_ts"]
            plannings.append(dict(zip(cols, row)))

    # Arricchisci vehicle_data con le assegnazioni autisti salvate
    if plannings:
        ensure_vehicle_drivers_table(db)
        driver_assignments = {}
        try:
            if DB_VENDOR == "mysql":
                driver_rows = db.execute(
                    "SELECT project_id, vehicle_id, driver_crew_id, driver_name FROM vehicle_driver_assignments WHERE planning_date = %s",
                    (target_date,)
                ).fetchall()
            else:
                driver_rows = db.execute(
                    "SELECT project_id, vehicle_id, driver_crew_id, driver_name FROM vehicle_driver_assignments WHERE planning_date = ?",
                    (target_date,)
                ).fetchall()
            for dr in driver_rows:
                if isinstance(dr, dict) or isinstance(dr, Mapping):
                    key = f"{dr['project_id']}_{dr['vehicle_id']}"
                    driver_assignments[key] = {"crew_id": dr["driver_crew_id"], "name": dr["driver_name"]}
                else:
                    key = f"{dr[0]}_{dr[1]}"
                    driver_assignments[key] = {"crew_id": dr[2], "name": dr[3]}
        except Exception as e:
            app.logger.warning(f"Errore caricamento assegnazioni autisti (saved): {e}")

        # converti campo custom_location_ids dal DB (JSON string) in lista
        for p in plannings:
            if isinstance(p.get("custom_location_ids"), str):
                try:
                    p["custom_location_ids"] = json.loads(p["custom_location_ids"])
                except Exception:
                    p["custom_location_ids"] = []

        for p in plannings:
            vd_str = p.get("vehicle_data", "")
            pid = p.get("project_id")
            if vd_str and pid:
                try:
                    vehicles = json.loads(vd_str)
                    for v in vehicles:
                        vkey = f"{pid}_{v['id']}"
                        if vkey in driver_assignments:
                            v["driver_crew_id"] = driver_assignments[vkey]["crew_id"]
                            v["driver_name"] = driver_assignments[vkey]["name"]
                    p["vehicle_data"] = json.dumps(vehicles)
                except (json.JSONDecodeError, KeyError):
                    pass

    return jsonify({
        "ok": True,
        "date": target_date,
        "count": len(plannings),
        "plannings": plannings,
    })


@app.post("/api/admin/rentman-planning/send")
@login_required
def api_admin_rentman_planning_send() -> ResponseReturnValue:
    """Invia le pianificazioni al webservice esterno e notifica gli utenti."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json() or {}
    planning_ids = data.get("ids", [])  # Lista di ID locali da inviare
    plannings = data.get("plannings", [])  # O lista di pianificazioni con rentman_id
    force_resend = data.get("force_resend", False)  # Se True, invia notifiche anche per già inviati

    db = get_db()
    ensure_rentman_plannings_table(db)

    rows = []
    
    if planning_ids:
        # Recupera le pianificazioni per ID locale
        placeholders = ",".join(["%s" if DB_VENDOR == "mysql" else "?"] * len(planning_ids))
        query = f"SELECT * FROM rentman_plannings WHERE id IN ({placeholders})"
        rows = db.execute(query, planning_ids).fetchall()
    elif plannings:
        # Recupera per rentman_id (se esistono nel DB)
        rentman_ids = [p.get("rentman_id") or p.get("id") for p in plannings if p.get("rentman_id") or p.get("id")]
        if rentman_ids:
            placeholders = ",".join(["%s" if DB_VENDOR == "mysql" else "?"] * len(rentman_ids))
            query = f"SELECT * FROM rentman_plannings WHERE rentman_id IN ({placeholders})"
            rows = db.execute(query, rentman_ids).fetchall()

    if not rows and not plannings:
        return jsonify({"error": "Nessuna pianificazione selezionata"}), 400

    # TODO: Implementare l'invio al webservice
    # Per ora segna come inviate
    now_ms_val = int(time.time() * 1000)
    sent_count = 0
    errors = []
    
    # Raccogli info per notifiche push
    users_to_notify: Dict[int, List[Dict[str, Any]]] = {}  # crew_id -> list of turni

    # Se abbiamo righe dal DB, processa quelle
    if rows:
        for row in rows:
            local_id = row["id"] if isinstance(row, Mapping) else row[0]
            crew_id = row["crew_id"] if isinstance(row, Mapping) else row[3]
            planning_date = row["planning_date"] if isinstance(row, Mapping) else row[2]
            project_name = row["project_name"] if isinstance(row, Mapping) else row[8]
            
            # Controlla se era già stato inviato
            was_sent = row["sent_to_webservice"] if isinstance(row, Mapping) else row[17]
            
            try:
                # TODO: Chiamata al webservice qui
                # response = requests.post(webservice_url, json=payload)
                # webservice_response = response.text
                
                webservice_response = "OK - Placeholder (webservice non configurato)"
                
                # Aggiorna il record come inviato
                if DB_VENDOR == "mysql":
                    db.execute("""
                        UPDATE rentman_plannings 
                        SET sent_to_webservice = 1, sent_ts = %s, webservice_response = %s, updated_ts = %s
                        WHERE id = %s
                    """, (now_ms_val, webservice_response, now_ms_val, local_id))
                else:
                    db.execute("""
                        UPDATE rentman_plannings 
                        SET sent_to_webservice = 1, sent_ts = ?, webservice_response = ?, updated_ts = ?
                        WHERE id = ?
                    """, (now_ms_val, webservice_response, now_ms_val, local_id))
                
                sent_count += 1
                
                # Aggiungi alla lista per notifica:
                # - Se non era già inviato (primo invio)
                # - OPPURE se force_resend=True (reinvio manuale o turno modificato)
                should_notify = not was_sent or force_resend
                if should_notify and crew_id:
                    if crew_id not in users_to_notify:
                        users_to_notify[crew_id] = []
                    users_to_notify[crew_id].append({
                        "date": str(planning_date)[:10] if planning_date else "",
                        "project": project_name or "Progetto",
                        "is_update": was_sent  # Per differenziare il messaggio notifica
                    })
                
            except Exception as exc:
                app.logger.error("Errore invio pianificazione %s: %s", local_id, exc)
                errors.append({"id": local_id, "error": str(exc)})
    else:
        # Se non abbiamo righe dal DB ma abbiamo pianificazioni raw, segna come "inviate" ma non salvate
        # Questo è un caso limite: l'utente vuole inviare senza salvare nel DB locale
        for p in plannings:
            try:
                # TODO: Chiamata al webservice qui
                webservice_response = "OK - Placeholder (webservice non configurato, non salvato nel DB)"
                sent_count += 1
            except Exception as exc:
                errors.append({"id": p.get("id"), "error": str(exc)})

    db.commit()
    
    # Invia notifiche push agli utenti
    notifications_sent = 0
    if users_to_notify:
        notifications_sent = _send_turni_notifications(db, users_to_notify)

    return jsonify({
        "ok": True,
        "sent": sent_count,
        "notifications_sent": notifications_sent,
        "errors": errors,
    })


# ═══════════════════════════════════════════════════════════════════════════════
#  FASI FUNZIONE - ROUTES API
# ═══════════════════════════════════════════════════════════════════════════════

@app.get("/api/admin/function-phases")
@login_required
def api_get_function_phases() -> ResponseReturnValue:
    """Restituisce la configurazione dei template fasi per funzione."""
    db = get_db()
    config = get_function_phases_config(db)
    return jsonify({"ok": True, "function_phases": config})


@app.post("/api/admin/function-phases")
@login_required
def api_save_function_phases() -> ResponseReturnValue:
    """Salva la configurazione dei template fasi per funzione."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403

    data = request.get_json()
    if data is None:
        return jsonify({"error": "Dati mancanti"}), 400

    function_phases = data.get("function_phases", {})

    db = get_db()
    settings = get_company_settings(db)
    custom = settings.get("custom_settings", {})
    if not isinstance(custom, dict):
        custom = {}
    custom["function_phases"] = function_phases

    # Salva usando il metodo esistente
    settings["custom_settings"] = custom
    username = session.get("user") or session.get("username") or "admin"
    save_company_settings(db, settings, username)

    return jsonify({"ok": True, "message": "Template fasi salvati"})


@app.get("/api/admin/function-phases/distinct-functions")
@login_required
def api_get_distinct_functions() -> ResponseReturnValue:
    """Restituisce la lista delle funzioni distinte presenti nei planning."""
    db = get_db()
    ensure_rentman_plannings_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    rows = db.execute(
        "SELECT DISTINCT function_name FROM rentman_plannings WHERE function_name IS NOT NULL AND function_name != '' ORDER BY function_name"
    ).fetchall()
    functions = []
    for r in rows:
        fn = r["function_name"] if isinstance(r, dict) else r[0]
        if fn:
            functions.append(fn)
    return jsonify({"ok": True, "functions": functions})


@app.get("/api/project-phases")
@login_required
def api_get_project_phases() -> ResponseReturnValue:
    """Restituisce lo stato delle fasi per un progetto+data+funzione.
    
    Query params: date, project_key, function_key (opzionale, se non fornito restituisce tutte le funzioni)
    """
    db = get_db()
    ensure_project_phase_progress_table(db)

    date_str = request.args.get("date")
    project_key = request.args.get("project_key")

    if not date_str or not project_key:
        return jsonify({"error": "Parametri date e project_key obbligatori"}), 400

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    function_key = request.args.get("function_key")

    if function_key:
        rows = db.execute(
            f"""SELECT * FROM project_phase_progress 
                WHERE project_date = {placeholder} AND project_key = {placeholder} AND function_key = {placeholder}
                ORDER BY phase_order""",
            (date_str, project_key, function_key)
        ).fetchall()
    else:
        rows = db.execute(
            f"""SELECT * FROM project_phase_progress 
                WHERE project_date = {placeholder} AND project_key = {placeholder}
                ORDER BY function_key, phase_order""",
            (date_str, project_key)
        ).fetchall()

    phases = []
    for r in rows:
        if isinstance(r, dict):
            phases.append(r)
        else:
            phases.append(dict(r))

    return jsonify({"ok": True, "phases": phases})


@app.post("/api/project-phases/toggle")
@login_required
def api_toggle_project_phase() -> ResponseReturnValue:
    """Toggle completamento di una fase. Crea il record se non esiste.
    
    Body JSON: { date, project_key, function_key, phase_name, phase_order, completed (bool) }
    """
    db = get_db()
    ensure_project_phase_progress_table(db)

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400

    date_str = data.get("date")
    project_key = data.get("project_key")
    function_key = data.get("function_key")
    phase_name = data.get("phase_name")
    phase_order = data.get("phase_order", 0)
    completed = 1 if data.get("completed") else 0

    if not all([date_str, project_key, function_key, phase_name]):
        return jsonify({"error": "Campi obbligatori: date, project_key, function_key, phase_name"}), 400

    now_ts = int(time.time() * 1000)
    username = session.get("user") or session.get("username") or "unknown"
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Prova UPSERT
    if DB_VENDOR == "mysql":
        db.execute(f"""
            INSERT INTO project_phase_progress 
                (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            ON DUPLICATE KEY UPDATE
                completed = VALUES(completed),
                completed_at = VALUES(completed_at),
                completed_by = VALUES(completed_by),
                updated_ts = VALUES(updated_ts)
        """, (date_str, project_key, function_key, phase_name, phase_order,
              completed, now_ts if completed else None, username if completed else None, now_ts, now_ts))
    else:
        db.execute(f"""
            INSERT INTO project_phase_progress 
                (project_date, project_key, function_key, phase_name, phase_order, completed, completed_at, completed_by, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            ON CONFLICT(project_date, project_key, function_key, phase_name) DO UPDATE SET
                completed = excluded.completed,
                completed_at = excluded.completed_at,
                completed_by = excluded.completed_by,
                updated_ts = excluded.updated_ts
        """, (date_str, project_key, function_key, phase_name, phase_order,
              completed, now_ts if completed else None, username if completed else None, now_ts, now_ts))

    db.commit()

    return jsonify({"ok": True, "completed": bool(completed), "completed_by": username if completed else None})


def _send_turni_notifications(db: DatabaseLike, users_to_notify: Dict[int, List[Dict[str, Any]]]) -> int:
    """Invia notifiche push agli utenti per i nuovi turni pubblicati."""
    app.logger.info("_send_turni_notifications chiamata con %d crew_id", len(users_to_notify))
    
    settings = get_webpush_settings()
    if not settings:
        app.logger.info("Notifiche push non configurate, skip invio turni")
        return 0
    
    notifications_sent = 0
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    for crew_id, turni in users_to_notify.items():
        app.logger.info("Cerco utente per crew_id=%s", crew_id)
        
        # Trova l'utente associato a questo crew_id
        user_row = db.execute(
            f"SELECT username FROM app_users WHERE rentman_crew_id = {placeholder}",
            (crew_id,)
        ).fetchone()
        
        if not user_row:
            app.logger.warning("Nessun utente trovato per crew_id=%s", crew_id)
            continue
        
        username = user_row['username'] if isinstance(user_row, dict) else user_row[0]
        app.logger.info("Trovato utente %s per crew_id=%s", username, crew_id)
        
        # Recupera le subscription push dell'utente
        subscriptions = db.execute(
            f"SELECT endpoint, p256dh, auth FROM push_subscriptions WHERE username = {placeholder}",
            (username,)
        ).fetchall()
        
        if not subscriptions:
            app.logger.warning("Nessuna subscription push per utente %s", username)
            continue
        
        app.logger.info("Trovate %d subscription per %s", len(subscriptions), username)
        
        # Prepara il messaggio
        if len(turni) == 1:
            title = "📅 Nuovo turno pubblicato"
            body = f"{turni[0]['date']} - {turni[0]['project']}"
        else:
            title = f"📅 {len(turni)} nuovi turni pubblicati"
            body = f"Hai {len(turni)} nuovi turni. Apri l'app per i dettagli."
        
        payload = {
            "title": title,
            "body": body,
            "icon": "/static/icons/icon-192.png",
            "badge": "/static/icons/badge-72.png",
            "tag": "turni-update",
            "data": {
                "url": "/user/turni",
                "type": "turni_published"
            }
        }
        
        # Invia a tutte le subscription dell'utente
        for sub in subscriptions:
            endpoint = sub['endpoint'] if isinstance(sub, dict) else sub[0]
            p256dh = sub['p256dh'] if isinstance(sub, dict) else sub[1]
            auth = sub['auth'] if isinstance(sub, dict) else sub[2]
            
            subscription_info = {
                "endpoint": endpoint,
                "keys": {
                    "p256dh": p256dh,
                    "auth": auth
                }
            }
            
            try:
                webpush(
                    subscription_info=subscription_info,
                    data=json.dumps(payload),
                    vapid_private_key=settings["vapid_private"],
                    vapid_claims={"sub": settings["subject"]},
                    ttl=86400,  # 24 ore
                )
                notifications_sent += 1
                app.logger.info("Notifica turno inviata a %s", username)
                    
            except WebPushException as e:
                app.logger.warning("Errore invio notifica turno a %s: %s", username, e)
                # Rimuovi subscription se non valida
                if e.response and e.response.status_code in {404, 410}:
                    remove_push_subscription(db, endpoint)
            except Exception as e:
                app.logger.error("Errore generico invio notifica turno: %s", e)
        
        # Salva la notifica nel log (una volta per utente, dopo aver provato tutte le subscription)
        if notifications_sent > 0:
            try:
                record_push_notification(
                    db,
                    kind="turni_published",
                    title=title,
                    body=body,
                    payload=payload,
                    username=username,
                )
                app.logger.info("Notifica turno salvata nel log per %s", username)
            except Exception as e:
                app.logger.error("Errore salvataggio notifica nel log: %s", e)
    
    return notifications_sent


def _send_document_notifications(
    db: DatabaseLike,
    category: str,
    title: str,
    target_all: bool,
    target_users_json: str,
    doc_id: int = None
) -> int:
    """Invia notifiche push per un nuovo documento caricato."""
    settings = get_webpush_settings()
    if not settings:
        app.logger.info("Notifiche push non configurate, skip invio documento")
        return 0
    
    notifications_sent = 0
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Etichette categoria per il messaggio
    category_labels = {
        "circolare": "📋 Nuova Circolare",
        "comunicazione": "📢 Nuova Comunicazione",
        "busta_paga": "💰 Nuovo Cedolino"
    }
    
    notification_title = category_labels.get(category, "📄 Nuovo Documento")
    notification_body = title
    
    # Costruisci URL con documento specifico se disponibile
    target_url = "/user/documents"
    if doc_id:
        target_url = f"/user/documents?doc={doc_id}"
    
    payload = {
        "title": notification_title,
        "body": notification_body,
        "icon": "/static/icons/icon-192x192.png",
        "badge": "/static/icons/icon-72x72.png",
        "tag": f"document-{category}",
        "data": {
            "url": target_url,
            "type": "new_document",
            "doc_id": doc_id
        }
    }
    
    # Determina i destinatari
    target_usernames = []
    
    if target_all:
        # Tutti gli operatori (role = 'user')
        rows = db.execute(
            f"SELECT username FROM app_users WHERE role = {placeholder} AND is_active = 1",
            ("user",)
        ).fetchall()
        target_usernames = [r['username'] if isinstance(r, dict) else r[0] for r in rows]
    else:
        # Utenti specifici dal JSON
        try:
            target_usernames = json.loads(target_users_json) if target_users_json else []
        except:
            target_usernames = []
    
    app.logger.info("Invio notifica documento a %d utenti", len(target_usernames))
    
    for username in target_usernames:
        # Recupera le subscription push dell'utente
        subscriptions = db.execute(
            f"SELECT endpoint, p256dh, auth FROM push_subscriptions WHERE username = {placeholder}",
            (username,)
        ).fetchall()
        
        if not subscriptions:
            continue
        
        user_notified = False
        
        # Invia a tutte le subscription dell'utente
        for sub in subscriptions:
            endpoint = sub['endpoint'] if isinstance(sub, dict) else sub[0]
            p256dh = sub['p256dh'] if isinstance(sub, dict) else sub[1]
            auth = sub['auth'] if isinstance(sub, dict) else sub[2]
            
            subscription_info = {
                "endpoint": endpoint,
                "keys": {
                    "p256dh": p256dh,
                    "auth": auth
                }
            }
            
            try:
                webpush(
                    subscription_info=subscription_info,
                    data=json.dumps(payload),
                    vapid_private_key=settings["vapid_private"],
                    vapid_claims={"sub": settings["subject"]},
                    ttl=86400,
                )
                notifications_sent += 1
                user_notified = True
                app.logger.info("Notifica documento inviata a %s", username)
                    
            except WebPushException as e:
                app.logger.warning("Errore invio notifica documento a %s: %s", username, e)
                if e.response and e.response.status_code in {404, 410}:
                    remove_push_subscription(db, endpoint)
            except Exception as e:
                app.logger.error("Errore generico invio notifica documento: %s", e)
        
        # Salva nel log
        if user_notified:
            try:
                record_push_notification(
                    db,
                    kind="new_document",
                    title=notification_title,
                    body=notification_body,
                    payload=payload,
                    username=username,
                )
            except Exception as e:
                app.logger.error("Errore salvataggio notifica documento nel log: %s", e)
    
    app.logger.info("Inviate %d notifiche documento totali", notifications_sent)
    return notifications_sent


# ═══════════════════════════════════════════════════════════════════════════════
#  QR CODE TIMBRATURA - GiQR LEVEL 4 LITE
# ═══════════════════════════════════════════════════════════════════════════════

QR_DEVICE_ID = os.environ.get("QR_DEVICE_ID", "WebApp-001")
QR_REFRESH_SECONDS = int(os.environ.get("QR_REFRESH_SECONDS", "10"))


def _generate_giqr_payload() -> dict:
    """Genera payload GiQR Level 4 Lite con firma."""
    now = datetime.now()
    
    dt_str = now.strftime("%Y%m%d%H%M%S")
    nonce = random.randint(0, 65535)
    
    # Firma semplice (algoritmo dal codice originale)
    sig = (
        now.hour * 97 +
        now.minute * 59 +
        now.second * 31 +
        now.year +
        now.month +
        now.day +
        sum(QR_DEVICE_ID.encode())
    ) % 100000
    
    return {
        "v": 1,
        "dt": dt_str,
        "dev": QR_DEVICE_ID,
        "n": nonce,
        "sig": sig
    }


@app.route("/api/qr-timbratura", methods=["GET"])
@login_required
def api_qr_timbratura():
    """Genera QR code dinamico per timbratura in formato base64 PNG."""
    payload = _generate_giqr_payload()
    
    # JSON → bytes → Base64
    raw_json = json.dumps(payload).encode("utf-8")
    b64_payload = base64.b64encode(raw_json).decode("utf-8")
    
    # Genera QR code
    qr = qrcode.QRCode(box_size=8, border=2)
    qr.add_data(b64_payload)
    qr.make(fit=True)
    
    img = qr.make_image(fill_color="black", back_color="white")
    
    # Converti in base64 per invio al frontend
    buffer = io.BytesIO()
    img.save(buffer, format="PNG")
    buffer.seek(0)
    img_base64 = base64.b64encode(buffer.getvalue()).decode("utf-8")
    
    return jsonify({
        "ok": True,
        "image": f"data:image/png;base64,{img_base64}",
        "payload": payload,
        "refresh_seconds": QR_REFRESH_SECONDS,
        "timestamp": datetime.now().isoformat()
    })


@app.route("/qr-timbratura")
@login_required
def qr_timbratura_page():
    """Pagina standalone per QR timbratura (schermo intero)."""
    return render_template(
        "qr_timbratura.html",
        refresh_seconds=QR_REFRESH_SECONDS,
        device_id=QR_DEVICE_ID
    )


def _validate_giqr_payload(payload: dict) -> Tuple[bool, str]:
    """
    Valida un payload GiQR.
    Ritorna (is_valid, error_message).
    """
    if not payload:
        return False, "Payload vuoto"
    
    required_fields = ["v", "dt", "dev", "n", "sig"]
    for field in required_fields:
        if field not in payload:
            return False, f"Campo mancante: {field}"
    
    # Verifica versione
    if payload.get("v") != 1:
        return False, "Versione QR non supportata"
    
    # Verifica timestamp (non più vecchio di 60 secondi)
    dt_str = payload.get("dt", "")
    try:
        qr_time = datetime.strptime(dt_str, "%Y%m%d%H%M%S")
        now = datetime.now()
        age_seconds = abs((now - qr_time).total_seconds())
        if age_seconds > 60:
            return False, f"QR scaduto ({int(age_seconds)} secondi)"
    except ValueError:
        return False, "Timestamp non valido"
    
    # Verifica firma
    dev = payload.get("dev", "")
    sig_expected = (
        qr_time.hour * 97 +
        qr_time.minute * 59 +
        qr_time.second * 31 +
        qr_time.year +
        qr_time.month +
        qr_time.day +
        sum(dev.encode())
    ) % 100000
    
    if payload.get("sig") != sig_expected:
        return False, "Firma QR non valida"
    
    return True, ""


@app.post("/api/timbratura/validate-qr")
@login_required
def api_timbratura_validate_qr():
    """Valida un QR code scansionato per la timbratura."""
    data = request.get_json()
    if not data:
        return jsonify({"valid": False, "error": "Dati mancanti"}), 400
    
    qr_data = data.get("qr_data", "")
    
    # Decodifica Base64 → JSON
    try:
        decoded = base64.b64decode(qr_data).decode("utf-8")
        payload = json.loads(decoded)
    except Exception:
        return jsonify({"valid": False, "error": "QR non valido"}), 400
    
    # Valida payload
    is_valid, error = _validate_giqr_payload(payload)
    
    if not is_valid:
        return jsonify({"valid": False, "error": error}), 400
    
    # Genera un token temporaneo di validazione (valido 5 minuti)
    validation_token = secrets.token_urlsafe(32)
    expires = now_ms() + (5 * 60 * 1000)  # 5 minuti
    
    # Salva in sessione
    session["timbratura_token"] = validation_token
    session["timbratura_token_expires"] = expires
    session["timbratura_method"] = "qr"
    session["timbratura_location"] = None  # QR non ha location
    session["timbratura_gps_lat"] = None
    session["timbratura_gps_lon"] = None
    
    return jsonify({
        "valid": True,
        "token": validation_token,
        "expires_in": 300,
        "device": payload.get("dev", "")
    })


# ═══════════════════════════════════════════════════════════════════════════════
#  TIMBRATURA GPS - Geolocalizzazione
# ═══════════════════════════════════════════════════════════════════════════════

def get_timbratura_config() -> Dict[str, Any]:
    """Restituisce la configurazione timbratura.
    
    Priorità:
    1. Database (company_settings.custom_settings.timbratura)
    2. config.json (fallback per retrocompatibilità)
    3. Valori di default
    """
    default_config = {
        "qr_enabled": True,
        "gps_enabled": False,
        "gps_locations": [],
        "gps_max_accuracy_meters": 50
    }
    
    # Prova prima dal database
    try:
        db = get_db()
        company_settings = get_company_settings(db)
        custom_settings = company_settings.get("custom_settings", {})
        
        if isinstance(custom_settings, str):
            custom_settings = json.loads(custom_settings) if custom_settings else {}
        
        if "timbratura" in custom_settings:
            db_config = custom_settings["timbratura"]
            # Merge con i default
            return {
                "qr_enabled": db_config.get("qr_enabled", True),
                "gps_enabled": db_config.get("gps_enabled", False),
                "gps_locations": db_config.get("gps_locations", []),
                "gps_max_accuracy_meters": db_config.get("gps_max_accuracy_meters", 50)
            }
    except Exception as e:
        app.logger.warning(f"Errore lettura config timbratura da DB: {e}")
    
    # Fallback: config.json (per retrocompatibilità)
    config = load_config()
    if "timbratura" in config:
        file_config = config["timbratura"]
        return {
            "qr_enabled": file_config.get("qr_enabled", True),
            "gps_enabled": file_config.get("gps_enabled", False),
            "gps_locations": file_config.get("gps_locations", []),
            "gps_max_accuracy_meters": file_config.get("gps_max_accuracy_meters", 50)
        }
    
    return default_config


def get_user_timbratura_config(member_key: str = None) -> Dict[str, Any]:
    """
    Restituisce la configurazione timbratura effettiva per un utente.
    
    Se l'utente ha delle eccezioni configurate (timbratura_override),
    queste DISABILITANO i metodi per quell'operatore.
    
    La logica è:
    - Config aziendale definisce i metodi disponibili per tutti
    - Le eccezioni operatore DISABILITANO metodi specifici
    - Se tutti i metodi sono disabilitati = timbratura diretta
    """
    base_config = get_timbratura_config()
    
    if not member_key:
        return base_config
    
    # Cerca le eccezioni per questo operatore
    try:
        db = get_db()
        ensure_crew_members_table(db)
        
        # Cerca prima per corrispondenza esatta, poi per corrispondenza parziale (nome inizia con)
        row = None
        member_key_lower = member_key.lower().strip()
        
        if DB_VENDOR == "mysql":
            # Prima cerca corrispondenza esatta
            row = db.execute(
                "SELECT timbratura_override FROM crew_members WHERE rentman_id = %s OR LOWER(name) = %s LIMIT 1",
                (member_key, member_key_lower)
            ).fetchone()
            
            # Se non trovato, cerca per nome che inizia con member_key (es. "angelo" -> "Angelo Ruggieri")
            if not row:
                row = db.execute(
                    "SELECT timbratura_override FROM crew_members WHERE LOWER(name) LIKE %s AND timbratura_override IS NOT NULL LIMIT 1",
                    (member_key_lower + '%',)
                ).fetchone()
        else:
            row = db.execute(
                "SELECT timbratura_override FROM crew_members WHERE rentman_id = ? OR LOWER(name) = ? LIMIT 1",
                (member_key, member_key_lower)
            ).fetchone()
            
            if not row:
                row = db.execute(
                    "SELECT timbratura_override FROM crew_members WHERE LOWER(name) LIKE ? AND timbratura_override IS NOT NULL LIMIT 1",
                    (member_key_lower + '%',)
                ).fetchone()
        
        if row and row[0]:
            override = row[0]
            if isinstance(override, str):
                override = json.loads(override)
            
            app.logger.info(f"Trovata eccezione timbratura per '{member_key}': {override}")
            
            # Le eccezioni DISABILITANO i metodi (override con False)
            if "qr_disabled" in override and override.get("qr_disabled"):
                base_config["qr_enabled"] = False
            if "gps_disabled" in override and override.get("gps_disabled"):
                base_config["gps_enabled"] = False
                
    except Exception as e:
        app.logger.warning(f"Errore lettura eccezioni timbratura per {member_key}: {e}")
    
    return base_config


def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """
    Calcola la distanza in metri tra due coordinate usando la formula di Haversine.
    """
    import math
    R = 6371000  # Raggio della Terra in metri
    
    phi1 = math.radians(lat1)
    phi2 = math.radians(lat2)
    delta_phi = math.radians(lat2 - lat1)
    delta_lambda = math.radians(lon2 - lon1)
    
    a = math.sin(delta_phi / 2) ** 2 + \
        math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    
    return R * c


@app.get("/api/timbratura/config")
@login_required
def api_timbratura_config():
    """Restituisce le opzioni di timbratura disponibili per l'utente corrente."""
    # Recupera il nome utente dalla sessione per verificare eventuali eccezioni
    # user_name contiene il nome completo che dovrebbe corrispondere a crew_members.name
    user_full_name = session.get("user_name") or session.get("user_display") or session.get("user")
    timb_config = get_user_timbratura_config(user_full_name)
    
    app.logger.debug(f"Timbratura config per utente '{user_full_name}': qr={timb_config.get('qr_enabled')}, gps={timb_config.get('gps_enabled')}")
    
    # Includi le coordinate delle locations per il calcolo della distanza lato client
    locations = []
    for loc in timb_config.get("gps_locations", []):
        locations.append({
            "name": loc.get("name", "Sede"),
            "latitude": loc.get("latitude"),
            "longitude": loc.get("longitude"),
            "radius_meters": loc.get("radius_meters", 300)
        })
    
    # Verifica se l'utente appartiene a un gruppo di produzione
    is_production_group = False
    try:
        username = session.get('user')
        db = get_db()
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        user_row = db.execute(
            f"SELECT group_id FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        if user_row:
            gid = user_row['group_id'] if isinstance(user_row, dict) else user_row[0]
            if gid:
                grp = db.execute(
                    f"SELECT is_production FROM user_groups WHERE id = {placeholder}",
                    (gid,)
                ).fetchone()
                if grp:
                    is_production_group = bool(grp['is_production'] if isinstance(grp, dict) else grp[0])
    except Exception as e:
        app.logger.warning(f"Errore verifica gruppo produzione: {e}")

    return jsonify({
        "qr_enabled": timb_config.get("qr_enabled", True),
        "gps_enabled": timb_config.get("gps_enabled", False),
        "gps_locations": locations,
        "gps_max_accuracy_meters": timb_config.get("gps_max_accuracy_meters", 50),
        "is_production_group": is_production_group
    })


@app.post("/api/timbratura/validate-gps")
@login_required
def api_timbratura_validate_gps():
    """
    Valida la posizione GPS dell'utente per la timbratura.
    Verifica che l'utente si trovi entro il raggio di una delle sedi configurate.
    Se il turno dell'utente ha una sede specifica, valida solo contro quella sede.
    """
    data = request.get_json()
    if not data:
        return jsonify({"valid": False, "error": "Dati mancanti"}), 400
    
    latitude = data.get("latitude")
    longitude = data.get("longitude")
    accuracy = data.get("accuracy", 999999)  # Accuratezza in metri
    shift_location_name = data.get("shift_location_name")
    # Coordinate della sede inviate dal frontend (calcolate dal backend /api/user/turno-oggi)
    shift_location_lat = data.get("shift_location_lat")
    shift_location_lon = data.get("shift_location_lon")
    # valid_locations: lista di locations valide calcolate dal backend (sede gruppo + location turno)
    valid_locations_from_frontend = data.get("valid_locations")
    
    app.logger.info(f"VALIDATE-GPS: shift_location_name={shift_location_name}, lat={latitude}, lon={longitude}, accuracy={accuracy}")
    app.logger.info(f"VALIDATE-GPS: shift_location_lat={shift_location_lat}, shift_location_lon={shift_location_lon}")
    app.logger.info(f"VALIDATE-GPS: valid_locations_from_frontend={valid_locations_from_frontend}")
    
    if latitude is None or longitude is None:
        return jsonify({"valid": False, "error": "Coordinate GPS mancanti"}), 400
    
    try:
        latitude = float(latitude)
        longitude = float(longitude)
        accuracy = float(accuracy)
    except (TypeError, ValueError):
        return jsonify({"valid": False, "error": "Coordinate non valide"}), 400
    
    # Recupera il nome utente dalla sessione per verificare eventuali eccezioni
    username = session.get("user")
    user_full_name = session.get("user_name") or session.get("user_display") or username
    timb_config = get_user_timbratura_config(user_full_name)
    
    # Verifica se GPS è abilitato (considerando eccezioni utente)
    if not timb_config.get("gps_enabled", False):
        return jsonify({"valid": False, "error": "Timbratura GPS non abilitata"}), 400
    
    # Verifica accuratezza del GPS
    max_accuracy = timb_config.get("gps_max_accuracy_meters", 50)
    if accuracy > max_accuracy:
        return jsonify({
            "valid": False, 
            "error": f"Precisione GPS insufficiente ({int(accuracy)}m). Richiesta: max {max_accuracy}m. Prova all'aperto o attendi qualche secondo."
        }), 400
    
    locations = timb_config.get("gps_locations", [])
    if not locations and not valid_locations_from_frontend:
        return jsonify({"valid": False, "error": "Nessuna sede configurata per timbratura GPS"}), 400
    
    # Debug logging
    app.logger.info(f"GPS Validate - Input: lat={latitude}, lon={longitude}, acc={accuracy}")
    app.logger.info(f"GPS Validate - Locations raw: {locations}")
    for loc in locations:
        app.logger.info(f"GPS Validate - Location '{loc.get('name')}': lat={loc.get('latitude')} ({type(loc.get('latitude'))}), lon={loc.get('longitude')} ({type(loc.get('longitude'))})")
    
    # Se il frontend ha inviato valid_locations (sede gruppo + location turno), usa quelle direttamente
    if valid_locations_from_frontend and isinstance(valid_locations_from_frontend, list) and len(valid_locations_from_frontend) > 0:
        # Le valid_locations sono già state calcolate dal backend in /api/user/turno-oggi
        # Contengono: sede default del gruppo + location del turno se presente e diversa
        locations = []
        for vl in valid_locations_from_frontend:
            if vl.get('latitude') and vl.get('longitude'):
                locations.append({
                    "name": vl.get("name", "Sede"),
                    "latitude": float(vl["latitude"]),
                    "longitude": float(vl["longitude"]),
                    "radius_meters": int(vl.get("radius_meters", 300))
                })
        app.logger.info(f"VALIDATE-GPS: Usando {len(locations)} valid_locations dal frontend: {[l['name'] for l in locations]}")
    else:
        # FALLBACK legacy: Prova a recuperare la location dal turno odierno
        app.logger.info(f"VALIDATE-GPS: Nessuna valid_locations dal frontend, usando logica legacy")
        
        shift_location_name = data.get('shift_location_name')
        app.logger.info(f"VALIDATE-GPS: Ricevuto shift_location_name dal frontend: '{shift_location_name}'")
        
        if not shift_location_name and username:
            # Prova a recuperare dal turno odierno
            db = get_db()
            ensure_employee_shifts_table(db)
            day_of_week = datetime.now().weekday()
            placeholder = "%s" if DB_VENDOR == "mysql" else "?"
            shift_row = db.execute(f"""
                SELECT location_name FROM employee_shifts
                WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
            """, (username, day_of_week)).fetchone()
            if shift_row:
                shift_location_name = shift_row['location_name'] if isinstance(shift_row, dict) else shift_row[0]
        
        # Se il turno ha una sede specifica, filtra le locations per usare solo quella
        if shift_location_name:
            filtered_locations = [loc for loc in locations if loc.get('name') == shift_location_name]
            if filtered_locations:
                locations = filtered_locations
                app.logger.info(f"VALIDATE-GPS: Sede specifica '{shift_location_name}' trovata! Filtrando locations. Rimaste: {len(locations)}")
            else:
                app.logger.warning(f"VALIDATE-GPS: Sede '{shift_location_name}' NON trovata nelle locations disponibili: {[l.get('name') for l in locations]}")
                # Se la sede non è trovata in configurazione ma abbiamo le coordinate dal backend, usale
                if shift_location_lat is not None and shift_location_lon is not None:
                    app.logger.info(f"VALIDATE-GPS: Usando coordinate ricevute dal frontend: lat={shift_location_lat}, lon={shift_location_lon}")
                    # Crea una location virtuale con le coordinate ricevute (convertendo in float)
                    try:
                        virtual_lat = float(shift_location_lat)
                        virtual_lon = float(shift_location_lon)
                    except (ValueError, TypeError):
                        app.logger.error(f"VALIDATE-GPS: Errore conversione coordinate: lat={shift_location_lat}, lon={shift_location_lon}")
                        return jsonify({"valid": False, "error": "Coordinate sede non valide"}), 400
                    
                    # Recupera il raggio dalla cache se disponibile
                    virtual_radius = 300
                    db = get_db()
                    cached = get_location_cache(db, shift_location_name)
                    if cached:
                        virtual_radius = cached[2]  # Il terzo elemento è il raggio
                        app.logger.info(f"VALIDATE-GPS: Usando raggio dalla cache: {virtual_radius}m")
                    
                    virtual_location = {
                        "name": shift_location_name or "Sede",
                        "latitude": virtual_lat,
                        "longitude": virtual_lon,
                        "radius_meters": virtual_radius
                    }
                    locations = [virtual_location]
    
    # Verifica se l'utente è entro il raggio di una delle sedi
    matched_location = None
    min_distance = float('inf')
    
    for loc in locations:
        loc_lat = loc.get("latitude")
        loc_lon = loc.get("longitude")
        loc_radius = loc.get("radius_meters", 300)
        
        if loc_lat is None or loc_lon is None:
            continue
        
        distance = haversine_distance(latitude, longitude, loc_lat, loc_lon)
        
        if distance < min_distance:
            min_distance = distance
        
        # Considera anche l'accuratezza del GPS nell'errore
        effective_distance = distance - accuracy  # Distanza minima possibile
        
        if effective_distance <= loc_radius:
            matched_location = loc
            break
    
    if not matched_location:
        return jsonify({
            "valid": False, 
            "error": f"Non sei in una sede autorizzata. Distanza minima: {int(min_distance)}m",
            "distance": int(min_distance)
        }), 400
    
    # GPS valido! Genera token come per QR
    validation_token = secrets.token_urlsafe(32)
    expires = now_ms() + (5 * 60 * 1000)  # 5 minuti
    
    # Salva in sessione (stesso meccanismo del QR)
    session["timbratura_token"] = validation_token
    session["timbratura_token_expires"] = expires
    session["timbratura_method"] = "gps"
    session["timbratura_location"] = matched_location.get("name", "Sede")
    session["timbratura_gps_lat"] = latitude
    session["timbratura_gps_lon"] = longitude
    
    app.logger.info(f"GPS validato per {session.get('user')}: {matched_location.get('name')} (distanza: {int(min_distance)}m, accuracy: {int(accuracy)}m)")
    
    return jsonify({
        "valid": True,
        "token": validation_token,
        "expires_in": 300,
        "location": matched_location.get("name", "Sede"),
        "distance": int(min_distance),
        "accuracy": int(accuracy)
    })


# ═══════════════════════════════════════════════════════════════════════════════
#  PLANNING GRUPPO - VISTA SETTIMANALE
# ═══════════════════════════════════════════════════════════════════════════════

@app.get("/admin/group-planning")
@app.get("/admin/group-planning/<int:group_id>")
@login_required
def admin_group_planning_page(group_id: Optional[int] = None) -> ResponseReturnValue:
    """Pagina planning settimanale per gruppo."""
    if not session.get("is_admin") and session.get("role") != "supervisor":
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    db = get_db()
    ensure_user_groups_table(db)

    # Recupera tutti i gruppi attivi
    groups = db.execute("SELECT id, name FROM user_groups WHERE is_active = 1 ORDER BY name").fetchall()
    groups_list = [{"id": g["id"] if isinstance(g, dict) else g[0], 
                    "name": g["name"] if isinstance(g, dict) else g[1]} for g in groups]

    # Se non specificato, usa il primo gruppo
    if group_id is None and groups_list:
        group_id = groups_list[0]["id"]
    
    group_name = "Nessun Gruppo"
    for g in groups_list:
        if g["id"] == group_id:
            group_name = g["name"]
            break

    return render_template(
        "admin_group_planning.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=session.get("is_admin"),
        groups=groups_list,
        group_id=group_id,
        group_name=group_name,
    )


@app.get("/api/admin/group-planning/<int:group_id>")
@login_required
def api_admin_group_planning(group_id: int) -> ResponseReturnValue:
    """API per recuperare il planning settimanale di un gruppo."""
    if not session.get("is_admin") and session.get("role") != "supervisor":
        return jsonify({"error": "forbidden"}), 403

    start_date = request.args.get("start")
    end_date = request.args.get("end")

    if not start_date or not end_date:
        return jsonify({"error": "Date start e end richieste"}), 400

    db = get_db()
    ensure_user_groups_table(db)
    ensure_rentman_plannings_table(db)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Recupera gli utenti del gruppo
    users = db.execute(f"""
        SELECT u.username, u.display_name, u.full_name, u.rentman_crew_id
        FROM app_users u
        WHERE u.group_id = {placeholder} AND u.is_active = 1
        ORDER BY u.display_name, u.username
    """, (group_id,)).fetchall()

    users_list = []
    crew_ids = []
    username_by_crew = {}

    for u in users:
        username = u["username"] if isinstance(u, dict) else u[0]
        display_name = u["display_name"] if isinstance(u, dict) else u[1]
        crew_id = u["rentman_crew_id"] if isinstance(u, dict) else u[3]
        
        users_list.append({
            "username": username,
            "display_name": display_name,
            "crew_id": crew_id
        })
        
        if crew_id:
            crew_ids.append(crew_id)
            username_by_crew[crew_id] = username

    shifts_list = []

    # Se ci sono crew_id, recupera i turni Rentman
    if crew_ids:
        placeholders = ",".join([placeholder] * len(crew_ids))
        
        plannings = db.execute(f"""
            SELECT crew_id, planning_date, project_code, project_name, function_name,
                   plan_start, plan_end, hours_planned, remark, is_leader, transport,
                   break_start, break_end, break_minutes, location_name, location_id
            FROM rentman_plannings
            WHERE crew_id IN ({placeholders})
              AND is_obsolete = 0
              AND planning_date >= {placeholder}
              AND planning_date <= {placeholder}
            ORDER BY planning_date, plan_start
        """, (*crew_ids, start_date, end_date)).fetchall()

        for p in plannings:
            crew_id = p["crew_id"] if isinstance(p, dict) else p[0]
            username = username_by_crew.get(crew_id)
            if not username:
                continue

            planning_date = p["planning_date"] if isinstance(p, dict) else p[1]
            plan_start = p["plan_start"] if isinstance(p, dict) else p[5]
            plan_end = p["plan_end"] if isinstance(p, dict) else p[6]
            hours_planned = p["hours_planned"] if isinstance(p, dict) else p[7]
            location_name = p["location_name"] if isinstance(p, dict) else p[14]
            location_id = p["location_id"] if isinstance(p, dict) else p[15]
            
            # Coordinate dalla cache globale
            location_lat, location_lon, location_radius = None, None, 300
            if location_name:
                ensure_location_cache_table(db)
                cached_coords = get_location_cache(db, location_name, location_id)
                if cached_coords:
                    location_lat, location_lon, location_radius = cached_coords
                    app.logger.info(f"✅ Group-planning: Location '{location_name}' (id={location_id}) - usando coordinate dalla cache: {location_lat}, {location_lon}, raggio={location_radius}m")

            # Normalizza data
            if hasattr(planning_date, 'isoformat'):
                date_str = planning_date.isoformat()
            else:
                date_str = str(planning_date)[:10]

            # Formatta orari
            start_str = ""
            end_str = ""
            if plan_start:
                if hasattr(plan_start, 'strftime'):
                    start_str = plan_start.strftime("%H:%M")
                else:
                    s = str(plan_start)
                    start_str = s[11:16] if len(s) > 11 else s[:5]
            if plan_end:
                if hasattr(plan_end, 'strftime'):
                    end_str = plan_end.strftime("%H:%M")
                else:
                    s = str(plan_end)
                    end_str = s[11:16] if len(s) > 11 else s[:5]

            shifts_list.append({
                "username": username,
                "date": date_str,
                "type": "shift",
                "project_code": p["project_code"] if isinstance(p, dict) else p[2],
                "project_name": p["project_name"] if isinstance(p, dict) else p[3],
                "function": p["function_name"] if isinstance(p, dict) else p[4],
                "start": start_str,
                "end": end_str,
                "hours": float(hours_planned or 0),
                "note": p["remark"] if isinstance(p, dict) else p[8],
                "is_leader": bool(p["is_leader"] if isinstance(p, dict) else p[9]),
                "location_name": location_name,
                "location_lat": location_lat,
                "location_lon": location_lon,
            })

    # Aggiungere le ferie/permessi approvati (solo tipo 1=Ferie e 3=Permesso)
    if users_list:
        usernames = [u["username"] for u in users_list]
        placeholders = ",".join([placeholder] * len(usernames))
        
        requests = db.execute(f"""
            SELECT username, request_type_id, date_from, date_to, notes, extra_data
            FROM user_requests
            WHERE username IN ({placeholders})
              AND status = 'approved'
              AND request_type_id IN (1, 3)
              AND date_from <= {placeholder}
              AND date_to >= {placeholder}
            ORDER BY date_from
        """, (*usernames, end_date, start_date)).fetchall()
        
        for req in requests:
            username = req["username"] if isinstance(req, dict) else req[0]
            request_type_id = req["request_type_id"] if isinstance(req, dict) else req[1]
            date_from = req["date_from"] if isinstance(req, dict) else req[2]
            date_to = req["date_to"] if isinstance(req, dict) else req[3]
            notes = req["notes"] if isinstance(req, dict) else req[4]
            extra_data_str = req["extra_data"] if isinstance(req, dict) else req[5]
            
            # Normalizza le date
            if hasattr(date_from, 'isoformat'):
                date_from_str = date_from.isoformat()
            else:
                date_from_str = str(date_from)[:10]
            
            if hasattr(date_to, 'isoformat'):
                date_to_str = date_to.isoformat()
            else:
                date_to_str = str(date_to)[:10]
            
            # Leggi il tipo di richiesta
            req_type = db.execute(
                f"SELECT name FROM request_types WHERE id = {placeholder}",
                (request_type_id,)
            ).fetchone()
            
            type_name = req_type["name"] if req_type and isinstance(req_type, dict) else (req_type[0] if req_type else "Permesso")
            
            # Estrai orari da extra_data per i permessi
            time_start = "00:00"
            time_end = "24:00"
            hours = 0
            extra_data = None
            
            if type_name == 'Permesso' and extra_data_str:
                try:
                    import json
                    # Parse extra_data se è stringa
                    if isinstance(extra_data_str, str):
                        extra = json.loads(extra_data_str)
                    else:
                        extra = extra_data_str
                    
                    time_start = extra.get("time_start", "00:00")
                    time_end = extra.get("time_end", "24:00")
                    extra_data = {"time_start": time_start, "time_end": time_end}
                    
                    # Calcola ore
                    from datetime import datetime as dt
                    start_time = dt.strptime(time_start, "%H:%M")
                    end_time = dt.strptime(time_end, "%H:%M")
                    delta = end_time - start_time
                    hours = delta.total_seconds() / 3600
                except Exception as e:
                    app.logger.error(f"Errore parsing extra_data per permesso: {e}")
                    pass
            
            # Aggiungi una card per ogni giorno della feria
            current_date = date_from
            while current_date <= date_to:
                date_str = current_date.isoformat() if hasattr(current_date, 'isoformat') else str(current_date)[:10]
                
                shift_item = {
                    "username": username,
                    "date": date_str,
                    "type": "vacation",
                    "project_code": type_name,
                    "project_name": type_name,
                    "function": type_name,
                    "start": time_start,
                    "end": time_end,
                    "hours": hours,
                    "note": notes or "",
                    "is_leader": False,
                }
                
                # Aggiungi extra_data solo se presente
                if extra_data:
                    shift_item["extra_data"] = extra_data
                
                shifts_list.append(shift_item)
                
                # Incrementa di un giorno
                from datetime import timedelta
                current_date = current_date + timedelta(days=1)

    return jsonify({
        "users": users_list,
        "shifts": shifts_list
    })


# ═══════════════════════════════════════════════════════════════════════════════
#  GESTIONE GRUPPI UTENTI - ADMIN UI
# ═══════════════════════════════════════════════════════════════════════════════

@app.get("/admin/groups")
@login_required
def admin_groups_page() -> ResponseReturnValue:
    """Pagina gestione gruppi utenti (solo admin)."""
    if not session.get("is_admin"):
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    # Verifica se CedolinoWeb è attivo (config.json + database settings)
    cedolino_sync_enabled = get_cedolino_settings() is not None
    app.logger.info(f"admin_groups_page: cedolino_sync_enabled={cedolino_sync_enabled}")

    # Recupera le location GPS configurate
    timbratura_config = get_timbratura_config()
    gps_locations = timbratura_config.get("gps_locations", [])

    return render_template(
        "admin_groups.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=True,
        cedolino_sync_enabled=cedolino_sync_enabled,
        gps_locations=gps_locations,
    )


@app.get("/api/admin/groups")
@login_required
def api_admin_groups_list() -> ResponseReturnValue:
    """Lista tutti i gruppi."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    ensure_user_groups_table(db)
    
    rows = db.execute("""
        SELECT id, name, description, cedolino_group_id, gps_location_name, is_active, is_production, created_ts, updated_ts
        FROM user_groups
        ORDER BY name ASC
    """).fetchall()

    groups = []
    for row in rows:
        groups.append({
            "id": row["id"] if isinstance(row, dict) else row[0],
            "name": row["name"] if isinstance(row, dict) else row[1],
            "description": row["description"] if isinstance(row, dict) else row[2],
            "cedolino_group_id": row["cedolino_group_id"] if isinstance(row, dict) else row[3],
            "gps_location_name": row["gps_location_name"] if isinstance(row, dict) else row[4],
            "is_active": bool(row["is_active"] if isinstance(row, dict) else row[5]),
            "is_production": bool(row["is_production"] if isinstance(row, dict) else row[6]),
            "created_ts": row["created_ts"] if isinstance(row, dict) else row[7],
            "updated_ts": row["updated_ts"] if isinstance(row, dict) else row[8],
        })

    return jsonify({"groups": groups})


@app.post("/api/admin/groups")
@login_required
def api_admin_groups_create() -> ResponseReturnValue:
    """Crea un nuovo gruppo."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati non validi"}), 400

    name = (data.get("name") or "").strip()
    description = (data.get("description") or "").strip() or None
    cedolino_group_id = (data.get("cedolino_group_id") or "").strip() or None
    gps_location_name = (data.get("gps_location_name") or "").strip() or None
    is_active = data.get("is_active", True)
    is_production = data.get("is_production", False)

    if not name:
        return jsonify({"error": "Nome gruppo richiesto"}), 400

    db = get_db()
    ensure_user_groups_table(db)

    # Verifica se esiste già
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    existing = db.execute(f"SELECT id FROM user_groups WHERE name = {placeholder}", (name,)).fetchone()

    if existing:
        return jsonify({"error": f"Il gruppo '{name}' esiste già"}), 409

    now = now_ms()

    if DB_VENDOR == "mysql":
        db.execute("""
            INSERT INTO user_groups (name, description, cedolino_group_id, gps_location_name, is_active, is_production, created_ts, updated_ts)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """, (name, description, cedolino_group_id, gps_location_name, 1 if is_active else 0, 1 if is_production else 0, now, now))
    else:
        db.execute("""
            INSERT INTO user_groups (name, description, cedolino_group_id, gps_location_name, is_active, is_production, created_ts, updated_ts)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (name, description, cedolino_group_id, gps_location_name, 1 if is_active else 0, 1 if is_production else 0, now, now))
    
    new_id = _last_insert_id(db)
    db.commit()

    app.logger.info("Admin %s ha creato gruppo '%s' (id=%s)", session.get("user"), name, new_id)
    return jsonify({"ok": True, "id": new_id, "name": name}), 201


@app.put("/api/admin/groups/<int:group_id>")
@login_required
def api_admin_groups_update(group_id: int) -> ResponseReturnValue:
    """Modifica un gruppo esistente."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati non validi"}), 400

    db = get_db()
    ensure_user_groups_table(db)

    # Verifica che il gruppo esista
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    existing = db.execute(f"SELECT id FROM user_groups WHERE id = {placeholder}", (group_id,)).fetchone()

    if not existing:
        return jsonify({"error": f"Gruppo con id={group_id} non trovato"}), 404

    # Prepara i campi da aggiornare
    updates = []
    params = []

    if "name" in data:
        name = (data["name"] or "").strip()
        if name:
            # Verifica unicità nome
            check = db.execute(
                f"SELECT id FROM user_groups WHERE name = {placeholder} AND id != {placeholder}",
                (name, group_id)
            ).fetchone()
            if check:
                return jsonify({"error": f"Il nome '{name}' è già utilizzato da un altro gruppo"}), 409
            updates.append("name = " + placeholder)
            params.append(name)

    if "description" in data:
        description = (data["description"] or "").strip() or None
        updates.append("description = " + placeholder)
        params.append(description)

    if "cedolino_group_id" in data:
        cedolino_group_id = (data["cedolino_group_id"] or "").strip() or None
        updates.append("cedolino_group_id = " + placeholder)
        params.append(cedolino_group_id)

    if "gps_location_name" in data:
        gps_location_name = (data["gps_location_name"] or "").strip() or None
        updates.append("gps_location_name = " + placeholder)
        params.append(gps_location_name)

    if "is_active" in data:
        is_active = data["is_active"]
        updates.append("is_active = " + placeholder)
        params.append(1 if is_active else 0)

    if "is_production" in data:
        is_production = data["is_production"]
        updates.append("is_production = " + placeholder)
        params.append(1 if is_production else 0)

    if not updates:
        return jsonify({"error": "Nessun campo da aggiornare"}), 400

    updates.append("updated_ts = " + placeholder)
    params.append(now_ms())
    params.append(group_id)

    sql = f"UPDATE user_groups SET {', '.join(updates)} WHERE id = {placeholder}"
    db.execute(sql, tuple(params))
    db.commit()

    app.logger.info("Admin %s ha modificato gruppo id=%s", session.get("user"), group_id)
    return jsonify({"ok": True})


@app.delete("/api/admin/groups/<int:group_id>")
@login_required
def api_admin_groups_delete(group_id: int) -> ResponseReturnValue:
    """Elimina un gruppo."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    ensure_user_groups_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    # Verifica che il gruppo esista
    existing = db.execute(f"SELECT id, name FROM user_groups WHERE id = {placeholder}", (group_id,)).fetchone()
    if not existing:
        return jsonify({"error": f"Gruppo con id={group_id} non trovato"}), 404

    group_name = existing["name"] if isinstance(existing, dict) else existing[1]

    # Verifica se ci sono utenti associati
    users_count = db.execute(
        f"SELECT COUNT(*) as cnt FROM app_users WHERE group_id = {placeholder}",
        (group_id,)
    ).fetchone()
    count = users_count["cnt"] if isinstance(users_count, dict) else users_count[0]
    
    if count > 0:
        return jsonify({"error": f"Impossibile eliminare: {count} utente/i ancora associato/i a questo gruppo"}), 400

    db.execute(f"DELETE FROM user_groups WHERE id = {placeholder}", (group_id,))
    db.commit()

    app.logger.info("Admin %s ha eliminato gruppo '%s' (id=%s)", session.get("user"), group_name, group_id)
    return jsonify({"ok": True})


# ═══════════════════════════════════════════════════════════════════════════════
#  GESTIONE UTENTI - ADMIN UI
# ═══════════════════════════════════════════════════════════════════════════════

VALID_USER_ROLES = {"user", "supervisor", "admin"}


@app.get("/admin/users")
@login_required
def admin_users_page() -> ResponseReturnValue:
    """Pagina gestione utenti (solo admin)."""
    if not session.get("is_admin"):
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    # Verifica se CedolinoWeb è attivo (config.json + database settings)
    cedolino_sync_enabled = get_cedolino_settings() is not None

    return render_template(
        "admin_users.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=True,
        cedolino_sync_enabled=cedolino_sync_enabled,
    )


@app.get("/api/admin/users")
@login_required
def api_admin_users_list() -> ResponseReturnValue:
    """Lista tutti gli utenti."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    ensure_user_groups_table(db)
    
    rows = db.execute("""
        SELECT u.username, u.display_name, u.full_name, u.role, u.is_active, 
               u.created_ts, u.updated_ts, u.rentman_crew_id, c.name as crew_name,
               u.external_id, u.external_group_id, u.group_id, g.name as group_name,
               g.cedolino_group_id as group_cedolino_id
        FROM app_users u
        LEFT JOIN crew_members c ON u.rentman_crew_id = c.rentman_id
        LEFT JOIN user_groups g ON u.group_id = g.id
        ORDER BY u.username ASC
    """).fetchall()

    users = []
    for row in rows:
        external_id = row["external_id"] if isinstance(row, dict) else row[9]
        
        users.append({
            "username": row["username"] if isinstance(row, dict) else row[0],
            "display_name": row["display_name"] if isinstance(row, dict) else row[1],
            "full_name": row["full_name"] if isinstance(row, dict) else row[2],
            "role": row["role"] if isinstance(row, dict) else row[3],
            "is_active": bool(row["is_active"] if isinstance(row, dict) else row[4]),
            "created_ts": row["created_ts"] if isinstance(row, dict) else row[5],
            "updated_ts": row["updated_ts"] if isinstance(row, dict) else row[6],
            "rentman_crew_id": row["rentman_crew_id"] if isinstance(row, dict) else row[7],
            "crew_name": row["crew_name"] if isinstance(row, dict) else row[8],
            "external_id": external_id,
            "external_group_id": row["external_group_id"] if isinstance(row, dict) else row[10],
            "group_id": row["group_id"] if isinstance(row, dict) else row[11],
            "group_name": row["group_name"] if isinstance(row, dict) else row[12],
            "group_cedolino_id": row["group_cedolino_id"] if isinstance(row, dict) else row[13],
        })

    return jsonify({"users": users})


@app.post("/api/admin/users")
@login_required
def api_admin_users_create() -> ResponseReturnValue:
    """Crea un nuovo utente."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati non validi"}), 400

    username = (data.get("username") or "").strip().lower()
    password = data.get("password", "")
    display_name = (data.get("display_name") or "").strip()
    full_name = (data.get("full_name") or "").strip() or None
    role = (data.get("role") or "user").strip().lower()
    is_active = data.get("is_active", True)
    rentman_crew_id = data.get("rentman_crew_id")
    if rentman_crew_id is not None:
        rentman_crew_id = int(rentman_crew_id) if rentman_crew_id else None

    if not username:
        return jsonify({"error": "Username richiesto"}), 400
    if not password:
        return jsonify({"error": "Password richiesta"}), 400
    if not display_name:
        display_name = username
    if role not in VALID_USER_ROLES:
        return jsonify({"error": f"Ruolo non valido. Valori ammessi: {', '.join(sorted(VALID_USER_ROLES))}"}), 400

    db = get_db()

    # Verifica se esiste già
    if DB_VENDOR == "mysql":
        existing = db.execute("SELECT username FROM app_users WHERE username = %s", (username,)).fetchone()
    else:
        existing = db.execute("SELECT username FROM app_users WHERE username = ?", (username,)).fetchone()

    if existing:
        return jsonify({"error": f"L'utente '{username}' esiste già"}), 409

    now = now_ms()
    password_hashed = hash_password(password)

    if DB_VENDOR == "mysql":
        db.execute("""
            INSERT INTO app_users (username, password_hash, display_name, full_name, role, is_active, rentman_crew_id, created_ts, updated_ts)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (username, password_hashed, display_name, full_name, role, 1 if is_active else 0, rentman_crew_id, now, now))
    else:
        db.execute("""
            INSERT INTO app_users (username, password_hash, display_name, full_name, role, is_active, rentman_crew_id, created_ts, updated_ts)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (username, password_hashed, display_name, full_name, role, 1 if is_active else 0, rentman_crew_id, now, now))
    db.commit()

    app.logger.info("Admin %s ha creato utente %s con ruolo %s", session.get("user"), username, role)
    return jsonify({"ok": True, "username": username}), 201


@app.put("/api/admin/users/<username>")
@login_required
def api_admin_users_update(username: str) -> ResponseReturnValue:
    """Modifica un utente esistente."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    username = username.strip().lower()
    data = request.get_json()
    app.logger.info("PUT /api/admin/users/%s - payload: %s", username, data)
    if not data:
        return jsonify({"error": "Dati non validi"}), 400

    db = get_db()

    # Verifica che l'utente esista
    if DB_VENDOR == "mysql":
        existing = db.execute("SELECT username FROM app_users WHERE username = %s", (username,)).fetchone()
    else:
        existing = db.execute("SELECT username FROM app_users WHERE username = ?", (username,)).fetchone()

    if not existing:
        return jsonify({"error": f"Utente '{username}' non trovato"}), 404

    # Prepara i campi da aggiornare
    updates = []
    params = []

    if "display_name" in data:
        display_name = (data["display_name"] or "").strip()
        if display_name:
            updates.append("display_name = " + ("%s" if DB_VENDOR == "mysql" else "?"))
            params.append(display_name)

    if "full_name" in data:
        full_name = (data["full_name"] or "").strip() or None
        updates.append("full_name = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(full_name)

    if "role" in data:
        role = (data["role"] or "").strip().lower()
        if role not in VALID_USER_ROLES:
            return jsonify({"error": f"Ruolo non valido. Valori ammessi: {', '.join(sorted(VALID_USER_ROLES))}"}), 400
        # Impedisci di rimuovere il ruolo admin a se stessi
        current_user = session.get("user", "").lower()
        if username == current_user and role != "admin":
            return jsonify({"error": "Non puoi rimuovere il ruolo admin a te stesso"}), 400
        updates.append("role = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(role)

    if "is_active" in data:
        is_active = data["is_active"]
        # Impedisci di disattivare se stessi
        current_user = session.get("user", "").lower()
        if username == current_user and not is_active:
            return jsonify({"error": "Non puoi disattivare il tuo account"}), 400
        updates.append("is_active = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(1 if is_active else 0)

    if "password" in data and data["password"]:
        password_hashed = hash_password(data["password"])
        updates.append("password_hash = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(password_hashed)

    if "rentman_crew_id" in data:
        rentman_crew_id = data.get("rentman_crew_id")
        # Può essere None per rimuovere l'associazione, o un intero
        if rentman_crew_id is not None and rentman_crew_id != "":
            rentman_crew_id = int(rentman_crew_id)
        else:
            rentman_crew_id = None
        updates.append("rentman_crew_id = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(rentman_crew_id)

    # Gestione external_id per CedolinoWeb (ID diretto utente)
    if "external_id" in data:
        external_id = data.get("external_id")
        # Può essere None/vuoto per rimuovere l'ID, o una stringa
        if external_id is not None and external_id != "":
            external_id = str(external_id).strip()
        else:
            external_id = None
        updates.append("external_id = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(external_id)

    # Gestione external_group_id per CedolinoWeb (Gruppo ID diretto utente - deprecato, usare group_id)
    if "external_group_id" in data:
        external_group_id = data.get("external_group_id")
        # Può essere None/vuoto per rimuovere l'ID, o una stringa
        if external_group_id is not None and external_group_id != "":
            external_group_id = str(external_group_id).strip()
        else:
            external_group_id = None
        updates.append("external_group_id = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(external_group_id)

    # Gestione group_id per collegamento a user_groups
    if "group_id" in data:
        group_id = data.get("group_id")
        # Può essere None/vuoto per rimuovere l'associazione, o un intero
        if group_id is not None and group_id != "":
            group_id = int(group_id)
        else:
            group_id = None
        updates.append("group_id = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(group_id)

    if not updates:
        return jsonify({"error": "Nessun campo da aggiornare"}), 400

    updates.append("updated_ts = " + ("%s" if DB_VENDOR == "mysql" else "?"))
    params.append(now_ms())
    params.append(username)

    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    sql = f"UPDATE app_users SET {', '.join(updates)} WHERE username = {placeholder}"
    app.logger.info("SQL UPDATE: %s con params: %s", sql, params)
    
    cursor = db.execute(sql, tuple(params))
    app.logger.info("Rows affected: %s", cursor.rowcount if hasattr(cursor, 'rowcount') else 'N/A')
    
    db.commit()
    app.logger.info("COMMIT eseguito per utente %s", username)
    
    # Verifica immediata
    if DB_VENDOR == "mysql":
        verify = db.execute("SELECT rentman_crew_id FROM app_users WHERE username = %s", (username,)).fetchone()
        app.logger.info("Verifica dopo commit - rentman_crew_id: %s", verify)

    app.logger.info("Admin %s ha modificato utente %s", session.get("user"), username)
    return jsonify({"ok": True, "username": username})


@app.delete("/api/admin/users/<username>")
@login_required
def api_admin_users_delete(username: str) -> ResponseReturnValue:
    """Elimina un utente."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    username = username.strip().lower()

    # Impedisci di eliminare se stessi
    current_user = session.get("user", "").lower()
    if username == current_user:
        return jsonify({"error": "Non puoi eliminare il tuo account"}), 400

    db = get_db()

    # Verifica che l'utente esista
    if DB_VENDOR == "mysql":
        existing = db.execute("SELECT username FROM app_users WHERE username = %s", (username,)).fetchone()
    else:
        existing = db.execute("SELECT username FROM app_users WHERE username = ?", (username,)).fetchone()

    if not existing:
        return jsonify({"error": f"Utente '{username}' non trovato"}), 404

    if DB_VENDOR == "mysql":
        db.execute("DELETE FROM app_users WHERE username = %s", (username,))
    else:
        db.execute("DELETE FROM app_users WHERE username = ?", (username,))
    db.commit()

    app.logger.info("Admin %s ha eliminato utente %s", session.get("user"), username)
    return jsonify({"ok": True, "deleted": username})


# ═══════════════════════════════════════════════════════════════════════════════
#  GESTIONE OPERATORI (Admin) - API
# ═══════════════════════════════════════════════════════════════════════════════

@app.route("/admin/operators")
@login_required
def admin_operators() -> ResponseReturnValue:
    """Pagina gestione operatori."""
    if not session.get("is_admin"):
        flash("Accesso non autorizzato", "danger")
        return redirect(url_for("index"))
    
    return render_template("admin_operators.html", is_admin=True)


@app.get("/api/admin/operators")
@login_required
def api_admin_operators_list() -> ResponseReturnValue:
    """Lista tutti gli operatori dal database."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    ensure_crew_members_table(db)

    cursor = db.execute(
        "SELECT id, rentman_id, name, email, phone, is_active, created_ts, updated_ts, timbratura_override "
        "FROM crew_members ORDER BY name"
    )
    rows = cursor.fetchall()

    operators = []
    for row in rows:
        timbratura_override = row[8] if len(row) > 8 else None
        if timbratura_override and isinstance(timbratura_override, str):
            try:
                timbratura_override = json.loads(timbratura_override)
            except:
                timbratura_override = None
        
        operators.append({
            "id": row[0],
            "rentman_id": row[1],
            "name": row[2],
            "email": row[3],
            "phone": row[4],
            "is_active": bool(row[5]),
            "created_ts": row[6],
            "updated_ts": row[7],
            "timbratura_override": timbratura_override
        })

    return jsonify({"ok": True, "operators": operators})


@app.put("/api/admin/operators/<int:operator_id>")
@login_required
def api_admin_operators_update(operator_id: int) -> ResponseReturnValue:
    """Aggiorna un operatore (email, phone, is_active, timbratura_override)."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json(silent=True) or {}

    db = get_db()
    ensure_crew_members_table(db)

    # Verifica che l'operatore esista
    if DB_VENDOR == "mysql":
        existing = db.execute("SELECT id, name FROM crew_members WHERE id = %s", (operator_id,)).fetchone()
    else:
        existing = db.execute("SELECT id, name FROM crew_members WHERE id = ?", (operator_id,)).fetchone()

    if not existing:
        return jsonify({"error": "Operatore non trovato"}), 404

    # Prepara i campi da aggiornare
    email = data.get("email")
    if email is not None:
        email = email.strip() if email else None

    phone = data.get("phone")
    if phone is not None:
        phone = phone.strip() if phone else None

    is_active = data.get("is_active")
    if is_active is not None:
        is_active = 1 if is_active else 0

    now = now_ms()

    # Costruisci query di aggiornamento dinamica
    updates = []
    params = []

    if "email" in data:
        updates.append("email = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(email)
    if "phone" in data:
        updates.append("phone = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(phone)
    if "is_active" in data:
        updates.append("is_active = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(is_active)
    
    # Gestione eccezioni timbratura (qr_disabled, gps_disabled)
    if "timbratura_override" in data:
        timbratura_override = data.get("timbratura_override")
        if timbratura_override and isinstance(timbratura_override, dict):
            # Verifica se c'è almeno una disabilitazione attiva
            has_override = timbratura_override.get("qr_disabled") or timbratura_override.get("gps_disabled")
            if has_override:
                timbratura_override = json.dumps(timbratura_override)
            else:
                timbratura_override = None
        else:
            timbratura_override = None
        updates.append("timbratura_override = " + ("%s" if DB_VENDOR == "mysql" else "?"))
        params.append(timbratura_override)

    if not updates:
        return jsonify({"error": "Nessun campo da aggiornare"}), 400

    updates.append("updated_ts = " + ("%s" if DB_VENDOR == "mysql" else "?"))
    params.append(now)
    params.append(operator_id)

    sql = f"UPDATE crew_members SET {', '.join(updates)} WHERE id = " + ("%s" if DB_VENDOR == "mysql" else "?")

    db.execute(sql, tuple(params))
    db.commit()

    app.logger.info("Admin %s ha modificato operatore %s (id=%d)", session.get("user"), existing[1], operator_id)
    return jsonify({"ok": True, "id": operator_id})


@app.post("/api/admin/operators/sync")
@login_required
def api_admin_operators_sync() -> ResponseReturnValue:
    """Forza la sincronizzazione degli operatori da Rentman."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    try:
        from rentman_client import rentman_request
    except ImportError:
        return jsonify({"error": "Client Rentman non disponibile"}), 500

    # Recupera tutti i crew members da Rentman
    try:
        response = rentman_request("GET", "/crew")
        if not response:
            return jsonify({"error": "Nessuna risposta da Rentman"}), 502
    except Exception as e:
        app.logger.error("Errore sync operatori Rentman: %s", e)
        return jsonify({"error": str(e)}), 500

    db = get_db()
    ensure_crew_members_table(db)

    synced = 0
    crew_data = response.get("data", [])
    for crew in crew_data:
        rentman_id = crew.get("id")
        name = crew.get("displayname") or crew.get("name") or f"Crew {rentman_id}"
        if rentman_id:
            sync_crew_member_from_rentman(db, rentman_id, name)
            synced += 1

    db.commit()

    app.logger.info("Admin %s ha sincronizzato %d operatori da Rentman", session.get("user"), synced)
    return jsonify({"ok": True, "synced": synced})


# ═══════════════════════════════════════════════════════════════════════════════
#  LOCATION CACHE - Gestione coordinate GPS per location Rentman
# ═══════════════════════════════════════════════════════════════════════════════

def ensure_location_cache_table(db: DatabaseLike) -> None:
    """Crea la tabella location_cache per salvare le coordinate GPS delle location."""
    if DB_VENDOR == "mysql":
        db.execute("""
            CREATE TABLE IF NOT EXISTS location_cache (
                id INT AUTO_INCREMENT PRIMARY KEY,
                rentman_location_id INT COMMENT 'ID della location da Rentman',
                location_name VARCHAR(500) NOT NULL COMMENT 'Nome della location Rentman',
                latitude DECIMAL(10,7) NOT NULL COMMENT 'Latitudine GPS',
                longitude DECIMAL(10,7) NOT NULL COMMENT 'Longitudine GPS',
                radius_meters INT DEFAULT 300 COMMENT 'Raggio tolleranza GPS in metri',
                is_custom TINYINT(1) DEFAULT 0 COMMENT '1 = location creata manualmente, 0 = da Rentman',
                address VARCHAR(500) COMMENT 'Indirizzo per le location custom',
                created_ts BIGINT DEFAULT 0,
                updated_ts BIGINT DEFAULT 0,
                INDEX idx_location_name (location_name),
                INDEX idx_rentman_location_id (rentman_location_id)
            ) COMMENT='Cache delle coordinate GPS per le location Rentman e custom'
        """)
        
        # Aggiungi la colonna rentman_location_id se manca
        try:
            db.execute("ALTER TABLE location_cache ADD COLUMN rentman_location_id INT COMMENT 'ID della location da Rentman' AFTER id")
            db.execute("ALTER TABLE location_cache ADD INDEX idx_rentman_location_id (rentman_location_id)")
            app.logger.info("✅ Colonna rentman_location_id aggiunta a location_cache")
        except Exception as e:
            if "Duplicate column" in str(e) or "already exists" in str(e):
                app.logger.info("ℹ️ Colonna rentman_location_id esiste già")
            else:
                app.logger.warning(f"⚠️ Errore aggiunta colonna rentman_location_id: {e}")
        
        # Aggiungi la colonna radius_meters se manca
        try:
            db.execute("ALTER TABLE location_cache ADD COLUMN radius_meters INT DEFAULT 300 COMMENT 'Raggio tolleranza GPS in metri' AFTER longitude")
            app.logger.info("✅ Colonna radius_meters aggiunta a location_cache")
        except Exception as e:
            if "Duplicate column" in str(e) or "already exists" in str(e):
                app.logger.info("ℹ️ Colonna radius_meters esiste già")
            else:
                app.logger.warning(f"⚠️ Errore aggiunta colonna radius_meters: {e}")
        
        # Aggiungi la colonna is_custom se manca
        try:
            db.execute("ALTER TABLE location_cache ADD COLUMN is_custom TINYINT(1) DEFAULT 0 COMMENT '1 = location creata manualmente, 0 = da Rentman' AFTER radius_meters")
            app.logger.info("✅ Colonna is_custom aggiunta a location_cache")
        except Exception as e:
            if "Duplicate column" in str(e) or "already exists" in str(e):
                pass
            else:
                app.logger.warning(f"⚠️ Errore aggiunta colonna is_custom: {e}")
        
        # Aggiungi la colonna address se manca
        try:
            db.execute("ALTER TABLE location_cache ADD COLUMN address VARCHAR(500) COMMENT 'Indirizzo per le location custom' AFTER is_custom")
            app.logger.info("✅ Colonna address aggiunta a location_cache")
        except Exception as e:
            if "Duplicate column" in str(e) or "already exists" in str(e):
                pass
            else:
                app.logger.warning(f"⚠️ Errore aggiunta colonna address: {e}")
    else:
        db.execute("""
            CREATE TABLE IF NOT EXISTS location_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                rentman_location_id INTEGER,
                location_name TEXT NOT NULL UNIQUE,
                latitude REAL NOT NULL,
                longitude REAL NOT NULL,
                radius_meters INTEGER DEFAULT 300,
                is_custom INTEGER DEFAULT 0,
                address TEXT,
                created_ts INTEGER DEFAULT 0,
                updated_ts INTEGER DEFAULT 0
            )
        """)
        # Migrazione colonne per SQLite (aggiungi se mancano)
        try:
            db.execute("ALTER TABLE location_cache ADD COLUMN is_custom INTEGER DEFAULT 0")
        except Exception:
            pass
        try:
            db.execute("ALTER TABLE location_cache ADD COLUMN address TEXT")
        except Exception:
            pass
    
    db.commit()

def get_location_cache(db: DatabaseLike, location_name: str, rentman_location_id: Optional[int] = None) -> Optional[Tuple[float, float, int]]:
    """Recupera le coordinate GPS e il raggio dalla cache per una location.
    Cerca prima per location_id (se fornito), poi per location_name.
    Ritorna (lat, lon, radius_meters) oppure None."""
    if not location_name:
        return None
    
    ensure_location_cache_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Cerca prima per location_id se disponibile (più preciso)
    if rentman_location_id:
        row = db.execute(
            f"SELECT latitude, longitude, COALESCE(radius_meters, 300) as radius_meters FROM location_cache WHERE rentman_location_id = {placeholder}",
            (rentman_location_id,)
        ).fetchone()
        if row:
            lat = row["latitude"] if isinstance(row, dict) else row[0]
            lon = row["longitude"] if isinstance(row, dict) else row[1]
            radius = row["radius_meters"] if isinstance(row, dict) else row[2]
            return (lat, lon, radius)
    
    # Fallback: cerca per location_name
    row = db.execute(
        f"SELECT latitude, longitude, COALESCE(radius_meters, 300) as radius_meters FROM location_cache WHERE location_name = {placeholder}",
        (location_name,)
    ).fetchone()
    
    if row:
        lat = row["latitude"] if isinstance(row, dict) else row[0]
        lon = row["longitude"] if isinstance(row, dict) else row[1]
        radius = row["radius_meters"] if isinstance(row, dict) else row[2]
        return (lat, lon, radius)
    
    return None

def save_location_cache(db: DatabaseLike, location_name: str, latitude: float, longitude: float, rentman_location_id: Optional[int] = None, radius_meters: int = 300, is_custom: int = 0, address: Optional[str] = None) -> None:
    """Salva le coordinate GPS e il raggio nella cache per una location."""
    if not location_name or latitude is None or longitude is None:
        return
    
    ensure_location_cache_table(db)
    
    now = int(datetime.now().timestamp() * 1000)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    try:
        # Prova l'INSERT o l'UPDATE se già esiste
        if DB_VENDOR == "mysql":
            db.execute("""
                INSERT INTO location_cache (rentman_location_id, location_name, latitude, longitude, radius_meters, is_custom, address, created_ts, updated_ts)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE rentman_location_id = %s, latitude = %s, longitude = %s, radius_meters = %s, is_custom = %s, address = %s, updated_ts = %s
            """, (rentman_location_id, location_name, latitude, longitude, radius_meters, is_custom, address, now, now, rentman_location_id, latitude, longitude, radius_meters, is_custom, address, now))
        else:
            # SQLite: prova INSERT, altrimenti UPDATE
            db.execute(
                "INSERT OR IGNORE INTO location_cache (rentman_location_id, location_name, latitude, longitude, radius_meters, is_custom, address, created_ts, updated_ts) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                (rentman_location_id, location_name, latitude, longitude, radius_meters, is_custom, address, now, now)
            )
            db.execute(
                "UPDATE location_cache SET rentman_location_id = ?, latitude = ?, longitude = ?, radius_meters = ?, is_custom = ?, address = ?, updated_ts = ? WHERE location_name = ?",
                (rentman_location_id, latitude, longitude, radius_meters, is_custom, address, now, location_name)
            )
        db.commit()
        app.logger.info(f"Location cache salvata: location_id={rentman_location_id}, name={location_name} ({latitude}, {longitude}), raggio={radius_meters}m, custom={is_custom}")
    except Exception as e:
        app.logger.error(f"Errore salvataggio location cache: {e}")

# ═══════════════════════════════════════════════════════════════════════════════
#  REGOLE TIMBRATURE - ADMIN
# ═══════════════════════════════════════════════════════════════════════════════

def ensure_timbratura_rules_table(db):
    """Crea la tabella timbratura_rules se non esiste."""
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    if DB_VENDOR == "mysql":
        db.execute("""
            CREATE TABLE IF NOT EXISTS timbratura_rules (
                id INT PRIMARY KEY DEFAULT 1,
                anticipo_max_minuti INT DEFAULT 30,
                tolleranza_ritardo_minuti INT DEFAULT 5,
                arrotondamento_ingresso_minuti INT DEFAULT 15,
                arrotondamento_ingresso_tipo VARCHAR(1) DEFAULT '+',
                arrotondamento_uscita_minuti INT DEFAULT 15,
                arrotondamento_uscita_tipo VARCHAR(1) DEFAULT '-',
                pausa_blocco_minimo_minuti INT DEFAULT 30,
                pausa_incremento_minuti INT DEFAULT 15,
                pausa_tolleranza_minuti INT DEFAULT 5,
                updated_ts BIGINT,
                updated_by VARCHAR(100)
            )
        """)
        # Aggiunge colonne se mancanti (per upgrade)
        try:
            db.execute("ALTER TABLE timbratura_rules ADD COLUMN arrotondamento_ingresso_tipo VARCHAR(1) DEFAULT '+'")
            db.commit()
        except:
            pass
        try:
            db.execute("ALTER TABLE timbratura_rules ADD COLUMN arrotondamento_uscita_tipo VARCHAR(1) DEFAULT '-'")
            db.commit()
        except:
            pass
    else:
        db.execute("""
            CREATE TABLE IF NOT EXISTS timbratura_rules (
                id INTEGER PRIMARY KEY DEFAULT 1,
                anticipo_max_minuti INTEGER DEFAULT 30,
                tolleranza_ritardo_minuti INTEGER DEFAULT 5,
                arrotondamento_ingresso_minuti INTEGER DEFAULT 15,
                arrotondamento_ingresso_tipo TEXT DEFAULT '+',
                arrotondamento_uscita_minuti INTEGER DEFAULT 15,
                arrotondamento_uscita_tipo TEXT DEFAULT '-',
                pausa_blocco_minimo_minuti INTEGER DEFAULT 30,
                pausa_incremento_minuti INTEGER DEFAULT 15,
                pausa_tolleranza_minuti INTEGER DEFAULT 5,
                updated_ts INTEGER,
                updated_by TEXT
            )
        """)
        # Aggiunge colonne se mancanti (per upgrade)
        try:
            db.execute("ALTER TABLE timbratura_rules ADD COLUMN arrotondamento_ingresso_tipo TEXT DEFAULT '+'")
            db.commit()
        except:
            pass
        try:
            db.execute("ALTER TABLE timbratura_rules ADD COLUMN arrotondamento_uscita_tipo TEXT DEFAULT '-'")
            db.commit()
        except:
            pass
    db.commit()


# ═══════════════════════════════════════════════════════════════════════════════
#  REGOLE TIMBRATURE PER GRUPPO
# ═══════════════════════════════════════════════════════════════════════════════

GROUP_TIMBRATURA_RULES_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS group_timbratura_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    group_id INT NOT NULL,
    rounding_mode ENUM('single', 'daily') NOT NULL DEFAULT 'single' COMMENT 'single=arrotonda singola timbrata, daily=arrotonda totale giornaliero',
    flessibilita_ingresso_minuti INT DEFAULT 30 COMMENT 'Minuti di flessibilità in ingresso rispetto al turno',
    flessibilita_uscita_minuti INT DEFAULT 30 COMMENT 'Minuti di flessibilità in uscita rispetto al turno',
    arrotondamento_giornaliero_minuti INT DEFAULT 15 COMMENT 'Blocco arrotondamento per daily mode',
    arrotondamento_giornaliero_tipo ENUM('floor', 'ceil', 'nearest') DEFAULT 'floor' COMMENT 'floor=in difetto, ceil=in eccesso, nearest=al più vicino',
    oltre_flessibilita_action ENUM('allow', 'warn', 'block') DEFAULT 'allow' COMMENT 'Azione se timbrata oltre flessibilità',
    late_threshold_minutes INT DEFAULT 15 COMMENT 'Soglia minuti ritardo per richiedere giustificazione (0=disabilitato)',
    usa_regole_pausa_standard TINYINT(1) DEFAULT 1 COMMENT 'Se true, usa regole pausa globali',
    is_active TINYINT(1) NOT NULL DEFAULT 1,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    updated_by VARCHAR(100),
    UNIQUE KEY uk_group_rules (group_id),
    FOREIGN KEY (group_id) REFERENCES user_groups(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

GROUP_TIMBRATURA_RULES_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS group_timbratura_rules (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    group_id INTEGER NOT NULL UNIQUE,
    rounding_mode TEXT NOT NULL DEFAULT 'single',
    flessibilita_ingresso_minuti INTEGER DEFAULT 30,
    flessibilita_uscita_minuti INTEGER DEFAULT 30,
    arrotondamento_giornaliero_minuti INTEGER DEFAULT 15,
    arrotondamento_giornaliero_tipo TEXT DEFAULT 'floor',
    oltre_flessibilita_action TEXT DEFAULT 'allow',
    late_threshold_minutes INTEGER DEFAULT 15,
    usa_regole_pausa_standard INTEGER DEFAULT 1,
    is_active INTEGER NOT NULL DEFAULT 1,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL,
    updated_by TEXT,
    FOREIGN KEY (group_id) REFERENCES user_groups(id) ON DELETE CASCADE
)
"""


def ensure_group_timbratura_rules_table(db):
    """Crea la tabella group_timbratura_rules se non esiste."""
    try:
        # Prima assicura che user_groups esista
        ensure_user_groups_table(db)
        
        if DB_VENDOR == "mysql":
            db.execute(GROUP_TIMBRATURA_RULES_TABLE_MYSQL)
        else:
            db.execute(GROUP_TIMBRATURA_RULES_TABLE_SQLITE)
        db.commit()
    except Exception as e:
        # Se fallisce per la foreign key, prova senza
        app.logger.warning(f"ensure_group_timbratura_rules_table: {e}")
        try:
            if DB_VENDOR == "mysql":
                # Crea senza foreign key
                db.execute("""
                    CREATE TABLE IF NOT EXISTS group_timbratura_rules (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        group_id INT NOT NULL,
                        rounding_mode ENUM('single', 'daily') NOT NULL DEFAULT 'single',
                        flessibilita_ingresso_minuti INT DEFAULT 30,
                        flessibilita_uscita_minuti INT DEFAULT 30,
                        arrotondamento_giornaliero_minuti INT DEFAULT 15,
                        arrotondamento_giornaliero_tipo ENUM('floor', 'ceil', 'nearest') DEFAULT 'floor',
                        oltre_flessibilita_action ENUM('allow', 'warn', 'block') DEFAULT 'allow',
                        late_threshold_minutes INT DEFAULT 15,
                        usa_regole_pausa_standard TINYINT(1) DEFAULT 1,
                        is_active TINYINT(1) NOT NULL DEFAULT 1,
                        created_ts BIGINT NOT NULL DEFAULT 0,
                        updated_ts BIGINT NOT NULL DEFAULT 0,
                        updated_by VARCHAR(100),
                        UNIQUE KEY uk_group_rules (group_id)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
                """)
            db.commit()
        except Exception as e2:
            app.logger.error(f"ensure_group_timbratura_rules_table fallback: {e2}")
    
    # Migrazione: aggiungi colonna late_threshold_minutes se non esiste
    if DB_VENDOR == "mysql":
        try:
            db.execute("ALTER TABLE group_timbratura_rules ADD COLUMN late_threshold_minutes INT DEFAULT 15 COMMENT 'Soglia minuti ritardo per richiedere giustificazione (0=disabilitato)'")
            db.commit()
            app.logger.info("Migrazione: aggiunta colonna late_threshold_minutes a group_timbratura_rules")
        except Exception:
            pass  # Colonna già esiste


def get_group_timbratura_rules(db, group_id: int) -> Optional[dict]:
    """
    Ottiene le regole timbrature per un gruppo specifico.
    Ritorna None se il gruppo non ha regole specifiche.
    """
    ensure_group_timbratura_rules_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    row = db.execute(
        f"SELECT * FROM group_timbratura_rules WHERE group_id = {placeholder} AND is_active = 1",
        (group_id,)
    ).fetchone()
    
    if not row:
        return None
    
    if isinstance(row, dict):
        return row
    
    # Converte tuple a dict
    columns = ['id', 'group_id', 'rounding_mode', 'flessibilita_ingresso_minuti',
               'flessibilita_uscita_minuti', 'arrotondamento_giornaliero_minuti',
               'arrotondamento_giornaliero_tipo', 'oltre_flessibilita_action',
               'late_threshold_minutes', 'usa_regole_pausa_standard', 'is_active', 
               'created_ts', 'updated_ts', 'updated_by']
    return dict(zip(columns, row))


def get_user_timbratura_rules(db, username: str) -> dict:
    """
    Ottiene le regole timbrature per un utente.
    
    Logica:
    1. Se l'utente appartiene a un gruppo con regole specifiche, usa quelle
    2. Altrimenti usa le regole globali di timbratura_rules
    
    Returns:
        dict con le regole + campo 'source' ('group' o 'global') e 'rounding_mode'
    """
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Trova il gruppo dell'utente
    user_row = db.execute(
        f"SELECT group_id FROM app_users WHERE username = {placeholder}",
        (username,)
    ).fetchone()
    
    group_id = None
    if user_row:
        group_id = user_row['group_id'] if isinstance(user_row, dict) else user_row[0]
    
    # Se ha un gruppo, cerca regole specifiche
    group_rules = None
    if group_id:
        group_rules = get_group_timbratura_rules(db, group_id)
    
    # Ottieni sempre le regole globali come fallback
    global_rules = get_timbratura_rules(db)
    
    if group_rules:
        # Controlla se il gruppo è di produzione
        _is_prod_group = False
        try:
            _pg = db.execute(
                f"SELECT is_production FROM user_groups WHERE id = {placeholder}",
                (group_id,)
            ).fetchone()
            _is_prod_group = bool((_pg['is_production'] if isinstance(_pg, dict) else _pg[0]) if _pg else False)
        except Exception:
            pass
        
        # Merge: regole gruppo + regole pausa da globali (se usa_regole_pausa_standard)
        result = {
            'source': 'group',
            'group_id': group_id,
            'is_production': _is_prod_group,
            'rounding_mode': group_rules.get('rounding_mode', 'single'),
            # Per gruppi di produzione: flessibilità FORZATA a 0
            'flessibilita_ingresso_minuti': 0 if _is_prod_group else group_rules.get('flessibilita_ingresso_minuti', 30),
            'flessibilita_uscita_minuti': 0 if _is_prod_group else group_rules.get('flessibilita_uscita_minuti', 30),
            'arrotondamento_giornaliero_minuti': group_rules.get('arrotondamento_giornaliero_minuti', 15),
            'arrotondamento_giornaliero_tipo': group_rules.get('arrotondamento_giornaliero_tipo', 'floor'),
            'oltre_flessibilita_action': group_rules.get('oltre_flessibilita_action', 'allow'),
            # Per single mode, usa comunque i valori globali
            'anticipo_max_minuti': global_rules.get('anticipo_max_minuti', 30),
            'tolleranza_ritardo_minuti': global_rules.get('tolleranza_ritardo_minuti', 5),
            'arrotondamento_ingresso_minuti': global_rules.get('arrotondamento_ingresso_minuti', 15),
            'arrotondamento_ingresso_tipo': global_rules.get('arrotondamento_ingresso_tipo', '+'),
            'arrotondamento_uscita_minuti': global_rules.get('arrotondamento_uscita_minuti', 15),
            'arrotondamento_uscita_tipo': global_rules.get('arrotondamento_uscita_tipo', '-'),
        }
        
        # Regole pausa: da globali se usa_regole_pausa_standard
        if group_rules.get('usa_regole_pausa_standard', True):
            result['pausa_blocco_minimo_minuti'] = global_rules.get('pausa_blocco_minimo_minuti', 30)
            result['pausa_incremento_minuti'] = global_rules.get('pausa_incremento_minuti', 15)
            result['pausa_tolleranza_minuti'] = global_rules.get('pausa_tolleranza_minuti', 5)
        else:
            # Prendi la pausa minima dal turno dell'utente per oggi
            from datetime import datetime
            day_of_week = datetime.now().weekday()  # 0=Lunedì, 6=Domenica
            try:
                ensure_employee_shifts_table(db)
                shift_row = db.execute(
                    f"""SELECT break_start, break_end FROM employee_shifts 
                       WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                       LIMIT 1""",
                    (username, day_of_week)
                ).fetchone()
                
                if shift_row:
                    break_start = shift_row['break_start'] if isinstance(shift_row, dict) else shift_row[0]
                    break_end = shift_row['break_end'] if isinstance(shift_row, dict) else shift_row[1]
                    
                    if break_start and break_end:
                        # Converti timedelta in minuti
                        if hasattr(break_start, 'total_seconds'):
                            bs_min = int(break_start.total_seconds()) // 60
                            be_min = int(break_end.total_seconds()) // 60
                        else:
                            # Stringa HH:MM
                            bs_parts = str(break_start)[:5].split(':')
                            be_parts = str(break_end)[:5].split(':')
                            bs_min = int(bs_parts[0]) * 60 + int(bs_parts[1])
                            be_min = int(be_parts[0]) * 60 + int(be_parts[1])
                        
                        pausa_minima_turno = be_min - bs_min
                        if pausa_minima_turno > 0:
                            result['pausa_blocco_minimo_minuti'] = pausa_minima_turno
                            result['pausa_incremento_minuti'] = 0  # Nessun incremento, usa esattamente la pausa del turno
                            result['pausa_tolleranza_minuti'] = 0  # Nessuna tolleranza
                            result['pausa_source'] = 'shift'
                            app.logger.info(f"Pausa da turno per {username}: {pausa_minima_turno} min (day {day_of_week})")
                        else:
                            # Pausa turno = 0, usa default
                            result['pausa_blocco_minimo_minuti'] = global_rules.get('pausa_blocco_minimo_minuti', 30)
                            result['pausa_incremento_minuti'] = global_rules.get('pausa_incremento_minuti', 15)
                            result['pausa_tolleranza_minuti'] = global_rules.get('pausa_tolleranza_minuti', 5)
                    else:
                        # No break definito nel turno, usa globali
                        result['pausa_blocco_minimo_minuti'] = global_rules.get('pausa_blocco_minimo_minuti', 30)
                        result['pausa_incremento_minuti'] = global_rules.get('pausa_incremento_minuti', 15)
                        result['pausa_tolleranza_minuti'] = global_rules.get('pausa_tolleranza_minuti', 5)
                else:
                    # Nessun turno per oggi, usa globali
                    result['pausa_blocco_minimo_minuti'] = global_rules.get('pausa_blocco_minimo_minuti', 30)
                    result['pausa_incremento_minuti'] = global_rules.get('pausa_incremento_minuti', 15)
                    result['pausa_tolleranza_minuti'] = global_rules.get('pausa_tolleranza_minuti', 5)
            except Exception as e:
                app.logger.warning(f"Errore lettura pausa da turno per {username}: {e}")
                result['pausa_blocco_minimo_minuti'] = global_rules.get('pausa_blocco_minimo_minuti', 30)
                result['pausa_incremento_minuti'] = global_rules.get('pausa_incremento_minuti', 15)
                result['pausa_tolleranza_minuti'] = global_rules.get('pausa_tolleranza_minuti', 5)
        
        if _is_prod_group:
            app.logger.info(
                "get_user_timbratura_rules: gruppo PRODUZIONE per %s → flessibilità forzata a 0", username
            )
        
        return result
    else:
        # Nessuna regola gruppo: usa globali con rounding_mode='single'
        return {
            'source': 'global',
            'group_id': None,
            'rounding_mode': 'single',
            'flessibilita_ingresso_minuti': global_rules.get('anticipo_max_minuti', 30),
            'flessibilita_uscita_minuti': 30,
            'arrotondamento_giornaliero_minuti': 15,
            'arrotondamento_giornaliero_tipo': 'floor',
            'oltre_flessibilita_action': 'allow',
            **global_rules
        }


def get_timbratura_rules(db) -> dict:
    """Ottiene le regole timbrature dal database."""
    ensure_timbratura_rules_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    row = db.execute("SELECT * FROM timbratura_rules WHERE id = 1").fetchone()
    
    if not row:
        # Inserisce valori di default
        db.execute("""
            INSERT INTO timbratura_rules (id, anticipo_max_minuti, tolleranza_ritardo_minuti,
                arrotondamento_ingresso_minuti, arrotondamento_uscita_minuti,
                pausa_blocco_minimo_minuti, pausa_incremento_minuti, pausa_tolleranza_minuti)
            VALUES (1, 30, 5, 15, 15, 30, 15, 5)
        """)
        db.commit()
        row = db.execute("SELECT * FROM timbratura_rules WHERE id = 1").fetchone()
    
    if isinstance(row, dict):
        return row
    
    # Converte tuple a dict
    columns = ['id', 'anticipo_max_minuti', 'tolleranza_ritardo_minuti',
               'arrotondamento_ingresso_minuti', 'arrotondamento_uscita_minuti',
               'pausa_blocco_minimo_minuti', 'pausa_incremento_minuti', 
               'pausa_tolleranza_minuti', 'updated_ts', 'updated_by']
    return dict(zip(columns, row))


@app.get("/admin/timbratura-rules")
@login_required
def admin_timbratura_rules_page() -> ResponseReturnValue:
    """Pagina configurazione regole timbrature (solo admin)."""
    if not session.get("is_admin"):
        abort(403)
    return render_template("admin_timbratura_rules.html", is_admin=True)


@app.get("/admin/group-timbratura-rules")
@login_required
def admin_group_timbratura_rules_page() -> ResponseReturnValue:
    """Pagina configurazione regole timbrature per gruppo (solo admin)."""
    if not session.get("is_admin"):
        abort(403)
    return render_template("admin_group_timbratura_rules.html", is_admin=True)


@app.get("/api/admin/timbratura-rules")
@login_required
def api_get_timbratura_rules():
    """Restituisce le regole timbrature correnti."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    db = get_db()
    rules = get_timbratura_rules(db)
    return jsonify(rules)


@app.post("/api/admin/timbratura-rules")
@login_required
def api_save_timbratura_rules():
    """Salva le regole timbrature."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    db = get_db()
    ensure_timbratura_rules_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Valida i dati numerici
    fields = {
        'anticipo_max_minuti': (0, 120),
        'tolleranza_ritardo_minuti': (0, 60),
        'arrotondamento_ingresso_minuti': (1, 60),
        'arrotondamento_uscita_minuti': (1, 60),
        'pausa_blocco_minimo_minuti': (5, 120),
        'pausa_incremento_minuti': (5, 60),
        'pausa_tolleranza_minuti': (0, 30)
    }
    
    # Campi di tipo arrotondamento (+ - ~)
    tipo_fields = ['arrotondamento_ingresso_tipo', 'arrotondamento_uscita_tipo']
    valid_tipos = ['+', '-', '~']
    
    values = {}
    for field, (min_val, max_val) in fields.items():
        val = data.get(field)
        if val is not None:
            val = int(val)
            if val < min_val or val > max_val:
                return jsonify({"error": f"{field} deve essere tra {min_val} e {max_val}"}), 400
            values[field] = val
    
    # Valida e aggiungi campi tipo
    for field in tipo_fields:
        val = data.get(field)
        if val is not None:
            if val not in valid_tipos:
                return jsonify({"error": f"{field} deve essere uno di: +, -, ~"}), 400
            values[field] = val
    
    if not values:
        return jsonify({"error": "Nessun campo da aggiornare"}), 400
    
    # Costruisce query di update
    set_clause = ", ".join([f"{k} = {placeholder}" for k in values.keys()])
    params = list(values.values()) + [now_ms(), session.get('user')]
    
    db.execute(
        f"UPDATE timbratura_rules SET {set_clause}, updated_ts = {placeholder}, updated_by = {placeholder} WHERE id = 1",
        params
    )
    db.commit()
    
    app.logger.info("Admin %s ha aggiornato le regole timbrature: %s", session.get('user'), values)
    return jsonify({"success": True})


# ═══════════════════════════════════════════════════════════════════════════════
#  API REGOLE TIMBRATURE PER GRUPPO
# ═══════════════════════════════════════════════════════════════════════════════

@app.get("/api/admin/group-timbratura-rules")
@login_required
def api_get_all_group_timbratura_rules():
    """Restituisce tutte le regole timbrature per gruppo."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    db = get_db()
    ensure_group_timbratura_rules_table(db)
    ensure_user_groups_table(db)
    
    # Ottieni tutti i gruppi con eventuali regole
    rows = db.execute("""
        SELECT g.id, g.name, g.description,
               r.id as rule_id, r.rounding_mode, r.flessibilita_ingresso_minuti,
               r.flessibilita_uscita_minuti, r.arrotondamento_giornaliero_minuti,
               r.arrotondamento_giornaliero_tipo, r.oltre_flessibilita_action,
               r.late_threshold_minutes, r.usa_regole_pausa_standard, r.is_active as rule_active
        FROM user_groups g
        LEFT JOIN group_timbratura_rules r ON g.id = r.group_id
        WHERE g.is_active = 1
        ORDER BY g.name
    """).fetchall()
    
    result = []
    for row in rows:
        if isinstance(row, dict):
            item = {
                'group_id': row['id'],
                'group_name': row['name'],
                'group_description': row['description'],
                'has_rules': row['rule_id'] is not None,
                'rules': None
            }
            if row['rule_id']:
                item['rules'] = {
                    'id': row['rule_id'],
                    'rounding_mode': row['rounding_mode'],
                    'flessibilita_ingresso_minuti': row['flessibilita_ingresso_minuti'],
                    'flessibilita_uscita_minuti': row['flessibilita_uscita_minuti'],
                    'arrotondamento_giornaliero_minuti': row['arrotondamento_giornaliero_minuti'],
                    'arrotondamento_giornaliero_tipo': row['arrotondamento_giornaliero_tipo'],
                    'oltre_flessibilita_action': row['oltre_flessibilita_action'],
                    'late_threshold_minutes': row['late_threshold_minutes'],
                    'usa_regole_pausa_standard': bool(row['usa_regole_pausa_standard']),
                    'is_active': bool(row['rule_active'])
                }
        else:
            item = {
                'group_id': row[0],
                'group_name': row[1],
                'group_description': row[2],
                'has_rules': row[3] is not None,
                'rules': None
            }
            if row[3]:
                item['rules'] = {
                    'id': row[3],
                    'rounding_mode': row[4],
                    'flessibilita_ingresso_minuti': row[5],
                    'flessibilita_uscita_minuti': row[6],
                    'arrotondamento_giornaliero_minuti': row[7],
                    'arrotondamento_giornaliero_tipo': row[8],
                    'oltre_flessibilita_action': row[9],
                    'late_threshold_minutes': row[10],
                    'usa_regole_pausa_standard': bool(row[11]),
                    'is_active': bool(row[12])
                }
        result.append(item)
    
    return jsonify(result)


@app.get("/api/admin/group-timbratura-rules/<int:group_id>")
@login_required
def api_get_group_timbratura_rules(group_id: int):
    """Restituisce le regole timbrature per un gruppo specifico."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    db = get_db()
    rules = get_group_timbratura_rules(db, group_id)
    
    if rules:
        return jsonify(rules)
    else:
        # Ritorna valori di default per nuovo inserimento
        return jsonify({
            'group_id': group_id,
            'rounding_mode': 'single',
            'flessibilita_ingresso_minuti': 30,
            'flessibilita_uscita_minuti': 30,
            'arrotondamento_giornaliero_minuti': 15,
            'arrotondamento_giornaliero_tipo': 'floor',
            'oltre_flessibilita_action': 'allow',
            'usa_regole_pausa_standard': True,
            'is_new': True
        })


@app.post("/api/admin/group-timbratura-rules/<int:group_id>")
@login_required
def api_save_group_timbratura_rules(group_id: int):
    """Salva o aggiorna le regole timbrature per un gruppo."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    db = get_db()
    ensure_group_timbratura_rules_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica che il gruppo esista
    group_row = db.execute(
        f"SELECT id FROM user_groups WHERE id = {placeholder}",
        (group_id,)
    ).fetchone()
    if not group_row:
        return jsonify({"error": "Gruppo non trovato"}), 404
    
    # Validazione
    rounding_mode = data.get('rounding_mode', 'single')
    if rounding_mode not in ('single', 'daily'):
        return jsonify({"error": "rounding_mode deve essere 'single' o 'daily'"}), 400
    
    flessibilita_ingresso = int(data.get('flessibilita_ingresso_minuti', 30))
    flessibilita_uscita = int(data.get('flessibilita_uscita_minuti', 30))
    arrot_giornaliero = int(data.get('arrotondamento_giornaliero_minuti', 15))
    
    arrot_tipo = data.get('arrotondamento_giornaliero_tipo', 'floor')
    if arrot_tipo not in ('floor', 'ceil', 'nearest'):
        return jsonify({"error": "arrotondamento_giornaliero_tipo deve essere 'floor', 'ceil' o 'nearest'"}), 400
    
    oltre_action = data.get('oltre_flessibilita_action', 'allow')
    if oltre_action not in ('allow', 'warn', 'block'):
        return jsonify({"error": "oltre_flessibilita_action deve essere 'allow', 'warn' o 'block'"}), 400
    
    late_threshold = int(data.get('late_threshold_minutes', 15))
    if late_threshold < 0:
        late_threshold = 0  # Permetti 0 per disabilitare
    
    usa_pausa_std = 1 if data.get('usa_regole_pausa_standard', True) else 0
    is_active = 1 if data.get('is_active', True) else 0
    
    now = now_ms()
    user = session.get('user')
    
    # Verifica se esiste già una regola per questo gruppo
    existing = db.execute(
        f"SELECT id FROM group_timbratura_rules WHERE group_id = {placeholder}",
        (group_id,)
    ).fetchone()
    
    if existing:
        # Update
        db.execute(f"""
            UPDATE group_timbratura_rules SET
                rounding_mode = {placeholder},
                flessibilita_ingresso_minuti = {placeholder},
                flessibilita_uscita_minuti = {placeholder},
                arrotondamento_giornaliero_minuti = {placeholder},
                arrotondamento_giornaliero_tipo = {placeholder},
                oltre_flessibilita_action = {placeholder},
                late_threshold_minutes = {placeholder},
                usa_regole_pausa_standard = {placeholder},
                is_active = {placeholder},
                updated_ts = {placeholder},
                updated_by = {placeholder}
            WHERE group_id = {placeholder}
        """, (rounding_mode, flessibilita_ingresso, flessibilita_uscita, arrot_giornaliero,
              arrot_tipo, oltre_action, late_threshold, usa_pausa_std, is_active, now, user, group_id))
    else:
        # Insert
        db.execute(f"""
            INSERT INTO group_timbratura_rules 
                (group_id, rounding_mode, flessibilita_ingresso_minuti, flessibilita_uscita_minuti,
                 arrotondamento_giornaliero_minuti, arrotondamento_giornaliero_tipo,
                 oltre_flessibilita_action, late_threshold_minutes, usa_regole_pausa_standard, is_active,
                 created_ts, updated_ts, updated_by)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder},
                    {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
        """, (group_id, rounding_mode, flessibilita_ingresso, flessibilita_uscita, arrot_giornaliero,
              arrot_tipo, oltre_action, late_threshold, usa_pausa_std, is_active, now, now, user))
    
    db.commit()
    app.logger.info("Admin %s ha salvato regole timbratura per gruppo %s: mode=%s", user, group_id, rounding_mode)
    return jsonify({"success": True})


@app.delete("/api/admin/group-timbratura-rules/<int:group_id>")
@login_required
def api_delete_group_timbratura_rules(group_id: int):
    """Elimina le regole timbrature per un gruppo (torna a usare quelle globali)."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    db.execute(
        f"DELETE FROM group_timbratura_rules WHERE group_id = {placeholder}",
        (group_id,)
    )
    db.commit()
    
    app.logger.info("Admin %s ha eliminato regole timbratura per gruppo %s", session.get('user'), group_id)
    return jsonify({"success": True})


# ═══════════════════════════════════════════════════════════════════════════════
#  RILEVAMENTO EXTRA TURNO
# ═══════════════════════════════════════════════════════════════════════════════

def _detect_extra_turno(
    ora_timbrata: str,
    ora_mod: str,
    tipo: str,
    turno_start: str = None,
    turno_end: str = None,
    rules: dict = None
) -> Optional[dict]:
    """
    [NOTA: Funzione NON più utilizzata - il calcolo Extra Turno è inline nel blocco fine_giornata.
     Mantenuta per eventuale refactoring futuro.]
    
    Rileva se una timbratura genera Extra Turno.
    
    LOGICA:
    - INGRESSO (inizio_giornata): Se l'ora timbrata è PRIMA di (turno_start - anticipo_max)
      → Extra Turno anticipato. I minuti extra sono da ora_timbrata a (turno_start - anticipo_max)
    
    - USCITA (fine_giornata): Se l'ora arrotondata (ora_mod) è DOPO fine_turno
      → Extra Turno posticipato. I minuti extra sono da fine_turno a ora_mod
    
    Args:
        ora_timbrata: orario originale timbrato (HH:MM:SS o HH:MM)
        ora_mod: orario arrotondato (HH:MM:SS o HH:MM)
        tipo: tipo timbratura (inizio_giornata, fine_giornata)
        turno_start: orario inizio turno (HH:MM) - richiesto per ingresso
        turno_end: orario fine turno (HH:MM) - richiesto per uscita
        rules: dizionario con le regole (se None, usa default)
    
    Returns:
        dict con dettagli Extra Turno se rilevato, None altrimenti
        {
            "extra_type": "before_shift" | "after_shift",
            "extra_minutes": int,
            "turno_time": str (HH:MM),
            "ora_timbrata": str,
            "ora_mod": str
        }
    """
    if tipo not in ('inizio_giornata', 'fine_giornata'):
        return None
    
    if rules is None:
        rules = {
            'anticipo_max_minuti': 30,
            'tolleranza_ritardo_minuti': 5,
            'arrotondamento_ingresso_minuti': 15,
            'arrotondamento_uscita_minuti': 15
        }
    
    # Converte ora timbrata in minuti
    parts = ora_timbrata.split(':')
    timbrata_min = int(parts[0]) * 60 + int(parts[1])
    
    # Converte ora_mod in minuti
    mod_parts = ora_mod.split(':')
    mod_min = int(mod_parts[0]) * 60 + int(mod_parts[1])
    
    if tipo == 'inizio_giornata' and turno_start:
        # INGRESSO: Extra Turno se timbro PRIMA di (turno_start - anticipo_max)
        turno_parts = turno_start.split(':')
        turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
        anticipo_max = rules.get('anticipo_max_minuti', 30)
        
        # Soglia: turno_start - anticipo_max
        soglia_min = turno_min - anticipo_max
        
        app.logger.info(
            "_detect_extra_turno INGRESSO: timbrata_min=%s, turno_min=%s, anticipo_max=%s, soglia_min=%s, check=%s",
            timbrata_min, turno_min, anticipo_max, soglia_min, timbrata_min < soglia_min
        )
        
        if timbrata_min < soglia_min:
            # Extra Turno anticipato!
            # I minuti extra sono calcolati dall'ora_mod (già arrotondata) all'inizio del turno
            # L'ora_mod usa arrotondamento in eccesso per l'ingresso (sfavorevole al dipendente)
            # quindi i minuti extra saranno coerenti con l'orario mostrato
            
            # Usa l'ora_mod per calcolare i minuti extra (coerenza con il valore mostrato)
            mod_parts_inner = ora_mod.split(':')
            mod_min_inner = int(mod_parts_inner[0]) * 60 + int(mod_parts_inner[1])
            
            # Extra minuti = dall'ora_mod (arrotondata in eccesso) all'inizio del turno
            extra_minutes = turno_min - mod_min_inner
            
            if extra_minutes > 0:
                h_soglia = soglia_min // 60
                m_soglia = soglia_min % 60
                return {
                    "extra_type": "before_shift",
                    "extra_minutes": extra_minutes,
                    "turno_time": turno_start,
                    "soglia_time": f"{h_soglia:02d}:{m_soglia:02d}",
                    "ora_timbrata": ora_timbrata,
                    "ora_mod": ora_mod
                }
    
    elif tipo == 'fine_giornata' and turno_end:
        # USCITA: Extra Turno se ora_mod > fine_turno (+ flessibilità se daily mode)
        turno_parts = turno_end.split(':')
        turno_end_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
        
        # Per modalità daily, considera la flessibilità uscita
        rounding_mode = rules.get('rounding_mode', 'single')
        flessibilita_uscita = 0
        if rounding_mode == 'daily':
            flessibilita_uscita = rules.get('flessibilita_uscita_minuti', 30)
        
        # Soglia per Extra Turno = fine turno + flessibilità
        soglia_extra = turno_end_min + flessibilita_uscita
        
        app.logger.info(
            "_detect_extra_turno USCITA: timbrata_min=%s, mod_min=%s, turno_end_min=%s, flessibilita=%s, soglia_extra=%s, check=%s",
            timbrata_min, mod_min, turno_end_min, flessibilita_uscita, soglia_extra, mod_min > soglia_extra
        )
        
        if mod_min > soglia_extra:
            # Extra Turno posticipato!
            # I minuti extra partono dalla soglia (fine turno + flessibilità)
            extra_minutes = mod_min - soglia_extra
            
            if extra_minutes > 0:
                return {
                    "extra_type": "after_shift",
                    "extra_minutes": extra_minutes,
                    "turno_time": turno_end,
                    "ora_timbrata": ora_timbrata,
                    "ora_mod": ora_mod,
                    "flessibilita_usata": flessibilita_uscita
                }
    
    return None


def _create_auto_extra_turno_request(
    db: DatabaseLike,
    username: str,
    date_str: str,
    extra_data: dict,
    notes: str = ""
) -> Optional[int]:
    """
    Crea automaticamente una richiesta di Extra Turno quando rilevato.
    
    Args:
        db: connessione database
        username: username dell'utente
        date_str: data in formato YYYY-MM-DD
        extra_data: dati Extra Turno da _detect_extra_turno
        notes: note opzionali
    
    Returns:
        ID della richiesta creata, o None se errore
    """
    try:
        ensure_user_requests_table(db)
        overtime_type_id = get_overtime_request_type_id(db)
        
        # Controllo anti-duplicato: se esiste già una richiesta pending dello stesso tipo per oggi, skip
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        existing = db.execute(
            f"""SELECT id FROM user_requests 
               WHERE username = {placeholder} AND request_type_id = {placeholder} 
               AND date_from = {placeholder} AND status = 'pending'
               LIMIT 1""",
            (username, overtime_type_id, date_str)
        ).fetchone()
        if existing:
            existing_id = existing['id'] if isinstance(existing, dict) else existing[0]
            app.logger.info(
                "Extra Turno request SKIP duplicato: esiste già richiesta id=%s per user=%s, date=%s",
                existing_id, username, date_str
            )
            return existing_id
        
        now_ts = int(time.time() * 1000)
        
        # Prepara extra_data con tutti i dettagli
        # Mappa i campi per compatibilità con il frontend admin_user_requests
        extra_type = extra_data.get("extra_type")
        ora_timbrata = extra_data.get("ora_timbrata", "")[:5] if extra_data.get("ora_timbrata") else ""
        ora_mod = extra_data.get("ora_mod", "")[:5] if extra_data.get("ora_mod") else ""
        planned_start = extra_data.get("planned_start", "")
        planned_end = extra_data.get("planned_end", "")
        
        request_extra_data = {
            "extra_type": extra_type,
            "extra_minutes": extra_data.get("extra_minutes"),
            "turno_time": extra_data.get("turno_time"),
            "ora_timbrata": extra_data.get("ora_timbrata"),
            "ora_mod": extra_data.get("ora_mod"),
            "soglia_time": extra_data.get("soglia_time"),
            "auto_detected": True,
            "overtime_type": extra_type,
            "shift_source": extra_data.get("shift_source", "employee_shift"),
            # Campi per visualizzazione nel riepilogo admin
            "planned_start": planned_start,
            "planned_end": planned_end,
            # Per ingresso anticipato: actual_start = ora_timbrata, actual_end = TBD
            # Per uscita posticipata: actual_start = TBD, actual_end = ora_timbrata
            "actual_start": ora_timbrata if extra_type == "before_shift" else "",
            "actual_end": ora_timbrata if extra_type == "after_shift" else "",
            "rounded_start": ora_mod if extra_type == "before_shift" else "",
            "rounded_end": ora_mod if extra_type == "after_shift" else "",
            # Minuti extra per tipo
            "extra_minutes_before": extra_data.get("extra_minutes") if extra_type == "before_shift" else 0,
            "extra_minutes_after": extra_data.get("extra_minutes") if extra_type == "after_shift" else 0,
        }
        extra_data_json = json.dumps(request_extra_data)
        
        total_minutes = extra_data.get("extra_minutes", 0)
        
        db.execute(f"""
            INSERT INTO user_requests 
            (user_id, username, request_type_id, date_from, date_to, value_amount, 
             notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 
                    {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 'pending', {placeholder}, {placeholder})
        """, (0, username, overtime_type_id, date_str, date_str, total_minutes, 
              notes, None, None, None, extra_data_json, now_ts, now_ts))
        
        # Recupera l'ID appena inserito
        if DB_VENDOR == "mysql":
            row = db.execute("SELECT LAST_INSERT_ID() as id").fetchone()
        else:
            row = db.execute("SELECT last_insert_rowid() as id").fetchone()
        
        request_id = row['id'] if isinstance(row, dict) else row[0]
        
        db.commit()
        
        app.logger.info(
            "Auto-created Extra Turno request: id=%s, user=%s, date=%s, type=%s, minutes=%s",
            request_id, username, date_str, extra_data.get("extra_type"), total_minutes
        )
        
        # Notifica admin
        _send_overtime_notification_to_admins(db, username, date_str, total_minutes)
        
        return request_id
        
    except Exception as e:
        app.logger.error(f"Errore creazione richiesta Extra Turno automatica: {e}")
        return None


def _ensure_fuori_flessibilita_request_type(db: DatabaseLike) -> int:
    """
    Assicura che esista il tipo richiesta 'Fuori Flessibilità' e ritorna il suo ID.
    Lookup per nome (stabile tra ambienti diversi).
    """
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Fuori Flessibilità",)
    ).fetchone()

    if row:
        return row["id"] if isinstance(row, Mapping) else row[0]

    # Crea il tipo se non esiste
    db.execute(f"""
        INSERT INTO request_types (name, value_type, description, active, sort_order)
        VALUES ({placeholder}, {placeholder}, {placeholder}, 1, 7)
    """, ("Fuori Flessibilità", "minutes", "Timbrata oltre i limiti di flessibilità consentiti"))
    db.commit()

    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Fuori Flessibilità",)
    ).fetchone()
    return row["id"] if isinstance(row, Mapping) else row[0]


def _create_flex_request(
    db, 
    username: str, 
    date_str: str, 
    tipo: str, 
    ora_timbrata: str, 
    ora_mod: str,
    diff_minutes: int,
    message: str,
    placeholder: str,
    turno_start: str = None,
    turno_end: str = None,
    arrotondamento_minuti: int = 30
) -> Optional[int]:
    """
    Crea automaticamente una richiesta di tipo "Fuori Flessibilità" quando
    una timbratura viene registrata oltre la flessibilità consentita.
    
    Args:
        db: connessione database
        username: username dell'utente
        date_str: data della timbratura (YYYY-MM-DD)
        tipo: tipo timbratura (inizio_giornata, fine_giornata)
        ora_timbrata: ora effettiva della timbratura
        ora_mod: ora modificata/arrotondata
        diff_minutes: minuti di differenza dal turno
        message: messaggio descrittivo
        placeholder: placeholder SQL (%s o ?)
        turno_start: ora inizio turno (HH:MM)
        turno_end: ora fine turno (HH:MM)
        arrotondamento_minuti: minuti per arrotondamento (dalle regole gruppo)
    
    Returns:
        ID della richiesta creata, o None se errore
    """
    try:
        FLEX_TYPE_ID = _ensure_fuori_flessibilita_request_type(db)
        
        # Controllo anti-duplicato: se esiste già una richiesta pending dello stesso tipo per oggi, skip
        existing = db.execute(
            f"""SELECT id FROM user_requests 
               WHERE username = {placeholder} AND request_type_id = {placeholder} 
               AND date_from = {placeholder} AND status = 'pending'
               LIMIT 1""",
            (username, FLEX_TYPE_ID, date_str)
        ).fetchone()
        if existing:
            existing_id = existing['id'] if isinstance(existing, dict) else existing[0]
            app.logger.info(
                "Flex request SKIP duplicato: esiste già richiesta id=%s per user=%s, date=%s",
                existing_id, username, date_str
            )
            return existing_id
        
        now_ts = now_ms()
        
        # Note descrittive
        tipo_label = "Ingresso" if tipo == "inizio_giornata" else "Uscita"
        if tipo == "inizio_giornata":
            notes = f"Richiesta anticipo ingresso: {message}"
        else:
            notes = f"{tipo_label} fuori flessibilità: {message}"
        
        # Extra data con dettagli
        extra_data = {
            "tipo_timbratura": tipo,
            "ora_timbrata": ora_timbrata,
            "ora_mod": ora_mod,
            "diff_minutes": diff_minutes,
            "turno_start": turno_start,
            "turno_end": turno_end,
            "arrotondamento_minuti": arrotondamento_minuti,
            "auto_created": True,
            "created_reason": "timbratura_fuori_flessibilita"
        }
        extra_data_json = json.dumps(extra_data)
        
        db.execute(f"""
            INSERT INTO user_requests 
            (user_id, username, request_type_id, date_from, date_to, value_amount, 
             notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 
                    {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 'pending', {placeholder}, {placeholder})
        """, (0, username, FLEX_TYPE_ID, date_str, date_str, abs(diff_minutes), 
              notes, None, None, None, extra_data_json, now_ts, now_ts))
        
        # Recupera l'ID appena inserito
        if DB_VENDOR == "mysql":
            row = db.execute("SELECT LAST_INSERT_ID() as id").fetchone()
        else:
            row = db.execute("SELECT last_insert_rowid() as id").fetchone()
        
        request_id = row['id'] if isinstance(row, dict) else row[0]
        
        db.commit()
        
        app.logger.info(
            "Auto-created richiesta anticipo/flex: id=%s, user=%s, date=%s, tipo=%s, diff=%smin",
            request_id, username, date_str, tipo, diff_minutes
        )
        
        # Notifica admin
        _send_flex_notification_to_admins(db, username, date_str, tipo, diff_minutes)
        
        return request_id
        
    except Exception as e:
        app.logger.error(f"Errore creazione richiesta Fuori Flessibilità: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        return None


def _send_flex_notification_to_admins(db, username: str, date_str: str, tipo: str, diff_minutes: int):
    """Invia notifica push agli admin per richiesta fuori flessibilità."""
    try:
        tipo_label = "Ingresso" if tipo == "inizio_giornata" else "Uscita"
        direction = "ritardo" if diff_minutes > 0 else "anticipo"
        
        if tipo == "inizio_giornata":
            title = "⏰ Richiesta anticipo ingresso"
        else:
            title = "⏰ Uscita oltre flessibilità"
        body = f"{username}: {tipo_label} {abs(diff_minutes)} min di {direction} il {date_str}"
        
        # Recupera admin attivi
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        admins = db.execute(
            f"SELECT username FROM app_users WHERE role IN ('admin', 'superadmin') AND is_active = 1"
        ).fetchall()
        
        for admin_row in admins:
            admin_username = admin_row['username'] if isinstance(admin_row, dict) else admin_row[0]
            try:
                send_push_notification(db, admin_username, title, body, data={"type": "flex_request"})
            except Exception as e:
                app.logger.debug(f"Push notification to {admin_username} failed: {e}")
    except Exception as e:
        app.logger.warning(f"Errore invio notifiche flex agli admin: {e}")


def _detect_late_arrival(
    ora_timbrata: str,
    ora_mod: str,
    turno_start: str,
    rules: dict,
    is_production: bool = False
) -> Optional[dict]:
    """
    Rileva se una timbratura di inizio giornata è in ritardo rispetto al turno.
    
    Per gruppi ufficio (non produzione) con flessibilità, il ritardo scatta
    solo se supera la flessibilità di ingresso.
    Per gruppi produzione, usa late_threshold_minutes direttamente.
    
    Args:
        ora_timbrata: ora effettiva della timbratura (HH:MM o HH:MM:SS)
        ora_mod: ora modificata/normalizzata (HH:MM:SS)
        turno_start: ora inizio turno previsto (HH:MM)
        rules: regole del gruppo con late_threshold_minutes e flessibilita_ingresso_minuti
        is_production: True se il gruppo è di produzione
    
    Returns:
        dict con late_minutes e threshold se ritardo rilevato, None altrimenti
    """
    if not turno_start:
        return None
    
    # Soglia base per il ritardo
    late_threshold = rules.get('late_threshold_minutes', 15)
    if late_threshold <= 0:
        return None  # Controllo ritardi disabilitato
    
    # Per gruppi ufficio (non produzione): flessibilità + threshold
    # Es: turno 09:00, flex 30 min, threshold 15 min → ritardo solo dopo 09:45
    flex_ingresso = rules.get('flessibilita_ingresso_minuti', 0)
    if not is_production and flex_ingresso > 0:
        effective_threshold = flex_ingresso + late_threshold
    else:
        effective_threshold = late_threshold
    
    # Converti in minuti
    parts = ora_timbrata.split(':')
    ora_min = int(parts[0]) * 60 + int(parts[1])
    
    turno_parts = turno_start.split(':')
    turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
    
    # Calcola ritardo (solo se positivo = arrivato dopo)
    late_minutes = ora_min - turno_min
    
    if late_minutes <= 0:
        return None  # Non è in ritardo (arrivato in anticipo o puntuale)
    
    if late_minutes <= effective_threshold:
        app.logger.info(
            f"Late arrival within tolerance: ora_timbrata={ora_timbrata}, turno_start={turno_start}, "
            f"late_minutes={late_minutes}, effective_threshold={effective_threshold} "
            f"(threshold={late_threshold}, flex={flex_ingresso}, is_production={is_production})"
        )
        return None  # Ritardo coperto dalla flessibilità o sotto soglia
    
    app.logger.info(
        f"Late arrival detected: ora_timbrata={ora_timbrata}, turno_start={turno_start}, "
        f"late_minutes={late_minutes}, effective_threshold={effective_threshold}"
    )
    
    return {
        "late_minutes": late_minutes,
        "threshold": effective_threshold,
        "late_threshold_minutes": late_threshold,
        "turno_start": turno_start,
        "ora_timbrata": ora_timbrata,
        "ora_mod": ora_mod,
        "flessibilita_ingresso_minuti": flex_ingresso,
    }


def _create_late_arrival_request(
    db,
    username: str,
    date_str: str,
    late_data: dict,
    placeholder: str
) -> Optional[int]:
    """
    Crea automaticamente una richiesta di tipo "Giustificazione Ritardo".
    
    Args:
        db: connessione database
        username: username dell'utente
        date_str: data della timbratura (YYYY-MM-DD)
        late_data: dati del ritardo da _detect_late_arrival()
        placeholder: placeholder SQL (%s o ?)
    
    Returns:
        ID della richiesta creata, o None se errore
    """
    try:
        # Ottieni l'ID del tipo "Giustificazione Ritardo"
        late_type_id = _ensure_late_arrival_request_type(db)
        
        # Controllo anti-duplicato: se esiste già una richiesta pending dello stesso tipo per oggi, skip
        existing = db.execute(
            f"""SELECT id FROM user_requests 
               WHERE username = {placeholder} AND request_type_id = {placeholder} 
               AND date_from = {placeholder} AND status = 'pending'
               LIMIT 1""",
            (username, late_type_id, date_str)
        ).fetchone()
        if existing:
            existing_id = existing['id'] if isinstance(existing, dict) else existing[0]
            app.logger.info(
                "Late Arrival request SKIP duplicato: esiste già richiesta id=%s per user=%s, date=%s",
                existing_id, username, date_str
            )
            return existing_id
        
        now_ts = now_ms()
        
        late_minutes = late_data["late_minutes"]
        turno_start = late_data["turno_start"]
        
        # Note descrittive
        notes = f"Ritardo di {late_minutes} minuti rispetto all'orario previsto ({turno_start})"
        
        # Extra data con dettagli
        flex_ingresso = late_data.get("flessibilita_ingresso_minuti", 0)
        is_production = late_data.get("is_production", False)
        
        extra_data = {
            "tipo_timbratura": "inizio_giornata",
            "ora_timbrata": late_data["ora_timbrata"],
            "ora_mod": late_data["ora_mod"],
            "turno_start": turno_start,
            "late_minutes": late_minutes,
            "threshold": late_data["threshold"],
            "late_threshold_minutes": late_data.get("late_threshold_minutes", 15),
            "auto_created": True,
            "created_reason": "late_arrival_detection",
            "is_production": is_production,
            "flessibilita_ingresso_minuti": flex_ingresso,
        }
        extra_data_json = json.dumps(extra_data)
        
        db.execute(f"""
            INSERT INTO user_requests 
            (user_id, username, request_type_id, date_from, date_to, value_amount, 
             notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 
                    {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 'pending', {placeholder}, {placeholder})
        """, (0, username, late_type_id, date_str, date_str, late_minutes, 
              notes, None, None, None, extra_data_json, now_ts, now_ts))
        
        # Recupera l'ID appena inserito
        if DB_VENDOR == "mysql":
            row = db.execute("SELECT LAST_INSERT_ID() as id").fetchone()
        else:
            row = db.execute("SELECT last_insert_rowid() as id").fetchone()
        
        request_id = row['id'] if isinstance(row, dict) else row[0]
        
        db.commit()
        
        app.logger.info(
            "Auto-created Late Arrival request: id=%s, user=%s, date=%s, late_minutes=%s",
            request_id, username, date_str, late_minutes
        )
        
        # Notifica admin
        ora_timbrata = late_data.get('ora_timbrata', '')
        _send_late_arrival_notification_to_admins(db, username, date_str, late_minutes, turno_start, ora_timbrata)
        
        # Notifica utente
        _send_late_arrival_notification_to_user(db, username, date_str, late_minutes, turno_start, ora_timbrata)
        
        return request_id
        
    except Exception as e:
        app.logger.error(f"Errore creazione richiesta Giustificazione Ritardo: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        return None


def _send_late_arrival_notification_to_admins(
    db, 
    username: str, 
    date_str: str, 
    late_minutes: int,
    turno_start: str,
    ora_timbrata: str
):
    """Invia notifica push agli admin per ritardo rilevato."""
    try:
        title = f"⏰ Ritardo rilevato: {username}"
        body = f"Ritardo di {late_minutes} min\n• Turno previsto: {turno_start}\n• Timbrata: {ora_timbrata}\n• Data: {date_str}"
        
        # Recupera admin attivi
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        admins = db.execute(
            f"SELECT username FROM app_users WHERE role IN ('admin', 'superadmin') AND is_active = 1"
        ).fetchall()
        
        for admin_row in admins:
            admin_username = admin_row['username'] if isinstance(admin_row, dict) else admin_row[0]
            try:
                send_push_notification(db, admin_username, title, body, data={"type": "late_arrival_request"})
            except Exception as e:
                app.logger.debug(f"Push notification to {admin_username} failed: {e}")
    except Exception as e:
        app.logger.warning(f"Errore invio notifiche ritardo agli admin: {e}")


def _send_late_arrival_notification_to_user(
    db,
    username: str,
    date_str: str,
    late_minutes: int,
    turno_start: str,
    ora_timbrata: str
):
    """Invia notifica push all'utente quando viene rilevato un ritardo."""
    try:
        title = f"⏰ Ritardo rilevato"
        body = f"Ritardo di {late_minutes} min\n• Turno previsto: {turno_start}\n• Timbrata: {ora_timbrata}\n\n📝 Inserisci la motivazione nella richiesta creata"
        
        send_push_notification(
            db, 
            username, 
            title, 
            body, 
            data={
                "type": "late_arrival_detected",
                "url": "/user/requests"
            }
        )
        app.logger.info(f"Notifica ritardo inviata a {username}")
    except Exception as e:
        app.logger.warning(f"Errore invio notifica ritardo all'utente {username}: {e}")


def _safe_time_to_minutes(value) -> Optional[int]:
    """Converte un orario (TIME/datetime/stringa) in minuti dal mezzanotte."""
    if value is None:
        return None
    try:
        if hasattr(value, 'total_seconds'):
            return int(value.total_seconds()) // 60
        if hasattr(value, 'hour'):
            return int(value.hour) * 60 + int(value.minute)

        raw = str(value)
        if len(raw) > 11 and ':' in raw:
            raw = raw[11:16]
        else:
            raw = raw[:5]
        parts = raw.split(':')
        if len(parts) < 2:
            return None
        return int(parts[0]) * 60 + int(parts[1])
    except Exception:
        return None


def _get_effective_break_minutes_from_timbrature(db, username: str, date_str: str, placeholder: str) -> int:
    """Somma la pausa effettivamente timbrata (coppie inizio_pausa/fine_pausa)."""
    total = 0
    try:
        pause_rows = db.execute(
            f"""SELECT tipo, ora FROM timbrature
               WHERE username = {placeholder} AND data = {placeholder}
                 AND tipo IN ('inizio_pausa', 'fine_pausa')
               ORDER BY created_ts ASC""",
            (username, date_str)
        ).fetchall()

        pause_start = None
        for row in pause_rows:
            p_type = row['tipo'] if isinstance(row, dict) else row[0]
            p_ora = row['ora'] if isinstance(row, dict) else row[1]
            p_min = _safe_time_to_minutes(p_ora)
            if p_min is None:
                continue

            if p_type == 'inizio_pausa':
                pause_start = p_min
            elif p_type == 'fine_pausa' and pause_start is not None and p_min >= pause_start:
                total += (p_min - pause_start)
                pause_start = None
    except Exception as e:
        app.logger.warning(f"Errore calcolo pausa effettiva timbrata: {e}")

    return max(0, int(total))


def _get_planned_break_minutes_for_day(
    db,
    username: str,
    date_str: str,
    day_of_week: int,
    placeholder: str,
) -> dict:
    """Recupera pausa pianificata del giorno (employee_shifts o Rentman)."""
    try:
        ensure_employee_shifts_table(db)
        row = db.execute(
            f"""SELECT break_start, break_end FROM employee_shifts
               WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
               ORDER BY start_time ASC LIMIT 1""",
            (username, day_of_week)
        ).fetchone()
        if row:
            break_start = row['break_start'] if isinstance(row, dict) else row[0]
            break_end = row['break_end'] if isinstance(row, dict) else row[1]
            bs_min = _safe_time_to_minutes(break_start)
            be_min = _safe_time_to_minutes(break_end)
            if bs_min is not None and be_min is not None and be_min > bs_min:
                return {
                    "minutes": be_min - bs_min,
                    "source": "employee_shifts",
                    "break_start": f"{bs_min // 60:02d}:{bs_min % 60:02d}",
                    "break_end": f"{be_min // 60:02d}:{be_min % 60:02d}",
                }
    except Exception as e:
        app.logger.warning(f"Errore lettura pausa da employee_shifts: {e}")

    try:
        user_row = db.execute(
            f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
            (username,)
        ).fetchone()
        crew_id = None
        if user_row:
            crew_id = user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]

        if crew_id:
            rows = db.execute(
                f"""SELECT break_start, break_end, break_minutes
                   FROM rentman_plannings
                   WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                     AND (is_obsolete IS NULL OR is_obsolete = 0)
                   ORDER BY plan_start ASC""",
                (crew_id, date_str)
            ).fetchall()

            for row in rows:
                break_start = row['break_start'] if isinstance(row, dict) else row[0]
                break_end = row['break_end'] if isinstance(row, dict) else row[1]
                break_minutes = row['break_minutes'] if isinstance(row, dict) else row[2]

                bs_min = _safe_time_to_minutes(break_start)
                be_min = _safe_time_to_minutes(break_end)
                if bs_min is not None and be_min is not None and be_min > bs_min:
                    return {
                        "minutes": be_min - bs_min,
                        "source": "rentman_break_times",
                        "break_start": f"{bs_min // 60:02d}:{bs_min % 60:02d}",
                        "break_end": f"{be_min // 60:02d}:{be_min % 60:02d}",
                    }

                try:
                    if break_minutes is not None and int(float(break_minutes)) > 0:
                        return {
                            "minutes": int(float(break_minutes)),
                            "source": "rentman_break_minutes",
                            "break_start": None,
                            "break_end": None,
                        }
                except Exception:
                    continue
    except Exception as e:
        app.logger.warning(f"Errore lettura pausa da rentman_plannings: {e}")

    return {
        "minutes": 0,
        "source": "none",
        "break_start": None,
        "break_end": None,
    }


def _ensure_break_reduction_request_type(db: DatabaseLike) -> int:
    """Assicura che esista il tipo richiesta 'Deroga Pausa Ridotta' e ritorna il suo ID."""
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"

    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Deroga Pausa Ridotta",)
    ).fetchone()
    if row:
        return row["id"] if isinstance(row, Mapping) else row[0]

    db.execute(f"""
        INSERT INTO request_types (name, value_type, description, active, sort_order)
        VALUES ({placeholder}, {placeholder}, {placeholder}, 1, 6)
    """, (
        "Deroga Pausa Ridotta",
        "minutes",
        "Richiesta autorizzazione pausa inferiore rispetto al pianificato"
    ))
    db.commit()

    row = db.execute(
        f"SELECT id FROM request_types WHERE name = {placeholder}",
        ("Deroga Pausa Ridotta",)
    ).fetchone()
    return row["id"] if isinstance(row, Mapping) else row[0]


def _create_break_reduction_request(
    db,
    username: str,
    date_str: str,
    break_data: dict,
    reason: str,
    placeholder: str,
) -> Optional[int]:
    """Crea (o riusa) richiesta pending per pausa ridotta oltre soglia."""
    try:
        request_type_id = _ensure_break_reduction_request_type(db)

        existing = db.execute(
            f"""SELECT id FROM user_requests
               WHERE username = {placeholder} AND request_type_id = {placeholder}
                 AND date_from = {placeholder} AND status = 'pending'
               LIMIT 1""",
            (username, request_type_id, date_str)
        ).fetchone()
        if existing:
            return existing['id'] if isinstance(existing, dict) else existing[0]

        now_ts = now_ms()
        planned = int(break_data.get('planned_break_minutes', 0) or 0)
        effective = int(break_data.get('effective_break_minutes', 0) or 0)
        reduction = int(break_data.get('break_reduction_minutes', 0) or 0)

        notes = (
            f"Pausa ridotta: effettuati {effective} min su {planned} min pianificati "
            f"(differenza {reduction} min). Motivazione utente: {reason}"
        )

        extra_data = {
            "created_reason": "break_reduction_short_pause",
            "planned_break_minutes": planned,
            "effective_break_minutes": effective,
            "rounded_break_minutes": int(break_data.get('rounded_break_minutes') or 0) or None,
            "break_reduction_minutes": reduction,
            "break_source": break_data.get('break_source'),
            "break_start": break_data.get('break_start'),
            "break_end": break_data.get('break_end'),
            "reason": reason,
            "tipo_timbratura": "fine_giornata",
            "turno_start": break_data.get('turno_start'),
            "turno_end": break_data.get('turno_end'),
            "ora_timbrata": break_data.get('ora_timbrata'),
            "ora_mod": break_data.get('ora_mod'),
            "auto_created": True,
        }

        db.execute(f"""
            INSERT INTO user_requests
            (user_id, username, request_type_id, date_from, date_to, value_amount,
             notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder},
                    {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 'pending', {placeholder}, {placeholder})
        """, (
            0,
            username,
            request_type_id,
            date_str,
            date_str,
            reduction,
            notes,
            None,
            None,
            None,
            json.dumps(extra_data),
            now_ts,
            now_ts,
        ))

        if DB_VENDOR == "mysql":
            row = db.execute("SELECT LAST_INSERT_ID() as id").fetchone()
        else:
            row = db.execute("SELECT last_insert_rowid() as id").fetchone()

        request_id = row['id'] if isinstance(row, dict) else row[0]
        app.logger.info(
            "Creata richiesta Deroga Pausa Ridotta id=%s per %s (%s)",
            request_id,
            username,
            date_str,
        )
        return request_id
    except Exception as e:
        app.logger.error(f"Errore creazione richiesta Deroga Pausa Ridotta: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        return None


def _process_break_reduction_review(
    db,
    username: str,
    date_from,
    status: str,
    extra_data_str: str,
) -> dict:
    """
    In review admin, applica la pausa valida:
    - approved  -> usa pausa effettiva timbrata
    - rejected  -> usa pausa pianificata
    e ricalcola ora_mod in daily mode.
    """
    result = {"processed": False, "skipped": False}
    try:
        extra = json.loads(extra_data_str) if isinstance(extra_data_str, str) else (extra_data_str or {})
        if not isinstance(extra, dict):
            result["skipped"] = True
            result["reason"] = "extra_data non valido"
            return result

        date_str = date_from.strftime("%Y-%m-%d") if hasattr(date_from, 'strftime') else str(date_from)[:10]
        planned_break = int(extra.get("planned_break_minutes", 0) or 0)
        effective_break = int(extra.get("effective_break_minutes", 0) or 0)
        rounded_break = int(extra.get("rounded_break_minutes", 0) or 0)
        # Approvato: usa pausa arrotondata ai 15 min (es. 29→30 min reali) per calcolo ora_mod fine_giornata
        # Se rounded_break non disponibile (record vecchi), fallback su effective_break
        forced_break = (rounded_break or effective_break) if status == "approved" else planned_break

        rules = get_user_timbratura_rules(db, username)
        rounding_mode = rules.get('rounding_mode', 'single')

        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        fg_row = db.execute(
            f"""SELECT ora FROM timbrature
               WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'fine_giornata'
               ORDER BY created_ts DESC LIMIT 1""",
            (username, date_str)
        ).fetchone()
        if not fg_row:
            result["skipped"] = True
            result["reason"] = "fine_giornata non trovata"
            return result

        ora_timbrata = fg_row['ora'] if isinstance(fg_row, dict) else fg_row[0]
        if hasattr(ora_timbrata, 'strftime'):
            ora_timbrata = ora_timbrata.strftime("%H:%M:%S")
        elif hasattr(ora_timbrata, 'total_seconds'):
            total_sec = int(ora_timbrata.total_seconds())
            ora_timbrata = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}:00"
        else:
            ora_timbrata = str(ora_timbrata)

        if rounding_mode == 'daily':
            turno_start = extra.get("turno_start")
            turno_end = extra.get("turno_end")
            new_ora_mod = _calcola_ora_fine_daily(
                db=db,
                username=username,
                today=date_str,
                ora=ora_timbrata,
                turno_start=turno_start,
                turno_end=turno_end,
                rules=rules,
                placeholder=placeholder,
                break_info=None,
                forced_break_minutes=forced_break,
            )

            db.execute(
                f"""UPDATE timbrature
                   SET ora_mod = {placeholder}
                   WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'fine_giornata'""",
                (new_ora_mod, username, date_str)
            )

            db.execute(
                f"""UPDATE cedolino_timbrature
                   SET ora_modificata = {placeholder}, synced_ts = NULL
                   WHERE username = {placeholder}
                     AND data_riferimento = {placeholder}
                     AND timeframe_id = 8""",
                (new_ora_mod, username, date_str)
            )

            db.commit()
            result.update({
                "processed": True,
                "forced_break_minutes": forced_break,
                "new_ora_mod": new_ora_mod,
                "rounding_mode": rounding_mode,
            })
        else:
            # In modalità non-daily la pausa impatta su fine_pausa.ora_mod:
            # - approved: arrotonda ora reale ai 15 min più vicini
            #   (TODO FUTURO: rendere configurabile l'intervallo di arrotondamento)
            # - rejected: applica pausa pianificata (calcola_pausa_mod)
            fine_pausa_row = db.execute(
                f"""SELECT id, ora, ora_mod FROM timbrature
                   WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'fine_pausa'
                   ORDER BY created_ts DESC LIMIT 1""",
                (username, date_str)
            ).fetchone()

            inizio_pausa_row = db.execute(
                f"""SELECT ora, ora_mod FROM timbrature
                   WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'inizio_pausa'
                   ORDER BY created_ts DESC LIMIT 1""",
                (username, date_str)
            ).fetchone()

            if fine_pausa_row and inizio_pausa_row:
                fp_id = fine_pausa_row['id'] if isinstance(fine_pausa_row, dict) else fine_pausa_row[0]
                fp_ora = fine_pausa_row['ora'] if isinstance(fine_pausa_row, dict) else fine_pausa_row[1]

                if hasattr(fp_ora, 'strftime'):
                    fp_ora_str = fp_ora.strftime("%H:%M:%S")
                elif hasattr(fp_ora, 'total_seconds'):
                    total_sec = int(fp_ora.total_seconds())
                    fp_ora_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}:00"
                else:
                    fp_ora_str = str(fp_ora)

                # Recupera inizio pausa ora_mod
                ip_ora_mod = inizio_pausa_row['ora_mod'] if isinstance(inizio_pausa_row, dict) else inizio_pausa_row[1]
                if not ip_ora_mod:
                    ip_ora_mod = inizio_pausa_row['ora'] if isinstance(inizio_pausa_row, dict) else inizio_pausa_row[0]
                if hasattr(ip_ora_mod, 'strftime'):
                    ip_str = ip_ora_mod.strftime("%H:%M")
                elif hasattr(ip_ora_mod, 'total_seconds'):
                    total_sec = int(ip_ora_mod.total_seconds())
                    ip_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
                else:
                    ip_str = str(ip_ora_mod)[:5]

                ip_parts = ip_str.split(':')
                ip_min = int(ip_parts[0]) * 60 + int(ip_parts[1])

                if status == "approved":
                    # Approvato: arrotonda la pausa reale ai 15 min più vicini (per eccesso)
                    # TODO FUTURO: rendere configurabile questo intervallo (ora fisso a 15 min)
                    fp_parts = fp_ora_str[:5].split(':')
                    fp_min = int(fp_parts[0]) * 60 + int(fp_parts[1])
                    durata_reale = fp_min - ip_min
                    arrotondamento = 15  # TODO: rendere configurabile
                    if durata_reale <= 0:
                        durata_arrotondata = arrotondamento
                    else:
                        # Arrotonda ai 15 min più vicini
                        durata_arrotondata = ((durata_reale + arrotondamento // 2) // arrotondamento) * arrotondamento
                    new_fp_min = ip_min + durata_arrotondata
                    h = new_fp_min // 60
                    m = new_fp_min % 60
                    new_fp_ora_mod = f"{h:02d}:{m:02d}:00"
                    app.logger.info(
                        f"Break reduction APPROVED: durata reale={durata_reale}min, "
                        f"arrotondata={durata_arrotondata}min (ai {arrotondamento}min), "
                        f"ora_mod={new_fp_ora_mod}"
                    )
                else:
                    # Rifiutato: applica pausa pianificata (calcola_pausa_mod con regole)
                    durata_mod = calcola_pausa_mod(ip_str, fp_ora_str[:5], rules)
                    new_fp_min = ip_min + durata_mod
                    h = new_fp_min // 60
                    m = new_fp_min % 60
                    new_fp_ora_mod = f"{h:02d}:{m:02d}:00"
                    app.logger.info(
                        f"Break reduction REJECTED: applico pausa pianificata, "
                        f"durata_mod={durata_mod}min, ora_mod={new_fp_ora_mod}"
                    )

                db.execute(
                    f"UPDATE timbrature SET ora_mod = {placeholder} WHERE id = {placeholder}",
                    (new_fp_ora_mod, fp_id)
                )

                db.execute(
                    f"""UPDATE cedolino_timbrature
                       SET ora_modificata = {placeholder}, synced_ts = NULL
                       WHERE username = {placeholder}
                         AND data_riferimento = {placeholder}
                         AND timeframe_id = 5""",
                    (new_fp_ora_mod, username, date_str)
                )

            db.commit()
            result.update({
                "processed": True,
                "forced_break_minutes": forced_break,
                "rounding_mode": rounding_mode,
                "note": "non-daily: aggiornata fine_pausa su approvazione",
            })
        return result
    except Exception as e:
        app.logger.error(f"Errore _process_break_reduction_review: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        result["error"] = str(e)
        return result


def _calcola_ora_fine_daily(db, username: str, today: str, ora: str, turno_start: str, turno_end: str, rules: dict, placeholder: str, break_info: dict = None, forced_break_minutes: Optional[int] = None) -> str:
    """
    Calcola l'ora di fine giornata per il mode 'daily'.
    
    In modalità giornaliera:
    1. Calcola le ore EFFETTIVE lavorate (fine - inizio - pausa)
    2. Arrotonda il totale secondo le regole (blocco 30 min, floor)
    3. Ricalcola l'ora di uscita per ottenere quel totale arrotondato
    
    Esempio (uscita anticipata):
        - Inizio: 09:20, Uscita effettiva: 16:29, Pausa: 60 min
        - Ore lorde: 16:29 - 09:20 = 7:09
        - Ore nette: 7:09 - 1:00 = 6:09
        - Arrotondato (blocco 30, floor): 6:00
        - Uscita arrotondata: 09:20 + 6:00 + 1:00 = 16:20
    """
    try:
        # 1. Recupera l'ora di inizio giornata di oggi (ora_mod se presente)
        inizio_row = db.execute(
            f"""SELECT ora, ora_mod FROM timbrature 
               WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'inizio_giornata'
               ORDER BY created_ts ASC LIMIT 1""",
            (username, today)
        ).fetchone()
        
        if not inizio_row:
            app.logger.warning(f"Daily mode: nessun inizio giornata trovato per {username} il {today}")
            return ora if ':' in ora and ora.count(':') == 2 else f"{ora}:00"
        
        ora_inizio = inizio_row['ora_mod'] if isinstance(inizio_row, dict) else inizio_row[1]
        if not ora_inizio:
            ora_inizio = inizio_row['ora'] if isinstance(inizio_row, dict) else inizio_row[0]
        
        # Converti in stringa
        if hasattr(ora_inizio, 'strftime'):
            ora_inizio_str = ora_inizio.strftime("%H:%M")
        elif hasattr(ora_inizio, 'total_seconds'):
            total_sec = int(ora_inizio.total_seconds())
            ora_inizio_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
        else:
            ora_inizio_str = str(ora_inizio)[:5]
        
        # Converti ora inizio in minuti
        inizio_parts = ora_inizio_str.split(':')
        inizio_min = int(inizio_parts[0]) * 60 + int(inizio_parts[1])
        
        # Converti ora fine effettiva in minuti
        ora_fine_str = str(ora)[:5]
        fine_parts = ora_fine_str.split(':')
        fine_min = int(fine_parts[0]) * 60 + int(fine_parts[1])
        
        # 2. Recupera la pausa prevista dal turno (da normalizzare)
        pausa_turno_minuti = 60  # Default 1 ora
        try:
            day_of_week = datetime.strptime(today, '%Y-%m-%d').weekday()
            shift_row = db.execute(
                f"""SELECT break_start, break_end FROM employee_shifts 
                   WHERE username = {placeholder} AND day_of_week = {placeholder}""",
                (username, day_of_week)
            ).fetchone()
            
            if shift_row:
                break_start = shift_row['break_start'] if isinstance(shift_row, dict) else shift_row[0]
                break_end = shift_row['break_end'] if isinstance(shift_row, dict) else shift_row[1]
                
                if break_start and break_end:
                    if hasattr(break_start, 'total_seconds'):
                        bs_min = int(break_start.total_seconds()) // 60
                    else:
                        bs_parts = str(break_start)[:5].split(':')
                        bs_min = int(bs_parts[0]) * 60 + int(bs_parts[1])
                    
                    if hasattr(break_end, 'total_seconds'):
                        be_min = int(break_end.total_seconds()) // 60
                    else:
                        be_parts = str(break_end)[:5].split(':')
                        be_min = int(be_parts[0]) * 60 + int(be_parts[1])
                    
                    pausa_turno_minuti = be_min - bs_min
        except Exception as e:
            app.logger.warning(f"Errore lettura pausa turno: {e}")
        
        # 2b. Verifica se la pausa è stata effettivamente timbrata
        #     Se non timbrata, non sottrarre pause → le ore lorde = ore nette
        pausa_effettiva = 0
        try:
            pausa_rows = db.execute(
                f"""SELECT tipo, ora FROM timbrature 
                   WHERE username = {placeholder} AND data = {placeholder} 
                   AND tipo IN ('inizio_pausa', 'fine_pausa')
                   ORDER BY ora ASC""",
                (username, today)
            ).fetchall()
            
            pausa_inizio_tmp = None
            for pr in pausa_rows:
                pr_tipo = pr['tipo'] if isinstance(pr, dict) else pr[0]
                pr_ora = pr['ora'] if isinstance(pr, dict) else pr[1]
                if hasattr(pr_ora, 'total_seconds'):
                    pr_min = int(pr_ora.total_seconds()) // 60
                elif hasattr(pr_ora, 'strftime'):
                    pr_min = pr_ora.hour * 60 + pr_ora.minute
                else:
                    pr_parts = str(pr_ora)[:5].split(':')
                    pr_min = int(pr_parts[0]) * 60 + int(pr_parts[1])
                
                if pr_tipo == 'inizio_pausa':
                    pausa_inizio_tmp = pr_min
                elif pr_tipo == 'fine_pausa' and pausa_inizio_tmp is not None:
                    pausa_effettiva += (pr_min - pausa_inizio_tmp)
                    pausa_inizio_tmp = None
        except Exception as e:
            app.logger.warning(f"Errore lettura pausa effettiva: {e}")
        
        # Per il calcolo giornaliero, la logica della pausa dipende dallo stato:
        # 1. Se la pausa è stata effettivamente timbrata → usa pausa turno (obbligatoria)
        # 2. Se l'utente ha confermato la pausa (popup) → usa pausa turno
        # 3. Se l'utente ha saltato la pausa (popup skip) → pausa = 0
        # 4. Se non c'è info (nessun popup mostrato, nessuna timbrata) → pausa = 0
        #    (non sottrarre pausa mai chiesta/confermata)
        if forced_break_minutes is not None:
            pausa_da_usare = max(0, int(forced_break_minutes))
            app.logger.info(f"Daily mode: pausa forzata da review admin = {pausa_da_usare} min")
        elif pausa_effettiva > 0:
            pausa_da_usare = pausa_turno_minuti
            app.logger.info(f"Daily mode: pausa effettiva timbrata = {pausa_effettiva} min, uso pausa turno = {pausa_turno_minuti} min")
        elif break_info and break_info.get('break_confirmed'):
            pausa_da_usare = pausa_turno_minuti
            app.logger.info(f"Daily mode: pausa confermata dall'utente (non timbrata), uso pausa turno = {pausa_turno_minuti} min")
        elif break_info and break_info.get('break_skipped'):
            reason = break_info.get('break_skip_reason', 'Nessuna motivazione')
            pausa_da_usare = 0
            app.logger.info(f"Daily mode: pausa saltata dall'utente, motivo: {reason}, pausa = 0 min")
        else:
            pausa_da_usare = 0
            app.logger.info(f"Daily mode: nessuna pausa timbrata né confermata, pausa = 0 min (pausa pianificata era {pausa_turno_minuti} min)")
        
        # 3. Calcola ore EFFETTIVE lavorate (ore lorde - pausa pianificata)
        ore_lorde_effettive = fine_min - inizio_min
        ore_nette_effettive = ore_lorde_effettive - pausa_da_usare
        
        # 4. Applica arrotondamento giornaliero alle ore nette EFFETTIVE
        blocco = rules.get('arrotondamento_giornaliero_minuti', 15)
        tipo_arrot = rules.get('arrotondamento_giornaliero_tipo', 'floor')
        
        if tipo_arrot == 'floor':
            ore_arrotondate = (ore_nette_effettive // blocco) * blocco
        elif tipo_arrot == 'ceil':
            ore_arrotondate = ((ore_nette_effettive + blocco - 1) // blocco) * blocco
        else:  # round
            ore_arrotondate = round(ore_nette_effettive / blocco) * blocco
        
        # Evita ore negative
        if ore_arrotondate < 0:
            ore_arrotondate = 0
        
        # 5. Calcola ora_mod = uscita_reale - differenza
        #    differenza = ore_nette_effettive - ore_arrotondate (i minuti in eccesso troncati dal blocco)
        #    Questa formula detrae dalla timbrata reale solo i minuti non conteggiabili
        differenza = ore_nette_effettive - ore_arrotondate
        ora_fine_mod_min = fine_min - differenza
        
        h = ora_fine_mod_min // 60
        m = ora_fine_mod_min % 60
        ora_mod = f"{h:02d}:{m:02d}:00"
        
        app.logger.info(
            f"Daily mode fine_giornata: inizio={ora_inizio_str}, fine_effettiva={ora_fine_str}, "
            f"pausa_turno={pausa_turno_minuti}min, pausa_effettiva_timbrata={pausa_effettiva}min, "
            f"ore_lorde={ore_lorde_effettive}min, ore_nette={ore_nette_effettive}min, "
            f"ore_arrot={ore_arrotondate}min, differenza={differenza}min, ora_mod={ora_mod}"
        )
        
        return ora_mod
        
    except Exception as e:
        app.logger.error(f"Errore _calcola_ora_fine_daily: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        return ora if ':' in ora and ora.count(':') == 2 else f"{ora}:00"


# ═══════════════════════════════════════════════════════════════════════════════
#  CALCOLO ORA MODIFICATA (ora_mod)
# ═══════════════════════════════════════════════════════════════════════════════

def calcola_ora_mod(ora_originale: str, tipo: str, turno_start: str = None, rules: dict = None) -> str:
    """
    Calcola l'ora modificata in base alle regole.
    
    Args:
        ora_originale: orario originale (HH:MM:SS o HH:MM)
        tipo: tipo timbratura (inizio_giornata, fine_giornata, inizio_pausa, fine_pausa)
        turno_start: orario inizio turno se presente (HH:MM)
        rules: dizionario con le regole (se None, usa default)
    
    Returns:
        ora modificata (HH:MM:SS)
    
    Note:
        Per gruppi con rounding_mode='daily', questa funzione restituisce l'ora originale
        senza arrotondamento (l'arrotondamento viene fatto sul totale giornaliero).
    """
    if rules is None:
        rules = {
            'anticipo_max_minuti': 30,
            'tolleranza_ritardo_minuti': 5,
            'arrotondamento_ingresso_minuti': 15,
            'arrotondamento_uscita_minuti': 15,
            'rounding_mode': 'single'
        }
    
    # Converte ora originale in minuti
    parts = ora_originale.split(':')
    ora_min = int(parts[0]) * 60 + int(parts[1])
    
    # Se rounding_mode è 'daily', non arrotonda la singola timbrata
    # Verifica solo la flessibilità
    rounding_mode = rules.get('rounding_mode', 'single')
    
    if rounding_mode == 'daily':
        # Modalità giornaliera: non arrotonda, verifica solo flessibilità
        if turno_start and tipo == 'inizio_giornata':
            turno_parts = turno_start.split(':')
            turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
            flessibilita = rules.get('flessibilita_ingresso_minuti', 30)
            
            # Finestra flessibilità: [turno - fless, turno + fless]
            oltre_action = rules.get('oltre_flessibilita_action', 'allow')
            
            diff = abs(ora_min - turno_min)
            if diff <= flessibilita:
                # Dentro la flessibilità: registra ora reale
                return ora_originale if ':' in ora_originale and ora_originale.count(':') == 2 else f"{ora_originale}:00"
            else:
                # Fuori flessibilità: dipende dall'azione configurata
                if oltre_action == 'block':
                    # In teoria dovrebbe bloccare, ma qui restituiamo comunque l'ora
                    # Il blocco va gestito a livello di API
                    pass
                # Per 'allow' e 'warn': registra ora reale
                return ora_originale if ':' in ora_originale and ora_originale.count(':') == 2 else f"{ora_originale}:00"
        
        # Per fine_giornata e altri tipi: registra ora reale
        return ora_originale if ':' in ora_originale and ora_originale.count(':') == 2 else f"{ora_originale}:00"
    
    # Modalità 'single': comportamento originale
    # Se c'è un turno e siamo in ingresso, prova normalizzazione
    if turno_start and tipo == 'inizio_giornata':
        turno_parts = turno_start.split(':')
        turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
        
        anticipo = rules.get('anticipo_max_minuti', 30)
        tolleranza = rules.get('tolleranza_ritardo_minuti', 5)
        
        # Finestra di normalizzazione: [turno - anticipo, turno + tolleranza]
        min_window = turno_min - anticipo
        max_window = turno_min + tolleranza
        
        if min_window <= ora_min <= max_window:
            # Normalizza all'orario del turno
            h = turno_min // 60
            m = turno_min % 60
            return f"{h:02d}:{m:02d}:00"
    
    # Arrotondamento
    if tipo == 'inizio_giornata':
        blocco = rules.get('arrotondamento_ingresso_minuti', 15)
        tipo_arrot = rules.get('arrotondamento_ingresso_tipo', '+')
        if tipo_arrot == '+':
            # In eccesso (ceil)
            ora_mod_min = ((ora_min + blocco - 1) // blocco) * blocco
        elif tipo_arrot == '-':
            # In difetto (floor)
            ora_mod_min = (ora_min // blocco) * blocco
        else:
            # Circa / più vicino (round)
            ora_mod_min = round(ora_min / blocco) * blocco
    elif tipo == 'fine_giornata':
        blocco = rules.get('arrotondamento_uscita_minuti', 15)
        tipo_arrot = rules.get('arrotondamento_uscita_tipo', '-')
        if tipo_arrot == '-':
            # In difetto (floor)
            ora_mod_min = (ora_min // blocco) * blocco
        elif tipo_arrot == '+':
            # In eccesso (ceil)
            ora_mod_min = ((ora_min + blocco - 1) // blocco) * blocco
        else:
            # Circa / più vicino (round)
            ora_mod_min = round(ora_min / blocco) * blocco
    else:
        # Per inizio_pausa e fine_pausa, nessun arrotondamento sull'ora singola
        # Le pause vengono gestite sulla durata totale
        return ora_originale if ':' in ora_originale and ora_originale.count(':') == 2 else f"{ora_originale}:00"
    
    h = ora_mod_min // 60
    m = ora_mod_min % 60
    return f"{h:02d}:{m:02d}:00"


def calcola_ore_giornaliere_arrotondate(
    ora_inizio: str,
    ora_fine: str,
    pausa_minuti: int,
    rules: dict
) -> dict:
    """
    Calcola le ore giornaliere con arrotondamento a fine giornata (daily mode).
    
    Args:
        ora_inizio: orario inizio giornata (HH:MM o HH:MM:SS)
        ora_fine: orario fine giornata (HH:MM o HH:MM:SS)
        pausa_minuti: durata pausa in minuti
        rules: regole del gruppo con rounding_mode='daily'
    
    Returns:
        dict con:
        - ore_lorde: minuti lordi (fine - inizio)
        - ore_nette: minuti netti (lordi - pausa)
        - ore_arrotondate: minuti arrotondati secondo regola
        - ore_str: stringa formattata (es. "8:15")
        - turno_base_minuti: durata turno base in minuti
        - straordinario_lordo: minuti straordinario lordo (netto - turno)
        - straordinario_arrotondato: minuti straordinario arrotondato
        - blocco_minuti: blocco usato per arrotondamento
        - blocchi_straordinario: numero blocchi di straordinario
    """
    # Parse orari
    inizio_parts = ora_inizio.split(':')
    fine_parts = ora_fine.split(':')
    
    inizio_min = int(inizio_parts[0]) * 60 + int(inizio_parts[1])
    fine_min = int(fine_parts[0]) * 60 + int(fine_parts[1])
    
    # Calcola
    ore_lorde = fine_min - inizio_min
    ore_nette = ore_lorde - pausa_minuti
    
    # Arrotondamento
    blocco = rules.get('arrotondamento_giornaliero_minuti', 15)
    tipo_arrot = rules.get('arrotondamento_giornaliero_tipo', 'floor')
    
    # Turno base (default 8 ore = 480 minuti)
    turno_base = rules.get('turno_base_minuti', 480)
    
    # Calcola straordinario lordo
    straordinario_lordo = max(0, ore_nette - turno_base)
    
    # Arrotonda lo straordinario per blocchi
    if straordinario_lordo > 0:
        if tipo_arrot == 'floor':
            blocchi = straordinario_lordo // blocco
        elif tipo_arrot == 'ceil':
            blocchi = (straordinario_lordo + blocco - 1) // blocco
        else:  # nearest
            blocchi = round(straordinario_lordo / blocco)
        straordinario_arrotondato = blocchi * blocco
    else:
        blocchi = 0
        straordinario_arrotondato = 0
    
    # Ore totali arrotondate = turno base + straordinario arrotondato (ma non superiore alle ore nette)
    ore_arrotondate = min(turno_base + straordinario_arrotondato, ore_nette)
    
    # Se sotto il turno base, arrotonda anche quello
    if ore_nette < turno_base:
        if tipo_arrot == 'floor':
            ore_arrotondate = (ore_nette // blocco) * blocco
        elif tipo_arrot == 'ceil':
            ore_arrotondate = ((ore_nette + blocco - 1) // blocco) * blocco
        else:  # nearest
            ore_arrotondate = round(ore_nette / blocco) * blocco
    
    # Formatta stringa
    h = ore_arrotondate // 60
    m = ore_arrotondate % 60
    ore_str = f"{h}:{m:02d}"
    
    return {
        'ore_lorde': ore_lorde,
        'ore_nette': ore_nette,
        'ore_arrotondate': ore_arrotondate,
        'ore_str': ore_str,
        'turno_base_minuti': turno_base,
        'straordinario_lordo': straordinario_lordo,
        'straordinario_arrotondato': straordinario_arrotondato,
        'blocco_minuti': blocco,
        'blocchi_straordinario': blocchi,
        'tipo_arrotondamento': tipo_arrot
    }


def verifica_flessibilita_timbrata(
    ora_timbrata: str,
    tipo: str,
    turno_start: str,
    turno_end: str,
    rules: dict
) -> dict:
    """
    Verifica se una timbrata è dentro la flessibilità per gruppi con daily mode.
    
    Args:
        ora_timbrata: orario timbrato (HH:MM o HH:MM:SS)
        tipo: 'inizio_giornata' o 'fine_giornata'
        turno_start: orario inizio turno (HH:MM)
        turno_end: orario fine turno (HH:MM)
        rules: regole del gruppo
    
    Returns:
        dict con:
        - within_flex: True se dentro flessibilità
        - diff_minutes: differenza in minuti dal turno
        - action: 'allow', 'warn', 'block'
        - message: messaggio per l'utente
    """
    parts = ora_timbrata.split(':')
    ora_min = int(parts[0]) * 60 + int(parts[1])
    
    if tipo == 'inizio_giornata' and turno_start:
        turno_parts = turno_start.split(':')
        turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
        flessibilita = rules.get('flessibilita_ingresso_minuti', 30)
        diff = ora_min - turno_min  # positivo = ritardo, negativo = anticipo
    elif tipo == 'fine_giornata' and turno_end:
        turno_parts = turno_end.split(':')
        turno_min = int(turno_parts[0]) * 60 + int(turno_parts[1])
        flessibilita = rules.get('flessibilita_uscita_minuti', 30)
        diff = ora_min - turno_min  # positivo = dopo turno, negativo = prima
    else:
        return {'within_flex': True, 'diff_minutes': 0, 'action': 'allow', 'message': ''}
    
    within_flex = abs(diff) <= flessibilita
    action = rules.get('oltre_flessibilita_action', 'allow')
    
    message = ''
    if not within_flex:
        # Calcola quanto oltre la flessibilita (non la differenza totale dal turno)
        oltre_flex = abs(diff) - flessibilita
        if diff > 0:
            message = f"Timbrata {oltre_flex} minuti oltre flessibilita"
        else:
            message = f"Timbrata {oltre_flex} minuti prima della flessibilita"
    
    return {
        'within_flex': within_flex,
        'diff_minutes': diff,
        'action': action if not within_flex else 'allow',
        'message': message
    }


def calcola_pausa_mod(inizio_pausa: str, fine_pausa: str, rules: dict = None) -> int:
    """
    Calcola la durata della pausa modificata in minuti.
    
    Args:
        inizio_pausa: orario inizio pausa (HH:MM:SS o HH:MM)
        fine_pausa: orario fine pausa (HH:MM:SS o HH:MM)
        rules: dizionario con le regole (se None, usa default)
    
    Returns:
        durata pausa in minuti (arrotondata secondo le regole)
    """
    if rules is None:
        rules = {
            'pausa_blocco_minimo_minuti': 30,
            'pausa_incremento_minuti': 15,
            'pausa_tolleranza_minuti': 5
        }
    
    # Converte in minuti
    ip = inizio_pausa.split(':')
    fp = fine_pausa.split(':')
    inizio_min = int(ip[0]) * 60 + int(ip[1])
    fine_min = int(fp[0]) * 60 + int(fp[1])
    
    durata_effettiva = fine_min - inizio_min
    
    blocco_min = rules.get('pausa_blocco_minimo_minuti', 30)
    incremento = rules.get('pausa_incremento_minuti', 15)
    tolleranza = rules.get('pausa_tolleranza_minuti', 5)
    
    # Se durata < blocco minimo, usa blocco minimo
    if durata_effettiva <= blocco_min:
        return blocco_min
    
    # Calcola eccesso rispetto al blocco minimo
    eccesso = durata_effettiva - blocco_min
    
    # Quanti blocchi di incremento sono necessari?
    blocchi_extra = eccesso // incremento
    resto = eccesso % incremento
    
    # Se il resto è > tolleranza, aggiungi un blocco
    if resto > tolleranza:
        blocchi_extra += 1
    
    return blocco_min + (blocchi_extra * incremento)


# ═══════════════════════════════════════════════════════════════════════════════
#  CONFIGURAZIONE AZIENDA - COMPANY SETTINGS
# ═══════════════════════════════════════════════════════════════════════════════

COMPANY_SETTINGS_TABLE_MYSQL = """
CREATE TABLE IF NOT EXISTS company_settings (
    id INT PRIMARY KEY DEFAULT 1,
    company_name VARCHAR(200) NOT NULL DEFAULT 'La Mia Azienda',
    external_id VARCHAR(100),
    logo_path VARCHAR(500),
    address TEXT,
    phone VARCHAR(50),
    email VARCHAR(200),
    website VARCHAR(200),
    vat_number VARCHAR(50),
    fiscal_code VARCHAR(50),
    modules_enabled JSON,
    custom_settings JSON,
    created_ts BIGINT NOT NULL,
    updated_ts BIGINT NOT NULL,
    updated_by VARCHAR(100)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
"""

COMPANY_SETTINGS_TABLE_SQLITE = """
CREATE TABLE IF NOT EXISTS company_settings (
    id INTEGER PRIMARY KEY DEFAULT 1,
    company_name TEXT NOT NULL DEFAULT 'La Mia Azienda',
    external_id TEXT,
    logo_path TEXT,
    address TEXT,
    phone TEXT,
    email TEXT,
    website TEXT,
    vat_number TEXT,
    fiscal_code TEXT,
    modules_enabled TEXT,
    custom_settings TEXT,
    created_ts INTEGER NOT NULL,
    updated_ts INTEGER NOT NULL,
    updated_by TEXT
)
"""


def ensure_company_settings_table(db: DatabaseLike) -> None:
    """Crea la tabella company_settings se non esiste."""
    statement = (
        COMPANY_SETTINGS_TABLE_MYSQL if DB_VENDOR == "mysql" else COMPANY_SETTINGS_TABLE_SQLITE
    )
    for stmt in statement.strip().split(";"):
        sql = stmt.strip()
        if not sql:
            continue
        cursor = db.execute(sql)
        try:
            cursor.close()
        except AttributeError:
            pass
    db.commit()


def get_company_settings(db: DatabaseLike) -> dict:
    """Ottiene le impostazioni azienda dal database."""
    ensure_company_settings_table(db)
    
    cursor = db.execute("SELECT * FROM company_settings WHERE id = 1")
    row = cursor.fetchone()
    
    if not row:
        # Inserisci valori di default
        now_ts = int(time.time() * 1000)
        if DB_VENDOR == "mysql":
            db.execute(
                """INSERT INTO company_settings 
                   (id, company_name, modules_enabled, custom_settings, created_ts, updated_ts) 
                   VALUES (1, 'La Mia Azienda', '{}', '{}', %s, %s)""",
                (now_ts, now_ts)
            )
        else:
            db.execute(
                """INSERT INTO company_settings 
                   (id, company_name, modules_enabled, custom_settings, created_ts, updated_ts) 
                   VALUES (1, 'La Mia Azienda', '{}', '{}', ?, ?)""",
                (now_ts, now_ts)
            )
        db.commit()
        cursor = db.execute("SELECT * FROM company_settings WHERE id = 1")
        row = cursor.fetchone()
    
    # Converti in dizionario - gestisce sia tuple che dict
    if isinstance(row, dict):
        settings = dict(row)
    else:
        columns = [desc[0] for desc in cursor.description]
        settings = dict(zip(columns, row))
    
    # Parse JSON fields
    for json_field in ['modules_enabled', 'custom_settings']:
        if settings.get(json_field):
            try:
                if isinstance(settings[json_field], str):
                    settings[json_field] = json.loads(settings[json_field])
            except (json.JSONDecodeError, TypeError):
                settings[json_field] = {}
        else:
            settings[json_field] = {}
    
    return settings


def is_module_enabled(db: DatabaseLike, module_name: str) -> bool:
    """Verifica se un modulo è attivo nelle impostazioni azienda.
    
    Args:
        db: connessione database
        module_name: nome del modulo (es. 'straordinari', 'magazzino', 'requests')
    
    Returns:
        True se il modulo è attivo (default True per moduli non specificati)
    """
    settings = get_company_settings(db)
    modules = settings.get('modules_enabled', {})
    enabled = modules.get(module_name, True)
    app.logger.info(f"Modulo '{module_name}' attivo: {enabled} (modules_enabled: {modules})")
    return enabled


def save_company_settings(db: DatabaseLike, data: dict, updated_by: str) -> bool:
    """Salva le impostazioni azienda (INSERT o UPDATE)."""
    ensure_company_settings_table(db)
    now_ts = int(time.time() * 1000)
    
    # Prepara JSON fields
    modules_enabled = json.dumps(data.get('modules_enabled', {}))
    custom_settings = json.dumps(data.get('custom_settings', {}))
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica se esiste già un record
    cursor = db.execute("SELECT id FROM company_settings WHERE id = 1")
    exists = cursor.fetchone() is not None
    
    if exists:
        # UPDATE
        db.execute(f"""
            UPDATE company_settings SET
                company_name = {placeholder},
                external_id = {placeholder},
                logo_path = {placeholder},
                address = {placeholder},
                phone = {placeholder},
                email = {placeholder},
                website = {placeholder},
                vat_number = {placeholder},
                fiscal_code = {placeholder},
                modules_enabled = {placeholder},
                custom_settings = {placeholder},
                updated_ts = {placeholder},
                updated_by = {placeholder}
            WHERE id = 1
        """, (
            data.get('company_name', 'La Mia Azienda'),
            data.get('external_id'),
            data.get('logo_path'),
            data.get('address'),
            data.get('phone'),
            data.get('email'),
            data.get('website'),
            data.get('vat_number'),
            data.get('fiscal_code'),
            modules_enabled,
            custom_settings,
            now_ts,
            updated_by
        ))
    else:
        # INSERT
        db.execute(f"""
            INSERT INTO company_settings (
                id, company_name, external_id, logo_path, address, phone, email, 
                website, vat_number, fiscal_code, modules_enabled, custom_settings, 
                created_ts, updated_ts, updated_by
            ) VALUES (
                1, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 
                {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 
                {placeholder}, {placeholder}, {placeholder}, {placeholder}
            )
        """, (
            data.get('company_name', 'La Mia Azienda'),
            data.get('external_id'),
            data.get('logo_path'),
            data.get('address'),
            data.get('phone'),
            data.get('email'),
            data.get('website'),
            data.get('vat_number'),
            data.get('fiscal_code'),
            modules_enabled,
            custom_settings,
            now_ts,
            now_ts,
            updated_by
        ))
    
    db.commit()
    return True


@app.get("/admin/company-settings")
@login_required
def admin_company_settings_page() -> ResponseReturnValue:
    """Pagina configurazione azienda (solo admin)."""
    if not session.get("is_admin"):
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    return render_template(
        "admin_company_settings.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=True,
    )


@app.get("/api/admin/company-settings")
@login_required
def api_get_company_settings() -> ResponseReturnValue:
    """API per ottenere le impostazioni azienda."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    db = get_db()
    settings = get_company_settings(db)
    
    # Aggiungi flag per indicare se CedolinoWeb è configurato nel config.json
    config = load_config()
    cedolino_section = config.get("cedolino_web", {})
    settings["cedolino_configured"] = bool(
        cedolino_section.get("enabled") and 
        cedolino_section.get("username") and 
        cedolino_section.get("password")
    )
    
    return jsonify(settings)


@app.post("/api/admin/company-settings")
@login_required
def api_save_company_settings() -> ResponseReturnValue:
    """API per salvare le impostazioni azienda."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    db = get_db()
    username = session.get("user") or session.get("username") or "admin"
    
    try:
        save_company_settings(db, data, username)
        return jsonify({"ok": True, "message": "Impostazioni salvate"})
    except Exception as e:
        app.logger.error(f"Errore salvataggio company settings: {e}")
        return jsonify({"error": str(e)}), 500


@app.post("/api/admin/company-settings/logo")
@login_required
def api_upload_company_logo() -> ResponseReturnValue:
    """API per caricare il logo aziendale."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    if 'logo' not in request.files:
        return jsonify({"error": "Nessun file caricato"}), 400
    
    file = request.files['logo']
    if file.filename == '':
        return jsonify({"error": "Nessun file selezionato"}), 400
    
    # Verifica estensione
    allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'svg', 'webp'}
    ext = file.filename.rsplit('.', 1)[-1].lower() if '.' in file.filename else ''
    if ext not in allowed_extensions:
        return jsonify({"error": f"Formato non supportato. Usa: {', '.join(allowed_extensions)}"}), 400
    
    # Salva il file
    logo_dir = os.path.join(app.root_path, 'static', 'uploads', 'logo')
    os.makedirs(logo_dir, exist_ok=True)
    
    # Nome file univoco
    filename = f"company_logo_{int(time.time())}.{ext}"
    filepath = os.path.join(logo_dir, filename)
    file.save(filepath)
    
    # Path relativo per il database
    logo_path = f"/static/uploads/logo/{filename}"
    
    # Aggiorna database
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now_ts = int(time.time() * 1000)
    username = session.get("user") or session.get("username") or "admin"
    
    ensure_company_settings_table(db)
    db.execute(f"""
        UPDATE company_settings SET 
            logo_path = {placeholder}, 
            updated_ts = {placeholder},
            updated_by = {placeholder}
        WHERE id = 1
    """, (logo_path, now_ts, username))
    db.commit()
    
    return jsonify({"ok": True, "logo_path": logo_path})


@app.delete("/api/admin/company-settings/logo")
@login_required
def api_delete_company_logo() -> ResponseReturnValue:
    """API per eliminare il logo aziendale."""
    if not session.get("is_admin"):
        return jsonify({"error": "Non autorizzato"}), 403
    
    db = get_db()
    settings = get_company_settings(db)
    
    # Elimina file se esiste
    if settings.get('logo_path'):
        old_path = os.path.join(app.root_path, settings['logo_path'].lstrip('/'))
        if os.path.exists(old_path):
            try:
                os.remove(old_path)
            except Exception as e:
                app.logger.warning(f"Errore eliminazione logo: {e}")
    
    # Aggiorna database
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    now_ts = int(time.time() * 1000)
    username = session.get("user") or session.get("username") or "admin"
    
    db.execute(f"""
        UPDATE company_settings SET 
            logo_path = NULL, 
            updated_ts = {placeholder},
            updated_by = {placeholder}
        WHERE id = 1
    """, (now_ts, username))
    db.commit()
    
    return jsonify({"ok": True})


# ═══════════════════════════════════════════════════════════════════════════════
#  GESTIONE TIPOLOGIE RICHIESTE - ADMIN UI
# ═══════════════════════════════════════════════════════════════════════════════

VALUE_TYPE_LABELS = {
    "hours": "Ore",
    "days": "Giorni",
    "amount": "Importo €",
    "km": "Chilometri",
    "minutes": "Minuti"
}


@app.get("/admin/request-types")
@login_required
def admin_request_types_page() -> ResponseReturnValue:
    """Pagina gestione tipologie richieste (solo admin)."""
    if not session.get("is_admin"):
        abort(403)

    display_name = session.get("user_display") or session.get("user_name") or session.get("user")
    primary_name = session.get("user_name") or display_name or session.get("user")
    initials = session.get("user_initials") or compute_initials(primary_name or "")

    return render_template(
        "admin_request_types.html",
        user_name=primary_name,
        user_display=display_name,
        user_initials=initials,
        is_admin=True,
    )


@app.get("/api/admin/request-types")
@login_required
def api_admin_request_types_list() -> ResponseReturnValue:
    """Lista tutte le tipologie di richiesta."""
    if not is_admin_or_supervisor():
        return jsonify({"error": "forbidden"}), 403

    try:
        db = get_db()
        ensure_request_types_table(db)
        
        rows = db.execute("""
            SELECT id, name, value_type, external_id, abbreviation, description, active, sort_order, created_ts, updated_ts, is_giustificativo
            FROM request_types
            ORDER BY sort_order ASC, name ASC
        """).fetchall()
    except Exception as e:
        app.logger.error(f"Errore in api_admin_request_types_list: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        return jsonify({"error": str(e)}), 500

    types = []
    for row in rows:
        if isinstance(row, Mapping):
            types.append({
                "id": row["id"],
                "name": row["name"],
                "value_type": row["value_type"],
                "value_type_label": VALUE_TYPE_LABELS.get(row["value_type"], row["value_type"]),
                "external_id": row["external_id"],
                "abbreviation": row["abbreviation"],
                "description": row["description"],
                "active": bool(row["active"]),
                "sort_order": row["sort_order"],
                "created_ts": row["created_ts"],
                "updated_ts": row["updated_ts"],
                "is_giustificativo": bool(row.get("is_giustificativo", False)),
            })
        else:
            types.append({
                "id": row[0],
                "name": row[1],
                "value_type": row[2],
                "value_type_label": VALUE_TYPE_LABELS.get(row[2], row[2]),
                "external_id": row[3],
                "abbreviation": row[4],
                "description": row[5],
                "active": bool(row[6]),
                "sort_order": row[7],
                "created_ts": row[8],
                "updated_ts": row[9],
                "is_giustificativo": bool(row[10]) if len(row) > 10 else False,
            })

    return jsonify({"types": types, "value_types": VALUE_TYPE_LABELS})


@app.post("/api/admin/request-types")
@login_required
def api_admin_request_types_create() -> ResponseReturnValue:
    """Crea una nuova tipologia di richiesta."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati non validi"}), 400

    name = (data.get("name") or "").strip()
    value_type = data.get("value_type", "hours")
    external_id = (data.get("external_id") or "").strip() or None
    abbreviation = (data.get("abbreviation") or "").strip() or None
    description = (data.get("description") or "").strip() or None
    active = data.get("active", True)
    sort_order = data.get("sort_order", 0)
    is_giustificativo = data.get("is_giustificativo", False)

    if not name:
        return jsonify({"error": "Il nome è obbligatorio"}), 400

    if value_type not in VALUE_TYPE_LABELS:
        return jsonify({"error": f"Tipo valore non valido. Valori ammessi: {list(VALUE_TYPE_LABELS.keys())}"}), 400

    db = get_db()
    ensure_request_types_table(db)
    now_ms = int(time.time() * 1000)

    if DB_VENDOR == "mysql":
        db.execute("""
            INSERT INTO request_types (name, value_type, external_id, abbreviation, description, active, sort_order, created_ts, updated_ts, is_giustificativo)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (name, value_type, external_id, abbreviation, description, 1 if active else 0, sort_order, now_ms, now_ms, 1 if is_giustificativo else 0))
    else:
        db.execute("""
            INSERT INTO request_types (name, value_type, external_id, abbreviation, description, active, sort_order, created_ts, updated_ts, is_giustificativo)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (name, value_type, external_id, abbreviation, description, 1 if active else 0, sort_order, now_ms, now_ms, 1 if is_giustificativo else 0))
    
    db.commit()

    return jsonify({"ok": True, "message": f"Tipologia '{name}' creata con successo"})


@app.put("/api/admin/request-types/<int:type_id>")
@login_required
def api_admin_request_types_update(type_id: int) -> ResponseReturnValue:
    """Aggiorna una tipologia di richiesta."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati non validi"}), 400

    name = (data.get("name") or "").strip()
    value_type = data.get("value_type", "hours")
    external_id = (data.get("external_id") or "").strip() or None
    abbreviation = (data.get("abbreviation") or "").strip() or None
    description = (data.get("description") or "").strip() or None
    active = data.get("active", True)
    sort_order = data.get("sort_order", 0)
    is_giustificativo = data.get("is_giustificativo", False)

    if not name:
        return jsonify({"error": "Il nome è obbligatorio"}), 400

    if value_type not in VALUE_TYPE_LABELS:
        return jsonify({"error": f"Tipo valore non valido"}), 400

    db = get_db()
    ensure_request_types_table(db)
    now_ms = int(time.time() * 1000)

    if DB_VENDOR == "mysql":
        db.execute("""
            UPDATE request_types
            SET name = %s, value_type = %s, external_id = %s, abbreviation = %s, description = %s, 
                active = %s, sort_order = %s, updated_ts = %s, is_giustificativo = %s
            WHERE id = %s
        """, (name, value_type, external_id, abbreviation, description, 1 if active else 0, sort_order, now_ms, 1 if is_giustificativo else 0, type_id))
    else:
        db.execute("""
            UPDATE request_types
            SET name = ?, value_type = ?, external_id = ?, abbreviation = ?, description = ?, 
                active = ?, sort_order = ?, updated_ts = ?, is_giustificativo = ?
            WHERE id = ?
        """, (name, value_type, external_id, abbreviation, description, 1 if active else 0, sort_order, now_ms, 1 if is_giustificativo else 0, type_id))
    
    db.commit()

    return jsonify({"ok": True, "message": f"Tipologia '{name}' aggiornata"})


@app.delete("/api/admin/request-types/<int:type_id>")
@login_required
def api_admin_request_types_delete(type_id: int) -> ResponseReturnValue:
    """Elimina una tipologia di richiesta."""
    if not session.get("is_admin"):
        return jsonify({"error": "forbidden"}), 403

    db = get_db()
    ensure_request_types_table(db)
    ensure_user_requests_table(db)

    # Verifica che non ci siano richieste collegate
    if DB_VENDOR == "mysql":
        count = db.execute("SELECT COUNT(*) as cnt FROM user_requests WHERE request_type_id = %s", (type_id,)).fetchone()
    else:
        count = db.execute("SELECT COUNT(*) as cnt FROM user_requests WHERE request_type_id = ?", (type_id,)).fetchone()
    
    cnt = count["cnt"] if isinstance(count, Mapping) else count[0]
    if cnt > 0:
        return jsonify({"error": f"Impossibile eliminare: ci sono {cnt} richieste collegate a questa tipologia"}), 400

    if DB_VENDOR == "mysql":
        db.execute("DELETE FROM request_types WHERE id = %s", (type_id,))
    else:
        db.execute("DELETE FROM request_types WHERE id = ?", (type_id,))
    
    db.commit()

    return jsonify({"ok": True, "message": "Tipologia eliminata"})


def _build_late_arrival_details(extra_data_str: str = None) -> str:
    """Costruisce i dettagli del ritardo per le notifiche push."""
    if not extra_data_str:
        return ""
    try:
        extra = json.loads(extra_data_str) if isinstance(extra_data_str, str) else extra_data_str
        turno_start = extra.get("turno_start", "")
        ora_timbrata = extra.get("ora_timbrata", "")
        late_minutes = extra.get("late_minutes", 0)
        
        if turno_start and ora_timbrata:
            return (
                f"\n\n• Turno previsto: {turno_start}"
                f"\n• Timbrata: {ora_timbrata}"
                f"\n• Ritardo: {late_minutes} min"
            )
    except Exception:
        pass
    return ""


def _send_request_review_notification(
    db: DatabaseLike, 
    username: str, 
    type_name: str, 
    status: str, 
    review_notes: str,
    is_partial: bool = False,
    rounded_start: str = None,
    rounded_end: str = None,
    extra_data_str: str = None
) -> None:
    """Invia notifica push all'utente quando la sua richiesta viene revisionata.
    
    Args:
        is_partial: True se l'admin ha modificato gli orari (approvazione parziale)
        rounded_start: Orario inizio arrotondato confermato
        rounded_end: Orario fine arrotondato confermato
        extra_data_str: JSON string con dati extra della richiesta
    """
    settings = get_webpush_settings()
    if not settings:
        app.logger.info("Notifiche push non configurate, skip notifica revisione richiesta")
        return
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera le subscription push dell'utente
    subscriptions = db.execute(
        f"SELECT endpoint, p256dh, auth FROM push_subscriptions WHERE username = {placeholder}",
        (username,)
    ).fetchall()
    
    if not subscriptions:
        app.logger.info("Nessuna subscription push per utente %s", username)
        return
    
    # Prepara il messaggio
    if status == "approved":
        if is_partial:
            title = "⚠️ Richiesta approvata parzialmente"
            body = f"La tua richiesta di {type_name} è stata approvata con modifiche"
            # Aggiungi gli orari arrotondati
            if rounded_start and rounded_end:
                body += f"\n🕐 Orari confermati: {rounded_start} - {rounded_end}"
            elif rounded_start:
                body += f"\n🕐 Inizio confermato: {rounded_start}"
            elif rounded_end:
                body += f"\n🕐 Fine confermata: {rounded_end}"
        else:
            # Messaggio specifico per Giustificazione Ritardo approvata
            if type_name == "Giustificazione Ritardo":
                title = "✅ Giustificazione accettata"
                body = "La tua giustificazione per il ritardo è stata accettata"
                body += _build_late_arrival_details(extra_data_str)
            else:
                title = "✅ Richiesta approvata"
                body = f"La tua richiesta di {type_name} è stata approvata"
    else:
        # Messaggio specifico per Giustificazione Ritardo respinta (= Ritardo registrato)
        if type_name == "Giustificazione Ritardo":
            title = "⏰ Ritardo registrato"
            body = "Il ritardo è stato registrato nelle statistiche"
            body += _build_late_arrival_details(extra_data_str)
        else:
            title = "❌ Richiesta respinta"
            body = f"La tua richiesta di {type_name} è stata respinta"
    
    if review_notes:
        body += f"\n📝 Note: {review_notes}"
    
    payload = {
        "title": title,
        "body": body,
        "icon": "/static/icons/icon-192x192.png",
        "badge": "/static/icons/icon-72x72.png",
        "tag": f"request-review-{status}",
        "data": {
            "url": "/user/requests",
            "type": "request_reviewed"
        }
    }
    
    # Invia a tutte le subscription dell'utente
    sent_ok = False
    for sub in subscriptions:
        endpoint = sub['endpoint'] if isinstance(sub, dict) else sub[0]
        p256dh = sub['p256dh'] if isinstance(sub, dict) else sub[1]
        auth = sub['auth'] if isinstance(sub, dict) else sub[2]
        
        subscription_info = {
            "endpoint": endpoint,
            "keys": {
                "p256dh": p256dh,
                "auth": auth
            }
        }
        
        try:
            webpush(
                subscription_info=subscription_info,
                data=json.dumps(payload),
                vapid_private_key=settings["vapid_private"],
                vapid_claims={"sub": settings["subject"]},
                ttl=86400,  # 24 ore
            )
            app.logger.info("Notifica revisione richiesta inviata a %s", username)
            sent_ok = True
                
        except WebPushException as e:
            app.logger.warning("Errore invio notifica revisione a %s: %s", username, e)
            if e.response and e.response.status_code in {404, 410}:
                remove_push_subscription(db, endpoint)
        except Exception as e:
            app.logger.error("Errore generico invio notifica revisione: %s", e)
    
    # Salva la notifica nel log (una volta per utente)
    if sent_ok:
        try:
            record_push_notification(
                db,
                kind="request_reviewed",
                title=title,
                body=body,
                payload=payload,
                username=username,
            )
            app.logger.info("Notifica revisione salvata nel log per %s", username)
        except Exception as e:
            app.logger.error("Errore salvataggio notifica revisione nel log: %s", e)


# =====================================================
# ADMIN DOCUMENTS - Gestione documenti aziendali
# =====================================================

@app.get("/admin/documents")
@login_required
def admin_documents_page() -> ResponseReturnValue:
    """Pagina admin per gestire i documenti aziendali."""
    if not session.get("is_admin"):
        return ("Forbidden", 403)
    
    username = session.get("username", "Admin")
    initials = "".join([p[0].upper() for p in username.split()[:2]]) if username else "?"
    
    return render_template(
        "admin_documents.html",
        is_admin=True,
        user_name=username,
        user_initials=initials
    )


@app.get("/api/admin/documents")
@login_required
def api_admin_documents_list() -> ResponseReturnValue:
    """Lista tutti i documenti caricati."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_documents_table(db)
    
    rows = db.execute("""
        SELECT id, category, title, description, file_path, file_name, 
               target_users, target_all, created_by, created_at, notified_at
        FROM user_documents
        ORDER BY created_at DESC
    """).fetchall()
    
    # Carica la lista utenti per mostrare i nomi completi
    users_dict = {}
    try:
        users_rows = db.execute("SELECT username, display_name FROM users").fetchall()
        for u in users_rows:
            if isinstance(u, Mapping):
                users_dict[u["username"]] = u["display_name"] or u["username"]
            else:
                users_dict[u[0]] = u[1] or u[0]
    except:
        pass
    
    documents = []
    for row in rows:
        if isinstance(row, Mapping):
            target_users = row["target_users"]
            file_name = row["file_name"]
        else:
            target_users = row[6]
            file_name = row[5]
            
        if target_users and isinstance(target_users, str):
            try:
                target_users = json.loads(target_users)
            except:
                target_users = []
        
        # Costruisci lista destinatari con nomi completi
        target_users_display = []
        if target_users:
            for username in target_users:
                display_name = users_dict.get(username, username)
                target_users_display.append({"username": username, "display_name": display_name})
        
        # Costruisci file_url usando file_name (come API user)
        file_url = None
        if file_name:
            file_url = f"/uploads/documents/{file_name}"
        
        if isinstance(row, Mapping):
            documents.append({
                "id": row["id"],
                "category": row["category"],
                "title": row["title"],
                "description": row["description"],
                "file_name": row["file_name"],
                "file_url": file_url,
                "target_users": target_users,
                "target_users_display": target_users_display,
                "target_all": bool(row["target_all"]),
                "created_by": row["created_by"],
                "created_at": row["created_at"],
                "notified_at": row["notified_at"]
            })
        else:
            documents.append({
                "id": row[0],
                "category": row[1],
                "title": row[2],
                "description": row[3],
                "file_name": row[5],
                "file_url": file_url,
                "target_users": target_users,
                "target_users_display": target_users_display,
                "target_all": bool(row[7]),
                "created_by": row[8],
                "created_at": row[9],
                "notified_at": row[10]
            })
    
    return jsonify({"documents": documents})


@app.post("/api/admin/documents")
@login_required
def api_admin_documents_create() -> ResponseReturnValue:
    """Carica un nuovo documento."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    category = request.form.get("category")
    title = request.form.get("title")
    description = request.form.get("description", "")
    target_all = request.form.get("target_all", "1") == "1"
    target_users_json = request.form.get("target_users", "[]")
    
    if not category or category not in ("circolare", "comunicazione", "busta_paga"):
        return jsonify({"error": "Categoria non valida"}), 400
    
    if not title:
        return jsonify({"error": "Titolo obbligatorio"}), 400
    
    # Gestione file allegato
    file_path = None
    file_name = None
    
    if "file" in request.files:
        file = request.files["file"]
        if file and file.filename:
            # Genera nome file univoco
            import uuid
            ext = os.path.splitext(file.filename)[1]
            file_name = f"{uuid.uuid4().hex}{ext}"
            file_path = os.path.join("uploads", "documents", file_name)
            
            # Salva il file
            full_path = os.path.join(os.path.dirname(__file__), file_path)
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            file.save(full_path)
    
    db = get_db()
    ensure_user_documents_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    created_by = session.get("user", "admin")
    
    db.execute(f"""
        INSERT INTO user_documents (category, title, description, file_path, file_name, 
                                    target_users, target_all, created_by)
        VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, 
                {placeholder}, {placeholder}, {placeholder})
    """, (category, title, description, file_path, file_name, 
          target_users_json if not target_all else None, 
          1 if target_all else 0, created_by))
    
    db.commit()
    
    # Le notifiche NON vengono inviate automaticamente
    # L'admin deve inviarle manualmente dal tab "Da Inviare"
    
    return jsonify({"success": True, "message": "Documento caricato. Vai su 'Da Inviare' per inviare le notifiche."})


@app.put("/api/admin/documents/<int:doc_id>")
@login_required
def api_admin_documents_update(doc_id: int) -> ResponseReturnValue:
    """Aggiorna titolo e descrizione di un documento."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_documents_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera il documento esistente
    row = db.execute(f"SELECT id FROM user_documents WHERE id = {placeholder}", (doc_id,)).fetchone()
    if not row:
        return jsonify({"error": "Documento non trovato"}), 404
    
    data = request.get_json() or {}
    title = data.get("title", "").strip()
    description = data.get("description", "").strip()
    
    if not title:
        return jsonify({"error": "Il titolo è obbligatorio"}), 400
    
    # Aggiorna il documento
    db.execute(
        f"UPDATE user_documents SET title = {placeholder}, description = {placeholder} WHERE id = {placeholder}",
        (title, description, doc_id)
    )
    db.commit()
    
    return jsonify({"success": True, "message": "Documento aggiornato"})


@app.delete("/api/admin/documents/<int:doc_id>")
@login_required
def api_admin_documents_delete(doc_id: int) -> ResponseReturnValue:
    """Elimina un documento."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_documents_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera il file path per eliminarlo
    row = db.execute(f"SELECT file_path FROM user_documents WHERE id = {placeholder}", (doc_id,)).fetchone()
    if row:
        file_path = row["file_path"] if isinstance(row, Mapping) else row[0]
        if file_path:
            full_path = os.path.join(os.path.dirname(__file__), file_path)
            try:
                os.remove(full_path)
            except:
                pass
    
    # Elimina dal database
    db.execute(f"DELETE FROM user_documents_read WHERE document_id = {placeholder}", (doc_id,))
    db.execute(f"DELETE FROM user_documents WHERE id = {placeholder}", (doc_id,))
    db.commit()
    
    return jsonify({"success": True, "message": "Documento eliminato"})


@app.post("/api/admin/documents/<int:doc_id>/notify")
@login_required
def api_admin_documents_notify(doc_id: int) -> ResponseReturnValue:
    """Reinvia la notifica per un documento."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_documents_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera il documento
    row = db.execute(
        f"SELECT category, title, target_all, target_users FROM user_documents WHERE id = {placeholder}",
        (doc_id,)
    ).fetchone()
    
    if not row:
        return jsonify({"error": "Documento non trovato"}), 404
    
    if isinstance(row, Mapping):
        category = row["category"]
        title = row["title"]
        target_all = row["target_all"]
        target_users_json = row["target_users"] or "[]"
    else:
        category, title, target_all, target_users_json = row[0], row[1], row[2], row[3] or "[]"
    
    # Invia le notifiche (passa doc_id per URL diretto)
    count = _send_document_notifications(db, category, title, bool(target_all), target_users_json, doc_id)
    
    # Aggiorna notified_at
    if count > 0:
        db.execute(
            f"UPDATE user_documents SET notified_at = {placeholder} WHERE id = {placeholder}",
            (now_ms(), doc_id)
        )
        db.commit()
    
    return jsonify({
        "success": True, 
        "message": f"Notifica inviata a {count} dispositivi",
        "count": count
    })


@app.get("/api/admin/documents/<int:doc_id>/recipients")
@login_required
def api_admin_documents_recipients(doc_id: int) -> ResponseReturnValue:
    """Restituisce la lista dei destinatari di un documento con stato di lettura."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_documents_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera il documento
    row = db.execute(
        f"SELECT target_all, target_users FROM user_documents WHERE id = {placeholder}",
        (doc_id,)
    ).fetchone()
    
    if not row:
        return jsonify({"error": "Documento non trovato"}), 404
    
    if isinstance(row, Mapping):
        target_all = row["target_all"]
        target_users_json = row["target_users"] or "[]"
    else:
        target_all, target_users_json = row[0], row[1] or "[]"
    
    # Determina i destinatari
    if target_all:
        # Tutti gli operatori (role = 'user')
        users_rows = db.execute(
            f"SELECT username, display_name FROM app_users WHERE role = 'user' AND is_active = 1"
        ).fetchall()
        target_usernames = []
        user_display_map = {}
        for u in users_rows:
            if isinstance(u, Mapping):
                target_usernames.append(u["username"])
                user_display_map[u["username"]] = u["display_name"]
            else:
                target_usernames.append(u[0])
                user_display_map[u[0]] = u[1]
    else:
        # Destinatari specifici
        try:
            target_usernames = json.loads(target_users_json)
        except json.JSONDecodeError:
            target_usernames = []
        
        # Recupera display_name per ciascuno
        user_display_map = {}
        if target_usernames:
            placeholders = ",".join([placeholder] * len(target_usernames))
            users_rows = db.execute(
                f"SELECT username, display_name FROM app_users WHERE username IN ({placeholders})",
                tuple(target_usernames)
            ).fetchall()
            for u in users_rows:
                if isinstance(u, Mapping):
                    user_display_map[u["username"]] = u["display_name"]
                else:
                    user_display_map[u[0]] = u[1]
    
    # Recupera chi ha letto il documento
    read_rows = db.execute(
        f"SELECT username, read_at FROM user_documents_read WHERE document_id = {placeholder}",
        (doc_id,)
    ).fetchall()
    
    read_map = {}
    for r in read_rows:
        if isinstance(r, Mapping):
            read_map[r["username"]] = r["read_at"]
        else:
            read_map[r[0]] = r[1]
    
    # Costruisci la lista destinatari con stato lettura
    recipients = []
    for username in target_usernames:
        display_name = user_display_map.get(username, username)
        read_at = read_map.get(username)
        recipients.append({
            "username": username,
            "display_name": display_name,
            "read": read_at is not None,
            "read_at": str(read_at) if read_at else None
        })
    
    # Ordina: prima non letti, poi letti
    recipients.sort(key=lambda x: (x["read"], x["display_name"].lower()))
    
    return jsonify({
        "target_all": bool(target_all),
        "recipients": recipients,
        "total": len(recipients),
        "read_count": len(read_map),
        "unread_count": len(recipients) - len(read_map)
    })


# =====================================================
# ADMIN EMPLOYEE SHIFTS - Turni settimanali impiegati
# =====================================================

@app.get("/admin/employee-shifts")
@login_required
def admin_employee_shifts_page() -> ResponseReturnValue:
    """Pagina admin per gestire i turni settimanali degli impiegati."""
    if not session.get("is_admin"):
        return ("Forbidden", 403)
    
    username = session.get("username", "Admin")
    initials = "".join([p[0].upper() for p in username.split()[:2]]) if username else "?"
    
    return render_template(
        "admin_employee_shifts.html",
        is_admin=True,
        user_name=username,
        user_initials=initials
    )


@app.get("/api/admin/employee-shifts/users")
@login_required
def api_admin_employee_shifts_users() -> ResponseReturnValue:
    """Restituisce gli utenti che NON hanno rentman_crew_id (impiegati non-Rentman)."""
    if not session.get("is_admin"):
        return jsonify({"error": "Forbidden"}), 403
    
    db = get_db()
    ensure_employee_shifts_table(db)
    
    # Utenti senza associazione Rentman
    rows = db.execute("""
        SELECT username, display_name, full_name, role
        FROM app_users
        WHERE is_active = 1 AND (rentman_crew_id IS NULL OR rentman_crew_id = 0)
        ORDER BY display_name ASC
    """).fetchall()
    
    users = []
    for row in rows:
        if isinstance(row, dict):
            users.append({
                "username": row["username"],
                "display_name": row["display_name"],
                "full_name": row.get("full_name") or row["display_name"],
                "role": row["role"]
            })
        else:
            users.append({
                "username": row[0],
                "display_name": row[1],
                "full_name": row[2] or row[1],
                "role": row[3]
            })
    
    return jsonify({"users": users})


@app.get("/api/admin/employee-shifts")
@login_required
def api_admin_employee_shifts_list() -> ResponseReturnValue:
    """Lista tutti i turni configurati, raggruppati per utente."""
    if not session.get("is_admin"):
        return jsonify({"error": "Forbidden"}), 403
    
    db = get_db()
    ensure_employee_shifts_table(db)
    
    rows = db.execute("""
        SELECT es.id, es.username, es.day_of_week, es.start_time, es.end_time,
               es.break_start, es.break_end, es.shift_name, es.location_name, es.is_active,
               au.display_name, au.full_name
        FROM employee_shifts es
        LEFT JOIN app_users au ON es.username = au.username
        ORDER BY au.display_name ASC, es.day_of_week ASC
    """).fetchall()
    
    shifts_by_user = {}
    for row in rows:
        if isinstance(row, dict):
            username = row["username"]
            shift = {
                "id": row["id"],
                "day_of_week": row["day_of_week"],
                "start_time": format_time_value(row["start_time"]),
                "end_time": format_time_value(row["end_time"]),
                "break_start": format_time_value(row["break_start"]),
                "break_end": format_time_value(row["break_end"]),
                "shift_name": row.get("shift_name"),
                "location_name": row.get("location_name"),
                "is_active": bool(row["is_active"])
            }
            display_name = row.get("display_name") or username
            full_name = row.get("full_name") or display_name
        else:
            username = row[1]
            shift = {
                "id": row[0],
                "day_of_week": row[2],
                "start_time": format_time_value(row[3]),
                "end_time": format_time_value(row[4]),
                "break_start": format_time_value(row[5]),
                "break_end": format_time_value(row[6]),
                "shift_name": row[7] if len(row) > 7 else None,
                "location_name": row[8] if len(row) > 8 else None,
                "is_active": bool(row[9]) if len(row) > 9 else True
            }
            display_name = row[10] if len(row) > 10 else username
            full_name = row[11] if len(row) > 11 else display_name
        
        if username not in shifts_by_user:
            shifts_by_user[username] = {
                "username": username,
                "display_name": display_name,
                "full_name": full_name,
                "shifts": []
            }
        shifts_by_user[username]["shifts"].append(shift)
    
    return jsonify({"users": list(shifts_by_user.values())})


@app.get("/api/admin/employee-shifts/<username>")
@login_required
def api_admin_employee_shifts_get(username: str) -> ResponseReturnValue:
    """Restituisce i turni di un utente specifico."""
    if not session.get("is_admin"):
        return jsonify({"error": "Forbidden"}), 403
    
    db = get_db()
    ensure_employee_shifts_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    rows = db.execute(f"""
        SELECT id, day_of_week, start_time, end_time, break_start, break_end, shift_name, location_name, is_active
        FROM employee_shifts
        WHERE username = {placeholder}
        ORDER BY day_of_week ASC
    """, (username,)).fetchall()
    
    shifts = []
    for row in rows:
        if isinstance(row, dict):
            shifts.append({
                "id": row["id"],
                "day_of_week": row["day_of_week"],
                "start_time": format_time_value(row["start_time"]),
                "end_time": format_time_value(row["end_time"]),
                "break_start": format_time_value(row["break_start"]),
                "break_end": format_time_value(row["break_end"]),
                "shift_name": row.get("shift_name"),
                "location_name": row.get("location_name"),
                "is_active": bool(row["is_active"])
            })
        else:
            shifts.append({
                "id": row[0],
                "day_of_week": row[1],
                "start_time": format_time_value(row[2]),
                "end_time": format_time_value(row[3]),
                "break_start": format_time_value(row[4]),
                "break_end": format_time_value(row[5]),
                "shift_name": row[6] if len(row) > 6 else None,
                "location_name": row[7] if len(row) > 7 else None,
                "is_active": bool(row[8]) if len(row) > 8 else True
            })
    
    return jsonify({"username": username, "shifts": shifts})


@app.post("/api/admin/employee-shifts/<username>")
@login_required
def api_admin_employee_shifts_save(username: str) -> ResponseReturnValue:
    """Salva i turni settimanali di un utente (sovrascrive tutti)."""
    if not session.get("is_admin"):
        return jsonify({"error": "Forbidden"}), 403
    
    data = request.get_json()
    if not data or "shifts" not in data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    shifts = data["shifts"]  # Array di {day_of_week, start_time, end_time, break_start, break_end, shift_name, location_name, is_active}
    
    db = get_db()
    ensure_employee_shifts_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Elimina turni esistenti per l'utente
    db.execute(f"DELETE FROM employee_shifts WHERE username = {placeholder}", (username,))
    
    # Inserisce i nuovi turni
    for shift in shifts:
        day = shift.get("day_of_week")
        if day is None:
            continue
        
        start_time = shift.get("start_time") or None
        end_time = shift.get("end_time") or None
        break_start = shift.get("break_start") or None
        break_end = shift.get("break_end") or None
        shift_name = shift.get("shift_name") or None
        location_name = shift.get("location_name") or None
        is_active = 1 if shift.get("is_active", True) else 0
        
        # Salta se orari non validi
        if not start_time or not end_time:
            continue
        
        db.execute(f"""
            INSERT INTO employee_shifts (username, day_of_week, start_time, end_time, break_start, break_end, shift_name, location_name, is_active)
            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
        """, (username, day, start_time, end_time, break_start, break_end, shift_name, location_name, is_active))
    
    db.commit()
    
    return jsonify({"success": True, "message": "Turni salvati con successo"})


@app.delete("/api/admin/employee-shifts/<username>")
@login_required
def api_admin_employee_shifts_delete(username: str) -> ResponseReturnValue:
    """Elimina tutti i turni di un utente."""
    if not session.get("is_admin"):
        return jsonify({"error": "Forbidden"}), 403
    
    db = get_db()
    ensure_employee_shifts_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    db.execute(f"DELETE FROM employee_shifts WHERE username = {placeholder}", (username,))
    db.commit()
    
    return jsonify({"success": True, "message": "Turni eliminati"})


@app.post("/api/admin/employee-shifts/bulk")
@login_required
def api_admin_employee_shifts_bulk() -> ResponseReturnValue:
    """Salva gli stessi turni per più utenti contemporaneamente."""
    if not session.get("is_admin"):
        return jsonify({"error": "Forbidden"}), 403
    
    data = request.get_json()
    if not data:
        return jsonify({"error": "Dati mancanti"}), 400
    
    usernames = data.get("usernames", [])
    shifts = data.get("shifts", [])
    
    if not usernames:
        return jsonify({"error": "Nessun utente selezionato"}), 400
    
    if not shifts:
        return jsonify({"error": "Nessun turno configurato"}), 400
    
    db = get_db()
    ensure_employee_shifts_table(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    saved_count = 0
    
    for username in usernames:
        # Elimina turni esistenti per l'utente
        db.execute(f"DELETE FROM employee_shifts WHERE username = {placeholder}", (username,))
        
        # Inserisce i nuovi turni
        for shift in shifts:
            day = shift.get("day_of_week")
            if day is None:
                continue
            
            start_time = shift.get("start_time") or None
            end_time = shift.get("end_time") or None
            break_start = shift.get("break_start") or None
            break_end = shift.get("break_end") or None
            shift_name = shift.get("shift_name") or None
            location_name = shift.get("location_name") or None
            is_active = 1 if shift.get("is_active", True) else 0
            
            # Salta se orari non validi
            if not start_time or not end_time:
                continue
            
            db.execute(f"""
                INSERT INTO employee_shifts (username, day_of_week, start_time, end_time, break_start, break_end, shift_name, location_name, is_active)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            """, (username, day, start_time, end_time, break_start, break_end, shift_name, location_name, is_active))
        
        saved_count += 1
    
    db.commit()
    
    return jsonify({"success": True, "message": f"Turni salvati per {saved_count} utenti"})


# =====================================================
# ADMIN USER REQUESTS - Gestione richieste utenti
# =====================================================

@app.route("/admin/user-requests")
@login_required
def admin_user_requests_page() -> ResponseReturnValue:
    """Pagina admin per gestire le richieste degli utenti."""
    if not session.get("is_admin"):
        return ("Forbidden", 403)
    
    username = session.get("username", "Admin")
    initials = "".join([p[0].upper() for p in username.split()[:2]]) if username else "?"

    # Carica i gruppi direttamente dal DB per renderizzarli server-side
    groups = []
    try:
        db = get_db()
        cur = db.execute("SELECT id, name FROM user_groups ORDER BY name")
        rows = cur.fetchall()
        for row in rows:
            if hasattr(row, 'keys'):
                groups.append({"id": row["id"], "name": row["name"]})
            else:
                groups.append({"id": row[0], "name": row[1]})
        app.logger.info(f"[admin_user_requests_page] Gruppi caricati: {groups}")
    except Exception as e:
        app.logger.error(f"[admin_user_requests_page] Errore caricamento gruppi: {e}")
    
    return render_template(
        "admin_user_requests.html",
        is_admin=True,
        user_name=username,
        user_initials=initials,
        groups=groups
    )


@app.get("/api/admin/user-requests/pending-count")
@login_required
def api_admin_pending_requests_count() -> ResponseReturnValue:
    """Restituisce il conteggio delle richieste in attesa."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_requests_table(db)
    
    row = db.execute("SELECT COUNT(*) as cnt FROM user_requests WHERE status = 'pending'").fetchone()
    count = row["cnt"] if isinstance(row, Mapping) else row[0]
    
    return jsonify({"count": count})


@app.get("/api/admin/user-requests")
@login_required
def api_admin_user_requests_list() -> ResponseReturnValue:
    """Restituisce tutte le richieste degli utenti per l'admin."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    ensure_user_requests_table(db)
    
    if DB_VENDOR == "mysql":
        rows = db.execute("""
                 SELECT ur.id, ur.username, ur.request_type_id, rt.name as type_name, rt.value_type,
                     ur.date_from, ur.date_to, ur.value_amount, ur.notes, ur.status,
                     ur.reviewed_by, ur.reviewed_ts, ur.review_notes, ur.created_ts, ur.updated_ts,
                     ur.cdc, ur.attachment_path, ur.tratte, ur.extra_data,
                     u.group_id AS group_id, ug.name AS group_name
                 FROM user_requests ur
                 JOIN request_types rt ON ur.request_type_id = rt.id
                 LEFT JOIN app_users u ON ur.username = u.username
                 LEFT JOIN user_groups ug ON u.group_id = ug.id
            ORDER BY 
                CASE ur.status WHEN 'pending' THEN 0 ELSE 1 END,
                ur.created_ts DESC
        """).fetchall()
    else:
        rows = db.execute("""
                 SELECT ur.id, ur.username, ur.request_type_id, rt.name as type_name, rt.value_type,
                     ur.date_from, ur.date_to, ur.value_amount, ur.notes, ur.status,
                     ur.reviewed_by, ur.reviewed_ts, ur.review_notes, ur.created_ts, ur.updated_ts,
                     ur.cdc, ur.attachment_path, ur.tratte, ur.extra_data,
                     u.group_id AS group_id, ug.name AS group_name
                 FROM user_requests ur
                 JOIN request_types rt ON ur.request_type_id = rt.id
                 LEFT JOIN app_users u ON ur.username = u.username
                 LEFT JOIN user_groups ug ON u.group_id = ug.id
            ORDER BY 
                CASE ur.status WHEN 'pending' THEN 0 ELSE 1 END,
                ur.created_ts DESC
        """).fetchall()

    requests = []
    for row in rows:
        # Parsing tratte JSON
        tratte_data = None
        if isinstance(row, Mapping):
            tratte_raw = row.get("tratte")
        else:
            tratte_raw = row[17] if len(row) > 17 else None
        
        if tratte_raw:
            try:
                if isinstance(tratte_raw, str):
                    tratte_data = json.loads(tratte_raw)
                else:
                    tratte_data = tratte_raw
            except:
                tratte_data = None
        
        # Parsing extra_data JSON (per straordinari e altri dati)
        extra_data = None
        if isinstance(row, Mapping):
            extra_raw = row.get("extra_data")
        else:
            extra_raw = row[18] if len(row) > 18 else None
        
        if extra_raw:
            try:
                if isinstance(extra_raw, str):
                    extra_data = json.loads(extra_raw)
                else:
                    extra_data = extra_raw
            except:
                extra_data = None
        
        if isinstance(row, Mapping):
            req_item = {
                "id": row["id"],
                "username": row["username"],
                "request_type_id": row["request_type_id"],
                "type_name": row["type_name"],
                "value_type": row["value_type"],
                "date_from": row["date_from"],
                "date_to": row["date_to"],
                "value": float(row["value_amount"]) if row["value_amount"] else None,
                "notes": row["notes"],
                "status": row["status"],
                "reviewed_by": row["reviewed_by"],
                "reviewed_ts": row["reviewed_ts"],
                "review_notes": row["review_notes"],
                "created_ts": row["created_ts"],
                "updated_ts": row["updated_ts"],
                "cdc": row["cdc"],
                "attachment_path": row["attachment_path"],
                "tratte": tratte_data,
                "extra_data": extra_data,
                "group_id": row.get("group_id"),
                "group_name": row.get("group_name"),
            }
        else:
            req_item = {
                "id": row[0],
                "username": row[1],
                "request_type_id": row[2],
                "type_name": row[3],
                "value_type": row[4],
                "date_from": row[5],
                "date_to": row[6],
                "value": float(row[7]) if row[7] else None,
                "notes": row[8],
                "status": row[9],
                "reviewed_by": row[10],
                "reviewed_ts": row[11],
                "review_notes": row[12],
                "created_ts": row[13],
                "updated_ts": row[14],
                "cdc": row[15] if len(row) > 15 else None,
                "attachment_path": row[16] if len(row) > 16 else None,
                "tratte": tratte_data,
                "extra_data": extra_data,
                "group_id": row[19] if len(row) > 19 else None,
                "group_name": row[20] if len(row) > 20 else None,
            }
        
        requests.append(req_item)
    
    # Per le richieste di tipo "timbratura", aggiungi i dati del turno previsto
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    for req in requests:
        if req.get("value_type") == "timbratura":
            req_username = req.get("username")
            date_from = req.get("date_from")
            app.logger.info(f"Cerco turno per {req_username} - date_from={date_from}")
            if req_username and date_from:
                # Converti date_from in data e giorno della settimana
                try:
                    if hasattr(date_from, 'weekday'):
                        check_date = date_from
                    else:
                        check_date = datetime.strptime(str(date_from)[:10], "%Y-%m-%d")
                    day_of_week = check_date.weekday()
                    app.logger.info(f"day_of_week={day_of_week} per data {date_from}")
                    
                    # Cerca il turno da employee_shifts
                    shift_row = db.execute(f"""
                        SELECT start_time, end_time, break_start, break_end, location_name
                        FROM employee_shifts
                        WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                    """, (req_username, day_of_week)).fetchone()
                    
                    app.logger.info(f"shift_row trovato: {shift_row}")
                    if shift_row:
                        if isinstance(shift_row, Mapping):
                            turno_info = {
                                "start_time": str(shift_row['start_time'])[:5] if shift_row.get('start_time') else None,
                                "end_time": str(shift_row['end_time'])[:5] if shift_row.get('end_time') else None,
                                "break_start": str(shift_row['break_start'])[:5] if shift_row.get('break_start') else None,
                                "break_end": str(shift_row['break_end'])[:5] if shift_row.get('break_end') else None,
                                "location_name": shift_row.get('location_name')
                            }
                        else:
                            turno_info = {
                                "start_time": str(shift_row[0])[:5] if shift_row[0] else None,
                                "end_time": str(shift_row[1])[:5] if shift_row[1] else None,
                                "break_start": str(shift_row[2])[:5] if shift_row[2] else None,
                                "break_end": str(shift_row[3])[:5] if shift_row[3] else None,
                                "location_name": shift_row[4] if len(shift_row) > 4 else None
                            }
                        req["turno_previsto"] = turno_info
                except Exception as e:
                    app.logger.warning(f"Errore recupero turno per {req_username}: {e}")

    resp = jsonify({"requests": requests})
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate'
    resp.headers['Pragma'] = 'no-cache'
    return resp


def _process_approved_mancata_timbratura(
    db: DatabaseLike,
    username: str,
    date_from: str,
    extra_data_str: str
) -> dict:
    """
    Processa una richiesta di 'Mancata Timbratura' approvata.
    
    1. Inserisce la timbratura nella tabella 'timbrature'
    2. Se CedolinoWeb è attivo, inserisce in 'cedolino_timbrature' e invia al webservice
    
    Args:
        db: connessione database
        username: username dell'utente
        date_from: data della timbratura (YYYY-MM-DD)
        extra_data_str: JSON con tipo_timbratura, ora_timbratura, motivazione
    
    Returns:
        dict con risultato operazione
    """
    result = {
        "inserted_timbratura": False,
        "cedolino_sent": False,
        "cedolino_error": None
    }
    
    # Parse extra_data
    try:
        extra_data = json.loads(extra_data_str) if extra_data_str else {}
    except:
        extra_data = {}
    
    tipo_timbratura = extra_data.get("tipo_timbratura")  # ingresso/uscita/pausa_in/pausa_out
    ora_timbratura = extra_data.get("ora_timbratura")    # HH:MM
    motivazione = extra_data.get("motivazione", "")
    
    if not tipo_timbratura or not ora_timbratura:
        result["error"] = "Dati timbratura mancanti"
        return result
    
    # Formatta data come stringa YYYY-MM-DD
    if hasattr(date_from, 'strftime'):
        date_str = date_from.strftime("%Y-%m-%d")
    else:
        date_str = str(date_from)[:10]
    
    # Mappa tipo timbratura utente -> tipo interno
    TIPO_MAP = {
        "ingresso": "inizio_giornata",
        "uscita": "fine_giornata",
        "pausa_in": "inizio_pausa",
        "pausa_out": "fine_pausa"
    }
    tipo_interno = TIPO_MAP.get(tipo_timbratura, tipo_timbratura)
    
    # Mappa tipo interno -> timeframe CedolinoWeb
    TIPO_TO_TIMEFRAME = {
        'inizio_giornata': TIMEFRAME_INIZIO_GIORNATA,  # 1
        'inizio_pausa': TIMEFRAME_INIZIO_PAUSA,        # 4
        'fine_pausa': TIMEFRAME_FINE_PAUSA,            # 5
        'fine_giornata': TIMEFRAME_FINE_GIORNATA,      # 8
    }
    timeframe_id = TIPO_TO_TIMEFRAME.get(tipo_interno)
    
    # Formatta ora con secondi
    ora_full = f"{ora_timbratura}:00" if len(ora_timbratura) == 5 else ora_timbratura
    
    now_ts = now_ms()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # ── Calcola ora_mod con le regole di arrotondamento ──
    _appr_rules = get_user_timbratura_rules(db, username)
    _appr_turno_start = None
    if tipo_interno in ('inizio_giornata', 'fine_giornata'):
        try:
            ensure_employee_shifts_table(db)
            _appr_shift = db.execute(
                f"""SELECT start_time, end_time FROM employee_shifts
                   WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                   ORDER BY start_time ASC LIMIT 1""",
                (username, datetime.strptime(date_str, '%Y-%m-%d').weekday())
            ).fetchone()
            if _appr_shift:
                _appr_st = _appr_shift['start_time'] if isinstance(_appr_shift, dict) else _appr_shift[0]
                if _appr_st:
                    if hasattr(_appr_st, 'total_seconds'):
                        _ats = int(_appr_st.total_seconds())
                        _appr_turno_start = f"{_ats // 3600:02d}:{(_ats % 3600) // 60:02d}"
                    else:
                        _appr_turno_start = str(_appr_st)[:5]
        except Exception:
            pass
        if not _appr_turno_start:
            _appr_urow = db.execute(
                f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
                (username,)
            ).fetchone()
            if _appr_urow:
                _appr_cid = (_appr_urow['rentman_crew_id'] if isinstance(_appr_urow, dict) else _appr_urow[0])
                if _appr_cid:
                    _appr_trow = db.execute(
                        f"""SELECT plan_start FROM rentman_plannings
                            WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                            ORDER BY plan_start ASC LIMIT 1""",
                        (_appr_cid, date_str)
                    ).fetchone()
                    if _appr_trow:
                        _appr_ps = _appr_trow['plan_start'] if isinstance(_appr_trow, dict) else _appr_trow[0]
                        if _appr_ps:
                            if hasattr(_appr_ps, 'strftime'):
                                _appr_turno_start = _appr_ps.strftime("%H:%M")
                            else:
                                _appr_ps_str = str(_appr_ps)
                                _appr_turno_start = _appr_ps_str[11:16] if len(_appr_ps_str) > 11 else _appr_ps_str[:5]
    
    ora_mod_calc = calcola_ora_mod(ora_full, tipo_interno, _appr_turno_start, _appr_rules)
    app.logger.info(f"Mancata Timbratura approvata rounding: ora={ora_full}, tipo={tipo_interno}, turno_start={_appr_turno_start}, ora_mod={ora_mod_calc}")
    
    # 1. Inserisci nella tabella 'timbrature' (se non già pre-inserita per gruppo produzione)
    _already_exists = db.execute(
        f"""SELECT id FROM timbrature
            WHERE username = {placeholder} AND data = {placeholder}
              AND tipo = {placeholder} AND method = 'manual_request'
              AND location_name = 'Mancata Timbratura'""",
        (username, date_str, tipo_interno)
    ).fetchone()
    
    if _already_exists:
        # Timbratura già pre-inserita (gruppo produzione) → aggiorna con ora_mod calcolata
        _existing_id = _already_exists['id'] if isinstance(_already_exists, dict) else _already_exists[0]
        db.execute(
            f"UPDATE timbrature SET ora = {placeholder}, ora_mod = {placeholder} WHERE id = {placeholder}",
            (ora_full, ora_mod_calc, _existing_id)
        )
        result["inserted_timbratura"] = True
        result["was_preinserted"] = True
        app.logger.info(f"Mancata Timbratura: timbratura {tipo_interno} già pre-inserita per {username}, aggiornata ora={ora_full} ora_mod={ora_mod_calc}")
    else:
        try:
            db.execute(f"""
                INSERT INTO timbrature (username, tipo, data, ora, ora_mod, created_ts, method, gps_lat, gps_lon, location_name)
                VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
            """, (username, tipo_interno, date_str, ora_full, ora_mod_calc, now_ts, "manual_request", None, None, "Mancata Timbratura"))
            result["inserted_timbratura"] = True
            app.logger.info(f"Mancata Timbratura: inserita timbratura {tipo_interno} per {username} alle {ora_full} (mod: {ora_mod_calc}) del {date_str}")
        except Exception as e:
            app.logger.error(f"Mancata Timbratura: errore inserimento timbrature - {e}")
            result["error"] = f"Errore inserimento timbratura: {e}"
            return result
    
    # 2. Se CedolinoWeb è attivo, invia la timbrata
    settings = get_cedolino_settings()
    if settings and timeframe_id:
        try:
            # Recupera display_name per il log
            user_row = db.execute(
                f"SELECT display_name FROM app_users WHERE username = {placeholder}",
                (username,)
            ).fetchone()
            display_name = username
            if user_row:
                display_name = (user_row['display_name'] if isinstance(user_row, dict) else user_row[0]) or username
            
            # Usa la funzione esistente per inviare a CedolinoWeb (con ora_mod arrotondata)
            success, external_id, error, request_url = send_timbrata_utente(
                db=db,
                username=username,
                member_name=display_name,
                timeframe_id=timeframe_id,
                data_riferimento=date_str,
                ora_originale=ora_full,
                ora_modificata=ora_mod_calc,
                overtime_request_id=None  # Non bloccare, è già approvata
            )
            
            if success:
                result["cedolino_sent"] = True
                result["cedolino_external_id"] = external_id
                app.logger.info(f"Mancata Timbratura: inviata a CedolinoWeb per {username} (external_id={external_id})")
            else:
                result["cedolino_error"] = error
                app.logger.warning(f"Mancata Timbratura: errore CedolinoWeb per {username} - {error}")
        except Exception as e:
            result["cedolino_error"] = str(e)
            app.logger.error(f"Mancata Timbratura: eccezione CedolinoWeb - {e}")
    else:
        result["cedolino_sent"] = None  # CedolinoWeb non configurato
    
    db.commit()
    return result


def _update_timbrature_with_confirmed_times(
    db: DatabaseLike, 
    username: str, 
    date_from: str, 
    rounded_start: str, 
    rounded_end: str,
    extra_data_str: str
) -> None:
    """
    Aggiorna le timbrature con gli orari arrotondati confermati dall'admin.
    Chiamata quando uno straordinario viene approvato con orari modificati.
    Aggiorna sia la tabella 'timbrature' (per la visualizzazione utente)
    che 'cedolino_timbrature' (per l'export al gestionale).
    """
    if not date_from:
        return
    
    # Formatta data_from come stringa YYYY-MM-DD se necessario
    if hasattr(date_from, 'strftime'):
        date_str = date_from.strftime("%Y-%m-%d")
    else:
        date_str = str(date_from)[:10]
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera session_id da extra_data se disponibile
    session_id = None
    if extra_data_str:
        try:
            extra_data = json.loads(extra_data_str) if isinstance(extra_data_str, str) else extra_data_str
            session_id = extra_data.get("session_id")
        except:
            pass
    
    app.logger.info(
        f"Aggiornamento timbrature per {username} del {date_str} con orari confermati: "
        f"inizio={rounded_start}, fine={rounded_end}, session_id={session_id}"
    )
    
    # ===== AGGIORNA TABELLA 'timbrature' (per visualizzazione utente) =====
    # Aggiorna la timbrata di INIZIO giornata
    if rounded_start:
        result = db.execute(f"""
            UPDATE timbrature 
            SET ora_mod = {placeholder}
            WHERE username = {placeholder} 
              AND data = {placeholder}
              AND tipo = 'inizio_giornata'
        """, (rounded_start, username, date_str))
        app.logger.info(f"Aggiornato timbrature.ora_mod inizio_giornata: {rounded_start}")
    
    # Aggiorna la timbrata di FINE giornata
    if rounded_end:
        result = db.execute(f"""
            UPDATE timbrature 
            SET ora_mod = {placeholder}
            WHERE username = {placeholder} 
              AND data = {placeholder}
              AND tipo = 'fine_giornata'
        """, (rounded_end, username, date_str))
        app.logger.info(f"Aggiornato timbrature.ora_mod fine_giornata: {rounded_end}")
    
    # ===== AGGIORNA TABELLA 'cedolino_timbrature' (per export gestionale) =====
    # Aggiorna la timbrata di INIZIO giornata (timeframe_id = 1)
    if rounded_start:
        if session_id:
            db.execute(f"""
                UPDATE cedolino_timbrature 
                SET ora_modificata = {placeholder}, synced_ts = NULL
                WHERE username = {placeholder} 
                  AND data_riferimento = {placeholder}
                  AND timeframe_id = 1
                  AND session_id = {placeholder}
            """, (rounded_start, username, date_str, session_id))
        else:
            db.execute(f"""
                UPDATE cedolino_timbrature 
                SET ora_modificata = {placeholder}, synced_ts = NULL
                WHERE username = {placeholder} 
                  AND data_riferimento = {placeholder}
                  AND timeframe_id = 1
            """, (rounded_start, username, date_str))
    
    # Aggiorna la timbrata di FINE giornata (timeframe_id = 8)
    if rounded_end:
        if session_id:
            db.execute(f"""
                UPDATE cedolino_timbrature 
                SET ora_modificata = {placeholder}, synced_ts = NULL
                WHERE username = {placeholder} 
                  AND data_riferimento = {placeholder}
                  AND timeframe_id = 8
                  AND session_id = {placeholder}
            """, (rounded_end, username, date_str, session_id))
        else:
            db.execute(f"""
                UPDATE cedolino_timbrature 
                SET ora_modificata = {placeholder}, synced_ts = NULL
                WHERE username = {placeholder} 
                  AND data_riferimento = {placeholder}
                  AND timeframe_id = 8
            """, (rounded_end, username, date_str))
    
    db.commit()
    
    app.logger.info(f"Timbrature aggiornate con successo per {username} del {date_str}")


@app.put("/api/admin/user-requests/<int:request_id>")
@login_required
def api_admin_user_request_review(request_id: int) -> ResponseReturnValue:
    """Approva o respinge una richiesta utente."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    data = request.get_json() or {}
    status = data.get("status")
    review_notes = data.get("review_notes", "").strip()
    confirmed_value = data.get("confirmed_value")  # Valore confermato (per straordinari)
    rounded_start = data.get("rounded_start")  # Orario arrotondato inizio confermato
    rounded_end = data.get("rounded_end")  # Orario arrotondato fine confermato
    flex_type = data.get("flex_type")  # Per distinguere "fuori_flessibilita"
    rounded_time = data.get("rounded_time")  # Orario singolo per fuori flessibilità
    
    app.logger.info(
        f"Review request: status={status}, confirmed_value={confirmed_value}, "
        f"rounded_start={rounded_start}, rounded_end={rounded_end}, flex_type={flex_type}, rounded_time={rounded_time}"
    )
    
    if status not in ("approved", "rejected"):
        return jsonify({"error": "Stato non valido. Usa 'approved' o 'rejected'"}), 400
    
    db = get_db()
    ensure_user_requests_table(db)
    
    # Verifica che la richiesta esista e sia pending
    if DB_VENDOR == "mysql":
        existing = db.execute("""
            SELECT ur.id, ur.status, ur.username, rt.name as type_name, rt.value_type,
                   ur.extra_data, ur.date_from
            FROM user_requests ur
            JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.id = %s
        """, (request_id,)).fetchone()
    else:
        existing = db.execute("""
            SELECT ur.id, ur.status, ur.username, rt.name as type_name, rt.value_type,
                   ur.extra_data, ur.date_from
            FROM user_requests ur
            JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.id = ?
        """, (request_id,)).fetchone()
    
    if not existing:
        return jsonify({"error": "Richiesta non trovata"}), 404
    
    if isinstance(existing, Mapping):
        current_status = existing["status"]
        target_username = existing["username"]
        type_name = existing["type_name"]
        value_type = existing.get("value_type")
        extra_data_str = existing.get("extra_data")
        date_from = existing.get("date_from")
    else:
        current_status = existing[1]
        target_username = existing[2]
        type_name = existing[3]
        value_type = existing[4] if len(existing) > 4 else None
        extra_data_str = existing[5] if len(existing) > 5 else None
        date_from = existing[6] if len(existing) > 6 else None
    
    if current_status != "pending":
        return jsonify({"error": "La richiesta è già stata revisionata"}), 400
    
    reviewed_by = session.get("user", "")
    now = int(datetime.now().timestamp() * 1000)
    
    # Estrai orari originali prima di modificarli (per determinare se approvazione parziale)
    original_rounded_start = None
    original_rounded_end = None
    if extra_data_str:
        try:
            orig_extra = json.loads(extra_data_str)
            original_rounded_start = orig_extra.get("rounded_start")
            original_rounded_end = orig_extra.get("rounded_end")
        except:
            pass
    
    # Se ci sono orari arrotondati confermati (modificati dall'admin), aggiorna extra_data
    if value_type == "minutes" and (rounded_start or rounded_end):
        try:
            extra_data = json.loads(extra_data_str) if extra_data_str else {}
            # Salva gli orari originali (calcolati dal sistema) se non già presenti
            if "original_rounded_start" not in extra_data and original_rounded_start:
                extra_data["original_rounded_start"] = original_rounded_start
            if "original_rounded_end" not in extra_data and original_rounded_end:
                extra_data["original_rounded_end"] = original_rounded_end
            # Ora aggiorna con i nuovi valori confermati dall'admin
            if rounded_start:
                extra_data["rounded_start"] = rounded_start
            if rounded_end:
                extra_data["rounded_end"] = rounded_end
            extra_data_str = json.dumps(extra_data)
            
            # Aggiorna extra_data nella richiesta
            placeholder = "%s" if DB_VENDOR == "mysql" else "?"
            db.execute(f"""
                UPDATE user_requests SET extra_data = {placeholder} WHERE id = {placeholder}
            """, (extra_data_str, request_id))
            
            app.logger.info(f"Extra data aggiornato con orari confermati: {extra_data_str}")
        except Exception as e:
            app.logger.warning(f"Errore aggiornamento extra_data: {e}")
    
    # Se è uno straordinario (minutes) e c'è un valore confermato, aggiorna anche value_amount
    if value_type == "minutes" and confirmed_value is not None:
        if DB_VENDOR == "mysql":
            db.execute("""
                UPDATE user_requests 
                SET status = %s, reviewed_by = %s, reviewed_ts = %s, review_notes = %s, 
                    value_amount = %s, updated_ts = %s
                WHERE id = %s
            """, (status, reviewed_by, now, review_notes, confirmed_value, now, request_id))
        else:
            db.execute("""
                UPDATE user_requests 
                SET status = ?, reviewed_by = ?, reviewed_ts = ?, review_notes = ?, 
                    value_amount = ?, updated_ts = ?
                WHERE id = ?
            """, (status, reviewed_by, now, review_notes, confirmed_value, now, request_id))
    else:
        if DB_VENDOR == "mysql":
            db.execute("""
                UPDATE user_requests 
                SET status = %s, reviewed_by = %s, reviewed_ts = %s, review_notes = %s, updated_ts = %s
                WHERE id = %s
            """, (status, reviewed_by, now, review_notes, now, request_id))
        else:
            db.execute("""
                UPDATE user_requests 
                SET status = ?, reviewed_by = ?, reviewed_ts = ?, review_notes = ?, updated_ts = ?
                WHERE id = ?
            """, (status, reviewed_by, now, review_notes, now, request_id))
    
    db.commit()
    
    # Se è uno straordinario approvato e ci sono orari arrotondati confermati, aggiorna le timbrature
    app.logger.info(
        f"Checking overtime update: value_type={value_type}, status={status}, "
        f"rounded_start={rounded_start}, rounded_end={rounded_end}"
    )
    # Determina se è un'approvazione parziale (orari modificati)
    is_partial_approval = False
    if value_type == "minutes" and status == "approved" and (rounded_start or rounded_end):
        _update_timbrature_with_confirmed_times(
            db, target_username, date_from, rounded_start, rounded_end, extra_data_str
        )
        # È parziale se l'admin ha cambiato almeno uno degli orari rispetto agli originali
        if (rounded_start and original_rounded_start and rounded_start != original_rounded_start) or \
           (rounded_end and original_rounded_end and rounded_end != original_rounded_end):
            is_partial_approval = True
            app.logger.info(
                f"Approvazione parziale: originale={original_rounded_start}-{original_rounded_end}, "
                f"confermato={rounded_start}-{rounded_end}"
            )
    
    # Se è richiesta Anticipo/Fuori Flessibilità, gestisci l'aggiornamento della timbratura
    # Compatibile con nome legacy e nuovo nome
    is_fuori_flessibilita = (type_name in ("Fuori Flessibilità", "Richiesta anticipo ingresso"))
    flex_result = None
    if is_fuori_flessibilita:
        try:
            app.logger.info(f"Processing Fuori Flessibilità: request_id={request_id}, status={status}, extra_data={extra_data_str}")
            flex_result = _process_fuori_flessibilita(
                db, request_id, target_username, date_from, status, rounded_time, extra_data_str
            )
            app.logger.info(f"Fuori Flessibilità result: {flex_result}")
        except Exception as e:
            import traceback
            app.logger.error(f"Errore processing Fuori Flessibilità: {e}\n{traceback.format_exc()}")
            flex_result = {"error": str(e)}
    
    # Se è uno straordinario (minutes) o Extra Turno, sincronizza le timbrature bloccate
    # MA escludi Fuori Flessibilità che ha la sua gestione dedicata
    cedolino_debug = None
    is_overtime = (value_type == "minutes" or type_name == "Extra Turno") and not is_fuori_flessibilita
    app.logger.info(f"DEBUG: value_type={value_type}, type_name={type_name}, status={status}, is_overtime={is_overtime}")
    if is_overtime:
        try:
            app.logger.info(f"DEBUG: Calling _sync_overtime_blocked_timbrature for request {request_id}")
            cedolino_debug = _sync_overtime_blocked_timbrature(db, request_id, status, extra_data_str)
            app.logger.info(f"DEBUG: cedolino_debug result = {cedolino_debug}")
        except Exception as e:
            import traceback
            app.logger.error(f"Errore sync overtime: {e}\n{traceback.format_exc()}")
            cedolino_debug = {"error": str(e)}
    
    # Se è una Mancata Timbratura approvata, inserisci la timbratura e invia a CedolinoWeb
    timbratura_result = None
    if value_type == "timbratura" and status == "approved":
        try:
            app.logger.info(f"Processing approved Mancata Timbratura for request {request_id}")
            timbratura_result = _process_approved_mancata_timbratura(
                db, target_username, date_from, extra_data_str
            )
            app.logger.info(f"Mancata Timbratura result: {timbratura_result}")
        except Exception as e:
            import traceback
            app.logger.error(f"Errore processing Mancata Timbratura: {e}\n{traceback.format_exc()}")
            timbratura_result = {"error": str(e)}

    # Se è una Mancata Timbratura RESPINTA, rimuovi la timbratura pre-inserita (gruppo produzione)
    if value_type == "timbratura" and status == "rejected":
        try:
            placeholder_rej = "%s" if DB_VENDOR == "mysql" else "?"
            # Verifica se l'utente appartiene a un gruppo di produzione
            _prod_check = db.execute(
                f"""SELECT g.is_production FROM app_users u
                    JOIN user_groups g ON u.group_id = g.id
                    WHERE u.username = {placeholder_rej}""",
                (target_username,)
            ).fetchone()
            _is_prod = bool(
                (_prod_check['is_production'] if isinstance(_prod_check, dict) else _prod_check[0]) if _prod_check else False
            )
            if _is_prod and extra_data_str:
                _rej_ed = json.loads(extra_data_str) if isinstance(extra_data_str, str) else extra_data_str
                _rej_tipo = _rej_ed.get("tipo_timbratura")
                _TIPO_MAP_REJ = {
                    "ingresso": "inizio_giornata",
                    "uscita": "fine_giornata",
                    "pausa_in": "inizio_pausa",
                    "pausa_out": "fine_pausa"
                }
                _rej_tipo_interno = _TIPO_MAP_REJ.get(_rej_tipo, _rej_tipo)
                _rej_date = str(date_from)[:10] if hasattr(date_from, 'strftime') else str(date_from)[:10]

                deleted = db.execute(
                    f"""DELETE FROM timbrature
                        WHERE username = {placeholder_rej} AND data = {placeholder_rej}
                          AND tipo = {placeholder_rej} AND method = 'manual_request'
                          AND location_name = 'Mancata Timbratura'""",
                    (target_username, _rej_date, _rej_tipo_interno)
                )
                db.commit()
                app.logger.info(
                    f"Mancata Timbratura RESPINTA: rimossa timbratura pre-inserita {_rej_tipo_interno} "
                    f"per {target_username} del {_rej_date} (gruppo produzione)"
                )
                timbratura_result = {"removed_preinserted": True, "tipo": _rej_tipo_interno}
        except Exception as _rej_e:
            app.logger.error(f"Errore rimozione timbratura pre-inserita: {_rej_e}")
            import traceback
            app.logger.error(f"Traceback: {traceback.format_exc()}")

    # Se è richiesta Deroga Pausa Ridotta, ricalcola ora_mod daily in base all'esito admin
    break_reduction_result = None
    try:
        extra_data_obj = json.loads(extra_data_str) if isinstance(extra_data_str, str) else (extra_data_str or {})
        if isinstance(extra_data_obj, dict) and extra_data_obj.get("created_reason") == "break_reduction_short_pause":
            break_reduction_result = _process_break_reduction_review(
                db=db,
                username=target_username,
                date_from=date_from,
                status=status,
                extra_data_str=extra_data_str,
            )
    except Exception as e:
        app.logger.warning(f"Errore post-review Deroga Pausa Ridotta: {e}")
    
    # Invia notifica push all'utente
    _send_request_review_notification(
        db, target_username, type_name, status, review_notes,
        is_partial=is_partial_approval,
        rounded_start=rounded_start if is_partial_approval else None,
        rounded_end=rounded_end if is_partial_approval else None,
        extra_data_str=extra_data_str
    )
    
    status_label = "approvata parzialmente" if is_partial_approval else ("approvata" if status == "approved" else "respinta")
    response = {
        "ok": True, 
        "message": f"Richiesta {status_label} con successo",
        "debug": {
            "value_type": value_type,
            "type_name": type_name,
            "is_overtime": is_overtime,
            "status": status,
            "flex_type": flex_type
        }
    }
    if cedolino_debug:
        response["cedolino_debug"] = cedolino_debug
    if timbratura_result:
        response["timbratura_result"] = timbratura_result
    if flex_result:
        response["flex_result"] = flex_result
    if break_reduction_result:
        response["break_reduction_result"] = break_reduction_result
    return jsonify(response)


@app.delete("/api/admin/user-requests/<int:request_id>")
@login_required
def api_admin_user_request_delete(request_id: int) -> ResponseReturnValue:
    """Elimina una richiesta utente (protetto da password)."""
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    data = request.get_json() or {}
    password = data.get("password", "")
    
    # Password di sicurezza per eliminazione
    DELETE_PASSWORD = "225524"
    
    if password != DELETE_PASSWORD:
        return jsonify({"error": "Password non corretta"}), 403
    
    db = get_db()
    ensure_user_requests_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica che la richiesta esista
    existing = db.execute(
        f"SELECT id, username, status FROM user_requests WHERE id = {placeholder}",
        (request_id,)
    ).fetchone()
    
    if not existing:
        return jsonify({"error": "Richiesta non trovata"}), 404
    
    # Elimina la richiesta
    db.execute(f"DELETE FROM user_requests WHERE id = {placeholder}", (request_id,))
    db.commit()
    
    username = existing["username"] if isinstance(existing, Mapping) else existing[1]
    app.logger.info(f"Richiesta {request_id} eliminata da {session.get('user')} (utente: {username})")
    
    return jsonify({"ok": True, "message": "Richiesta eliminata con successo"})


# =====================================================
# USER REQUESTS - Pagina e API per richieste utente
# =====================================================

@app.route("/user/requests")
@login_required
def user_requests_page() -> ResponseReturnValue:
    """Pagina utente per inviare richieste (ferie, permessi, rimborsi, ecc.)."""
    db = get_db()
    return render_template(
        "user_requests.html",
        username=session.get("user"),
        user_display=session.get("user_display", session.get("user")),
        user_initials=session.get("user_initials", "U"),
        user_role=session.get("user_role", "Utente"),
    )


@app.route("/user/turni")
@login_required
def user_turni_page() -> ResponseReturnValue:
    """Pagina utente per visualizzare i propri turni."""
    db = get_db()
    return render_template(
        "user_turni.html",
        username=session.get("user"),
        user_display=session.get("user_display", session.get("user")),
        user_initials=session.get("user_initials", "U"),
        user_role=session.get("user_role", "Utente"),
    )


@app.route("/user/notifications")
@login_required
def user_notifications_page() -> ResponseReturnValue:
    """Pagina utente per visualizzare lo storico delle notifiche push."""
    db = get_db()
    return render_template(
        "user_notifications.html",
        username=session.get("user"),
        user_display=session.get("user_display", session.get("user")),
        user_initials=session.get("user_initials", "U"),
        user_role=session.get("user_role", "Utente"),
    )


@app.route("/user/storico-timbrature")
@login_required
def user_storico_timbrature_page() -> ResponseReturnValue:
    """Pagina utente per visualizzare lo storico delle timbrature per mese."""
    db = get_db()
    return render_template(
        "user_storico_timbrature.html",
        username=session.get("user"),
        user_display=session.get("user_display", session.get("user")),
        user_initials=session.get("user_initials", "U"),
        user_role=session.get("user_role", "Utente"),
    )


@app.get("/api/user/storico-timbrature")
@login_required
def api_user_storico_timbrature() -> ResponseReturnValue:
    """Restituisce lo storico delle timbrature dell'utente per un mese specifico."""
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    # Parametri: year e month (default: mese corrente)
    year = request.args.get("year", type=int)
    month = request.args.get("month", type=int)
    
    if not year or not month:
        today = datetime.now()
        year = year or today.year
        month = month or today.month
    
    print(f"[storico-timbrature] User: {username}, Year: {year}, Month: {month}")
    
    # Calcola primo e ultimo giorno del mese
    first_day = f"{year:04d}-{month:02d}-01"
    if month == 12:
        last_day = f"{year+1:04d}-01-01"
    else:
        last_day = f"{year:04d}-{month+1:02d}-01"
    
    db = get_db()
    ensure_timbrature_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera tutte le timbrature del mese
    rows = db.execute(f"""
        SELECT id, tipo, data, ora, ora_mod, created_ts, method, location_name
        FROM timbrature
        WHERE username = {placeholder}
          AND data >= {placeholder}
          AND data < {placeholder}
        ORDER BY data ASC, ora ASC
    """, (username, first_day, last_day)).fetchall()
    
    print(f"[storico-timbrature] Trovate {len(rows)} timbrature per {username}")
    
    # Helper per formattare ora in HH:MM
    def format_ora(ora_val):
        if not ora_val:
            return None
        ora_str = str(ora_val)
        # Gestisce formati come "9:30:00" o "09:30:00" o timedelta
        if ':' in ora_str:
            parts = ora_str.split(':')
            if len(parts) >= 2:
                return f"{int(parts[0]):02d}:{int(parts[1]):02d}"
        return ora_str[:5]
    
    # Raggruppa per giorno
    days_data = {}
    for row in rows:
        if isinstance(row, Mapping):
            data = str(row["data"])
            timbratura = {
                "id": row["id"],
                "tipo": row["tipo"],
                "ora": format_ora(row["ora"]),
                "ora_mod": format_ora(row.get("ora_mod")),
                "method": row.get("method"),
                "location": row.get("location_name"),
            }
        else:
            data = str(row[2])
            timbratura = {
                "id": row[0],
                "tipo": row[1],
                "ora": format_ora(row[3]),
                "ora_mod": format_ora(row[4]) if len(row) > 4 else None,
                "method": row[5] if len(row) > 5 else None,
                "location": row[7] if len(row) > 7 else None,
            }
        
        if data not in days_data:
            days_data[data] = []
        days_data[data].append(timbratura)
    
    # Recupera le richieste dell'utente per il mese (solo giustificativi approvati)
    requests_by_date = {}
    
    # Recupera anche le richieste "Anticipo ingresso" (qualunque stato) per mostrare i motivi delle normalizzazioni
    fuori_flex_by_date = {}
    try:
                # Query per richieste Anticipo ingresso/Fuori Flessibilità (tutte, non solo approvate)
        fuori_flex_rows = db.execute(f"""
            SELECT ur.id, ur.date_from, ur.status, ur.notes, ur.review_notes, ur.extra_data,
                   ur.reviewed_by, ur.reviewed_ts
            FROM user_requests ur
            LEFT JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.username = {placeholder}
                            AND (rt.name = 'Fuori Flessibilità' OR rt.name = 'Richiesta anticipo ingresso')
              AND ur.date_from >= {placeholder}
              AND ur.date_from < {placeholder}
            ORDER BY ur.date_from ASC
        """, (username, first_day, last_day)).fetchall()
        
        for req in fuori_flex_rows:
            if isinstance(req, Mapping):
                date_str = str(req["date_from"])[:10]
                extra_data = {}
                if req.get("extra_data"):
                    try:
                        extra_data = json.loads(req["extra_data"]) if isinstance(req["extra_data"], str) else req["extra_data"]
                    except:
                        pass
                fuori_flex_data = {
                    "id": req["id"],
                    "status": req["status"],
                    "notes": req.get("notes"),  # Contiene il motivo originale (es. "Fine Giornata fuori flessibilità: +41 minuti oltre la flessibilità")
                    "review_notes": req.get("review_notes"),  # Note dell'admin quando approva/rifiuta
                    "reviewed_by": req.get("reviewed_by"),
                    "reviewed_ts": req.get("reviewed_ts"),
                    "tipo_timbratura": extra_data.get("tipo_timbratura"),
                    "ora_timbrata": extra_data.get("ora_timbrata"),
                    "ora_finale": extra_data.get("ora_finale"),  # Orario approvato dall'admin
                    "rounded_time": extra_data.get("rounded_time"),
                    "turno_end": extra_data.get("turno_end"),
                    "flessibilita": extra_data.get("flessibilita"),
                    "diff_minuti": extra_data.get("diff_minuti"),
                    "extra_data": extra_data,  # Pass full extra_data for template use
                }
            else:
                date_str = str(req[1])[:10]
                extra_data = {}
                if req[5]:
                    try:
                        extra_data = json.loads(req[5]) if isinstance(req[5], str) else req[5]
                    except:
                        pass
                fuori_flex_data = {
                    "id": req[0],
                    "status": req[2],
                    "notes": req[3],
                    "review_notes": req[4],
                    "reviewed_by": req[6] if len(req) > 6 else None,
                    "reviewed_ts": req[7] if len(req) > 7 else None,
                    "tipo_timbratura": extra_data.get("tipo_timbratura"),
                    "ora_timbrata": extra_data.get("ora_timbrata"),
                    "ora_finale": extra_data.get("ora_finale"),
                    "rounded_time": extra_data.get("rounded_time"),
                    "turno_end": extra_data.get("turno_end"),
                    "flessibilita": extra_data.get("flessibilita"),
                    "diff_minuti": extra_data.get("diff_minuti"),
                    "extra_data": extra_data,  # Pass full extra_data for template use
                }
            
            if date_str not in fuori_flex_by_date:
                fuori_flex_by_date[date_str] = []
            fuori_flex_by_date[date_str].append(fuori_flex_data)
    except Exception as e:
        print(f"[storico-timbrature] Errore recupero richieste fuori flessibilità: {e}")
    
    try:
        requests_rows = db.execute(f"""
            SELECT ur.id, ur.request_type_id, ur.date_from, ur.date_to, ur.value_amount, 
                   ur.notes, ur.status, ur.review_notes, rt.name as type_name, rt.abbreviation,
                   ur.created_ts, ur.reviewed_ts, ur.reviewed_by
            FROM user_requests ur
            LEFT JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.username = {placeholder}
              AND ur.status = 'approved'
              AND rt.is_giustificativo = 1
              AND (
                (ur.date_from >= {placeholder} AND ur.date_from < {placeholder})
                OR (ur.date_to IS NOT NULL AND ur.date_to >= {placeholder} AND ur.date_to < {placeholder})
                OR (ur.date_from < {placeholder} AND (ur.date_to IS NULL OR ur.date_to >= {placeholder}))
              )
            ORDER BY ur.date_from ASC
        """, (username, first_day, last_day, first_day, last_day, first_day, first_day)).fetchall()
        
        # Mappa richieste per data
        for req in requests_rows:
            if isinstance(req, Mapping):
                date_from = str(req["date_from"])
                date_to = str(req["date_to"]) if req.get("date_to") else date_from
                req_data = {
                    "id": req["id"],
                    "type_name": req.get("type_name") or "Richiesta",
                    "abbreviation": req.get("abbreviation"),
                    "value": float(req["value_amount"]) if req["value_amount"] else 0,
                    "status": req["status"],
                    "notes": req.get("notes"),
                    "review_notes": req.get("review_notes"),
                    "created_ts": req.get("created_ts"),
                    "reviewed_ts": req.get("reviewed_ts"),
                    "reviewed_by": req.get("reviewed_by"),
                }
            else:
                date_from = str(req[2])
                date_to = str(req[3]) if req[3] else date_from
                req_data = {
                    "id": req[0],
                    "type_name": req[8] if len(req) > 8 and req[8] else "Richiesta",
                    "abbreviation": req[9] if len(req) > 9 else None,
                    "value": float(req[4]) if req[4] else 0,
                    "status": req[6],
                    "notes": req[5],
                    "review_notes": req[7],
                    "created_ts": req[10] if len(req) > 10 else None,
                    "reviewed_ts": req[11] if len(req) > 11 else None,
                    "reviewed_by": req[12] if len(req) > 12 else None,
                }
            
            # Aggiungi la richiesta a ogni giorno nel range
            try:
                start = datetime.strptime(date_from[:10], "%Y-%m-%d")
                end = datetime.strptime(date_to[:10], "%Y-%m-%d")
                current = start
                while current <= end:
                    date_str = current.strftime("%Y-%m-%d")
                    if date_str not in requests_by_date:
                        requests_by_date[date_str] = []
                    requests_by_date[date_str].append(req_data)
                    current += timedelta(days=1)
            except:
                pass
    except Exception as e:
        # Se la tabella non esiste o c'è un errore, ignora le richieste
        print(f"[storico-timbrature] Errore recupero richieste: {e}")
    
    # Converti in formato per il calendario
    # Recupera le regole di timbratura specifiche dell'utente (considera il gruppo)
    user_rules = get_user_timbratura_rules(db, username)
    rounding_mode = user_rules.get('rounding_mode', 'single')
    
    # Recupera il turno dell'utente da employee_shifts (per mostrare nel riepilogo)
    # Fetch TUTTI i turni della settimana per usare quello corretto per ogni giorno
    user_shift = None
    shifts_by_dow = {}  # day_of_week → shift dict
    try:
        ensure_employee_shifts_table(db)
        all_shift_rows = db.execute(f"""
            SELECT day_of_week, start_time, end_time, break_start, break_end
            FROM employee_shifts
            WHERE username = {placeholder} AND is_active = 1
            ORDER BY day_of_week ASC
        """, (username,)).fetchall()
        
        for sr in all_shift_rows:
            if isinstance(sr, Mapping):
                dow = sr['day_of_week']
                s = {
                    "start": str(sr['start_time'])[:5] if sr['start_time'] else None,
                    "end": str(sr['end_time'])[:5] if sr['end_time'] else None,
                    "break_start": str(sr['break_start'])[:5] if sr['break_start'] else None,
                    "break_end": str(sr['break_end'])[:5] if sr['break_end'] else None,
                }
            else:
                dow = sr[0]
                s = {
                    "start": str(sr[1])[:5] if sr[1] else None,
                    "end": str(sr[2])[:5] if sr[2] else None,
                    "break_start": str(sr[3])[:5] if sr[3] else None,
                    "break_end": str(sr[4])[:5] if sr[4] else None,
                }
            shifts_by_dow[dow] = s
            if user_shift is None:
                user_shift = s  # default: primo turno trovato
    except Exception as e:
        print(f"[storico-timbrature] Errore recupero turno utente: {e}")
    
    # Recupera le richieste Deroga Pausa Ridotta per il mese
    break_reduction_by_date = {}
    try:
        br_rows = db.execute(f"""
            SELECT ur.id, ur.date_from, ur.status, ur.notes, ur.extra_data
            FROM user_requests ur
            JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.username = {placeholder}
              AND rt.name = 'Deroga Pausa Ridotta'
              AND ur.date_from >= {placeholder} AND ur.date_from < {placeholder}
            ORDER BY ur.created_ts DESC
        """, (username, first_day, last_day)).fetchall()
        for br_row in br_rows:
            if isinstance(br_row, Mapping):
                d = str(br_row["date_from"])[:10]
                br_extra = {}
                if br_row.get("extra_data"):
                    try:
                        br_extra = json.loads(br_row["extra_data"]) if isinstance(br_row["extra_data"], str) else br_row["extra_data"]
                    except:
                        pass
                if d not in break_reduction_by_date:
                    break_reduction_by_date[d] = {
                        "id": br_row["id"],
                        "status": br_row["status"],
                        "notes": br_row.get("notes"),
                        "planned_break_minutes": br_extra.get("planned_break_minutes"),
                        "effective_break_minutes": br_extra.get("effective_break_minutes"),
                        "rounded_break_minutes": br_extra.get("rounded_break_minutes"),
                        "break_reduction_minutes": br_extra.get("break_reduction_minutes"),
                    }
            else:
                d = str(br_row[1])[:10]
                br_extra = {}
                if br_row[4]:
                    try:
                        br_extra = json.loads(br_row[4]) if isinstance(br_row[4], str) else br_row[4]
                    except:
                        pass
                if d not in break_reduction_by_date:
                    break_reduction_by_date[d] = {
                        "id": br_row[0],
                        "status": br_row[2],
                        "notes": br_row[3],
                        "planned_break_minutes": br_extra.get("planned_break_minutes"),
                        "effective_break_minutes": br_extra.get("effective_break_minutes"),
                        "rounded_break_minutes": br_extra.get("rounded_break_minutes"),
                        "break_reduction_minutes": br_extra.get("break_reduction_minutes"),
                    }
    except Exception as e:
        print(f"[storico-timbrature] Errore recupero Deroga Pausa Ridotta: {e}")

    # Calcola ore lavorate per ogni giorno
    timbrature_by_day = {}
    debug_calcs = []  # Per debug
    for data in sorted(days_data.keys()):
        timbrature_list = days_data[data]
        
        # Calcola ore lavorate
        ora_inizio = None
        ora_fine = None
        pausa_minuti = 0
        inizio_pausa = None
        
        for t in timbrature_list:
            tipo = t.get("tipo", "")
            ora = t.get("ora_mod") or t.get("ora")
            
            if tipo == "inizio_giornata" and not ora_inizio:
                ora_inizio = ora
            elif tipo == "fine_giornata":
                ora_fine = ora
            elif tipo == "inizio_pausa":
                inizio_pausa = ora
            elif tipo == "fine_pausa" and inizio_pausa:
                try:
                    h1, m1 = map(int, inizio_pausa.split(':')[:2])
                    h2, m2 = map(int, ora.split(':')[:2])
                    pausa_minuti += (h2 * 60 + m2) - (h1 * 60 + m1)
                except Exception as e:
                    print(f"[storico] Errore calcolo pausa: {e} ({inizio_pausa} -> {ora})")
                inizio_pausa = None
        
        # Calcola ore nette
        ore_lavorate = None
        calcolo_dettagli = None  # Dettagli per UI
        if ora_inizio and ora_fine:
            try:
                h1, m1 = map(int, ora_inizio.split(':')[:2])
                h2, m2 = map(int, ora_fine.split(':')[:2])
                total_minutes = (h2 * 60 + m2) - (h1 * 60 + m1) - pausa_minuti
                
                # Se rounding_mode è 'daily', applica arrotondamento giornaliero
                if rounding_mode == 'daily' and total_minutes > 0:
                    # Usa il turno specifico del giorno della settimana (non sempre il lunedì)
                    try:
                        day_of_week = datetime.strptime(data, '%Y-%m-%d').weekday()  # Monday=0
                        day_shift = shifts_by_dow.get(day_of_week) or user_shift
                    except Exception:
                        day_shift = user_shift

                    # Calcola pausa prevista dal turno (da break_start e break_end)
                    pausa_turno_minuti = 60  # Default 1 ora
                    if day_shift and day_shift.get('break_start') and day_shift.get('break_end'):
                        try:
                            bs_h, bs_m = map(int, day_shift['break_start'].split(':')[:2])
                            be_h, be_m = map(int, day_shift['break_end'].split(':')[:2])
                            pausa_turno_minuti = (be_h * 60 + be_m) - (bs_h * 60 + bs_m)
                        except:
                            pass
                    
                    # Se deroga pausa ridotta APPROVATA per questo giorno, usa la pausa effettiva
                    # timbrata (ora_mod già contiene il valore arrotondato salvato al momento della timbrata)
                    br_day = break_reduction_by_date.get(data)
                    if br_day and br_day.get('status') == 'approved' and pausa_minuti > 0:
                        # Deroga approvata: usa la pausa timbrata (ora_mod = già arrotondata)
                        pausa_per_calcolo = pausa_minuti
                    else:
                        # Comportamento standard: usa pausa pianificata se pausa è stata timbrata
                        pausa_per_calcolo = pausa_turno_minuti if pausa_minuti > 0 else 0
                    
                    result = calcola_ore_giornaliere_arrotondate(
                        ora_inizio, ora_fine, pausa_per_calcolo, user_rules
                    )
                    ore_lavorate = result['ore_str']
                    
                    # Salva dettagli per il frontend
                    calcolo_dettagli = {
                        "ore_lorde_minuti": result['ore_lorde'],
                        "ore_nette_minuti": result['ore_nette'],
                        "ore_arrotondate_minuti": result['ore_arrotondate'],
                        "turno_base_minuti": result['turno_base_minuti'],
                        "straordinario_lordo_minuti": result['straordinario_lordo'],
                        "straordinario_arrotondato_minuti": result['straordinario_arrotondato'],
                        "blocco_minuti": result['blocco_minuti'],
                        "blocchi_straordinario": result['blocchi_straordinario'],
                        "tipo_arrotondamento": result['tipo_arrotondamento'],
                        # Aggiungi dati turno per il riepilogo
                        "turno_inizio": day_shift.get('start') if day_shift else None,
                        "turno_fine": day_shift.get('end') if day_shift else None,
                        "pausa_turno_minuti": pausa_turno_minuti,  # Pausa prevista dal turno
                    }
                    debug_calcs.append(f"{data}: {ora_inizio}->{ora_fine} pausa={pausa_minuti} netto={total_minutes}m => arrotondato={ore_lavorate}")
                elif total_minutes > 0:
                    ore_lavorate = f"{total_minutes // 60}:{total_minutes % 60:02d}"
                    debug_calcs.append(f"{data}: {ora_inizio}->{ora_fine} pausa={pausa_minuti} => {ore_lavorate}")
            except Exception as e:
                print(f"[storico] Errore calcolo ore: {e} ({ora_inizio} -> {ora_fine})")
        
        timbrature_by_day[data] = {
            "timbrature": timbrature_list,
            "requests": requests_by_date.get(data, []),
            "fuori_flessibilita": fuori_flex_by_date.get(data, []),  # Richieste fuori flessibilità per mostrare motivi
            "break_reduction": break_reduction_by_date.get(data),  # Deroga Pausa Ridotta per il giorno
            "ora_inizio": ora_inizio,
            "ora_fine": ora_fine,
            "pausa_minuti": pausa_minuti,
            "ore_lavorate": ore_lavorate,
            "calcolo_dettagli": calcolo_dettagli  # Dettagli arrotondamento per UI
        }
    
    # Aggiungi anche le richieste per giorni senza timbrature
    all_requests = []
    for date_str, reqs in requests_by_date.items():
        if date_str not in timbrature_by_day:
            timbrature_by_day[date_str] = {
                "timbrature": [],
                "requests": reqs,
                "ora_inizio": None,
                "ora_fine": None,
                "pausa_minuti": 0,
                "ore_lavorate": None
            }
        for req in reqs:
            req_copy = req.copy()
            req_copy["data"] = date_str
            all_requests.append(req_copy)
    
    # Recupera le richieste Extra Turno (type 4) per il mese, qualsiasi stato
    extra_turno_by_date = {}
    try:
        et_rows = db.execute(f"""
            SELECT ur.id, ur.date_from, ur.status, ur.value_amount, ur.reviewed_by
            FROM user_requests ur
            JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.username = {placeholder}
              AND rt.name = 'Extra Turno'
              AND ur.date_from >= {placeholder} AND ur.date_from < {placeholder}
            ORDER BY ur.id DESC
        """, (username, first_day, last_day)).fetchall()
        for et_row in et_rows:
            if isinstance(et_row, Mapping):
                d = str(et_row["date_from"])[:10]
                if d not in extra_turno_by_date:
                    extra_turno_by_date[d] = {
                        "id": et_row["id"],
                        "status": et_row["status"],
                        "value_amount": float(et_row["value_amount"]) if et_row["value_amount"] else 0,
                        "reviewed_by": et_row.get("reviewed_by"),
                    }
            else:
                d = str(et_row[1])[:10]
                if d not in extra_turno_by_date:
                    extra_turno_by_date[d] = {
                        "id": et_row[0],
                        "status": et_row[2],
                        "value_amount": float(et_row[3]) if et_row[3] else 0,
                        "reviewed_by": et_row[4] if len(et_row) > 4 else None,
                    }
    except Exception as e:
        print(f"[storico-timbrature] Errore recupero Extra Turno requests: {e}")

    # Aggiungi info Extra Turno request a calcolo_dettagli di ogni giorno
    for data_key, day_info in timbrature_by_day.items():
        if day_info.get("calcolo_dettagli") and data_key in extra_turno_by_date:
            et_info = extra_turno_by_date[data_key]
            day_info["calcolo_dettagli"]["extra_turno_request_status"] = et_info["status"]
            day_info["calcolo_dettagli"]["extra_turno_request_id"] = et_info["id"]
            day_info["calcolo_dettagli"]["extra_turno_request_value"] = et_info["value_amount"]

    # Debug: stampa le ore calcolate per i primi 5 giorni
    if debug_calcs:
        print(f"[storico-timbrature] Calcoli ore: {debug_calcs[:5]}...")
    
    arrotondamento_info = {
        "rounding_mode": rounding_mode,
        "source": user_rules.get('source', 'global'),
        "ingresso": {
            "minuti": user_rules.get("arrotondamento_ingresso_minuti", 15),
            "tipo": user_rules.get("arrotondamento_ingresso_tipo", "~")
        },
        "uscita": {
            "minuti": user_rules.get("arrotondamento_uscita_minuti", 15),
            "tipo": user_rules.get("arrotondamento_uscita_tipo", "~")
        }
    }
    
    # Per rounding_mode daily, aggiungi info sulla flessibilità
    if rounding_mode == 'daily':
        arrotondamento_info["flessibilita_ingresso"] = user_rules.get("flessibilita_ingresso_minuti", 30)
        arrotondamento_info["flessibilita_uscita"] = user_rules.get("flessibilita_uscita_minuti", 30)
        arrotondamento_info["arrotondamento_giornaliero"] = {
            "minuti": user_rules.get("arrotondamento_giornaliero_minuti", 15),
            "tipo": user_rules.get("arrotondamento_giornaliero_tipo", "floor")
        }
    
    return jsonify({
        "success": True,
        "year": year,
        "month": month,
        "timbrature_by_day": timbrature_by_day,
        "requests": all_requests,
        "arrotondamento": arrotondamento_info
    })


@app.route("/user/documents")
@login_required
def user_documents_page() -> ResponseReturnValue:
    """Pagina utente per visualizzare i documenti (circolari, comunicazioni, buste paga)."""
    db = get_db()
    return render_template(
        "user_documents.html",
        username=session.get("user"),
        user_display=session.get("user_display", session.get("user")),
        user_initials=session.get("user_initials", "U"),
        user_role=session.get("user_role", "Utente"),
    )


# =====================================================
# USER DOCUMENTS - API per documenti utente
# =====================================================

@app.get("/api/user/documents")
@login_required
def api_user_documents_list() -> ResponseReturnValue:
    """Restituisce i documenti visibili all'utente (circolari, comunicazioni, buste paga)."""
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    ensure_user_documents_table(db)
    
    # Recupera documenti visibili all'utente (solo quelli già inviati: notified_at IS NOT NULL)
    # E che sono destinati all'utente (target_all=1 o username in target_users)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    rows = db.execute(f"""
        SELECT d.id, d.category, d.title, d.description, d.file_path, d.file_name, d.created_at,
               CASE WHEN r.id IS NOT NULL THEN 1 ELSE 0 END as is_read
        FROM user_documents d
        LEFT JOIN user_documents_read r ON d.id = r.document_id AND r.username = {placeholder}
        WHERE d.notified_at IS NOT NULL
          AND (d.target_all = 1 OR (d.target_users IS NOT NULL AND d.target_users LIKE {placeholder}))
        ORDER BY d.created_at DESC
    """, (username, f'%"{username}"%')).fetchall()
    
    documents = []
    for row in rows:
        if isinstance(row, Mapping):
            doc = {
                "id": row["id"],
                "category": row["category"],
                "title": row["title"],
                "description": row["description"],
                "file_url": f"/uploads/documents/{row['file_name']}" if row["file_name"] else None,
                "created_at": row["created_at"],
                "read": bool(row["is_read"])
            }
        else:
            doc = {
                "id": row[0],
                "category": row[1],
                "title": row[2],
                "description": row[3],
                "file_url": f"/uploads/documents/{row[5]}" if row[5] else None,
                "created_at": row[6],
                "read": bool(row[7])
            }
        documents.append(doc)
    
    return jsonify({"documents": documents})


@app.post("/api/user/documents/<int:doc_id>/read")
@login_required
def api_user_document_mark_read(doc_id: int) -> ResponseReturnValue:
    """Marca un documento come letto dall'utente."""
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    ensure_user_documents_table(db)
    
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    try:
        if DB_VENDOR == "mysql":
            db.execute(f"""
                INSERT IGNORE INTO user_documents_read (document_id, username)
                VALUES ({placeholder}, {placeholder})
            """, (doc_id, username))
        else:
            db.execute(f"""
                INSERT OR IGNORE INTO user_documents_read (document_id, username)
                VALUES ({placeholder}, {placeholder})
            """, (doc_id, username))
        db.commit()
        return jsonify({"success": True})
    except Exception as e:
        app.logger.error(f"Errore marcatura documento letto: {e}")
        return jsonify({"error": str(e)}), 500


@app.get("/api/user/request-types")
@login_required
def api_user_request_types_list() -> ResponseReturnValue:
    """Restituisce le tipologie di richiesta attive per l'utente (escluse quelle con ordine 99)."""
    db = get_db()
    ensure_request_types_table(db)
    
    rows = db.execute("""
        SELECT id, name, value_type, description
        FROM request_types
        WHERE active = 1 AND (sort_order IS NULL OR sort_order != 99)
        ORDER BY sort_order ASC, name ASC
    """).fetchall()

    types = []
    for row in rows:
        if isinstance(row, Mapping):
            types.append({
                "id": row["id"],
                "name": row["name"],
                "value_type": row["value_type"],
                "description": row["description"],
            })
        else:
            types.append({
                "id": row[0],
                "name": row[1],
                "value_type": row[2],
                "description": row[3],
            })

    return jsonify({"types": types})


@app.get("/api/user/residuals")
@login_required
def api_user_residuals() -> ResponseReturnValue:
    """Restituisce le ore residue di ferie e permessi per l'utente loggato."""
    # Per ora ritorna valori placeholder - in futuro si potrà integrare con sistema HR
    username = session.get("user", "")
    
    # TODO: Implementare calcolo reale basato su:
    # - Ore totali annuali assegnate
    # - Ore già godute/approvate
    
    return jsonify({
        "ferie_hours": 0,
        "permessi_hours": 0
    })


@app.get("/api/user/requests")
@login_required
def api_user_requests_list() -> ResponseReturnValue:
    """Restituisce lo storico delle richieste dell'utente loggato."""
    username = session.get("user", "")
    
    db = get_db()
    ensure_user_requests_table(db)
    
    if DB_VENDOR == "mysql":
        rows = db.execute("""
            SELECT ur.id, ur.request_type_id, rt.name as type_name, rt.value_type,
                   ur.date_from, ur.date_to, ur.value_amount, ur.notes, ur.status,
                   ur.review_notes, ur.created_ts, ur.updated_ts, ur.cdc, ur.attachment_path, ur.tratte, ur.extra_data,
                   ur.reviewed_by, ur.reviewed_ts
            FROM user_requests ur
            JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.username = %s
            ORDER BY ur.created_ts DESC
        """, (username,)).fetchall()
    else:
        rows = db.execute("""
            SELECT ur.id, ur.request_type_id, rt.name as type_name, rt.value_type,
                   ur.date_from, ur.date_to, ur.value_amount, ur.notes, ur.status,
                   ur.review_notes, ur.created_ts, ur.updated_ts, ur.cdc, ur.attachment_path, ur.tratte, ur.extra_data,
                   ur.reviewed_by, ur.reviewed_ts
            FROM user_requests ur
            JOIN request_types rt ON ur.request_type_id = rt.id
            WHERE ur.username = ?
            ORDER BY ur.created_ts DESC
        """, (username,)).fetchall()

    value_units = {"hours": "ore", "days": "giorni", "amount": "€", "km": "km", "minutes": "minuti"}
    
    requests = []
    for row in rows:
        if isinstance(row, Mapping):
            # Parse tratte JSON
            tratte_raw = row.get("tratte")
            tratte = None
            if tratte_raw:
                try:
                    tratte = json.loads(tratte_raw) if isinstance(tratte_raw, str) else tratte_raw
                except:
                    pass
            
            # Parse extra_data JSON (per straordinari)
            extra_data_raw = row.get("extra_data")
            extra_data = None
            if extra_data_raw:
                try:
                    extra_data = json.loads(extra_data_raw) if isinstance(extra_data_raw, str) else extra_data_raw
                except:
                    pass
            
            req_item = {
                "id": row["id"],
                "request_type_id": row["request_type_id"],
                "type_name": row["type_name"],
                "value_type": row["value_type"],
                "value_unit": value_units.get(row["value_type"], ""),
                "date_start": row["date_from"],
                "date_end": row["date_to"],
                "value": float(row["value_amount"]) if row["value_amount"] else None,
                "notes": row["notes"],
                "status": row["status"],
                "admin_notes": row["review_notes"],
                "created_ts": row["created_ts"],
                "updated_ts": row["updated_ts"],
                "cdc": row["cdc"],
                "attachment_path": row["attachment_path"],
                "tratte": tratte,
                "reviewed_by": row.get("reviewed_by"),
                "reviewed_ts": row.get("reviewed_ts"),
            }
            
            # Aggiungi dettagli straordinario se presenti
            if extra_data:
                req_item["planned_start"] = extra_data.get("planned_start")
                req_item["planned_end"] = extra_data.get("planned_end")
                req_item["actual_start"] = extra_data.get("actual_start")
                req_item["actual_end"] = extra_data.get("actual_end")
                req_item["rounded_start"] = extra_data.get("rounded_start")
                req_item["rounded_end"] = extra_data.get("rounded_end")
                req_item["extra_minutes_before"] = extra_data.get("extra_minutes_before", 0)
                req_item["extra_minutes_after"] = extra_data.get("extra_minutes_after", 0)
                req_item["shift_source"] = extra_data.get("shift_source")
                # Per permessi: orari
                req_item["time_start"] = extra_data.get("time_start")
                req_item["time_end"] = extra_data.get("time_end")
                # Per fuori flessibilità: dettagli
                req_item["tipo_timbratura"] = extra_data.get("tipo_timbratura")
                req_item["ora_timbrata"] = extra_data.get("ora_timbrata")
                req_item["turno_start"] = extra_data.get("turno_start")
                req_item["turno_end"] = extra_data.get("turno_end")
                req_item["diff_minutes"] = extra_data.get("diff_minutes")
                # Per timbratura manuale
                req_item["ora_timbratura"] = extra_data.get("ora_timbratura")
                req_item["motivazione"] = extra_data.get("motivazione")
                # Per giustificazione ritardo
                req_item["late_minutes"] = extra_data.get("late_minutes")
                req_item["ora_mod"] = extra_data.get("ora_mod")
                req_item["flessibilita_ingresso_minuti"] = extra_data.get("flessibilita_ingresso_minuti")
            
            requests.append(req_item)
        else:
            # Parse tratte JSON
            tratte_raw = row[14] if len(row) > 14 else None
            tratte = None
            if tratte_raw:
                try:
                    tratte = json.loads(tratte_raw) if isinstance(tratte_raw, str) else tratte_raw
                except:
                    pass
            
            # Parse extra_data JSON (per straordinari)
            extra_data_raw = row[15] if len(row) > 15 else None
            extra_data = None
            if extra_data_raw:
                try:
                    extra_data = json.loads(extra_data_raw) if isinstance(extra_data_raw, str) else extra_data_raw
                except:
                    pass
            
            req_item = {
                "id": row[0],
                "request_type_id": row[1],
                "type_name": row[2],
                "value_type": row[3],
                "value_unit": value_units.get(row[3], ""),
                "date_start": row[4],
                "date_end": row[5],
                "value": float(row[6]) if row[6] else None,
                "notes": row[7],
                "status": row[8],
                "admin_notes": row[9],
                "created_ts": row[10],
                "updated_ts": row[11],
                "cdc": row[12] if len(row) > 12 else None,
                "attachment_path": row[13] if len(row) > 13 else None,
                "tratte": tratte,
                "reviewed_by": row[16] if len(row) > 16 else None,
                "reviewed_ts": row[17] if len(row) > 17 else None,
            }
            
            # Aggiungi dettagli straordinario se presenti
            if extra_data:
                req_item["planned_start"] = extra_data.get("planned_start")
                req_item["planned_end"] = extra_data.get("planned_end")
                req_item["actual_start"] = extra_data.get("actual_start")
                req_item["actual_end"] = extra_data.get("actual_end")
                req_item["rounded_start"] = extra_data.get("rounded_start")
                req_item["rounded_end"] = extra_data.get("rounded_end")
                req_item["extra_minutes_before"] = extra_data.get("extra_minutes_before", 0)
                req_item["extra_minutes_after"] = extra_data.get("extra_minutes_after", 0)
                req_item["shift_source"] = extra_data.get("shift_source")
                # Per permessi: orari
                req_item["time_start"] = extra_data.get("time_start")
                req_item["time_end"] = extra_data.get("time_end")
                # Per fuori flessibilità: dettagli
                req_item["tipo_timbratura"] = extra_data.get("tipo_timbratura")
                req_item["ora_timbrata"] = extra_data.get("ora_timbrata")
                req_item["turno_start"] = extra_data.get("turno_start")
                req_item["turno_end"] = extra_data.get("turno_end")
                req_item["diff_minutes"] = extra_data.get("diff_minutes")
                # Per timbratura manuale
                req_item["ora_timbratura"] = extra_data.get("ora_timbratura")
                req_item["motivazione"] = extra_data.get("motivazione")
                # Per giustificazione ritardo
                req_item["late_minutes"] = extra_data.get("late_minutes")
                req_item["ora_mod"] = extra_data.get("ora_mod")
                req_item["flessibilita_ingresso_minuti"] = extra_data.get("flessibilita_ingresso_minuti")
            
            requests.append(req_item)

    return jsonify({"requests": requests})


@app.put("/api/user/requests/<int:request_id>/notes")
@login_required
def api_user_request_update_notes(request_id: int) -> ResponseReturnValue:
    """Aggiorna le note di una richiesta utente (solo se pending e di proprietà dell'utente)."""
    username = session.get("user", "")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    data = request.get_json() or {}
    notes = (data.get("notes") or "").strip()
    
    db = get_db()
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica che la richiesta esista, sia dell'utente e sia pending
    row = db.execute(
        f"SELECT id, username, status FROM user_requests WHERE id = {placeholder}",
        (request_id,)
    ).fetchone()
    
    if not row:
        return jsonify({"error": "Richiesta non trovata"}), 404
    
    req_username = row['username'] if isinstance(row, dict) else row[1]
    req_status = row['status'] if isinstance(row, dict) else row[2]
    
    if req_username != username:
        return jsonify({"error": "Non autorizzato"}), 403
    
    if req_status != 'pending':
        return jsonify({"error": "Impossibile modificare una richiesta già processata"}), 400
    
    # Aggiorna le note
    db.execute(
        f"UPDATE user_requests SET notes = {placeholder}, updated_ts = {placeholder} WHERE id = {placeholder}",
        (notes, now_ms(), request_id)
    )
    db.commit()
    
    return jsonify({"ok": True, "message": "Note aggiornate"})


@app.post("/api/user/requests")
@login_required
def api_user_requests_create() -> ResponseReturnValue:
    """Crea una nuova richiesta utente. Supporta JSON o multipart/form-data per upload file."""
    username = session.get("user", "")
    
    # Determina se è multipart/form-data o JSON
    content_type = request.content_type or ""
    
    if 'multipart/form-data' in content_type:
        # Form con allegati (supporta multipli)
        request_type_id = request.form.get("request_type_id")
        date_start = request.form.get("date_start") or request.form.get("start_date")
        date_end = request.form.get("date_end") or request.form.get("end_date")
        value = request.form.get("value")
        notes = (request.form.get("notes") or "").strip()
        cdc = (request.form.get("cdc") or "").strip() or None
        tratte = None  # Non supportato via form per ora
        extra_data_json = request.form.get("extra_data")  # Supporto extra_data via form
        # Supporta sia 'attachment' singolo che 'attachments' multipli
        attachment_files = request.files.getlist("attachments") or []
        single_attachment = request.files.get("attachment")
        if single_attachment and single_attachment.filename:
            attachment_files.append(single_attachment)
    else:
        # JSON (senza allegato) - force=True per evitare errore 415
        data = request.get_json(force=True, silent=True) or {}
        request_type_id = data.get("request_type_id")
        date_start = data.get("date_start") or data.get("start_date")
        date_end = data.get("date_end") or data.get("end_date")
        value = data.get("value")
        notes = (data.get("notes") or "").strip()
        cdc = (data.get("cdc") or "").strip() or None
        tratte = data.get("tratte")  # Array di {da, a, km}
        extra_data_json = data.get("extra_data")  # JSON per dati aggiuntivi (es. orari permessi)
        attachment_files = []

    if not request_type_id or not date_start:
        return jsonify({"error": "Tipo richiesta e data inizio sono obbligatori"}), 400

    db = get_db()
    ensure_user_requests_table(db)
    
    # Verifica che il tipo richiesta esista e sia attivo
    if DB_VENDOR == "mysql":
        rt = db.execute("SELECT id, value_type FROM request_types WHERE id = %s AND active = 1", (request_type_id,)).fetchone()
    else:
        rt = db.execute("SELECT id, value_type FROM request_types WHERE id = ? AND active = 1", (request_type_id,)).fetchone()
    
    if not rt:
        return jsonify({"error": "Tipologia richiesta non valida o non attiva"}), 400

    value_type = rt["value_type"] if isinstance(rt, dict) else rt[1]
    
    # Validazioni specifiche per value_type
    if value_type == "amount":
        if not cdc:
            return jsonify({"error": "Centro di costo (CDC) è obbligatorio per i rimborsi"}), 400
        if not attachment_files or len(attachment_files) == 0:
            return jsonify({"error": "Almeno un allegato (foto ricevuta) è obbligatorio per i rimborsi"}), 400
    
    # Validazioni specifiche per km
    if value_type == "km":
        if not cdc:
            return jsonify({"error": "Centro di costo (CDC) è obbligatorio per i rimborsi km"}), 400
        if tratte and len(tratte) > 0:
            # Valida le tratte
            total_km = 0
            for t in tratte:
                if not t.get("da") or not t.get("a"):
                    return jsonify({"error": "Ogni tratta deve avere origine e destinazione"}), 400
                km = t.get("km", 0)
                if km <= 0:
                    return jsonify({"error": "Ogni tratta deve avere km > 0"}), 400
                total_km += km
            # Sovrascrivi value con il totale calcolato dalle tratte
            value = total_km

    # Gestione upload file multipli
    attachment_paths = []
    allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'webp', 'pdf'}
    
    for idx, attachment_file in enumerate(attachment_files):
        if attachment_file and attachment_file.filename:
            ext = attachment_file.filename.rsplit('.', 1)[-1].lower() if '.' in attachment_file.filename else ''
            if ext not in allowed_extensions:
                return jsonify({"error": f"Formato file non supportato: {attachment_file.filename}. Usa: {', '.join(allowed_extensions)}"}), 400
            
            # Crea directory se non esiste
            upload_dir = os.path.join(app.root_path, 'uploads', 'requests', username)
            os.makedirs(upload_dir, exist_ok=True)
            
            # Nome file univoco (con indice per multipli)
            timestamp = int(time.time() * 1000)  # millisecondi per unicità
            filename = f"request_{timestamp}_{idx}.{ext}"
            filepath = os.path.join(upload_dir, filename)
            attachment_file.save(filepath)
            attachment_paths.append(f"/uploads/requests/{username}/{filename}")
    
    # Salva come JSON array se ci sono più file, altrimenti stringa singola per retrocompatibilità
    if len(attachment_paths) == 0:
        attachment_path = None
    elif len(attachment_paths) == 1:
        attachment_path = attachment_paths[0]
    else:
        attachment_path = json.dumps(attachment_paths)

    now = int(datetime.now().timestamp() * 1000)  # timestamp in millisecondi
    value_amount = float(value) if value else 0.0
    tratte_json = json.dumps(tratte) if tratte else None
    
    # extra_data_json può essere valorizzato dal frontend (es. per permessi con orari)
    # Se non viene passato, rimane None

    # ═══════════════════════════════════════════════════════════════════════════
    # CONTROLLO DUPLICATI: blocca richieste dello stesso tipo con date sovrapposte
    # Considera solo richieste non rifiutate (pending o approved).
    # ═══════════════════════════════════════════════════════════════════════════
    _dup_end = date_end or date_start  # se date_end è None, la richiesta è per un solo giorno
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    existing_dup = db.execute(
        f"""SELECT id, date_from, date_to, status FROM user_requests
            WHERE username = {placeholder}
              AND request_type_id = {placeholder}
              AND status != 'rejected'
              AND date_from <= {placeholder}
              AND COALESCE(date_to, date_from) >= {placeholder}
        """,
        (username, request_type_id, _dup_end, date_start)
    ).fetchone()
    if existing_dup:
        _dup_status = existing_dup['status'] if isinstance(existing_dup, dict) else existing_dup[3]
        _status_label = "in attesa di approvazione" if _dup_status == "pending" else "già approvata"
        return jsonify({"error": f"Esiste già una richiesta dello stesso tipo per le date selezionate ({_status_label}). Controlla lo storico."}), 409

    if DB_VENDOR == "mysql":
        db.execute("""
            INSERT INTO user_requests (user_id, username, request_type_id, date_from, date_to, value_amount, notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 'pending', %s, %s)
        """, (0, username, request_type_id, date_start, date_end, value_amount, notes, cdc, attachment_path, tratte_json, extra_data_json, now, now))
    else:
        db.execute("""
            INSERT INTO user_requests (user_id, username, request_type_id, date_from, date_to, value_amount, notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'pending', ?, ?)
        """, (0, username, request_type_id, date_start, date_end, value_amount, notes, cdc, attachment_path, tratte_json, extra_data_json, now, now))
    
    db.commit()

    # ═══════════════════════════════════════════════════════════════════════════
    # MANCATA TIMBRATURA + GRUPPO PRODUZIONE: sblocco immediato del timeframe
    # Per operatori del gruppo produzione, quando si invia una richiesta di
    # mancata timbratura, si inserisce subito la timbratura (senza attendere
    # l'approvazione admin) in modo da sbloccare il timeframe e gestire
    # l'attività come se l'utente avesse effettivamente timbrato.
    # La sync a CedolinoWeb avverrà solo all'approvazione admin.
    # Se l'admin rifiuta, la timbratura verrà rimossa.
    # ═══════════════════════════════════════════════════════════════════════════
    production_preinserted = False
    production_activity_data = None
    _tipo_interno = None
    if value_type == "timbratura":
        try:
            placeholder = "%s" if DB_VENDOR == "mysql" else "?"
            # Verifica se l'utente appartiene a un gruppo di produzione
            _prod_row = db.execute(
                f"""SELECT g.is_production FROM app_users u
                    JOIN user_groups g ON u.group_id = g.id
                    WHERE u.username = {placeholder}""",
                (username,)
            ).fetchone()
            _is_production = bool(
                (_prod_row['is_production'] if isinstance(_prod_row, dict) else _prod_row[0]) if _prod_row else False
            )

            if _is_production and extra_data_json:
                # Parse extra_data per estrarre tipo e ora
                _ed = json.loads(extra_data_json) if isinstance(extra_data_json, str) else extra_data_json
                _tipo_timb = _ed.get("tipo_timbratura")   # ingresso/uscita/pausa_in/pausa_out
                _ora_timb = _ed.get("ora_timbratura")      # HH:MM

                if _tipo_timb and _ora_timb:
                    _TIPO_MAP = {
                        "ingresso": "inizio_giornata",
                        "uscita": "fine_giornata",
                        "pausa_in": "inizio_pausa",
                        "pausa_out": "fine_pausa"
                    }
                    _tipo_interno = _TIPO_MAP.get(_tipo_timb, _tipo_timb)
                    _ora_full = f"{_ora_timb}:00" if len(_ora_timb) == 5 else _ora_timb
                    _date_str = str(date_start)[:10]

                    # ── Calcola ora_mod con le stesse regole della timbratura normale ──
                    _mt_rules = get_user_timbratura_rules(db, username)
                    _mt_turno_start = None
                    _mt_turno_end = None
                    if _tipo_interno in ('inizio_giornata', 'fine_giornata'):
                        # Cerca turno in employee_shifts
                        try:
                            ensure_employee_shifts_table(db)
                            _mt_shift = db.execute(
                                f"""SELECT start_time, end_time FROM employee_shifts
                                   WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
                                   ORDER BY start_time ASC LIMIT 1""",
                                (username, datetime.strptime(_date_str, '%Y-%m-%d').weekday())
                            ).fetchone()
                            if _mt_shift:
                                _st = _mt_shift['start_time'] if isinstance(_mt_shift, dict) else _mt_shift[0]
                                _et = _mt_shift['end_time'] if isinstance(_mt_shift, dict) else _mt_shift[1]
                                if _st:
                                    if hasattr(_st, 'total_seconds'):
                                        _ts = int(_st.total_seconds())
                                        _mt_turno_start = f"{_ts // 3600:02d}:{(_ts % 3600) // 60:02d}"
                                    else:
                                        _mt_turno_start = str(_st)[:5]
                                if _et:
                                    if hasattr(_et, 'total_seconds'):
                                        _ts2 = int(_et.total_seconds())
                                        _mt_turno_end = f"{_ts2 // 3600:02d}:{(_ts2 % 3600) // 60:02d}"
                                    else:
                                        _mt_turno_end = str(_et)[:5]
                        except Exception:
                            pass
                        # Se non trovato, cerca in rentman_plannings
                        if not _mt_turno_start:
                            _mt_urow = db.execute(
                                f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
                                (username,)
                            ).fetchone()
                            if _mt_urow:
                                _mt_cid = (_mt_urow['rentman_crew_id'] if isinstance(_mt_urow, dict) else _mt_urow[0])
                                if _mt_cid:
                                    _mt_trow = db.execute(
                                        f"""SELECT
                                               (SELECT plan_start FROM rentman_plannings
                                                WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                                                ORDER BY plan_start ASC LIMIT 1) as first_start,
                                               (SELECT plan_end FROM rentman_plannings
                                                WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                                                ORDER BY plan_end DESC LIMIT 1) as last_end
                                        """, (_mt_cid, _date_str, _mt_cid, _date_str)
                                    ).fetchone()
                                    if _mt_trow:
                                        _ps = _mt_trow['first_start'] if isinstance(_mt_trow, dict) else _mt_trow[0]
                                        _pe = _mt_trow['last_end'] if isinstance(_mt_trow, dict) else _mt_trow[1]
                                        if _ps and not _mt_turno_start:
                                            if hasattr(_ps, 'strftime'):
                                                _mt_turno_start = _ps.strftime("%H:%M")
                                            else:
                                                _ps_str = str(_ps)
                                                _mt_turno_start = _ps_str[11:16] if len(_ps_str) > 11 else _ps_str[:5]
                                        if _pe and not _mt_turno_end:
                                            if hasattr(_pe, 'strftime'):
                                                _mt_turno_end = _pe.strftime("%H:%M")
                                            else:
                                                _pe_str = str(_pe)
                                                _mt_turno_end = _pe_str[11:16] if len(_pe_str) > 11 else _pe_str[:5]

                    _ora_mod_calc = calcola_ora_mod(_ora_full, _tipo_interno, _mt_turno_start, _mt_rules)
                    app.logger.info(
                        f"Mancata Timbratura PRODUZIONE rounding: ora={_ora_full}, tipo={_tipo_interno}, "
                        f"turno_start={_mt_turno_start}, ora_mod={_ora_mod_calc}")

                    # Verifica che non esista già la stessa timbratura
                    _existing = db.execute(
                        f"""SELECT id FROM timbrature
                            WHERE username = {placeholder} AND data = {placeholder}
                              AND tipo = {placeholder}""",
                        (username, _date_str, _tipo_interno)
                    ).fetchone()

                    if not _existing:
                        db.execute(f"""
                            INSERT INTO timbrature (username, tipo, data, ora, ora_mod, created_ts, method, gps_lat, gps_lon, location_name)
                            VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})
                        """, (username, _tipo_interno, _date_str, _ora_full, _ora_mod_calc, now, "manual_request", None, None, "Mancata Timbratura"))
                        db.commit()
                        production_preinserted = True
                        app.logger.info(
                            f"Mancata Timbratura PRODUZIONE: pre-inserita timbratura {_tipo_interno} per {username} "
                            f"alle {_ora_full} (mod: {_ora_mod_calc}) del {_date_str} (in attesa di approvazione admin)"
                        )
                    else:
                        # La timbratura esiste già → consideriamo comunque come pre-inserita
                        production_preinserted = True
                        app.logger.info(
                            f"Mancata Timbratura PRODUZIONE: timbratura {_tipo_interno} già presente per {username} del {_date_str}, skip insert"
                        )

                    # ── Calcola timestamp basato su ora_mod per l'attività produzione ──
                    try:
                        _om_parts = _ora_mod_calc.split(':')
                        _om_dt = datetime.strptime(_date_str, '%Y-%m-%d').replace(
                            hour=int(_om_parts[0]), minute=int(_om_parts[1]), second=0)
                        _timbratura_ts_mod = int(_om_dt.timestamp() * 1000)
                    except Exception:
                        _timbratura_ts_mod = now

                    # ── Genera dati production_activity per il frontend (stessa logica di api_timbratura_registra) ──
                    if production_preinserted and _tipo_interno == 'inizio_giornata':
                        try:
                            _user_info = db.execute(
                                f"SELECT group_id, rentman_crew_id FROM app_users WHERE username = {placeholder}",
                                (username,)
                            ).fetchone()
                            _user_crew_id = (_user_info['rentman_crew_id'] if isinstance(_user_info, dict) else _user_info[1]) if _user_info else None

                            _prod_activity = None
                            if _user_crew_id:
                                _turni = db.execute(
                                    f"""SELECT project_code, project_name, function_name, is_leader, gestione_squadra
                                        FROM rentman_plannings
                                        WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                                          AND sent_to_webservice = 1 AND (is_obsolete = 0 OR is_obsolete IS NULL)
                                        ORDER BY plan_start ASC""",
                                    (_user_crew_id, _date_str)
                                ).fetchall()

                                _turno_popup = None
                                for _t in _turni:
                                    _t_leader = bool(_t['is_leader'] if isinstance(_t, dict) else _t[3])
                                    _t_gest = bool(_t['gestione_squadra'] if isinstance(_t, dict) else _t[4])
                                    if _t_leader or _t_gest:
                                        continue
                                    _turno_popup = _t
                                    break

                                if _turno_popup:
                                    _p_code = _turno_popup['project_code'] if isinstance(_turno_popup, dict) else _turno_popup[0]
                                    _p_name = _turno_popup['project_name'] if isinstance(_turno_popup, dict) else _turno_popup[1]
                                    _p_func = _turno_popup['function_name'] if isinstance(_turno_popup, dict) else _turno_popup[2]
                                    if _p_func:
                                        _prod_activity = {
                                            "detected": True,
                                            "project_code": _p_code,
                                            "project_name": _p_name,
                                            "activity_label": _p_func,
                                            "action": "start",
                                            "timbratura_ts": _timbratura_ts_mod
                                        }
                                    else:
                                        _prod_activity = {
                                            "detected": True, "project_code": "", "project_name": "",
                                            "activity_label": "", "action": "start",
                                            "manual_selection": True, "requires_project_selection": True,
                                            "requires_activity_selection": True, "timbratura_ts": _timbratura_ts_mod
                                        }
                                else:
                                    _prod_activity = {
                                        "detected": True, "project_code": "", "project_name": "",
                                        "activity_label": "", "action": "start",
                                        "manual_selection": True, "requires_project_selection": True,
                                        "requires_activity_selection": True, "timbratura_ts": _timbratura_ts_mod
                                    }
                            else:
                                _prod_activity = {
                                    "detected": True, "project_code": "", "project_name": "",
                                    "activity_label": "", "action": "start",
                                    "manual_selection": True, "requires_project_selection": True,
                                    "requires_activity_selection": True, "timbratura_ts": _timbratura_ts_mod
                                }

                            if _prod_activity:
                                production_activity_data = _prod_activity
                        except Exception as _pa_e:
                            app.logger.warning(f"Errore generazione production_activity per mancata timbratura: {_pa_e}")

                    # ── Per pausa/resume/stop: gestisci timer produzione ──
                    if production_preinserted and _tipo_interno in ('inizio_pausa', 'fine_pausa', 'fine_giornata'):
                        try:
                            _user_info2 = db.execute(
                                f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
                                (username,)
                            ).fetchone()
                            _crew2 = (_user_info2['rentman_crew_id'] if isinstance(_user_info2, dict) else _user_info2[0]) if _user_info2 else None
                            _proj_code = None
                            if _crew2:
                                _t2 = db.execute(
                                    f"""SELECT project_code FROM rentman_plannings
                                        WHERE crew_id = {placeholder} AND planning_date = {placeholder}
                                          AND sent_to_webservice = 1 AND (is_obsolete = 0 OR is_obsolete IS NULL)
                                        ORDER BY plan_start ASC LIMIT 1""",
                                    (_crew2, _date_str)
                                ).fetchone()
                                if _t2:
                                    _proj_code = _t2['project_code'] if isinstance(_t2, dict) else _t2[0]

                            if _tipo_interno == 'inizio_pausa':
                                _pause_production_timer(db, username, _proj_code)
                            elif _tipo_interno == 'fine_pausa':
                                _resume_production_timer(db, username, _proj_code)
                            elif _tipo_interno == 'fine_giornata':
                                _stop_production_timer(db, username, _proj_code)
                        except Exception as _timer_e:
                            app.logger.warning(f"Errore gestione timer produzione per mancata timbratura: {_timer_e}")

        except Exception as _prod_e:
            app.logger.error(f"Errore pre-inserimento mancata timbratura produzione: {_prod_e}")
            import traceback
            app.logger.error(f"Traceback: {traceback.format_exc()}")

    resp = {"ok": True, "message": "Richiesta inviata con successo"}
    if production_preinserted:
        resp["production_preinserted"] = True
        resp["production_tipo"] = _tipo_interno
        resp["message"] = "Richiesta inviata. Timbratura registrata immediatamente (in attesa di conferma admin)."
        if production_activity_data:
            resp["production_activity"] = production_activity_data
    return jsonify(resp)


# Route per servire gli allegati delle richieste
@app.route('/uploads/requests/<path:filename>')
@login_required
def serve_request_attachment(filename):
    """Serve gli allegati delle richieste (solo per l'utente proprietario o admin)."""
    # Verifica accesso: l'utente può vedere solo i propri file, admin può vedere tutti
    username = session.get("user", "")
    is_admin = session.get("is_admin", False)
    
    # Estrai username dal path
    parts = filename.split('/')
    if len(parts) >= 1:
        file_owner = parts[0]
        if not is_admin and file_owner != username:
            return jsonify({"error": "Accesso negato"}), 403
    
    return send_from_directory(
        os.path.join(app.root_path, 'uploads', 'requests'),
        filename
    )


@app.route("/uploads/documents/<path:filename>")
@login_required
def serve_document_file(filename):
    """Serve i file dei documenti aziendali."""
    return send_from_directory(
        os.path.join(app.root_path, 'uploads', 'documents'),
        filename
    )


# ═══════════════════════════════════════════════════════════════════════════════
# OVERTIME (STRAORDINARI) - API
# ═══════════════════════════════════════════════════════════════════════════════

@app.route("/admin/overtime")
@login_required
def admin_overtime_page() -> ResponseReturnValue:
    """Pagina admin per gestire le richieste di straordinario."""
    if not session.get("is_admin"):
        return redirect(url_for("home"))
    
    # Verifica se il modulo straordinari è attivo
    db = get_db()
    if not is_module_enabled(db, "straordinari"):
        flash("Modulo straordinari non attivo", "warning")
        return redirect(url_for("admin_home"))
    
    username = session.get("user", "")
    initials = "".join([p[0].upper() for p in username.split()[:2]]) if username else "A"
    
    return render_template(
        "admin_overtime.html",
        user_name=username,
        user_initials=initials
    )


@app.route("/user/overtime")
@login_required
def user_overtime_page() -> ResponseReturnValue:
    """Pagina utente per visualizzare i propri straordinari."""
    # Verifica se il modulo straordinari è attivo
    db = get_db()
    if not is_module_enabled(db, "straordinari"):
        flash("Modulo straordinari non attivo", "warning")
        return redirect(url_for("user_home"))
    
    return render_template(
        "user_overtime.html",
        username=session.get("user"),
        user_display=session.get("user_display", session.get("user")),
        user_initials=session.get("user_initials", "U"),
        user_role=session.get("user_role", "Utente"),
    )


@app.get("/api/admin/overtime")
@login_required
def api_admin_overtime_list() -> ResponseReturnValue:
    """
    Restituisce tutte le richieste di straordinario per l'admin.
    Legge dalla tabella user_requests filtrando per tipo 'Straordinario'.
    """
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    db = get_db()
    
    # Verifica se il modulo straordinari è attivo
    if not is_module_enabled(db, "straordinari"):
        return jsonify({"error": "Modulo straordinari non attivo", "overtime": []}), 200
    
    ensure_user_requests_table(db)
    
    # Ottieni l'ID del tipo "Straordinario"
    overtime_type_id = get_overtime_request_type_id(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    status_filter = request.args.get("status")
    username_filter = request.args.get("username")
    date_from = request.args.get("date_from")
    date_to = request.args.get("date_to")
    
    query = f"""
        SELECT ur.id, ur.username, ur.date_from as date, ur.value_amount as total_extra_minutes,
               ur.notes, ur.extra_data, ur.status, ur.reviewed_by, ur.reviewed_ts, ur.review_notes,
               ur.created_ts, ur.updated_ts,
               au.display_name, au.full_name
        FROM user_requests ur
        LEFT JOIN app_users au ON ur.username = au.username
        WHERE ur.request_type_id = {placeholder}
    """
    params = [overtime_type_id]
    
    if status_filter:
        query += f" AND ur.status = {placeholder}"
        params.append(status_filter)
    if username_filter:
        query += f" AND ur.username = {placeholder}"
        params.append(username_filter)
    if date_from:
        query += f" AND ur.date_from >= {placeholder}"
        params.append(date_from)
    if date_to:
        query += f" AND ur.date_from <= {placeholder}"
        params.append(date_to)
    
    query += " ORDER BY CASE ur.status WHEN 'pending' THEN 0 ELSE 1 END, ur.created_ts DESC"
    
    rows = db.execute(query, tuple(params)).fetchall()
    
    overtime_list = []
    for row in rows:
        if isinstance(row, Mapping):
            item = dict(row)
        else:
            columns = ['id', 'username', 'date', 'total_extra_minutes', 'notes', 'extra_data',
                      'status', 'reviewed_by', 'reviewed_ts', 'review_notes', 'created_ts', 'updated_ts',
                      'display_name', 'full_name']
            item = dict(zip(columns, row))
        
        # Parse extra_data per estrarre i dettagli dello straordinario
        extra_data = item.get('extra_data')
        if extra_data:
            try:
                if isinstance(extra_data, str):
                    extra_data = json.loads(extra_data)
                item.update({
                    'session_id': extra_data.get('session_id'),
                    'planning_id': extra_data.get('planning_id'),
                    'shift_source': extra_data.get('shift_source', 'none'),
                    'planned_start': extra_data.get('planned_start'),
                    'planned_end': extra_data.get('planned_end'),
                    'actual_start': extra_data.get('actual_start'),
                    'actual_end': extra_data.get('actual_end'),
                    'extra_minutes_before': extra_data.get('extra_minutes_before', 0),
                    'extra_minutes_after': extra_data.get('extra_minutes_after', 0),
                    'overtime_type': extra_data.get('overtime_type', 'after_shift'),
                    'auto_detected': extra_data.get('auto_detected', False)
                })
            except (json.JSONDecodeError, TypeError):
                pass
        
        # Rimuovi extra_data raw dalla risposta
        item.pop('extra_data', None)
        
        # Converti total_extra_minutes in intero
        item['total_extra_minutes'] = int(item.get('total_extra_minutes', 0))
        
        overtime_list.append(item)
    
    return jsonify({"overtime": overtime_list})


@app.get("/api/user/overtime")
@login_required
def api_user_overtime_list() -> ResponseReturnValue:
    """
    Restituisce gli straordinari dell'utente corrente.
    Legge dalla tabella user_requests filtrando per tipo 'Straordinario'.
    """
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    
    # Verifica se il modulo straordinari è attivo
    if not is_module_enabled(db, "straordinari"):
        return jsonify({"error": "Modulo straordinari non attivo", "overtime": []}), 200
    
    ensure_user_requests_table(db)
    
    # Ottieni l'ID del tipo "Straordinario"
    overtime_type_id = get_overtime_request_type_id(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    rows = db.execute(f"""
        SELECT ur.id, ur.username, ur.date_from as date, ur.value_amount as total_extra_minutes,
               ur.notes, ur.extra_data, ur.status, ur.reviewed_by, ur.reviewed_ts, ur.review_notes,
               ur.created_ts, ur.updated_ts
        FROM user_requests ur
        WHERE ur.username = {placeholder} AND ur.request_type_id = {placeholder}
        ORDER BY ur.date_from DESC, ur.created_ts DESC
    """, (username, overtime_type_id)).fetchall()
    
    overtime_list = []
    for row in rows:
        if isinstance(row, Mapping):
            item = dict(row)
        else:
            columns = ['id', 'username', 'date', 'total_extra_minutes', 'notes', 'extra_data',
                      'status', 'reviewed_by', 'reviewed_ts', 'review_notes', 'created_ts', 'updated_ts']
            item = dict(zip(columns, row))
        
        # Parse extra_data per estrarre i dettagli dello straordinario
        extra_data = item.get('extra_data')
        if extra_data:
            try:
                if isinstance(extra_data, str):
                    extra_data = json.loads(extra_data)
                item.update({
                    'session_id': extra_data.get('session_id'),
                    'planning_id': extra_data.get('planning_id'),
                    'shift_source': extra_data.get('shift_source', 'none'),
                    'planned_start': extra_data.get('planned_start'),
                    'planned_end': extra_data.get('planned_end'),
                    'actual_start': extra_data.get('actual_start'),
                    'actual_end': extra_data.get('actual_end'),
                    'extra_minutes_before': extra_data.get('extra_minutes_before', 0),
                    'extra_minutes_after': extra_data.get('extra_minutes_after', 0),
                    'overtime_type': extra_data.get('overtime_type', 'after_shift'),
                    'auto_detected': extra_data.get('auto_detected', False)
                })
            except (json.JSONDecodeError, TypeError):
                pass
        
        # Rimuovi extra_data raw dalla risposta
        item.pop('extra_data', None)
        
        # Converti total_extra_minutes in intero
        item['total_extra_minutes'] = int(item.get('total_extra_minutes', 0))
        
        overtime_list.append(item)
    
    return jsonify({"overtime": overtime_list})


@app.post("/api/user/overtime")
@login_required
def api_user_overtime_create() -> ResponseReturnValue:
    """
    Crea una nuova richiesta di straordinario come user_request.
    Usa la tabella user_requests con type='Straordinario' e extra_data per i dettagli.
    """
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    db = get_db()
    
    # Verifica se il modulo straordinari è attivo
    if not is_module_enabled(db, "straordinari"):
        return jsonify({"error": "Modulo straordinari non attivo"}), 400
    
    data = request.get_json() or {}
    
    required = ["date", "total_extra_minutes"]
    for field in required:
        if not data.get(field):
            return jsonify({"error": f"Campo obbligatorio mancante: {field}"}), 400
    
    ensure_user_requests_table(db)
    
    # Ottieni l'ID del tipo "Straordinario"
    overtime_type_id = get_overtime_request_type_id(db)
    
    now_ts = int(time.time() * 1000)
    
    # Prepara extra_data con tutti i dettagli dello straordinario
    extra_data = {
        "session_id": data.get("session_id"),
        "planning_id": data.get("planning_id"),
        "shift_source": data.get("shift_source", "none"),
        "planned_start": data.get("planned_start"),
        "planned_end": data.get("planned_end"),
        "actual_start": data.get("actual_start"),
        "actual_end": data.get("actual_end"),
        "rounded_start": data.get("rounded_start"),
        "rounded_end": data.get("rounded_end"),
        "extra_minutes_before": data.get("extra_minutes_before", 0),
        "extra_minutes_after": data.get("extra_minutes_after", 0),
        "overtime_type": data.get("overtime_type", "after_shift"),
        "auto_detected": data.get("auto_detected", False)
    }
    extra_data_json = json.dumps(extra_data)
    
    date_str = data.get("date")
    total_minutes = data.get("total_extra_minutes")
    notes = data.get("notes", "")
    
    if DB_VENDOR == "mysql":
        db.execute("""
            INSERT INTO user_requests 
            (user_id, username, request_type_id, date_from, date_to, value_amount, 
             notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 'pending', %s, %s)
        """, (0, username, overtime_type_id, date_str, date_str, total_minutes, 
              notes, None, None, None, extra_data_json, now_ts, now_ts))
    else:
        db.execute("""
            INSERT INTO user_requests 
            (user_id, username, request_type_id, date_from, date_to, value_amount, 
             notes, cdc, attachment_path, tratte, extra_data, status, created_ts, updated_ts)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'pending', ?, ?)
        """, (0, username, overtime_type_id, date_str, date_str, total_minutes, 
              notes, None, None, None, extra_data_json, now_ts, now_ts))
    
    db.commit()
    
    # Notifica admin
    _send_overtime_notification_to_admins(db, username, date_str, total_minutes)
    
    return jsonify({"ok": True, "message": "Richiesta Extra Turno inviata"})


def _calcola_ora_arrotondata_uscita(db, username: str, date_str: str, ora_uscita: str, placeholder: str) -> str:
    """
    Calcola l'ora di uscita arrotondata per modalità giornaliera.
    
    Formula:
    1. Prendi ora inizio (da timbrature)
    2. Calcola ore nette effettive: (uscita - inizio - pausa_turno)
    3. Arrotonda ore nette (blocco 30, floor)
    4. Ricalcola uscita: inizio + ore_arrotondate + pausa_turno
    
    Esempio:
        - Inizio: 09:20, Uscita: 16:29, Pausa turno: 60 min
        - Ore lorde: 7:09, Ore nette: 6:09
        - Arrotondato (blocco 30, floor): 6:00
        - Uscita arrotondata: 09:20 + 6:00 + 1:00 = 16:20
    """
    try:
        # 1. Recupera ora inizio
        inizio_row = db.execute(
            f"""SELECT ora, ora_mod FROM timbrature 
               WHERE username = {placeholder} AND data = {placeholder} AND tipo = 'inizio_giornata'
               ORDER BY created_ts ASC LIMIT 1""",
            (username, date_str)
        ).fetchone()
        
        if not inizio_row:
            app.logger.warning(f"_calcola_ora_arrotondata_uscita: nessun inizio trovato per {username} il {date_str}")
            return ora_uscita[:5] if ora_uscita else None
        
        ora_inizio = inizio_row['ora_mod'] if isinstance(inizio_row, dict) else inizio_row[1]
        if not ora_inizio:
            ora_inizio = inizio_row['ora'] if isinstance(inizio_row, dict) else inizio_row[0]
        
        # Converti in stringa e minuti
        if hasattr(ora_inizio, 'strftime'):
            ora_inizio_str = ora_inizio.strftime("%H:%M")
        elif hasattr(ora_inizio, 'total_seconds'):
            total_sec = int(ora_inizio.total_seconds())
            ora_inizio_str = f"{total_sec // 3600:02d}:{(total_sec % 3600) // 60:02d}"
        else:
            ora_inizio_str = str(ora_inizio)[:5]
        
        inizio_parts = ora_inizio_str.split(':')
        inizio_min = int(inizio_parts[0]) * 60 + int(inizio_parts[1])
        
        # Converti ora uscita in minuti
        ora_uscita_str = str(ora_uscita)[:5]
        uscita_parts = ora_uscita_str.split(':')
        uscita_min = int(uscita_parts[0]) * 60 + int(uscita_parts[1])
        
        # 2. Recupera pausa turno
        pausa_turno_min = 60  # Default
        try:
            day_of_week = datetime.strptime(date_str, '%Y-%m-%d').weekday()
            shift_row = db.execute(
                f"""SELECT break_start, break_end FROM employee_shifts 
                   WHERE username = {placeholder} AND day_of_week = {placeholder}""",
                (username, day_of_week)
            ).fetchone()
            
            if shift_row:
                break_start = shift_row['break_start'] if isinstance(shift_row, dict) else shift_row[0]
                break_end = shift_row['break_end'] if isinstance(shift_row, dict) else shift_row[1]
                
                if break_start and break_end:
                    if hasattr(break_start, 'total_seconds'):
                        bs_min = int(break_start.total_seconds()) // 60
                    else:
                        bs_parts = str(break_start)[:5].split(':')
                        bs_min = int(bs_parts[0]) * 60 + int(bs_parts[1])
                    
                    if hasattr(break_end, 'total_seconds'):
                        be_min = int(break_end.total_seconds()) // 60
                    else:
                        be_parts = str(break_end)[:5].split(':')
                        be_min = int(be_parts[0]) * 60 + int(be_parts[1])
                    
                    pausa_turno_min = be_min - bs_min
        except Exception as e:
            app.logger.warning(f"Errore lettura pausa turno: {e}")
        
        # 3. Recupera regole arrotondamento
        rules = get_user_timbratura_rules(db, username)
        blocco = rules.get('arrotondamento_giornaliero_minuti', 30) if rules else 30
        
        # 4. Calcola ore nette effettive e arrotonda
        ore_lorde = uscita_min - inizio_min
        ore_nette = ore_lorde - pausa_turno_min
        ore_arrotondate = (ore_nette // blocco) * blocco  # floor
        
        if ore_arrotondate < 0:
            ore_arrotondate = 0
        
        # 5. Ricalcola uscita arrotondata
        uscita_arrotondata_min = inizio_min + ore_arrotondate + pausa_turno_min
        h = uscita_arrotondata_min // 60
        m = uscita_arrotondata_min % 60
        ora_arrotondata = f"{h:02d}:{m:02d}"
        
        app.logger.info(
            f"_calcola_ora_arrotondata_uscita: inizio={ora_inizio_str}, uscita={ora_uscita_str}, "
            f"pausa={pausa_turno_min}min, ore_lorde={ore_lorde}min, ore_nette={ore_nette}min, "
            f"ore_arrot={ore_arrotondate}min, uscita_arrot={ora_arrotondata}"
        )
        
        return ora_arrotondata
        
    except Exception as e:
        app.logger.error(f"Errore _calcola_ora_arrotondata_uscita: {e}")
        import traceback
        app.logger.error(traceback.format_exc())
        return ora_uscita[:5] if ora_uscita else None


def _process_fuori_flessibilita(
    db: DatabaseLike,
    request_id: int,
    username: str,
    date_from: str,
    status: str,
    rounded_time: str,
    extra_data_str: str = None
) -> dict:
    """
    Elabora una richiesta Fuori Flessibilita approvata o respinta.
    
    La logica dipende dal tipo (anticipo vs ritardo):
    
    ANTICIPO (ingresso prima / uscita prima):
    - APPROVED (Autorizza anticipo): passa la timbrata effettiva
    - REJECTED (Non autorizzare): passa l orario del turno
    
    RITARDO (ingresso dopo / uscita dopo):
    - APPROVED (Accetta motivazione): ritardo giustificato (flag)
    - REJECTED (Conferma ritardo): ritardo confermato (flag)
    - In entrambi i casi l orario non cambia
    
    Args:
        db: connessione database
        request_id: ID della richiesta
        username: username dell utente
        date_from: data della timbratura
        status: approved o rejected
        rounded_time: orario (non usato per modifiche, solo per log)
        extra_data_str: JSON con i dettagli della richiesta
    
    Returns:
        Dict con info di debug
    """
    result = {"request_id": request_id, "status": status, "updated": False}
    
    try:
        # Parsing extra_data
        extra_data = {}
        if extra_data_str:
            try:
                extra_data = json.loads(extra_data_str) if isinstance(extra_data_str, str) else extra_data_str
            except:
                pass
        
        tipo_timbratura = extra_data.get("tipo_timbratura", "fine_giornata")
        ora_timbrata = extra_data.get("ora_timbrata", "")
        turno_start = extra_data.get("turno_start", "")
        turno_end = extra_data.get("turno_end", "")
        diff_minutes = extra_data.get("diff_minutes", 0)
        
        # Determina se e un INGRESSO ANTICIPATO (unico caso che cambia orario)
        # Altri casi (ritardo, uscita anticipata, uscita posticipata) non cambiano orario
        is_ingresso_anticipato = (tipo_timbratura == 'inizio_giornata' and diff_minutes < 0)
        
        # Orario di riferimento del turno
        ora_turno = turno_start if tipo_timbratura == 'inizio_giornata' else turno_end
        
        app.logger.info(
            "Fuori Flessibilita: processing request %s, status=%s, tipo=%s, is_ingresso_anticipato=%s, diff=%s",
            request_id, status, tipo_timbratura, is_ingresso_anticipato, diff_minutes
        )
        
        placeholder = "%s" if DB_VENDOR == "mysql" else "?"
        
        # Determina quale orario usare per la sincronizzazione
        if is_ingresso_anticipato:
            # INGRESSO ANTICIPATO: approved = usa timbrata (ore extra riconosciute), rejected = usa orario turno
            if status == 'approved':
                ora_da_usare = ora_timbrata[:5] if ora_timbrata else None
                extra_data["anticipo_autorizzato"] = True
                app.logger.info("Fuori Flessibilita INGRESSO ANTICIPATO AUTORIZZATO: usa timbrata %s", ora_da_usare)
            else:
                ora_da_usare = ora_turno[:5] if ora_turno else None
                extra_data["anticipo_autorizzato"] = False
                app.logger.info("Fuori Flessibilita INGRESSO ANTICIPATO NON AUTORIZZATO: usa orario turno %s", ora_da_usare)
        else:
            # RITARDO / USCITA ANTICIPATA / USCITA POSTICIPATA
            # Per fine_giornata in modalità giornaliera, SEMPRE calcolare l'ora arrotondata
            # Formula: inizio + ore_nette_arrotondate + pausa_turno
            if tipo_timbratura == 'fine_giornata':
                # Calcola ora arrotondata per uscita (anticipata o posticipata)
                ora_arrotondata = _calcola_ora_arrotondata_uscita(
                    db, username, date_from, ora_timbrata, placeholder
                )
                ora_da_usare = ora_arrotondata if ora_arrotondata else ora_timbrata[:5]
                app.logger.info(
                    "Fuori Flessibilita FINE GIORNATA: timbrata=%s, arrotondata=%s",
                    ora_timbrata, ora_da_usare
                )
            else:
                # Ritardo (inizio_giornata): usa l'ora timbrata (non si arrotonda il ritardo)
                ora_da_usare = ora_timbrata[:5] if ora_timbrata else None
                app.logger.info(
                    "Fuori Flessibilita RITARDO: timbrata=%s, non arrotondato",
                    ora_timbrata
                )
            
            extra_data["giustificato"] = (status == 'approved')
            extra_data["ora_arrotondata"] = ora_da_usare
            app.logger.info("Fuori Flessibilita: giustificato=%s, orario finale=%s", status == 'approved', ora_da_usare)
        
        # Aggiorna extra_data
        extra_data_updated = json.dumps(extra_data)
        db.execute(f"""
            UPDATE user_requests SET extra_data = {placeholder} WHERE id = {placeholder}
        """, (extra_data_updated, request_id))
        
        # Trova la timbratura in cedolino_timbrature
        timbratura_row = db.execute(f"""
            SELECT id, ora_modificata, synced_ts 
            FROM cedolino_timbrature 
            WHERE username = {placeholder} AND data_riferimento = {placeholder}
            ORDER BY id DESC LIMIT 1
        """, (username, date_from)).fetchone()
        
        if timbratura_row and ora_da_usare:
            timbr_id = timbratura_row['id'] if isinstance(timbratura_row, Mapping) else timbratura_row[0]
            
            # Costruisci il datetime completo
            datetime_str = f"{date_from} {ora_da_usare}:00"
            
            # Aggiorna ora_modificata e sblocca il sync
            db.execute(f"""
                UPDATE cedolino_timbrature 
                SET ora_modificata = {placeholder}, synced_ts = NULL, sync_error = NULL
                WHERE id = {placeholder}
            """, (datetime_str, timbr_id))
            
            result["cedolino_timbr_id"] = timbr_id
            result["updated"] = True
            result["ora_finale"] = ora_da_usare
            
            app.logger.info(
                "Fuori Flessibilita: aggiornato cedolino_timbrature id=%s, ora_modificata=%s",
                timbr_id, datetime_str
            )
            
            # Aggiorna anche la tabella timbrature per coerenza
            db.execute(f"""
                UPDATE timbrature 
                SET ora_mod = {placeholder}
                WHERE username = {placeholder} AND data = {placeholder} AND tipo = {placeholder}
            """, (ora_da_usare, username, date_from, tipo_timbratura))
            
            # Invia a CedolinoWeb
            try:
                cedolino_result = _resync_flex_to_cedolino(db, timbr_id, datetime_str)
                result["cedolino_sync"] = cedolino_result
            except Exception as e:
                app.logger.error(f"Errore sync CedolinoWeb per flex: {e}")
                result["cedolino_sync_error"] = str(e)
        else:
            app.logger.warning("Fuori Flessibilita: nessuna timbratura trovata per %s, %s", username, date_from)
        
        db.commit()
        return result
        
    except Exception as e:
        import traceback
        app.logger.error(f"Errore in _process_fuori_flessibilita: {e}\n{traceback.format_exc()}")
        return {"request_id": request_id, "error": str(e)}


def _resync_flex_to_cedolino(db: DatabaseLike, timbr_id: int, new_ora_modificata: str) -> dict:
    """
    Invia a CedolinoWeb la timbratura aggiornata per Fuori Flessibilità.
    Usa call_cedolino_webservice con tutti i parametri corretti.
    
    Args:
        timbr_id: ID della riga in cedolino_timbrature
        new_ora_modificata: Nuovo orario modificato (HH:MM o HH:MM:SS)
    """
    settings = get_cedolino_settings()
    if not settings:
        return {"error": "CedolinoWeb non configurato"}
    
    endpoint = settings.get("endpoint") or CEDOLINO_WEB_ENDPOINT
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Recupera i dati della timbratura
    row = db.execute(f"""
        SELECT external_id, timeframe_id, data_riferimento, ora_originale, username
        FROM cedolino_timbrature 
        WHERE id = {placeholder}
    """, (timbr_id,)).fetchone()
    
    if not row:
        return {"error": "Timbratura non trovata"}
    
    if isinstance(row, Mapping):
        external_id = row.get("external_id")
        timeframe_id = row.get("timeframe_id")
        data_rif = row.get("data_riferimento")
        ora_originale = row.get("ora_originale")
        username = row.get("username")
    else:
        external_id = row[0]
        timeframe_id = row[1]
        data_rif = row[2]
        ora_originale = row[3]
        username = row[4]
    
    # Converti data_riferimento in stringa se è un oggetto date
    if hasattr(data_rif, 'strftime'):
        data_rif = data_rif.strftime("%Y-%m-%d")
    else:
        data_rif = str(data_rif)
    
    # Converti ora_originale se è timedelta
    if isinstance(ora_originale, timedelta):
        total_secs = int(ora_originale.total_seconds())
        h, remainder = divmod(total_secs, 3600)
        m, s = divmod(remainder, 60)
        ora_originale = f"{h:02d}:{m:02d}:{s:02d}"
    else:
        ora_originale = str(ora_originale)
    
    # Normalizza new_ora_modificata - potrebbe essere solo HH:MM o già con data
    new_ora_modificata = str(new_ora_modificata)
    
    # Se contiene già la data (es. "2026-01-17 19:00:00"), estrai solo l'ora
    if " " in new_ora_modificata and len(new_ora_modificata) > 10:
        # Formato "YYYY-MM-DD HH:MM:SS" - prendi solo l'ora
        new_ora_modificata = new_ora_modificata.split(" ")[1]
    
    # Aggiungi secondi se mancano (HH:MM -> HH:MM:00)
    if len(new_ora_modificata) == 5:  # HH:MM
        new_ora_modificata = f"{new_ora_modificata}:00"
    
    # Costruisci data_originale e data_modificata complete
    data_originale = f"{data_rif} {ora_originale}"
    data_modificata = f"{data_rif} {new_ora_modificata}"
    
    # Recupera gruppo_id esterno
    external_group_id = get_external_group_id_for_username(db, username)
    
    app.logger.info(
        "CedolinoWeb Flex resync: timbr_id=%s, external_id=%s, timeframe=%s, data_rif=%s, ora_orig=%s, ora_mod=%s, gruppo=%s",
        timbr_id, external_id, timeframe_id, data_rif, ora_originale, new_ora_modificata, external_group_id
    )
    
    # Chiama il webservice con tutti i parametri
    success, error, request_url = call_cedolino_webservice(
        external_id, timeframe_id, data_rif, data_originale, data_modificata, endpoint, external_group_id
    )
    
    now_ts = int(datetime.now().timestamp() * 1000)
    
    if success:
        # Aggiorna synced_ts e resetta sync_error e overtime_request_id
        db.execute(f"""
            UPDATE cedolino_timbrature 
            SET synced_ts = {placeholder},
                sync_error = NULL, overtime_request_id = NULL
            WHERE id = {placeholder}
        """, (now_ts, timbr_id))
        db.commit()
        
        app.logger.info(f"CedolinoWeb Flex sync OK: timbr_id={timbr_id}")
        
        return {
            "success": True,
            "url": request_url
        }
    else:
        app.logger.error(f"CedolinoWeb Flex sync FAILED: timbr_id={timbr_id}, error={error}")
        return {"error": error, "url": request_url}


def _sync_overtime_blocked_timbrature(
    db: DatabaseLike, 
    overtime_request_id: int,
    request_status: str = None,
    extra_data_passed: str = None
) -> dict:
    """
    Sincronizza le timbrature che erano bloccate in attesa della revisione di uno straordinario.
    Chiamata dopo che una richiesta di straordinario viene approvata o respinta.
    
    - Se APPROVATA: invia la timbrata con l'orario arrotondato (Extra Turno)
    - Se RESPINTA: invia la timbrata con l'orario del turno pianificato (no Extra Turno)
    
    Args:
        db: connessione database
        overtime_request_id: ID della richiesta straordinario revisionata
        request_status: status della richiesta (passed from caller to avoid re-query)
        extra_data_passed: extra_data della richiesta (passed from caller)
    
    Returns:
        Dict con info di debug sulla sincronizzazione
    """
    app.logger.warning(
        "DEBUG SYNC: INIZIO _sync_overtime_blocked_timbrature - overtime_request_id=%s, request_status=%r, extra_data_passed=%r",
        overtime_request_id, request_status, extra_data_passed[:200] if extra_data_passed else None
    )
    
    settings = get_cedolino_settings()
    if not settings:
        return {"synced_count": 0, "error": "CedolinoWeb non configurato"}
    
    endpoint = settings.get("endpoint") or CEDOLINO_WEB_ENDPOINT
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Usa i dati passati dal chiamante oppure fai una query
    if request_status is None or extra_data_passed is None:
        request_row = db.execute(f"""
            SELECT status, extra_data FROM user_requests WHERE id = {placeholder}
        """, (overtime_request_id,)).fetchone()
        
        if not request_row:
            return {"synced_count": 0, "error": "Richiesta non trovata"}
        
        if isinstance(request_row, Mapping):
            request_status = request_row.get("status")
            extra_data_str = request_row.get("extra_data")
        else:
            request_status = request_row[0]
            extra_data_str = request_row[1]
    else:
        extra_data_str = extra_data_passed
    
    app.logger.info(
        "CedolinoWeb _sync_overtime: overtime_request_id=%s, request_status=%s",
        overtime_request_id, request_status
    )
    
    # Estrai i dati del turno pianificato
    planned_start = None
    planned_end = None
    extra_type = None
    
    if extra_data_str:
        try:
            extra_data = json.loads(extra_data_str) if isinstance(extra_data_str, str) else extra_data_str
            planned_start = extra_data.get("planned_start")
            planned_end = extra_data.get("planned_end")
            extra_type = extra_data.get("extra_type")
            app.logger.info(
                "CedolinoWeb: overtime %s - status=%s, extra_type=%s, planned_start=%s, planned_end=%s",
                overtime_request_id, request_status, extra_type, planned_start, planned_end
            )
        except Exception as e:
            app.logger.error("CedolinoWeb: errore parsing extra_data per overtime %s: %s", overtime_request_id, e)
    
    # Recupera le timbrature bloccate per questo straordinario
    # Nota: includiamo anche quelle già sincronizzate se stiamo respingendo (per correggerle)
    if request_status == 'rejected':
        # Per le respinte, recupera TUTTE le timbrature associate, anche quelle già sincronizzate
        rows = db.execute(f"""
            SELECT id, external_id, timeframe_id, data_riferimento, ora_originale, ora_modificata, username, synced_ts
            FROM cedolino_timbrature
            WHERE overtime_request_id = {placeholder}
        """, (overtime_request_id,)).fetchall()
        app.logger.info("CedolinoWeb: REJECTED - cercando tutte le timbrature per overtime_request_id=%s, trovate %d", 
                       overtime_request_id, len(rows) if rows else 0)
    else:
        # Per le approvate, solo quelle non ancora sincronizzate
        rows = db.execute(f"""
            SELECT id, external_id, timeframe_id, data_riferimento, ora_originale, ora_modificata, username, synced_ts
            FROM cedolino_timbrature
            WHERE overtime_request_id = {placeholder} AND synced_ts IS NULL
        """, (overtime_request_id,)).fetchall()
        app.logger.info("CedolinoWeb: APPROVED - cercando timbrature non sincronizzate per overtime_request_id=%s, trovate %d", 
                       overtime_request_id, len(rows) if rows else 0)
    
    if not rows:
        app.logger.warning("CedolinoWeb: nessuna timbratura trovata per overtime_request_id=%s", overtime_request_id)
        return {"synced_count": 0, "error": "Nessuna timbratura trovata"}
    
    synced_count = 0
    for row in rows:
        if isinstance(row, Mapping):
            timbrata_id = row.get("id")
            external_id = row.get("external_id")
            timeframe_id = row.get("timeframe_id")
            data_rif = row.get("data_riferimento")
            ora_orig = row.get("ora_originale")
            ora_mod = row.get("ora_modificata")
            username = row.get("username")
        else:
            timbrata_id = row[0]
            external_id = row[1]
            timeframe_id = row[2]
            data_rif = row[3]
            ora_orig = row[4]
            ora_mod = row[5]
            username = row[6]
        
        # Formatta data_riferimento come stringa se necessario
        if hasattr(data_rif, 'strftime'):
            data_riferimento = data_rif.strftime("%Y-%m-%d")
        else:
            data_riferimento = str(data_rif)
        
        # Formatta ora come stringa se necessario
        if hasattr(ora_orig, 'strftime'):
            ora_originale = ora_orig.strftime("%H:%M:%S")
        else:
            ora_originale = str(ora_orig)
        
        if hasattr(ora_mod, 'strftime'):
            ora_modificata = ora_mod.strftime("%H:%M:%S")
        else:
            ora_modificata = str(ora_mod) if ora_mod else ora_originale
        
        # Se RESPINTA: usa l'orario del turno pianificato invece dell'extra
        ora_modificata_originale = ora_modificata  # Salva il valore originale per il log
        if request_status == 'rejected':
            app.logger.info(
                "CedolinoWeb: Richiesta RESPINTA - extra_type=%s, planned_start=%s, planned_end=%s, ora_mod_attuale=%s",
                extra_type, planned_start, planned_end, ora_modificata
            )
            # Determina quale orario usare in base al tipo di extra turno
            if extra_type == 'before_shift' and planned_start:
                # Ingresso anticipato respinto: usa l'orario di inizio turno
                ora_modificata = f"{planned_start}:00" if len(planned_start) == 5 else planned_start
                app.logger.info(
                    "CedolinoWeb: Extra Turno RESPINTO (before_shift) - uso orario turno %s invece di %s",
                    ora_modificata, ora_modificata_originale
                )
            elif extra_type == 'after_shift' and planned_end:
                # Uscita posticipata respinta: usa l'orario di fine turno
                ora_modificata = f"{planned_end}:00" if len(planned_end) == 5 else planned_end
                app.logger.info(
                    "CedolinoWeb: Extra Turno RESPINTO (after_shift) - uso orario turno %s invece di %s",
                    ora_modificata, ora_modificata_originale
                )
            else:
                app.logger.warning(
                    "CedolinoWeb: Extra Turno RESPINTO ma mancano dati - extra_type=%s, planned_start=%s, planned_end=%s",
                    extra_type, planned_start, planned_end
                )
            
            # Aggiorna anche il record cedolino_timbrature con l'ora corretta
            if ora_modificata != ora_modificata_originale:
                if DB_VENDOR == "mysql":
                    db.execute(
                        "UPDATE cedolino_timbrature SET ora_modificata = %s WHERE id = %s",
                        (ora_modificata, timbrata_id)
                    )
                else:
                    db.execute(
                        "UPDATE cedolino_timbrature SET ora_modificata = ? WHERE id = ?",
                        (ora_modificata, timbrata_id)
                    )
                
                # Aggiorna anche la tabella timbrature per mostrare l'ora corretta nello storico
                # Converte timeframe_id in tipo timbratura
                tipo_map = {1: 'inizio_giornata', 4: 'inizio_pausa', 5: 'fine_pausa', 8: 'fine_giornata'}
                tipo_timbratura = tipo_map.get(timeframe_id)
                
                if tipo_timbratura and username:
                    # Solo ore e minuti per ora_mod
                    ora_mod_short = ora_modificata[:5] if len(ora_modificata) >= 5 else ora_modificata
                    if DB_VENDOR == "mysql":
                        db.execute(
                            """UPDATE timbrature SET ora_mod = %s 
                               WHERE username = %s AND data = %s AND tipo = %s""",
                            (ora_mod_short, username, data_riferimento, tipo_timbratura)
                        )
                    else:
                        db.execute(
                            """UPDATE timbrature SET ora_mod = ? 
                               WHERE username = ? AND data = ? AND tipo = ?""",
                            (ora_mod_short, username, data_riferimento, tipo_timbratura)
                        )
                    app.logger.info(
                        "CedolinoWeb: aggiornato timbrature.ora_mod=%s per user=%s, data=%s, tipo=%s",
                        ora_mod_short, username, data_riferimento, tipo_timbratura
                    )
        
        # Componi data_originale e data_modificata
        data_originale = f"{data_riferimento} {ora_originale}"
        data_modificata = f"{data_riferimento} {ora_modificata}"
        
        app.logger.warning(
            "DEBUG SYNC: PRIMA DI CALL WEBSERVICE - data_originale=%s, data_modificata=%s, ora_originale=%s, ora_modificata=%s",
            data_originale, data_modificata, ora_originale, ora_modificata
        )
        
        # Recupera external_group_id se possibile
        external_group_id = get_external_group_id_for_username(db, username) if username else None
        
        app.logger.info(
            "CedolinoWeb: sincronizzazione timbrata %s bloccata per straordinario %s (status=%s)",
            timbrata_id, overtime_request_id, request_status
        )
        
        success, error, _url = call_cedolino_webservice(
            external_id, timeframe_id, data_riferimento, data_originale, data_modificata, endpoint, external_group_id
        )
        
        if success:
            if DB_VENDOR == "mysql":
                db.execute(
                    "UPDATE cedolino_timbrature SET synced_ts = %s, sync_error = NULL WHERE id = %s",
                    (now_ms(), timbrata_id)
                )
            else:
                db.execute(
                    "UPDATE cedolino_timbrature SET synced_ts = ?, sync_error = NULL WHERE id = ?",
                    (now_ms(), timbrata_id)
                )
            synced_count += 1
            app.logger.info("CedolinoWeb: timbrata %s sincronizzata con successo", timbrata_id)
        else:
            if DB_VENDOR == "mysql":
                db.execute(
                    "UPDATE cedolino_timbrature SET sync_error = %s, sync_attempts = sync_attempts + 1 WHERE id = %s",
                    (error, timbrata_id)
                )
            else:
                db.execute(
                    "UPDATE cedolino_timbrature SET sync_error = ?, sync_attempts = sync_attempts + 1 WHERE id = ?",
                    (error, timbrata_id)
                )
            app.logger.warning("CedolinoWeb: errore sincronizzazione timbrata %s: %s", timbrata_id, error)
    
    if rows:
        db.commit()
    
    # Ritorna dati di debug
    return {
        "synced_count": synced_count,
        "request_status": request_status,
        "extra_type": extra_type,
        "planned_start": planned_start,
        "planned_end": planned_end,
        "rows_found": len(rows) if rows else 0,
        "last_ora_modificata": ora_modificata if rows else None,
        "last_ora_originale": ora_originale if rows else None
    }


@app.put("/api/admin/overtime/<int:overtime_id>")
@login_required
def api_admin_overtime_review(overtime_id: int) -> ResponseReturnValue:
    """
    Approva o respinge una richiesta di straordinario.
    Aggiorna la tabella user_requests.
    """
    if not session.get("is_admin"):
        return jsonify({"error": "Accesso negato"}), 403
    
    data = request.get_json() or {}
    status = data.get("status")
    review_notes = data.get("review_notes", "").strip()
    
    if status not in ("approved", "rejected"):
        return jsonify({"error": "Stato non valido. Usa 'approved' o 'rejected'"}), 400
    
    db = get_db()
    ensure_user_requests_table(db)
    
    # Ottieni l'ID del tipo "Straordinario"
    overtime_type_id = get_overtime_request_type_id(db)
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    # Verifica che esista e sia pending
    existing = db.execute(f"""
        SELECT id, status, username, date_from, value_amount 
        FROM user_requests 
        WHERE id = {placeholder} AND request_type_id = {placeholder}
    """, (overtime_id, overtime_type_id)).fetchone()
    
    if not existing:
        return jsonify({"error": "Richiesta non trovata"}), 404
    
    if isinstance(existing, Mapping):
        current_status = existing.get("status")
        target_username = existing.get("username")
        ot_date = existing.get("date_from")
        ot_minutes = int(existing.get("value_amount", 0))
    else:
        current_status = existing[1]
        target_username = existing[2]
        ot_date = existing[3]
        ot_minutes = int(existing[4] or 0)
    
    if current_status != "pending":
        return jsonify({"error": "Questa richiesta è già stata gestita"}), 400
    
    now_ts = int(time.time() * 1000)
    admin_user = session.get("user", "admin")
    
    db.execute(f"""
        UPDATE user_requests 
        SET status = {placeholder}, reviewed_by = {placeholder}, reviewed_ts = {placeholder}, 
            review_notes = {placeholder}, updated_ts = {placeholder}
        WHERE id = {placeholder}
    """, (status, admin_user, now_ts, review_notes, now_ts, overtime_id))
    
    db.commit()
    
    # Sincronizza le timbrature bloccate per questo straordinario
    _sync_overtime_blocked_timbrature(db, overtime_id)
    
    # Notifica utente
    _send_overtime_review_notification(db, target_username, ot_date, ot_minutes, status, review_notes)
    
    status_label = "approvata" if status == "approved" else "respinta"
    return jsonify({"ok": True, "message": f"Richiesta Extra Turno {status_label}"})


@app.get("/api/user/check-overtime")
@login_required
def api_user_check_overtime() -> ResponseReturnValue:
    """
    Verifica se c'è uno straordinario da dichiarare basandosi sul turno pianificato.
    Chiamato al momento del checkout.
    """
    username = session.get("user")
    if not username:
        return jsonify({"error": "Non autenticato"}), 401
    
    # Parametri dalla richiesta
    session_id = request.args.get("session_id", type=int)
    actual_start = request.args.get("actual_start")  # HH:MM
    actual_end = request.args.get("actual_end")  # HH:MM
    date_str = request.args.get("date")  # YYYY-MM-DD
    
    if not all([actual_start, actual_end, date_str]):
        return jsonify({"overtime_detected": False, "reason": "Parametri mancanti"})
    
    db = get_db()
    
    # Verifica se il modulo straordinari è attivo
    if not is_module_enabled(db, "straordinari"):
        return jsonify({"overtime_detected": False, "reason": "Modulo straordinari non attivo"})
    
    # Carica impostazioni straordinari
    settings = get_company_settings(db)
    overtime_settings = settings.get("custom_settings", {}).get("overtime", {})
    
    if not overtime_settings.get("auto_detect", True):
        return jsonify({"overtime_detected": False, "reason": "Rilevamento automatico disabilitato"})
    
    threshold_minutes = overtime_settings.get("threshold_minutes", 15)
    rounding_minutes = overtime_settings.get("rounding_minutes", 15)
    
    # Cerca turno pianificato per questo utente in questa data
    planned_shift = _find_planned_shift(db, username, date_str)
    
    if not planned_shift:
        return jsonify({
            "overtime_detected": False, 
            "reason": "Nessun turno pianificato trovato",
            "can_request_manual": True  # L'utente può comunque richiedere manualmente
        })
    
    # Calcola differenza
    planned_start = planned_shift.get("start_time")  # HH:MM
    planned_end = planned_shift.get("end_time")  # HH:MM
    shift_source = planned_shift.get("source")  # 'rentman' o 'manual'
    planning_id = planned_shift.get("planning_id")
    
    # Converti in minuti dal mezzanotte per il calcolo
    def time_to_minutes(t):
        if not t:
            return 0
        parts = str(t).split(":")
        return int(parts[0]) * 60 + int(parts[1])
    
    planned_start_min = time_to_minutes(planned_start)
    planned_end_min = time_to_minutes(planned_end)
    actual_start_min = time_to_minutes(actual_start)
    actual_end_min = time_to_minutes(actual_end)
    
    # Calcola straordinari (valori effettivi non arrotondati)
    extra_before_raw = max(0, planned_start_min - actual_start_min)  # Arrivato prima
    extra_after_raw = max(0, actual_end_min - planned_end_min)  # Uscito dopo
    total_extra_raw = extra_before_raw + extra_after_raw
    
    # Applica arrotondamento
    extra_before = extra_before_raw
    extra_after = extra_after_raw
    total_extra = total_extra_raw
    
    if rounding_minutes > 1:
        total_extra = (total_extra_raw // rounding_minutes) * rounding_minutes
        extra_before = (extra_before_raw // rounding_minutes) * rounding_minutes
        extra_after = (extra_after_raw // rounding_minutes) * rounding_minutes
    
    if total_extra < threshold_minutes:
        return jsonify({
            "overtime_detected": False,
            "reason": f"Differenza ({total_extra} min) sotto la soglia ({threshold_minutes} min)",
            "extra_minutes": total_extra
        })
    
    # Determina tipo
    if extra_before > 0 and extra_after > 0:
        overtime_type = "both"
    elif extra_before > 0:
        overtime_type = "before_shift"
    else:
        overtime_type = "after_shift"
    
    # Calcola orari arrotondati da mostrare nel modal
    # Stessa logica usata per ora_mod nelle timbrature:
    # - INIZIO giornata: arrotondamento PER ECCESSO (es. 7:27 → 7:30)
    # - FINE giornata: arrotondamento PER DIFETTO (es. 17:12 → 17:00)
    def minutes_to_time(m):
        return f"{m // 60:02d}:{m % 60:02d}"
    
    # Calcola ora arrotondata inizio (sempre arrotondamento PER ECCESSO)
    if rounding_minutes > 1:
        # Arrotonda per eccesso: ceil(actual_start_min / rounding) * rounding
        rounded_start_min = ((actual_start_min + rounding_minutes - 1) // rounding_minutes) * rounding_minutes
        rounded_start = minutes_to_time(rounded_start_min)
    else:
        rounded_start = actual_start
    
    # Calcola ora arrotondata fine (sempre arrotondamento PER DIFETTO)
    if rounding_minutes > 1:
        # Arrotonda per difetto: floor(actual_end_min / rounding) * rounding
        rounded_end_min = (actual_end_min // rounding_minutes) * rounding_minutes
        rounded_end = minutes_to_time(rounded_end_min)
    else:
        rounded_end = actual_end
    
    return jsonify({
        "overtime_detected": True,
        "session_id": session_id,
        "planning_id": planning_id,
        "shift_source": shift_source,
        "date": date_str,
        "planned_start": planned_start,
        "planned_end": planned_end,
        "actual_start": actual_start,
        "actual_end": actual_end,
        "rounded_start": rounded_start,
        "rounded_end": rounded_end,
        "extra_minutes_before": extra_before,
        "extra_minutes_after": extra_after,
        "extra_minutes_before_raw": extra_before_raw,
        "extra_minutes_after_raw": extra_after_raw,
        "total_extra_minutes": total_extra,
        "total_extra_minutes_raw": total_extra_raw,
        "rounding_minutes": rounding_minutes,
        "overtime_type": overtime_type,
        "require_approval": overtime_settings.get("require_approval", True)
    })


def _find_planned_shift(db, username: str, date_str: str) -> dict | None:
    """
    Cerca il turno pianificato per un utente in una data specifica.
    Controlla sia Rentman Planning (via crew_id) che turni employee_shifts.
    
    IMPORTANTE: Se ci sono più turni nella stessa giornata (es. 07:30-15:30 e 15:30-16:30),
    restituisce l'intervallo complessivo (MIN start, MAX end) per calcolare
    correttamente gli straordinari.
    """
    placeholder = "%s" if DB_VENDOR == "mysql" else "?"
    
    def _extract_time_hhmm(dt_value) -> str | None:
        """Estrae l'ora in formato HH:MM da un valore datetime o stringa."""
        if not dt_value:
            return None
        if hasattr(dt_value, 'strftime'):
            return dt_value.strftime("%H:%M")
        dt_str = str(dt_value)
        if " " in dt_str:
            return dt_str.split(" ")[-1][:5]
        return dt_str[:5]
    
    # Recupera il crew_id dell'utente per cercare i turni Rentman
    user_row = db.execute(
        f"SELECT rentman_crew_id FROM app_users WHERE username = {placeholder}",
        (username,)
    ).fetchone()
    
    crew_id = None
    if user_row:
        crew_id = user_row['rentman_crew_id'] if isinstance(user_row, dict) else user_row[0]
    
    # 1. Se l'utente ha un crew_id, cerca nei turni Rentman Planning
    if crew_id:
        try:
            # Usa i campi corretti della tabella: plan_start, plan_end, planning_date
            rentman_agg = db.execute(f"""
                SELECT COUNT(*) as shift_count,
                       MIN(plan_start) as first_start,
                       MAX(plan_end) as last_end,
                       GROUP_CONCAT(id) as planning_ids
                FROM rentman_plannings 
                WHERE crew_id = {placeholder} AND planning_date = {placeholder} AND sent_to_webservice = 1
            """, (crew_id, date_str)).fetchone()
            
            if rentman_agg:
                if isinstance(rentman_agg, Mapping):
                    shift_count = rentman_agg.get("shift_count", 0)
                    first_start = rentman_agg.get("first_start")
                    last_end = rentman_agg.get("last_end")
                    planning_ids = rentman_agg.get("planning_ids")
                else:
                    shift_count = rentman_agg[0] or 0
                    first_start = rentman_agg[1]
                    last_end = rentman_agg[2]
                    planning_ids = rentman_agg[3]
                
                if shift_count > 0 and first_start and last_end:
                    start_time = _extract_time_hhmm(first_start)
                    end_time = _extract_time_hhmm(last_end)
                    
                    # Usa il primo ID come riferimento (o tutti se multipli)
                    planning_id = planning_ids.split(",")[0] if planning_ids else None
                    
                    app.logger.info(
                        f"Turni Rentman trovati per {username} (crew_id={crew_id}) il {date_str}: "
                        f"{shift_count} turni, intervallo {start_time}-{end_time}"
                    )
                    
                    return {
                        "source": "rentman",
                        "planning_id": planning_id,
                        "start_time": start_time,
                        "end_time": end_time,
                        "shift_count": shift_count
                    }
        except Exception as e:
            app.logger.warning(f"Errore ricerca turni Rentman: {e}")
    
    # 2. Cerca nei turni employee_shifts (per impiegati senza Rentman)
    try:
        # Trova il giorno della settimana dalla data
        from datetime import datetime as dt
        date_obj = dt.strptime(date_str, "%Y-%m-%d")
        day_of_week = date_obj.weekday()  # 0=Lunedì, 6=Domenica
        
        employee_agg = db.execute(f"""
            SELECT COUNT(*) as shift_count,
                   MIN(start_time) as first_start,
                   MAX(end_time) as last_end,
                   GROUP_CONCAT(id) as shift_ids
            FROM employee_shifts 
            WHERE username = {placeholder} AND day_of_week = {placeholder} AND is_active = 1
        """, (username, day_of_week)).fetchone()
        
        if employee_agg:
            if isinstance(employee_agg, Mapping):
                shift_count = employee_agg.get("shift_count", 0)
                first_start = employee_agg.get("first_start")
                last_end = employee_agg.get("last_end")
                shift_ids = employee_agg.get("shift_ids")
            else:
                shift_count = employee_agg[0] or 0
                first_start = employee_agg[1]
                last_end = employee_agg[2]
                shift_ids = employee_agg[3]
            
            if shift_count > 0 and first_start and last_end:
                start_time = _extract_time_hhmm(first_start)
                end_time = _extract_time_hhmm(last_end)
                
                planning_id = shift_ids.split(",")[0] if shift_ids else None
                
                app.logger.info(
                    f"Turni impiegato trovati per {username} il {date_str} (giorno {day_of_week}): "
                    f"{shift_count} turni, intervallo {start_time}-{end_time}"
                )
                
                return {
                    "source": "employee_shifts",
                    "planning_id": planning_id,
                    "start_time": start_time,
                    "end_time": end_time,
                    "shift_count": shift_count
                }
    except Exception as e:
        app.logger.debug(f"Tabella employee_shifts non trovata o errore: {e}")
    
    app.logger.info(f"Nessun turno pianificato trovato per {username} il {date_str}")
    return None


def _send_overtime_notification_to_admins(db, username: str, date: str, minutes: int):
    """Invia notifica push agli admin per nuova richiesta Extra Turno."""
    try:
        hours = minutes // 60
        mins = minutes % 60
        time_str = f"{hours}h {mins}m" if hours > 0 else f"{mins} minuti"
        
        # Trova tutti gli admin
        if DB_VENDOR == "mysql":
            admins = db.execute("SELECT username FROM users WHERE is_admin = 1").fetchall()
        else:
            admins = db.execute("SELECT username FROM users WHERE is_admin = 1").fetchall()
        
        for admin in admins:
            admin_username = admin[0] if not isinstance(admin, Mapping) else admin.get("username")
            try:
                send_push_notification(
                    db,
                    admin_username,
                    "⏰ Nuova Richiesta Extra Turno",
                    f"{username} ha richiesto {time_str} di Extra Turno per {date}",
                    url="/admin/overtime",
                    tag=f"overtime-request-{username}-{date}"
                )
            except Exception as e:
                app.logger.warning(f"Errore invio notifica admin {admin_username}: {e}")
    except Exception as e:
        app.logger.error(f"Errore invio notifiche Extra Turno agli admin: {e}")


def _send_overtime_review_notification(db, username: str, date: str, minutes: int, status: str, notes: str):
    """Invia notifica push all'utente per esito richiesta Extra Turno."""
    try:
        hours = minutes // 60
        mins = minutes % 60
        time_str = f"{hours}h {mins}m" if hours > 0 else f"{mins} minuti"
        
        if status == "approved":
            title = "✅ Extra Turno Approvato"
            body = f"Il tuo Extra Turno di {time_str} del {date} è stato approvato"
        else:
            title = "❌ Extra Turno Rifiutato"
            body = f"Il tuo Extra Turno di {time_str} del {date} è stato rifiutato"
        
        if notes:
            body += f". Note: {notes}"
        
        send_push_notification(
            db,
            username,
            title,
            body,
            url="/user/requests",
            tag=f"overtime-review-{date}"
        )
        
        # Salva nel log notifiche
        now_ts = int(time.time() * 1000)
        if DB_VENDOR == "mysql":
            db.execute("""
                INSERT INTO push_notifications_log 
                (username, title, body, url, tag, sent_ts, event_type)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """, (username, title, body, "/user/requests", f"overtime-review-{date}", now_ts, "overtime_review"))
        else:
            db.execute("""
                INSERT INTO push_notifications_log 
                (username, title, body, url, tag, sent_ts, event_type)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (username, title, body, "/user/requests", f"overtime-review-{date}", now_ts, "overtime_review"))
        db.commit()
        
        app.logger.info(f"Notifica revisione Extra Turno inviata a {username}")
    except Exception as e:
        app.logger.error(f"Errore invio notifica revisione Extra Turno: {e}")


# ─────────────────────────────────────────────────────────────────────────────
# HR / Payroll Dashboard  (admin-only)
# ─────────────────────────────────────────────────────────────────────────────

@app.get("/admin/payroll")
@login_required
def admin_payroll_page() -> ResponseReturnValue:
    """Pagina Dashboard HR / Payroll — solo admin."""
    if not is_admin_only():
        abort(403)
    return render_template("admin_payroll.html")


@app.get("/api/admin/payroll-dashboard", endpoint="api_admin_payroll_dashboard")
@login_required
def api_admin_payroll_dashboard() -> ResponseReturnValue:
    """API aggregata per la dashboard HR/Payroll — v2 professionale.

    Query params:
        month (int) – mese 1-12
        year  (int) – anno
        group (str) – id gruppo (opzionale)
    """
    if not is_admin_only():
        return jsonify({"error": "forbidden"}), 403

    from collections import defaultdict

    month = _coerce_int(request.args.get("month")) or datetime.now().month
    year = _coerce_int(request.args.get("year")) or datetime.now().year
    group_filter = request.args.get("group") or None

    db = get_db()
    ph = "%s" if DB_VENDOR == "mysql" else "?"

    # ── Date ranges (current + previous month for comparison) ──
    first_day = datetime(year, month, 1).date()
    if month == 12:
        last_day = datetime(year + 1, 1, 1).date() - timedelta(days=1)
    else:
        last_day = datetime(year, month + 1, 1).date() - timedelta(days=1)

    # Previous month
    if month == 1:
        prev_month, prev_year = 12, year - 1
    else:
        prev_month, prev_year = month - 1, year
    prev_first = datetime(prev_year, prev_month, 1).date()
    if prev_month == 12:
        prev_last = datetime(prev_year + 1, 1, 1).date() - timedelta(days=1)
    else:
        prev_last = datetime(prev_year, prev_month + 1, 1).date() - timedelta(days=1)

    first_day_str = first_day.isoformat()
    last_day_str = last_day.isoformat()
    prev_first_str = prev_first.isoformat()
    prev_last_str = prev_last.isoformat()

    # Count business days in current month
    _bd = first_day
    business_days_in_month = 0
    while _bd <= last_day:
        if _bd.weekday() < 5:
            business_days_in_month += 1
        _bd += timedelta(days=1)

    # ── Employees ──
    if group_filter:
        users_rows = db.execute(
            f"SELECT username, display_name, full_name, group_id FROM app_users WHERE role != 'admin' AND is_active = 1 AND group_id = {ph}",
            (group_filter,)
        ).fetchall()
    else:
        users_rows = db.execute(
            "SELECT username, display_name, full_name, group_id FROM app_users WHERE role != 'admin' AND is_active = 1 ORDER BY display_name"
        ).fetchall()

    total_employees = len(users_rows)
    username_set = {u["username"] for u in users_rows}
    username_display = {u["username"]: (u["display_name"] or u["full_name"] or u["username"]) for u in users_rows}

    # Headcount by group
    headcount_by_group: Dict[str, int] = defaultdict(int)
    try:
        all_groups_rows = db.execute("SELECT id, name FROM user_groups ORDER BY name").fetchall()
        group_names = {str(g["id"]): g["name"] for g in all_groups_rows}
    except Exception:
        group_names = {}

    for u in users_rows:
        gid = str(u["group_id"]) if u["group_id"] else "no_group"
        gname = group_names.get(gid, "Senza gruppo")
        headcount_by_group[gname] += 1

    # ── 1. Richieste (user_requests + request_types) — current + previous month ──
    def _fetch_requests(d_start: str, d_end: str):
        try:
            sql = f"""
                SELECT ur.id, ur.username, ur.request_type_id, ur.date_from, ur.date_to,
                       ur.value_amount, ur.notes, ur.status, ur.created_ts,
                       rt.name AS type_name, rt.value_type, rt.abbreviation
                FROM user_requests ur
                JOIN request_types rt ON ur.request_type_id = rt.id
                WHERE ur.date_from <= {ph} AND (ur.date_to >= {ph} OR ur.date_to IS NULL AND ur.date_from >= {ph})
                ORDER BY ur.created_ts DESC
            """
            rows = db.execute(sql, (d_end, d_start, d_start)).fetchall()
            if group_filter:
                rows = [r for r in rows if r["username"] in username_set]
            return rows
        except Exception as e:
            app.logger.error(f"Payroll dashboard - errore query richieste: {e}")
            return []

    req_rows = _fetch_requests(first_day_str, last_day_str)
    prev_req_rows = _fetch_requests(prev_first_str, prev_last_str)

    # Helper: parse date from row
    def _parse_date(val, fallback):
        if isinstance(val, str):
            try: return datetime.strptime(val, "%Y-%m-%d").date()
            except: return fallback
        if hasattr(val, 'date'):
            return val.date()
        return val if hasattr(val, 'isoformat') else fallback

    # Helper: compute request aggregates
    def _aggregate_requests(rows, fd, ld):
        _type_stats: Dict[str, Dict[str, int]] = {}
        _status_summary = {"approved": 0, "pending": 0, "rejected": 0}
        _absence_map: Dict[str, int] = {}
        _overtime_mins = 0
        _ot_by_week: Dict[int, int] = {}
        _sick_days = 0
        _absent_users: Dict[str, int] = defaultdict(int)  # username -> absence days

        for r in rows:
            tname = r["type_name"] or "Altro"
            st = r["status"] or "pending"
            if tname not in _type_stats:
                _type_stats[tname] = {"approved": 0, "pending": 0, "rejected": 0}
            if st in _type_stats[tname]:
                _type_stats[tname][st] += 1
            if st in _status_summary:
                _status_summary[st] += 1

            if st == "approved":
                tname_lower = tname.lower()
                is_absence = any(kw in tname_lower for kw in [
                    "feri", "permess", "malatt", "rol", "congedo",
                    "aspettativa", "infortunio", "lutto"
                ])
                if is_absence:
                    d_from = _parse_date(r["date_from"], fd)
                    d_to = _parse_date(r["date_to"] or r["date_from"], fd)
                    eff_from = max(d_from, fd)
                    eff_to = min(d_to, ld)
                    n_days = max(0, (eff_to - eff_from).days + 1)
                    _absence_map[tname] = _absence_map.get(tname, 0) + n_days
                    _absent_users[r["username"]] += n_days
                    if "malatt" in tname_lower or "infortunio" in tname_lower:
                        _sick_days += n_days

                if "extra" in tname_lower or "straordinari" in tname_lower:
                    minutes = int(float(r["value_amount"] or 0))
                    _overtime_mins += minutes
                    d_from = _parse_date(r["date_from"], fd)
                    if hasattr(d_from, 'isocalendar'):
                        wk = d_from.isocalendar()[1]
                        _ot_by_week[wk] = _ot_by_week.get(wk, 0) + minutes

        return {
            "type_stats": _type_stats,
            "status_summary": _status_summary,
            "absence_map": _absence_map,
            "overtime_minutes": _overtime_mins,
            "ot_by_week": _ot_by_week,
            "sick_days": _sick_days,
            "absent_users": dict(_absent_users),
        }

    curr_agg = _aggregate_requests(req_rows, first_day, last_day)
    prev_agg = _aggregate_requests(prev_req_rows, prev_first, prev_last)

    requests_by_type = [
        {"type_name": k, "approved": v["approved"], "pending": v["pending"], "rejected": v["rejected"]}
        for k, v in sorted(curr_agg["type_stats"].items(), key=lambda x: -(x[1]["approved"] + x[1]["pending"] + x[1]["rejected"]))
    ]

    total_absence_days = sum(curr_agg["absence_map"].values())
    prev_absence_days = sum(prev_agg["absence_map"].values())
    total_overtime_minutes = curr_agg["overtime_minutes"]
    prev_overtime_minutes = prev_agg["overtime_minutes"]
    total_sick_days = curr_agg["sick_days"]

    absence_breakdown = [
        {"type": k, "days": v}
        for k, v in sorted(curr_agg["absence_map"].items(), key=lambda x: -x[1])
    ]

    overtime_weeks = [
        {"label": f"Sett. {wk}", "minutes": curr_agg["ot_by_week"][wk]}
        for wk in sorted(curr_agg["ot_by_week"].keys())
    ]

    # ── 2. Ritardi + turni ──
    total_late_count = 0
    prev_late_count = 0
    shifts_map: Dict[str, Dict[int, str]] = {}
    late_tolerance = 5
    late_employees: Dict[str, int] = defaultdict(int)  # username -> count

    try:
        shifts_rows = db.execute(
            "SELECT username, day_of_week, start_time FROM employee_shifts WHERE is_active = 1"
        ).fetchall()
        for sr in shifts_rows:
            u = sr["username"]
            if u not in shifts_map:
                shifts_map[u] = {}
            shifts_map[u][sr["day_of_week"]] = str(sr["start_time"])[:5] if sr["start_time"] else None

        try:
            rules_row = db.execute("SELECT tolleranza_ritardo_minuti FROM timbratura_rules LIMIT 1").fetchone()
            late_tolerance = int(rules_row["tolleranza_ritardo_minuti"]) if rules_row else 5
        except Exception:
            late_tolerance = 5

        def _count_lates(d_start, d_end):
            _rows = db.execute(
                f"SELECT username, data, ora FROM timbrature WHERE tipo = 'inizio_giornata' AND data >= {ph} AND data <= {ph}",
                (d_start, d_end)
            ).fetchall()
            _count = 0
            _late_map: Dict[str, int] = defaultdict(int)
            for t in _rows:
                uname = t["username"]
                if group_filter and uname not in username_set:
                    continue
                t_data = _parse_date(t["data"], first_day)
                t_ora = str(t["ora"])[:5] if t["ora"] else None
                if not t_ora or not hasattr(t_data, 'weekday'):
                    continue
                dow = t_data.weekday()
                shift_start = shifts_map.get(uname, {}).get(dow)
                if not shift_start:
                    continue
                try:
                    sh_h, sh_m = map(int, shift_start.split(":"))
                    tb_h, tb_m = map(int, t_ora.split(":"))
                    if (tb_h * 60 + tb_m) - (sh_h * 60 + sh_m) > late_tolerance:
                        _count += 1
                        _late_map[uname] += 1
                except Exception:
                    continue
            return _count, dict(_late_map)

        total_late_count, late_employees = _count_lates(first_day_str, last_day_str)
        prev_late_count, _ = _count_lates(prev_first_str, prev_last_str)
    except Exception as e:
        app.logger.error(f"Payroll dashboard - errore ritardi: {e}")

    # ── 3. Ore lavorate per dipendente ──
    employee_hours: Dict[str, Dict[str, int]] = {}  # username -> {worked_minutes, overtime_minutes, days_worked}

    def _calc_worked_hours(d_start, d_end):
        _eh: Dict[str, Dict[str, int]] = {}
        try:
            timb_work_rows = db.execute(
                f"""
                SELECT username, data, tipo, ora FROM timbrature
                WHERE data >= {ph} AND data <= {ph}
                  AND tipo IN ('inizio_giornata', 'fine_giornata')
                ORDER BY username, data, ora
                """,
                (d_start, d_end)
            ).fetchall()

            _timb_grouped: Dict[tuple, Dict[str, list]] = defaultdict(lambda: {"inizio_giornata": [], "fine_giornata": []})
            for tw in timb_work_rows:
                u = tw["username"]
                if group_filter and u not in username_set:
                    continue
                d = str(tw["data"])
                tipo = tw["tipo"]
                ora = str(tw["ora"])[:8] if tw["ora"] else None
                if ora:
                    _timb_grouped[(u, d)][tipo].append(ora)

            for (u, d), times in _timb_grouped.items():
                starts = times["inizio_giornata"]
                ends = times["fine_giornata"]
                if starts and ends:
                    try:
                        first_start = min(starts)
                        last_end = max(ends)
                        sh, sm, ss = map(int, first_start.split(":"))
                        eh, em, es = map(int, last_end.split(":"))
                        mins = (eh * 60 + em) - (sh * 60 + sm)
                        if mins > 0:
                            if u not in _eh:
                                _eh[u] = {"worked_minutes": 0, "overtime_minutes": 0, "days_worked": 0}
                            _eh[u]["worked_minutes"] += mins
                            _eh[u]["days_worked"] += 1
                    except Exception:
                        pass
        except Exception as e:
            app.logger.error(f"Payroll dashboard - errore ore: {e}")
        return _eh

    employee_hours = _calc_worked_hours(first_day_str, last_day_str)
    prev_employee_hours = _calc_worked_hours(prev_first_str, prev_last_str)
    missed_clocks_map: Dict[str, int] = {}

    # Conta le richieste "Mancata Timbratura" da user_requests
    # (ogni richiesta = un evento di mancata timbratura, indipendentemente dallo stato)
    for r in req_rows:
        tname = (r["type_name"] or "").strip()
        if "mancata" in tname.lower() and "timbratura" in tname.lower():
            u = r["username"]
            if group_filter and u not in username_set:
                continue
            missed_clocks_map[u] = missed_clocks_map.get(u, 0) + 1

    # Add overtime per employee
    for r in req_rows:
        if r["status"] == "approved":
            tname_lower = (r["type_name"] or "").lower()
            if "extra" in tname_lower or "straordinari" in tname_lower:
                u = r["username"]
                mins = int(float(r["value_amount"] or 0))
                if u not in employee_hours:
                    employee_hours[u] = {"worked_minutes": 0, "overtime_minutes": 0, "days_worked": 0}
                employee_hours[u]["overtime_minutes"] += mins

    # Build employee hours list with additional metrics
    emp_hours_list = []
    for u, data_ in employee_hours.items():
        avg_daily = round(data_["worked_minutes"] / data_["days_worked"]) if data_["days_worked"] > 0 else 0
        emp_hours_list.append({
            "username": u,
            "name": username_display.get(u, u),
            "worked_minutes": data_["worked_minutes"],
            "overtime_minutes": data_["overtime_minutes"],
            "days_worked": data_["days_worked"],
            "avg_daily_minutes": avg_daily,
            "late_count": late_employees.get(u, 0),
            "absence_days": curr_agg["absent_users"].get(u, 0),
            "missed_clocks": missed_clocks_map.get(u, 0),
        })
    emp_hours_list.sort(key=lambda x: -(x["worked_minutes"] + x["overtime_minutes"]))

    total_worked_minutes = sum(e["worked_minutes"] for e in emp_hours_list)
    prev_worked_minutes = sum(v["worked_minutes"] for v in prev_employee_hours.values())

    # Avg hours per employee per day
    total_days_worked_all = sum(e["days_worked"] for e in emp_hours_list)
    avg_hours_per_day = round(total_worked_minutes / total_days_worked_all / 60, 1) if total_days_worked_all > 0 else 0

    # ── 4. Presenze giornaliere ──
    daily_presences = []
    total_work_days = 0
    users_worked_set: set = set()

    try:
        timb_daily = db.execute(
            f"""
            SELECT data, username, MIN(ora) AS first_clock
            FROM timbrature
            WHERE tipo = 'inizio_giornata' AND data >= {ph} AND data <= {ph}
            GROUP BY data, username
            ORDER BY data
            """,
            (first_day_str, last_day_str)
        ).fetchall()

        day_data: Dict[str, Dict[str, Any]] = {}
        for row in timb_daily:
            d_str = str(row["data"])
            u = row["username"]
            if group_filter and u not in username_set:
                continue
            if d_str not in day_data:
                day_data[d_str] = {"present": set(), "late": set()}
            day_data[d_str]["present"].add(u)
            users_worked_set.add(u)

            first_clock = str(row["first_clock"])[:5] if row["first_clock"] else None
            if first_clock and u in shifts_map:
                t_data_parsed = _parse_date(d_str, first_day)
                if hasattr(t_data_parsed, 'weekday'):
                    dow = t_data_parsed.weekday()
                    shift_start = shifts_map.get(u, {}).get(dow)
                    if shift_start:
                        try:
                            sh_h, sh_m = map(int, shift_start.split(":"))
                            tb_h, tb_m = map(int, first_clock.split(":"))
                            if (tb_h * 60 + tb_m) - (sh_h * 60 + sh_m) > late_tolerance:
                                day_data[d_str]["late"].add(u)
                        except:
                            pass

        total_work_days = sum(1 for d in day_data.values() if d["present"])

        cur_d = first_day
        while cur_d <= last_day:
            d_str = cur_d.isoformat()
            weekday = cur_d.weekday()
            if weekday < 5 or d_str in day_data:
                dd = day_data.get(d_str, {"present": set(), "late": set()})
                n_present = len(dd["present"])
                n_late = len(dd["late"])
                n_absent = max(0, total_employees - n_present) if weekday < 5 else 0
                daily_presences.append({
                    "date": d_str,
                    "label": cur_d.strftime("%d/%m"),
                    "present": n_present,
                    "absent": n_absent,
                    "late": n_late,
                    "weekday": weekday,
                })
            cur_d += timedelta(days=1)
    except Exception as e:
        app.logger.error(f"Payroll dashboard - errore presenze giornaliere: {e}")

    # ── 5. KPI calcolati (rates) ──
    # Absenteeism rate = (absence days / (employees * business days)) * 100
    potential_days = total_employees * business_days_in_month
    absenteeism_rate = round((total_absence_days / potential_days) * 100, 1) if potential_days > 0 else 0
    prev_potential = total_employees * max(1, sum(1 for i in range((prev_last - prev_first).days + 1) if (prev_first + timedelta(days=i)).weekday() < 5))
    prev_absenteeism = round((prev_absence_days / prev_potential) * 100, 1) if prev_potential > 0 else 0

    # Punctuality rate
    total_clock_ins = sum(len(dd.get("present", set())) for dd in day_data.values()) if 'day_data' in dir() else 0
    punctuality_rate = round(((total_clock_ins - total_late_count) / total_clock_ins) * 100, 1) if total_clock_ins > 0 else 100

    # Sick days per employee
    avg_sick_days = round(total_sick_days / total_employees, 1) if total_employees > 0 else 0

    # ── 6. Monthly trend (last 6 months) ──
    monthly_trend = []
    try:
        for i in range(5, -1, -1):
            _m = month - i
            _y = year
            while _m < 1:
                _m += 12
                _y -= 1
            _fd = datetime(_y, _m, 1).date()
            if _m == 12:
                _ld = datetime(_y + 1, 1, 1).date() - timedelta(days=1)
            else:
                _ld = datetime(_y, _m + 1, 1).date() - timedelta(days=1)

            _cnt = db.execute(
                f"SELECT COUNT(DISTINCT username) AS c FROM timbrature WHERE tipo='inizio_giornata' AND data >= {ph} AND data <= {ph}",
                (_fd.isoformat(), _ld.isoformat())
            ).fetchone()
            _pres = int(_cnt["c"]) if _cnt else 0

            _late = db.execute(
                f"SELECT COUNT(*) AS c FROM timbrature WHERE tipo='inizio_giornata' AND data >= {ph} AND data <= {ph}",
                (_fd.isoformat(), _ld.isoformat())
            ).fetchone()
            _total_clocks = int(_late["c"]) if _late else 0

            _month_names_it = ["Gen", "Feb", "Mar", "Apr", "Mag", "Giu", "Lug", "Ago", "Set", "Ott", "Nov", "Dic"]
            monthly_trend.append({
                "label": f"{_month_names_it[_m - 1]} {_y}",
                "active_employees": _pres,
                "clock_ins": _total_clocks,
            })
    except Exception as e:
        app.logger.error(f"Payroll dashboard - errore trend mensile: {e}")

    # ── 7. Top richieste recenti ──
    recent_requests = []
    for r in req_rows[:30]:
        vt = r["value_type"] or "hours"
        val = float(r["value_amount"] or 0)
        if vt == "hours":
            val_display = f"{val:.1f}h"
        elif vt == "days":
            val_display = f"{int(val)}g"
        elif vt == "minutes":
            val_display = f"{int(val)}min"
        elif vt == "km":
            val_display = f"{val:.1f}km"
        elif vt == "amount":
            val_display = f"€{val:.2f}"
        else:
            val_display = str(val)

        d_from = r["date_from"]
        if hasattr(d_from, 'strftime'):
            d_from = d_from.strftime("%d/%m/%Y")

        recent_requests.append({
            "employee": username_display.get(r["username"], r["username"]),
            "type_name": r["type_name"] or "—",
            "date_from": d_from or "—",
            "value_display": val_display,
            "status": r["status"] or "pending",
            "notes": r["notes"] or "",
        })

    # ── 8. Top ritardatari ──
    top_late = sorted(
        [{"name": username_display.get(u, u), "count": c} for u, c in late_employees.items()],
        key=lambda x: -x["count"]
    )[:10]

    # ── Response ──
    return jsonify({
        "ok": True,
        "month": month,
        "year": year,
        # Core KPIs
        "total_employees": total_employees,
        "total_work_days": total_work_days,
        "total_worked_minutes": total_worked_minutes,
        "total_overtime_minutes": total_overtime_minutes,
        "total_absence_days": total_absence_days,
        "total_late_count": total_late_count,
        "total_sick_days": total_sick_days,
        # Rates
        "absenteeism_rate": absenteeism_rate,
        "punctuality_rate": punctuality_rate,
        "avg_sick_days_per_employee": avg_sick_days,
        "avg_hours_per_day": avg_hours_per_day,
        "business_days_in_month": business_days_in_month,
        # Deltas (previous month comparison)
        "prev_month": {"month": prev_month, "year": prev_year},
        "delta": {
            "worked_minutes": total_worked_minutes - prev_worked_minutes,
            "overtime_minutes": total_overtime_minutes - prev_overtime_minutes,
            "absence_days": total_absence_days - prev_absence_days,
            "late_count": total_late_count - prev_late_count,
            "absenteeism_rate": round(absenteeism_rate - prev_absenteeism, 1),
        },
        # Breakdowns
        "requests_by_type": requests_by_type,
        "request_status_summary": curr_agg["status_summary"],
        "overtime_by_week": overtime_weeks,
        "absence_breakdown": absence_breakdown,
        "headcount_by_group": [{"group": k, "count": v} for k, v in sorted(headcount_by_group.items(), key=lambda x: -x[1])],
        # Details
        "employee_hours": emp_hours_list[:25],
        "daily_presences": daily_presences,
        "recent_requests": recent_requests,
        "top_late_employees": top_late,
        "monthly_trend": monthly_trend,
    })


if __name__ == "__main__":
    init_db()
    
    # HTTPS per permettere accesso camera da mobile in rete locale
    # Usa: python app.py --https
    import sys
    if "--https" in sys.argv:
        print("🔐 Avvio in modalità HTTPS (per accesso camera da mobile)")
        print("⚠️  Il browser mostrerà un avviso di sicurezza - clicca 'Avanzate' → 'Procedi'")
        app.run(host="0.0.0.0", port=5000, debug=True, use_reloader=False, ssl_context='adhoc')
    else:
        app.run(host="0.0.0.0", port=5000, debug=True, use_reloader=False)
